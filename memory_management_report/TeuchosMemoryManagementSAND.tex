\documentclass[pdf,ps2pdf,11pt]{SANDreport}
\usepackage{pslatex}
%Local stuff
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{color}
\usepackage[all]{draftcopy}
\input{rab_commands}
\setcounter{tocdepth}{3}
\newtheorem{listing}{Listing}
\usepackage{hyperref}

\newtheorem{commandment}{Commandment}
\newtheorem{anticommandment}{Anti-Commandment}

\raggedright

% If you want to relax some of the SAND98-0730 requirements, use the "relax"
% option. It adds spaces and boldface in the table of contents, and does not
% force the page layout sizes.
% e.g. \documentclass[relax,12pt]{SANDreport}
%
% You can also use the "strict" option, which applies even more of the
% SAND98-0730 guidelines. It gets rid of section numbers which are often
% useful; e.g. \documentclass[strict]{SANDreport}

% ---------------------------------------------------------------------------- %
%
% Set the title, author, and date
%

\title{\center
Teuchos Memory Management Classes for C++ \\[2ex] A Comprehensive
Strategy for Safe and Efficient Memory Management in C++ for High
Performance Computing }

\author{
Roscoe Bartlett
}

\date{}

%Sandia National
%Laboratories\footnote{ Sandia is a multiprogram laboratory operated by Sandia
%Corporation, a Lockheed-Martin Company, for the United States Department of
%Energy under Contract DE-AC04-94AL85000.}, Albuquerque NM 87185 USA


% ---------------------------------------------------------------------------- %
% Set some things we need for SAND reports. These are mandatory
%
\SANDnum{SAND2010-xxx}
\SANDprintDate{January 2010}
\SANDauthor{
Roscoe Bartlett
}

% ---------------------------------------------------------------------------- %
% Build your markings. See example files and SAND Report Guide
%

\SANDreleaseType{Unlimited Release}
%\SANDreleaseType{Not approved for general release}
%\SANDmarkTopBottomCoverBackTitle{}
%\SANDmarkBottomCover{}
%\SANDmarkTopBottomCoverTitle{}
%\SANDmarkTop{}
%\SANDmarkBottom{}
%\SANDmarkTopBottom{}
%\SANDmarkCover{}
%\SANDmarkCoverTitle{}


% ---------------------------------------------------------------------------- %
%
% Start the document
%

\begin{document}

\maketitle


% ------------------------------------------------------------------------ %
% An Abstract is required for SAND reports
%

%\clearpage

%
\begin{abstract}
%


The ubiquitous use raw pointers in higher-level code is the primary
cause of all memory usage problems and memory leaks in C++
programs. This paper describes what might be considered a radical
approach to the problem which is to eliminate the use of all raw
pointers and all raw calls to {}\ttt{new} and {}\ttt{delete} in
higher-level C++ code.  Instead, a set of cooperating concrete
template classes developed in the Trilinos package Teuchos are used to
replace every use of raw C++ pointers in every use case where it
appears in high-level code.  Included in the set of memory management
classes is teh typical reference-counted smart pointer class similar
to {}\ttt{boost::shared\_ptr} (and therefore C++0x
{}\ttt{std::shared\_ptr}).  However, what is missing in boost and the
new standard library are non-reference counted classes for remaining
use cases where raw C++ pointers would need to be used.  These classes
have a debug build mode where nearly all programmer error are caught
and gracefully reported at runtime.  The default optimized build mode
strips all runtime checks and allows the code to perform as
efficiently as raw C++ pointers with reasonable usage.  Also included
is a novel approach for dealing with the circular references problem
that imparts little extra overhead and is almost completely invisible
to most of the code (unlike the boost and therefore C++0x approach).
Rather than being a radical approach, encapsulating all raw C++
pointers is simply the logical progression of a trend in the C++
development and standards community that started with
{}\ttt{std::auto\_ptr} and is continued (but not finished) with
{}\ttt{std::shared\_ptr} in C++0x.

%
\end{abstract}
%

% ------------------------------------------------------------------------ %
% An Acknowledgement section is optional but important, if someone made
% contributions or helped beyond the normal part of a work assignment.
% Use \section* since we don't want it in the table of context
%
%\clearpage
%\section*{Acknowledgment}
%
%
%The format of this report is based on information found
%in~\cite{Sand98-0730}.

% ------------------------------------------------------------------------ %
% The table of contents and list of figures and tables
% Comment out \listoffigures and \listoftables if there are no
% figures or tables. Make sure this starts on an odd numbered page
%
\cleardoublepage   % TOC needs to start on an odd page
\tableofcontents
\listoffigures
\listoftables

% ---------------------------------------------------------------------- %
% An optional preface or Foreword
%\clearpage
%\section{Preface}
%Although muggles usually have only limited experience with
%magic, and many even dispute its existence, it is worthwhile
%to be open minded and explore the possibilities.

% ---------------------------------------------------------------------- %
% An optional glossary. We don't want it to be numbered
%\clearpage
%\subsection*{Nomenclature}
%\addcontentsline{toc}{section}{Nomenclature}
%\begin{itemize}
%\item[alohomora]
%spell to open locked doors and containers
%\end{itemize}

% ---------------------------------------------------------------------- %
% This is where the body of the report begins; usually with an Introduction
%

\SANDmain % Start the main part of the report


%
\section{Introduction}
%

ToDo: Remove all references to 'you' and replace with 'one' or more
generic.

ToDo: Replace all references to 'we' and 'I' and make more generic.

ToDo: Look for 'where' when it should be 'were'.

ToDo: Spell check all attached tables, etc.

A critical problem in computational science and engineering (CS\&E)
software as well as in other types of software developed in C++ is in
the effective and safe management of memory and data.  CS\&E software
often has the goal of high performance where arbitrary data copy leads
to undo overhead and can actually complicate the software in many
cases.  It is common for CS\&E software to share and pass around large
blocks of memory in order to do work efficiently (however, common
approaches such as described in
{}\cite{DataSharinginScientificSimulations} lead to many of the
problems that exist in CS\&E programs).  At the most basic level,
large arrays of integral and floating point data are managed along
with more complex general objects and arrays of objects.  In C++, the
only universally accepted way to deal with memory for single objects
and arrays of objects is to use raw C++ pointers.  However, raw C++
pointer facilities for the manipulation and sharing of basic memory
are inherently unsafe and error prone.  The problem is further
exacerbated when larger programs composed out of different separately
developed and maintained components are integrated together.
Assumptions about the origin, ownership, and process for reclaiming
memory and other resources remain the most basic problems with
lower-level C++ programming techniques and are unfortunately still
ubiquitous in the C++ community and even in the current C++
best-practices literature {}\cite{C++CodingStandards05,
EffectiveC++ThirdEdition}.  Our inability to effectively address the
basic problem of the usage of memory in large-scale modular C++ codes
affects every aspect of software quality, productivity and
reusabliltiy, and undermines the most basic software verification
foundation for our codes.  The challenges of writing software that
uses raw memory management result in components that are overly ridgid
in how they can be used and reused which fundamentally detacts for the
impact that such software could otherwise have.  The problems created
by the use of raw memory management can single-handily derail the
vision of a large interconnected network of reusable CS\&E software
components developed and used by many different CS\&E organizations
{}\cite{HPCNeedsAToolsStrategy05}.  Therefore, the issue of memory
management has as much or more impact on the macroscopic properites of
our CS\&E software components as it does on low-level internal
software development.

C++ is an incredibility large and complex language that very few
people really know how to use in a confident and successful way.
Arguably the most serious problems in C++ are related to dynamic
memory management which must be used with any moderately complex
object-oriented program.  The built-in C++ support for dealing with
dynamic memory allocation with {}\ttt{new} and {}\ttt{delete} is
fundamentally incompatible with the built-in exception handling
mechanism using {}\ttt{try}, {}\ttt{throw}, and
{}\ttt{catch}.  One cannot effectively build large-scale integrated
software using just these low-level language features at the
application programming level.  Software developed this way segfaults
and leaks memory unpredictably and is nearly impossible to integrate
with other code.  The only successful way to use C++ to create complex
robust software is to develop and rigorously adopt a set of
programming idioms for safely dealing with memory.  By developing the
right support software and associated idioms, we make C++ programs
safer, better defined, faster to develop, and more efficient when run.

The reason that C++ is in this state of affairs is due to how C++ came
into being and how it evolved over many years {}\cite{stroustrup94,
stroustrup07}.  C++ was first developed in the early 1980s as an
extension to the popular C programming language and was first called
``C with Classes''.  At the time, high efficiency, very low runtime
overhead, and strong compatibility with C were critical requirements
to the success of the new language.  Without this, the original
creator of C++, Bjanre Stroustrup, concluded that C++ would be ``still
born'' {}\cite{stroustrup97}.  The first C++ compilers where little
more than preprocessors putting out C code on the backend which was
then compiled into executable binary code.

As the years went on, however, object-oriented programming was
refined, computers become faster with more memory, and it was realized
that more runtime support was required to enable more advanced usages
of C++.  As new features were added to C++ to support new programming
idioms, a strong need for backward compatibility constrained the
design of the language.  The most unfortunate example of this, which
was already mentioned, is the fundamental incompatibility of built-in
dynamic memory management (i.e.\ using
{}\ttt{new}/{}\ttt{delete}) and built-in exception handling
(i.e.\ using {}\ttt{try}/{}\ttt{throw}/{}\ttt{catch}) that
was added more than a decade later {}\cite{stroustrup94}.

Because of the way that C++ ``evolved'' along with a strong need for
backward compatibility, we have a language that is a disaster when
used in raw form on complex large-scale programs.  Many programming
teams have exploited this natural capability of C++ to create
travesties of software which in turn have dumbfounded many a C++
programmer (and entire teams) and have resulted in giving C++ a bad
name in the general software engineering community (see Section 6
``DDD Matters Today'' in {}\cite{DomainDrivenDesignQuickly} and ``The
Case of the Construction Blob'' in {}\cite[Chapter
9]{WorkingEffectivelyWithLegacyCode05} for a few examples).

More specifically, using low-level manual memory management (e.g.\
{}\ttt{new}/{}\ttt{delete}, raw pointers everywhere) at all
levels in C++ has resulted in several negative consequences in the
development of C++ (and C) software that other more modern languages
(e.g.\ Java and Python) have avoided:

\begin{itemize}

{}\item Programs that use raw memory management are more difficult to
write and debug because it is difficult to track down invalid memory
usage that results in segfaults, double deletes, and memory leaks.
(Also, memory checking tools like Valgrind and Purify do not catch
enough of these types of errors to adequately mitigate the problem.)

{}\item Programs that use raw memory management can have many
``hidden'' memory usage errors (i.e.\ undefiend behavior) that can
linger in the code for months or years which damage the most basic
foundations of software quality and verification.  Many of these
programs are ``ticking time bombs'' just ready to go off, sometimes
with disastrous consequences for users and developers alike.

{}\item Dealing with raw memory mangament at all levels consumes large
amounts of developer focus which detracts from more general design
focus.  This results in software with lower quality designs compared
to software written in other modern languages developed using the same
abount of effort.

{}\item Developers maintaining C++ programs that use raw memory
management typically have a high degree of paranoia and fear about
modifying the software (and for good reason because modifying such
software is dangerous and error prone).  This results in the tendency
to not refactor software as requirements and domain knowledge change
{}\cite{DomainDrivenDesign} which therefore results in software that
dies the slow painful death of software entropty
{}\cite{MythicalManMonth95}.

{}\item Software that uses raw memory management at all levels
necessarly have designs that overly constrain how the software is used
and reused.  For example, in such progorams factory objects typically
have to outlive the products they create and must also be responsible
for deleting the objects.  This results in large numbers of ``static''
factory objects that make the software hard to maintain and reuse in
reasonable contexts.

\end{itemize}

The consequences of raw memory management described above are all too
common in C++ development organizations and software produced by such
organizations.  This is why the general software development community
is largely moving away from C++ and instead moving to use more modern
languages that do not require manual unchecked memory management
{}\cite{DomainDrivenDesignQuickly}.

However, C++ has some unique features that differentiate it from every
other language in wide use:

\begin{itemize}

{}\item Strong typing (leads to high-performance code)

{}\item High-performance native code

{}\item Support for creating very efficient concrete data types with
efficiency on par with built-in data types that don't not require
dynamic memory management

{}\item Support for operator overloading

{}\item Support for object-oriented programming

{}\item Support for generic programming (i.e.\ templates)

{}\item Powerful turning-complete compile-time programming mechanism
(i.e.\ template meta-programming)

\end{itemize}

No other programming language with wide availability has this set of
features.  For instance, C++ can be used to create class libraries for
capabilities like automatic differentiation {}\cite{ref:ad} for
computing derivatives of functions (see the Trilinos
Sacado\footnote{\ttt{http://trilinos.sandia.gov/packages/sacado/}}
package {}\cite{phippsEtAl2006}) that achieves a level of generality
and efficiency that has no rival in a software library in any other
programming language.  It is precicely the above feature set along
with wide availability of high quality compilers on every major
platform (including the cutting-edge massively parallel computers),
good interoperability with other languges (through C
interoperability), and strong support for next generation
architectures {}\cite{DesignIssuesForMultiCore08} that makes C++ so
attractive for writing computational science \& engineering software
in the first place.

It is also this unique feature set that is C++'s saving grace with
respect memory management problems.  In C++, you can actually develop
a set of new data types that in essence can be used to develop new
programming environments in C++.  This essentially allows you to
define a new programming language within C++ with a level of
efficiency and flexibility that does not exist in any other
programming language.  This is exactly what this paper advocates with
respect to basic memory management in C++; developing a new
higher-level programming language in C++ for abstracting and
encapsulating all raw memory usage as well as dynamic memory
management that is very compatible with the built-in C++ exception
handling mechanism.

This paper describes a set of low-level C++ classes and supporting
software in the Teuchos package in
Trilinos\footnote{http://trilinos.sandia.gov} that is used to
encapsulate all raw pointers and enable strong debug runtime checking
while allowing for very high performance in optimized builds.

The Teuchos memory management classes and the idioms that they help to
define (which are described in this paper) do not remove the need for
programmers to learn and understand the intricate details of the C++
memory model and type system.  On the contrary, learning to
effectively use these memory management classes requires more effort
over just learning raw C++.  However, the payoff is that the programs
that result from the use of these classes and idioms will be more
likely to be correct on first writing, will be easier to debug when
there are defects, will be easier and safer to maintain, and will be
more self documenting (which helps all of the above).  In fact, the
self-documenting expressiveness of the resulting programs written
using these classes and idioms is unmatched in any other programming
language currently in popular use, including Java and Python.  This
statement will be backed up throughout this paper and then reiterated
in the final conclusions section.

The remainder of this paper assumes that the reader has some basic
knowledge of C++ and is somewhat familiar with smart reference-counted
pointer classes like {}\ttt{boost::shared\_ptr} (which is the basis
for the new C++0x {}\ttt{std::shared\_ptr} class).  The Teuchos
equivalent for these smart pointer classes is {}\ttt{Teuchos::RCP}
which we abbreviate as just {}\ttt{RCP} in sample code.  If the
reader is not familiar with the basics of smart reference-counted
pointer classes, then they should refer to
{}\cite{RefCountPtrBeginnersGuide} and {}\cite{C++CodingStandards05}.
If the reader is not familiar with fundamental C++ concepts like
implicit type conversions, templates, object lifetime models, raw
references and pointers and other basic topics, then some more basic
background will be needed.  However, specific references to basic C++
material in books like {}\cite{EffectiveC++ThirdEdition, stroustrup97,
C++CodingStandards05} are make throughout this document.  So if you
are a novice C++ programmer and are willing to look up the mentioned
references, then this paper can be a good guide to help you learn this
basic C++ material as well.

A final warning: the material in this paper is pretty detailed and
will take a significant investment in time and experience with writing
code with the Teuchos memory management classes using the idioms
describe here before a developer will be proficient.  It takes years
just to master raw C++ so it should be no surprise that learning a new
set of idioms to fix a large number of the problems with raw C++ will
also take a significant amount of time and effort.  What is needed is
a culture change in the C++ programming community where the memory
management classes and the idioms described here are taught at a very
early stage; much like the STL is now being taught in introductory C++
courses.  What we need is a revolution in C++ education but we have to
start somewhere and that is what this paper is all about, getting
started and on the road to a better generation of C++ programmers and
C++ software.

The reminder of this paper is organized as follows. The fundamental
problems with raw C++ pointers is described in Section
{}\ref{sec:problems-with-raw-pointers}.  Common (suboptimal)
approaches for addressing memory management problems are discussed in
Section {}\ref{sec:current-appraoches-to-mem-mng}.  Some important
prerequisite concepts like value-types verses references-types and
persisting verses non-persisting associations are defined in Section
{}\ref{sec:important-prerequisites}.  With all this background and
context in place, the Teuchos memory management classes are presented
in Section {}\ref{sec:teuchos-mem-mng-classes}.  The basic outline of
the approach in Section {}\ref{sec:overview_of_basic_approach} is
perhaps the first section one would jump to if they want to get a
quick idea what the Teuchos memory management classes are all about.
Finally, Taking a step back, a philosophical discussion of the
trade-offs between speed, safety and generality related to memory
management and the concepts of essential and accidental complexity are
discussed in Section {}\ref{sec:phylosophy-of-mem-mng}.  Concluding
remarks are given in Section {}\ref{sec:conclusions}.


%
{}\section{Fundamental problems with raw C++ pointers}
\label{sec:problems-with-raw-pointers}
%

In this section, I summarize some of the fundamental problems with
basic C++ features related to raw pointers.  What I am going to argue
is that while some people will claim that C++ pointers are strongly
typed, I will show that they are actually very weakly typed in many
respects and how this weak typing is the cause of many programming
errors that result in incorrect programs and segfaults.

In the following examples, I will use the simple classes shown in
Listing {}\ref{listing:Simple_A_B}:

\begin{listing}:\\
\label{listing:Simple_A_B}
{\small\begin{verbatim}
  class A {
  public:
    ...
    void incrementA() { ++(*char_ptr_); }
    ...
  private:
    char *char_ptr_;
  };

  class B : public A {
  public:
    ...
    void incrementB() { ++(*int_ptr_); }
    ...
  private:
    int size_;
    int *int_ptr_;
  };
\end{verbatim}}
\end{listing}

The concrete class hierarchy in Listing {}\ref{listing:Simple_A_B} was
chosen to demonstrate some insidious and perhaps less well known flaws
in the C++ type system when dealing with raw C++ pointers.


%
{}\subsection{Problems using raw C++ pointers for handling single objects}
%

There are a number of problems with using raw C++ pointers to manage
single objects.  For example, given a class of type {}\ttt{B} in
Listing {}\ref{listing:Simple_A_B} consider a pointer declared as:

{\small\begin{verbatim}
  B some_b(...);
  B *b_ptr = &some_b;
\end{verbatim}}

Some of the legitimate things that you can do with this pointer are:

{\small\begin{verbatim}
  // Call member functions
  b_ptr->incrementA();
  b_ptr->incrementB();
  // Extract reference
  B &b_ref = *b_ptr;
  // Copy pointer
  B *b_ptr2 = b_ptr;
  // Implicit conversion to const
  const B *b_ptr3 = b_ptr;
  // Implicit conversion to base type
  A *a_ptr4 = b_ptr;
\end{verbatim}}

However, nothing good can {}\underline{ever} come of any of the
following operations when a pointer is only pointing to a single
object:

{\small\begin{verbatim}
  b_ptr++
  b_ptr--
  ++b_ptr
  --b_ptr
  b_ptr+i
  b_ptr-i
  b_ptr[i]
\end{verbatim}}

No C++ compiler I have ever worked with will even issue a warning when
array operations are invoked on a raw C++ pointer for which it is
clear is only pointing to a single object.

The problem here of course is that there is no way to tell the C++
compiler that a raw pointer is only pointing to a single object.  With
respect to differentiating single objects and arrays of objects, C++
pointers are untyped and the compiler provides no help whatsoever in
statically asserting correct usage.  This is strike one for the
notation that C++ pointers being strongly typed!


%
{}\subsection{Problems using raw C++ pointers for handling arrays of
objects}
\label{sec:problem-with-raw-array-pointers}
%

When considering the semantics of raw C++ pointers one realizes that
raw pointers are really designed primarily for dealing with contiguous
arrays of objects (save for one exception that I mention below).  I
say this because almost every operation that C++ defined for raw
pointers makes sense and is fairly well defined when raw C++ pointers
are pointing with contiguous arrays of objects.  I will not review
every valid C++ operation for raw pointers to contiguous arrays of
objects (see {}\cite{stroustrup97} for a complete listing).  Instead,
I want to show a few examples where the C++ type system using raw
pointers falls flat on its face when dealing with arrays of memory.

One particularly troubling example where the C++ type system fails
when dealing with raw C++ pointers to contiguous arrays of memory is
shown in Listing {}\ref{listing:BadArrayPointerConversion}.

\begin{listing}:\\
\label{listing:BadArrayPointerConversion}
{\small\begin{verbatim}

  void foo( const int n )
  {
    B *b_array = new[n];
    ...
    A *a_array = b_array; // Compiles just fine :-(
    for (int i = 0; i < n; ++i) {
      a_array[i]->incrementA(); // KABOMMMMM!

    }
  }

\end{verbatim}}
\end{listing}

There are a lot of beginning and even some more experienced C++
programmers that would think that the C++ code in Listing
{}\ref{listing:BadArrayPointerConversion} is just fine.  I have seen
this mistake made more than once and the resulting program may seem to
run okay in some cases but in the above case will almost certainly
segfault right away.  The above code fragment is wrong, wrong, wrong
as described in {}\cite[Gotcha \#33]{C++Gotchas03} and {}\cite[Item
\#100]{C++CodingStandards05}.  I will not go into great detail about
what happens here, but converting from an array of type {}\ttt{B}
it a base of type {}\ttt{A} is almost always asking for disaster
because the alignment of the base type {}\ttt{A} will be wrong
according to the full type {}\ttt{B} (again see {}\cite[Gotcha
\#33]{C++Gotchas03} all the gory details).  As a result, for the
second iteration {}\ttt{i=1}, the embedded pointer in
{}\ttt{a\_array[1].char\_ptr\_} is pointing to garbage because on
most 32 bit machines with most compilers, the address in
{}\ttt{a\_array[1].char\_ptr\_} is actually the binary
representation of the integer {}\ttt{b\_array[0].size\_}.
Therefore, calling {}\ttt{a\_array[1]->increment()} on most 32 bit
machines is equivalent to performing:

{\small\begin{verbatim}
  ++(*reinterpret_cast<char*>(b_array[0].size_)); // KABOMMMMM!
\end{verbatim}}

If this sort of thing comes as a surprise to you, you should probably
fear using raw memory in C++ more than you currently do and you should
seriously consider the safer approach to encapsulating raw memory
usage that is being advocated in this paper.

So how did C++ come to allow such a completely wrong and dangerous
operation like shown in Listing
{}\ref{listing:BadArrayPointerConversion}?  It is because of the
untyped dual nature of raw C++ pointers in trying to handle both
single objects and contiguous arrays of objects with one set of what
should be non-overlapping semantics.  The ability to cast raw C++
pointers from derived types to base types only ever generally makes
sense when the pointer is pointing to a single object and will not be
interpreted as a pointer to a contiguous array of objects.  Note that
C does not have this problem since there is no such thing as type
derivation and the designers of C never even envisioned that raw C
pointers would be used for such a thing.  However, when the original
designer of C++ adopted the C type system along with raw pointers and
tried to apply it to an object-oriented language, he inadvertently
opened up a number of serious language gotchas that we are still
living with to this day.  This is strike two for the notation that C++
pointers are strongly typed!


%
{}\subsection{Problems with the incompatibility of
{}\ttt{new/delete} and {}\ttt{try/throw/catch}}
%

The use of raw pointers and raw calls to {}\ttt{new} and
{}\ttt{delete} is also fundamentally incompatible with the built-in
C++ exception handling mechanism using {}\ttt{try} and
{}\ttt{catch}.  For example, the following code will leak memory
if the function {}\ttt{someFunc()} throws a C++ exception:

{\small\begin{verbatim}
  void foo()
  {
    A *a = new A(...);
    someFunc(); // Could throw an exception
    delete a; // Will never be called if someFunc() throws!
  }
\end{verbatim}}

According to current C++ best practices relating to memory management
and exception handling as described in {}\cite[Item
{}\#29]{EffectiveC++ThirdEdition} and {}\cite[Item
{}\#71]{C++CodingStandards05}, code like shown above that leaks memory
is totally unacceptable in production quality C++ code.  This
fundamental incompatibility of the built-in C++ dynamic memory
management facilities using {}\ttt{new}/\ttt{delete} and the
built-in exception handling mechanism using
{}\ttt{try}/\ttt{catch} was clear even to the committee that
created the official C++ standard in 1998.  However, again, because of
the need for backward compatibility they were powerless to fix the
problem at the language level.  Instead, the C++ standards committee
included the first standard C++ smart pointer class;
{}\ttt{auto\_ptr}.  I will not go into the details about
{}\ttt{auto\_ptr} other than to say that is solved only the most
basic problem with raw C++ pointers and that is that it ensures that
memory will be reclaimed when exceptions are thrown.  For example, the
following rewritten function will not leak any memory when
{}\ttt{someFunc()} throws:

{\small\begin{verbatim}
  void foo()
  {
    std::auto_ptr<A> a(new A(...));
    someFunc(); // Could throw and exception
    // NOTE: delete will get called on the A object no matter how this
    // function exists (i.e. normal exit or with a throw) since it is
    // called by the destructor of the stack object 'a' of type
    // std::auto_ptr<A>. 
  }
\end{verbatim}}

The introduction of {}\ttt{std::auto\_ptr} is the first example
that I can think of where a user-defined type was added to the
standard C++ library in order to define an idiom meant to fix a
fundamental C++ language flaw.  Note that I said ``flaw'' and not
``deficiency''.  It is generally excepted in most modern programming
languages that the language proper will not support every programming
model or idiom that is of general interest and instead class libraries
are provided to fill the gaps.  The problem with C++ pointers is
different in that it is the language definition itself which is flawed
and is not just simply missing some desirable feature.  You could
argue that what C++ is really missing is garbage collection (GC) but
even that is not the case because to add GC would be fundamentally
incompatible with the current user-controlled memory management
facility using {}\ttt{new} and {}\ttt{delete}.  There is a lot
of C++ code out there that requires that destructors for objects be
called exactly when expected such as when {}\ttt{delete} is called.
Any form of language-supported GC will break some backward
compatibility of C++ and therefore we may never see a C++ standard
with full GC.

The boost library and the up-coming C++0x standard add more types that
I will mention below that continue in this trend of providing new
user-defined types and idioms to address fundamental C++ language
flaws and deficiencies.  However, as I describe in meat of this paper,
both the boost and the C++0x standard library fall short of providing
a complete and comprehensive solution to the problems with raw C++
pointers and raw access to memory.

Note that the upcoming C++0x standard as it is currently defined (at
least the time of this writing) will do nothing to fix the majority of
these nonsensical raw C++ pointer gotchas because to do so would
destroy backward compatibility of many millions of lines of existing
C++ code.  Because of the need for backward compatibility, we cannot
rely on any future C++ standard to fix the basic problems with raw C++
pointers.  Instead, the meat of this paper advocates using new C++
user-defined types to create a new safer type-system in C++ and
avoiding the direct use of raw C++ pointers in all but the lowest
level of code.

One has to wonder how the addition of such a feature as exception
handling which is so incompatible with a primary language feature like
basic memory management was ever accepted into the C++ language
standard.  It is clear what the advantages of exception handling are
in C++ (and any other language) but since the naive use of such a
feature will result in memory leaks one just have to wonder how this
was justified.  However, all is not lost since we don't have to write
naive memory management code and fixing this problem is one of the
main features of the memory management classes proposed here.


%
{}\section{Problems with common approaches for addressing memory
management in C++}
\label{sec:current-appraoches-to-mem-mng}
%

Because of some of the obvious problems with using raw C++ pointers to
access raw memory and using raw calls to {}\ttt{new} and
{}\ttt{delete} to perform dynamic memory management, various authors
have advocated a number of different approaches for addressing these
problems.  I will review a few of these approaches and I will argue
why these are much too sub-optimal.


%
{}\subsection{Problems with using {}\ttt{std::vector} for handling
all arrays}
%

A very common approach that I have seen used to try to get around
using raw C++ pointers for managing contiguous arrays of data is to
use the container class {}\ttt{std::vector} in {}\underline{every} use
case where a raw C++ array or pointer to an array would be used.
Before I describe use cases where {}\ttt{std::vector} is being poorly
used, first let's review what {}\ttt{std::vector} is and what it is
good for.  The standard library class {}\ttt{std::vector} is a
general-purpose concrete contiguous data container class for storing
and retrieving value objects\footnote{See Section
{}\ref{sec:value-and-reference-types} for a definition of ``Value
Types''.}.  What makes using {}\ttt{std::vector} attractive as
compared to a simple class that you would write yourself is:

\begin{itemize}

{}\item\ttt{std::vector} is a Standard Template Library (STL)
complaint data container which makes it easy to use with STL-like
generic algorithms.

{}\item\ttt{std::vector} contains functions for efficiently
expanding and shrinking the size of the array that can have
platform/compiler specific optimizations with much better performance
than what you would roll on your own.

{}\item\ttt{std::vector} is standardized so you can use it as a
means for interoperability with other software in appropriate
situations.

\end{itemize}

These are pretty much the advantages of using {}\ttt{std::vector} over
other alternatives.  When used as a general purpose data container
where you will be changing the size of the array on the fly,
{}\ttt{std::vector} is convenient, general, and efficient (just what
components from a standard library should be).  However, in other use
cases, {}\ttt{std::vector} is far from convenient, general, or
efficient.  As one example, consider using {}\ttt{std::vector} to
replace raw C++ pointers for array arguments in {}\underline{all} C++
functions as some authors have suggested (e.g.\ see
{}\cite{Modernizing-the-C++-Interface-to-MPI}).  For example, consider
the function that adds elements from one array into another array
expressed with raw C++ pointers shown in Listing
{}\ref{listing:addArrayIntoArray-raw}.

\begin{listing}:\\
\label{listing:addArrayIntoArray-raw}
{\small\begin{verbatim}
  template<class T>
  void addArrayIntoArray(const int n, const T a[], T b[])
  {
    for (int i = 0; i < n; ++i)
      b[i] += a[i];
  }
\end{verbatim}}
\end{listing}

The advantages of the function in Listing
{}\ref{listing:addArrayIntoArray-raw} are that a) it is clean, b) the
arrays of data can be sub-views of large arrays, and c) it will yield
very fast code.  Of course the problem with the above function
{}\ttt{addArrayIntoArray(...)} is that is uses raw C++ pointers.  How
does the function {}\ttt{addArrayIntoArray(...)} know that
{}\ttt{a} and {}\ttt{b} are valid pointers and really point to
valid arrays of data with at least {}\ttt{n} elements.  It is
impossible for the function {}\ttt{addArrayIntoArray(...)} to
assert anything about the data and completely relies on the caller of
the function to validate the data.  Even in a debug build of the code,
there is no way for the implementation of the function
{}\ttt{addArrayIntoArray(...)} to validate that the preconditions
concerning arguments have been met.  This is not good and does not
allow for even the most basic approaches for defensive programming.

Therefore, some C++ programmers look at this and then they change
functions like {}\ttt{addArrayIntoArray(...)} in Listing
{}\ref{listing:addArrayIntoArray-raw} to use {}\ttt{std::vector}
which is shown in Listing
{}\ref{listing:addArrayIntoArray-std-vector}.

\begin{listing}:\\
\label{listing:addArrayIntoArray-std-vector}
{\small\begin{verbatim}
  template<class T>
  void addArrayIntoArray( const std::vector<T> &a, std::vector<T> &b )
  {
    DEBUG_MODE_ASSERT_EQUALITY( a.size(), b.size() );
    for (int i = 0; i < a.size(); ++i)
      b[i] += a[i];
  }
\end{verbatim}}
\end{listing}

The advantages of the function in Listing
{}\ref{listing:addArrayIntoArray-std-vector} are that a) the size of
each array is kept with the pointer to the array itself inside of each
{}\ttt{std::vector} object, b) The sizes of the arrays can be
asserted by the implementation of the function
{}\ttt{addArrayIntoArray(...)}, c) it is easy for callers who
already use single {}\ttt{std::vector} objects.

While this use of {}\ttt{std::vector} replaces raw C++ pointers as
basic array function arguments, it has several serious problems in
both usability and performance in some important use cases.  The
primary disadvantages of using {}\ttt{std::vector} as general array
arguments to functions is a) there is no flexibility in how the arrays
are allocated, and b) one cannot pass sub-views of larger arrays of
data.

To illustrate the problems with using {}\ttt{std::vector} for all
array arguments to functions, consider a situation where the
application wants to allocate big arrays of data and then operate on
pieces of the array based on different logic.  One motivation for
allocating big arrays of data is to avoid memory fragmentation and
improve data locality.  Now consider in Listing
{}\ref{listing:someBlockAlgo-std-vector} what the client code would
have to look like when using the form of
{}\ttt{addArrayIntoArray(...)} in Listing
{}\ref{listing:addArrayIntoArray-std-vector} which takes in
{}\ttt{std::vector} objects.

\begin{listing}:\\
\label{listing:someBlockAlgo-std-vector}
{\small\begin{verbatim}
  void someBlockAlgo( const int numBlocks, const std::vector<double> &big_a,
    std::vector<double> &big_b )
  {
    DEBUG_MODE_ASSERT_EQUALITY( big_a.size(), big_b.size() );
    const int totalLen = big_a.size();
    const int blockSize = totalLen/numBlocks; // Assume no remainder!
    
    const int blockOffset = 0;
    for (int block_k = 0; block_k < numBlocks; ++block_k, blockOffset += blockSize)
    {
      if (big_a[blockOffset] > 0.0) {
        // Create temporary std::vectors to do function call
        std::vector a(big_a.begin()+blockOffset,
          big_a.begin()+blockOffset+blockSize);
        std::vector b(big_a.begin()+blockOffset,
          big_b.begin()+blockOffset+blockSize);
        // Do the operation
        addArrayIntoArray(a, b);
        // Copy back into the output array
        std::copy(b.begin(), b.end(), big_b.begin() + blockOffset);
      }
    }
  }
\end{verbatim}}
\end{listing}

As you can see, the client code that uses the {}\ttt{std::vector}
version of {}\ttt{addArrayIntoArray(...)} is neither clean, nor
efficient as temporary copies of all of the data have to be created
just to make the function call and then data has be be copied back
into the full array.

Now consider the client code in Listing
{}\ref{listing:someBlockAlgo-std-vector-raw-ptr} which uses the raw C++
pointer version of {}\ttt{addArrayIntoArray(...)} in Listing
{}\ref{listing:addArrayIntoArray-raw}.

\begin{listing}:\\
\label{listing:someBlockAlgo-std-vector-raw-ptr}
{\small\begin{verbatim}
  void someBlockAlgo( const int numBlocks, const std::vector<double> &big_a,
    std::vector<double> &big_b )
  {
    DEBUG_MODE_ASSERT_EQUALITY( big_a.size(), big_b.size() );
    const int totalLen = big_a.size();
    const int blockSize = totalLen/numBlocks; // Assume no remainder!
    
    const int blockOffset = 0;
    for (int block_k = 0; block_k < numBlocks; ++block_k, blockOffset += blockSize)
    {
      if (big_a[blockOffset] > 0.0) {
        addArrayIntoArray( blockSize, &big_a[blockOffset], &big_b[blockOffset]);
      }
    }
  }
\end{verbatim}}
\end{listing}

As you can clearly see, using the raw C++ pointer version of
{}\ttt{addArrayIntoArray(...)} makes the client code much cleaning
and much more efficient.  However, of course, if the client makes any
mistakes with its arrays of memory, then the resulting program will
(in the base case) segfault, or will silently produce the wrong
result, or (in the worst case) actually produce the right result on
the current platform but will fail on other platforms.

The Teuchos array utility classes make algorithms involving subviews
like shown above very clean, very efficient, and very safe (see the
same versions of this example code using these new Teuchos classes in
Section {}\ref{sec:array-views}).

In summary, {}\ttt{std::vector} is {}\underline{not} an efficient
or convenient general-purpose replacement for raw C++ pointers as
function arguments in many important use cases.


%
{}\subsection{Problems with relying on standard memory checking
utilities}
\label{sec:problems-with-mem-checkers}
%

Some programmers simply use raw C++ pointers and think that standard
memory checking tools like
Valgrind\footnote{{}\ttt{http://valgrind.org}} and
Purify\footnote{\ttt{http://www.ibm.com/software/awdtools/purify}}
will catch all of their mistakes.  When I first started coding in C++
back in 1996, I was very aware of the problems with using raw pointers
in C++ after experiencing the segfaults and memory leaks that all C++
programmers experience.  At the time, I had experimented some with
writing my own utility classes that encapsulated raw C++ pointers and
I considered taking that further.  However, at that time, I
conjectured that going through the effort of encapsulating all raw C++
pointers might be a waste of time because it would not be long until
someone came up with an 100\% bullet-proof memory checking tool for
C++ that would make my feeble programmer-controlled attempts to wrap
raw pointers obsolete.  After more than 10+ years of C++ programming
experience where I have written perhaps a million lines of C++ code on
a number of different platforms/compilers, I have come to regret that
decision.

Through painful experience and then through some more careful thought,
I have come to realize that memory checking tools like Valgrind and
Purify will never be able to provide an even sufficient (forget about
100\%) means to validate the memory usage of our C++ programs.  With
respect to existing tool implementations, I have experienced cases
where both Valgrind and Purify have reported not even a single warning
before the program segfaulted with essentially no feedback at all.  I
will not go into detail about what techniques memory tools like
Valgrind and Purify use to verify memory usage other than to say that
they can do a lot by just taking control of {}\ttt{malloc(...)} and
{}\ttt{free(...)} and in inserting checks into the execution of the
program by controlling the manipulation of the program stack.

One such case where the Valgrind and Purify were completely unhelpful
occurred with an off-by-one error with an {}\ttt{std::vector} using
Linux/gcc.  In the end, the way that I found the off-by-one error was
by just staring at the code over and over again until I happened to
see the problem.  However, what I discovered through two days of
debugging was that {}\ttt{std::vector} used its own allocator which
allocated big chunks of memory through {}\ttt{malloc(...)}.  It
then proceeded to do its own memory allocation scheme, which was very
fast but was invisible to the watchful eyes of Valgrind and Purify.
Any reads to this block of memory looked fine to Valgrind and Purify
because it was all contained within the block returned from
{}\ttt{malloc(...)}.  What the off-by-one error did was to write
over a library managed part of the memory block and that silent
corruption would doom a later attempt by {}\ttt{std::vector} to
allocate memory.

There are other categories of use cases where external memory checking
tools like Valgrind and Purify will never be able to verify correct
memory usage.  One example is semantic off-by-one errors committed in
larger blocks of data.  To demonstrate this type of error, consider
the example code in the function {}\ttt{someBlockAlgo(...)} in
Listing {}\ref{listing:someBlockAlgo-std-vector-raw-ptr} which uses
the raw C++ pointer version of the function
{}\ttt{addArrayIntoArray(...)} in Listing
{}\ref{listing:addArrayIntoArray-raw}.  Now consider what happens when
a developer introduces an off-by-one error as shown in
{}\ttt{addArrayIntoArray(...)} in Listing
{}\ref{listing:addArrayIntoArray_rawError}.

\begin{listing}:\\
\label{listing:addArrayIntoArray_rawError}
{\small\begin{verbatim}
  template<class T>
  void addArrayIntoArray( const int n, const T a[], T b[] )
  {
    for (int i = 0; i <= n; ++i)
      b[i] += a[i];
  }
\end{verbatim}}
\end{listing}

In case you missed it, the off-by-one error shown in Listing
{}\ref{listing:addArrayIntoArray_rawError} is the replacement of the
loop termination statement {}\ttt{i < n} with {}\ttt{i <= n}
which is a very common C++ programming error.

Now let's consider the implications that the off-by-one error shown in
Listing {}\ref{listing:addArrayIntoArray_rawError} will have of the
data in {}\ttt{big\_b} as driven by the code in Listing
{}\ref{listing:someBlockAlgo-std-vector-raw-ptr}.  If the last block
{}\ttt{block\_k=numBlocks-1} of data is processed, then there is a
reasonable chance a memory checking tool like Valgrind would catch the
off-by-one error being committed at the very end of the array
{}\ttt{big\_b}.  However, as described above, Valgrind may not
catch even this error.  Also, note that turning on bounds checking
with {}\ttt{std::vector} (i.e.\ by enabling
{}\ttt{\_GLIB\_CXX\_DEBUG} with gcc) will not catch this error
either because of the way the raw pointers are extracted in and and
passed in the function call:

{\small\begin{verbatim}
  addArrayIntoArray( blockSize, &big_a[blockOffset], &big_b[blockOffset]);
\end{verbatim}}

Now consider a defect caused by this off-by-one error for which no
automated memory checking tool that will ever be devised will ever be
able to catch.  This type of defect will occur, for example, when for
the last block {}\ttt{block\_k=numBlocks-1} we have
{}\ttt{big\_a[(numBlocks-2)*blockSize] > 0.0} and
{}\ttt{big\_a[(numBlocks-1)*blockSize] <= 0.0}.  In this case, only
the next-to-last block of data will be processed by the defective
{}\ttt{addArrayIntoArray(...)} function.  This will not result in a
classic off-by-one error that a memory checking tool would catch
because it would not touch memory outside of what is stored in
{}\ttt{big\_b}.  However, this off-by-one error committed in Listing
{}\ref{listing:addArrayIntoArray_rawError} would result in the array
entry {}\ttt{big\_b[(numBlocks-2)*blockSize+blockSize]} being
erroneously modified.  This is a defect that might only slightly
damage the final result of the program for the typical use case and
might therefore go unnoticed for years.  However, when the program was
really being used for something important years later for a
non-typical use case, this small off-by-one error could result in
reporting incorrect results which could embarrass a company, result in
a lawsuit, or (in an extreme case) even cause someone's death.

The point that I am trying to make in the above example is that
automated memory checking tools like Valgrind and Purify will never be
able to check the {}\textit{semantic} correctness of our usage of<
memory.  The off-by-one defect shown above is 100\% correct from a
strict memory usage point of view (i.e.\ only allocated memory can be
written to and only allocated and initialized memory can be read from)
but is 100\% wrong from a semantic point of view (i.e.\ the function
{}\ttt{addArrayIntoArray(...)} can only operate on the elements of
data from {}\ttt{0} to {}\ttt{n-1}).  The utility classes in
Teuchos described below help to verify that memory is used in a
semantically correct way.


%
{}\section{Important prerequisites}
\label{sec:important-prerequisites}
%

Before finally discussing the Teuchos memory management classes, I
need to discuss a set of prerequisite concepts that are needed in
order to understand the holistic memory management approach described
here.


%
{}\subsection{Value types versus reference types}
\label{sec:value-and-reference-types}
%

Because of the flexibility of C++, many C++ programmers can and do
implement a wide variety of types yielding objects with different types
of usage semantics.  A quick summary of ``accepted'' class types in
C++ is given in Item 33 ``Be clear what kink of class you're writing''
in {}\cite{C++CodingStandards05}.  I see little point here in trying
to classify all of the crazy ways that I have seen people code objects
in C++ that stray from these ``accepted'' class types.  Instead, I
want to suggest that we should classify 99\% of our classes as either
{}\textit{Value Types} or {}\textit{Reference Types}.  Value Types and
Reference Types are said to use {}\textit{Value Semantics} and
{}\textit{Reference Semantics}, respectively, and that is sometimes
how these data-types are described in various C++ literature.

{}\textit{Value Types} in general:

\begin{itemize}

{}\item have public destructors, default constructors, copy
constructors, and assignment operators (all implementing deep copy
semantics),

{}\item have an identity that is determined by their value not their
address,

{}\item are usually allocated on the stack or as direct data members
in other class objects,

{}\item are usually {}\underline{not} allocated on the heap (but can
be typically), and

{}\item do not have any virtual functions and are not to be used as
base classes (see Item 35 in {}\cite{C++CodingStandards05}).

\end{itemize}

If {}\ttt{S} denotes a typical Value Type, the class definition of
{}\ttt{S} includes:

{\small\begin{verbatim}
  class S {
  pubic:
    ~S();
    S();
    S(const S&);
    S& operator=(const S&);
    ...
  };
\end{verbatim}}

All of the built-in intrinsic C++ data-types like {}\ttt{char},
{}\ttt{int}, and {}\ttt{double} are Value Types.  Likewise,
derived class types like {}\ttt{std::complex} and
{}\ttt{std::vector} are also Value Types.  Value Types have also be
called by other names in the C++ literature.  Stroustrup refers to
Value Types as ``true local variables'' in {}\cite{stroustrup94}.  The
term Abstract Data Type (ADT) in older C++ literature such as
{}\cite{AdvancedC++92} usually maps to the concept of a value type,
but usually carries greater significance in implying that operator
overloading is used to make an ADT look more like a built-in C++ type
(such as is the case for {}\ttt{std::complex}).

Alternatively, {}\textit{Reference Types} in general:

\begin{itemize}

{}\item do not have a public copy constructor or assignment operator,

{}\item are manipulated through a (smart) pointer or reference,

{}\item have an identity that is determined by their address and not
their value,

{}\item are allocated on the heap,

{}\item typically are not permitted to be or cannot be allocated on
the stack,

{}\item are copied through an abstract clone function (if copying is
allowed at all),

{}\item have one or more virtual functions, and

{}\item are usually designed to be used as base classes or are derived
from base classes.

\end{itemize}

Reference Types (i.e.\ Reference Semantics) are typically used for base
classes in C++.  Examples of base classes in the C++ standard library
include {}\ttt{std::ios\_base} and
{}\ttt{std::basic\_streambuf}.  Reference Types in the form of
abstract base classes form the foundation for object-oriented
programming in C++.

If {}\ttt{A} denotes a typical Reference Type, the class definition
of {}\ttt{A} generally includes:

{\small\begin{verbatim}
  class A {
  pubic:
    virtual ~A();
    virtual A* clone() const = 0;  // NOTE: Should use RCP (see later)
    virtual void someFunc() = 0;
    ...
  protected: // or private
    A(const A&);
    A& operator=(const A&);
    ...
  };
\end{verbatim}}

Note that you can almost always choose to manipulate a Value Type
using Reference Semantics.  For example, it is very common to choose
to dynamically allocate large value objects like
{}\ttt{std::vector} and then pass around (smart) pointers and
references to the object to avoid unnecessary and expensive copying
and to facilitate the sharing of state.

While the ideas of Value Types and Reference Types and Value Semantics
and Reference Semantics are long established in the C++ literature
(even if the terminology is not very uniform), many C++ programmers
either seem to not know about these idioms or choose not to follow them
for some reason.  By forcing the majority of our classes into either
using {}\textit{Value Semantics} or {}\textit{Reference Semantics} we
eliminate meaningless variability in our C++ programs and we free
ourselves to think about more important things.

{}\textbf{Side Note:} The somewhat rigid classification of C++ types
into Value Types and Reference Types is similar in motivation and in
many other respects to Eric Evans' differentiation of all domain types
into {}\textit{Value Objects} and {}\textit{Entities} in Domain Driven
Design (DDD) {}\cite{DomainDrivenDesign}.  While there are
similarities between DDD's Value Objects and Entities and C++'s Value
Types and Reference Types, respectively, there is not a one-to-one
mapping.  In DDD, the distinction between a Value Object and an Entity
has more to do with the nature of the object in relation to the domain
model and is not related to how memory is manged.  Evans assumes that
you are using a language like Java where all objects use reference
semantics.


%
{}\subsection{Persisting associations versus non-persisting and
semi-persisting associations}
\label{sec:persisting-nonpersisting-associations}
%

Another important prerequisite for understanding the Teuchos memory
management classes is the distinction between {}\textit{non-persisting
associations} and {}\textit{persisting associations}.  Working
definitions for these are:

\begin{itemize}

{}\item\textit{Non-Persisting associations} are associations between
two or more objects that exist only within a single function call for
formal function arguments, or a single statement for function return
objects, where no memory of any of the objects is retained as a side
effect after the function returns or the statement ends.

{}\item\textit{Persisting associations} are associations that exist
between two or more objects that extend past a single function call
for formal function arguments, or a single statement for function
return objects.

\end{itemize}

To help define these two different types of associations, consider the
class and function definitions in Listing
{}\ref{listing:NonPersistingPersistingAssociationsRawPointers}.

\begin{listing}:\\
\label{listing:NonPersistingPersistingAssociationsRawPointers}
{\small\begin{verbatim}
  class A {
  public:
    void fooA() const;
  };

  class B {
  public:
    void fooB1(const A &a) { a.fooA(); }
    void fooB2() const { ... }
  };

  class C {
  public:
    C() : b_(0) {}
    void fooC1(B &b, const A &a)
      { b_ = &b; b_->fooB1(A); }
    void fooC2() const
      { b_->fooB2(); }
  private:
    B* b_;    
  };

  void someFunc(C &c, B &b, const A &a)
  {
    c.fooC1(b, a);
    c.fooC2();
  }
\end{verbatim}}
\end{listing}

The function {}\ttt{B::fooB1(...)} in Listing
{}\ref{listing:NonPersistingPersistingAssociationsRawPointers}
involves a non-persisting association with respect to the {}\ttt{A}
and {}\ttt{B} objects since no memory of the object {}\ttt{a}
remains after the function {}\ttt{B::fooB1(...)} exists.
Non-persisting associations represent typical input/output-only
arguments to a function.

The function {}\ttt{C::fooC1(...)} in Listing
{}\ref{listing:NonPersistingPersistingAssociationsRawPointers} creates
a persisting association between a {}\ttt{C} object and a
{}\ttt{B} object since the memory of the {}\ttt{B} object is
retained in the {}\ttt{C} object that persists after the function
{}\ttt{C::fooC1(...)} exits.  This memory of the {}\ttt{B}
object stored in the {}\ttt{C::b\_} pointer data member is then
used to implement the function {}\ttt{C::fooC2()}.  Note that the
function {}\ttt{C::fooC1(...)} also involves a non-persisting
association with the {}\ttt{A} object {}\ttt{a} since it is only
used to call {}\ttt{B::fooB1(...)} and no memory of {}\ttt{a}
lingers after {}\ttt{C::fooC1(...)} exists.

As a final example, consider the nonmember function
{}\ttt{someFunc(...)} in Listing
{}\ref{listing:NonPersistingPersistingAssociationsRawPointers}.  While
{}\ttt{someFunc(...)} is a free function, it actually involves the
creation of a persisting association between the {}\ttt{C} and
{}\ttt{B} objects as a side effect.

In the idioms advocated in this paper, smart reference counted
pointers are used for all persisting associations and never for
non-persisting associations.  Using the basic Teuchos {}\ttt{RCP}
class, the raw pointer code in Listing
{}\ref{listing:NonPersistingPersistingAssociationsRawPointers} would
be refactored into the code in Listing
{}\ref{listing:NonPersistingPersistingAssociationsRCP}.

\begin{listing}:\\
\label{listing:NonPersistingPersistingAssociationsRCP}
{\small\begin{verbatim}
  class A {
  public:
    void fooA() const;
  };

  class B {
  public:
    void fooB1(const A &a) { a.fooA(); }
    void fooB2() const { ... }
  };

  class C {
  public:
    C() : b_(0) {}
    void fooC1(const RCP<B> &b, const A &a)
      { b_ = &b; b_->fooB1(A); }
    void fooC2() const
      { b_->fooB2(); }
  private:
    RCP<B> b_;
  };

  void someFunc(C &c, const RCP<B> &b, const A &a)
  {
    c.fooC1(b, a);
    c.fooC2();
  }
\end{verbatim}}
\end{listing}

Note that the classes {}\ttt{A} and {}\ttt{B} remain unchanged
because they do not involve any persisting associations.

Another situation where the concepts of persisting and non-persisting
associations comes up relates to how objects are returned by C++
functions as return values.  A persisting relationship is made through
a function return object if that object is remembered past a single
statement.  For example, consider the following code fragment:

\begin{listing}:\\
{\small\begin{verbatim}
  std::vector<int> v(n);
  ...
  int &ele = v[0];  // Creates a persisting return object relationship
  ...
  ele = 5;          // Changes v[0] much later!
\end{verbatim}}
\end{listing}

The above code fragment shows a presenting relationship between the
client code that is initializing the local reference {}\ttt{ele}
and the {}\ttt{std::vector} container object {}\ttt{v}.  This is
very fragile and dangerous code because if {}\ttt{v} is resized,
grown or have some other type of change, then the reference pointed to
by {}\ttt{ele} can be invalid.  For example, the following code
fragment will likely result in a runtime memory usage error and (if
we are lucky) segfault:

\begin{listing}:\\
{\small\begin{verbatim}
  std::vector<int> v(n);
  int &ele = v[0];
  v.resize(10*n);
  ele = 5;  // ele is likely to be invalid here!
\end{verbatim}}
\end{listing}

If we are unlucky, the statement {}\ttt{ele = 5} will work just
fine on one platform with one implementation of the
{}\ttt{std::vector} but will break on another platform when run
with a different data-set.  Note that tools like Valgrind and Purify
may not flag the problem due to how many implementations of
{}\ttt{std::vector} deal with memory.

Basically the problem here is that the
{}\ttt{std::vector::operator=(size\_type)} function returns a raw
C++ reference that should never be remembered past a single statement.
The safe way to change an element is:

\begin{listing}:\\
{\small\begin{verbatim}
  std::vector<int> v(n);
  v[0] = 5; // Non-persisting relationship!
  v.resize(10*n);
\end{verbatim}}
\end{listing}

Here, we will say that {}\ttt{std::vector::operator[](size\_type)}
should only be used for non-persisting associations as shown above.

Most programming languages do not provide any means to differentiate
between non-persisting associations and persisting associations (see
Section {}\ref{sec:essentail-accidental-complexity} for an expanded
discussion).  However, note that the Unified Modeling Language (UML
{}\cite{UMLDistilledThirdEdition04}) does differentiates between them
in that presisting relationships are shown with a solid line while
non-persisting relationships are shown with a dotted line (see Figure
{}\ref{fig:TeuchosRCPDesign} for exmaples).

Before leaving the topic of persisting and non-persisting
associations, we have to recognize that there exists a third category
of associations that lie in between strict persisting and
non-persisting associations which we will refer to as semi-persisting
assocaitions defined as:

\begin{itemize}

{}\item\textit{Semi-persisting associations} are associations that
(like persisting assocations) exist between two or more objects that
extend past a single function call for formal function arguments, or a
single statement for function return objects except were the use of
the objects and the lifetime of the association have more ridgid
constraints requiring greater care.

\end{itemize}

An example of a semi-persisting association is the use of an iterator
to access an STL container.  For example, consider an iterator-based
loop such as shown in Listing {}\ref{listing:SemiPersistingIterators}:


\begin{listing}:\\
\label{listing:SemiPersistingIterators}
{\small\begin{verbatim}

  void someFunc(std::vector<int> &v)
  {
    typedef std::vector<int>::iterator itr_t;
    for (itr_t itr = v.begin(); itr != v.end(); ++itr) {
      *itr = 5;
    }
  }
\end{verbatim}}
\end{listing}


As shown in Listing {}\ref{listing:SemiPersistingIterators}, the
iterator object {}\ttt{itr} is used well past (perhaps thousands of
loop iterations) where it was created by the statement {}\ttt{itr\_t
itr = v.begin()}.  There are, however, significant restrictions on how
such iterators can be used: a) the iterator cannot be accessed after
the originating parent object has been destroyed, and b) the iterator
can not be accessed after the structure of the originating parent has
changed (e.g.\ {}\ttt{v.resize(...)} was called).  For the sake of
performance, we have to allow for the use of semi-persisting
associations such as this.  Note that in the case of the STL
containers that in a debug-mode checked STL build, these types of
dangling iterator references will typically be detected.  This type of
debug-mode runtime checking is the saving grace for the use of
iterators and other types of semi-persisting associations which makes
their use acceptable.

Semi-persisting associations will also play a role in the use of the
Teuchos memory management classes in situations where performance is
critical (see Section {}\ref{sec:perf-tuning-strategies} and
Commandments {}\ref{cmnd:ptr-semi-persisting} and
{}\ref{cmnd:arrayview-semi-persisting} in Appendix
{}\ref{apdx:commandments}).


%
{}\section{Teuchos classes for safer memory management and usage}
\label{sec:teuchos-mem-mng-classes}
%

The primary purpose for the Teuchos memory management classes is to
allow the replacement of all raw C++ pointers in all high-level code,
period.  These classes are efficient and general and, in a debug build
of the code, will catch and gracefully report 99\% or more of the
programming errors typically made with the ubiquitous high-level use
of raw C++ pointers.


%
{}\subsection{Overview of basic approach employed by Teuchos
memory mangement classes}
\label{sec:overview_of_basic_approach}
%

The basic approach being advocated here and implemented in the Teuchos
memory management classes is to:

\begin{itemize}

{}\item Encapsulate all raw C++ pointers in high-level code in
specially designed memory management classes, capture raw C++ pointers
as soon as possible, and avoid exposing raw calls to {}\ttt{new} in
library and application code.

{}\item Provide a complete set of cooperating types that work together
to safely and conveniently implement all hand-offs of raw C++ pointers
using supported and carefully scrutinized conversion code.  Also,
never define implicit conversions from these safe types to raw C++
pointers or the entire type safe system falls apart.

{}\item Differentiate memory management classes for handling single
objects and for handling contiguous arrays of objects.

{}\item Differentiate memory management classes according to
persisting and non-persisting (and semi-persisting) associations.

  \begin{itemize}

  {}\item Use reference counting for memory management classes
  designed to handle persisting associations.

  {}\item Do not impose the overhead of reference counting for memory
  management classes designed to handle non-persisting associations.

  {}\item Do not impose the overhead of reference counting for memory
  management classes designed to handle semi-persisting associations
  (but provide the machinery for strong debug-mode runtime checking).

  \end{itemize}

{}\item Provide encapsulations for all uses of raw C++ pointers for
arrays of memory including dynamically sized arrays, statically sized
arrays, and stack-based arrays.

{}\item Provide a default {}\textit{optimized mode} where maximum
performance and minimal overhead are the goals where raw C++ pointer
performance is achieved for all reasonable use cases.

{}\item Provide an optional {}\textit{debug mode} whose goal is to
provide maximum runtime checking with low overhead by default to catch
all sorts of common errors like:

  \begin{itemize}
  {}\item Multiple owning reference-counting node object
  {}\item Dereferencing null pointers
  {}\item Dereferencing dangling pointers (references)
  {}\item Array access errors like off-by-one and other errors
  {}\item Incorrect iterator usage
  {}\item Circular dependencies
  \end{itemize}

{}\item Structure debug-mode checking such that it does not alter the
observable behavior of correct programs in any way.  However, when
debug-mode checking is enabled, the software should never segfault or
exhibit any other type of illegal or undefined usage of memory.

\end{itemize}


\begin{table}
\begin{center}
\input{BasicTeuchosSmartPointerClasses}
\end{center}
\caption{\label{tbl:BasicSingleArrayTypes}
Basic Teuchos memory management utility classes for encapsulating raw
pointers.}
\end{table}


\begin{table}
\begin{center}
\input{OperationsSummaryTable}
\end{center}
\caption{\label{tbl:TypesSummary}
Summary of capabilities of the basic Teuchos memory management
classes.}
\end{table}

The basic templated Teuchos memory management classes for
encapsulating raw C++ pointers for single objects and arrays shown in
Table {}\ref{tbl:BasicSingleArrayTypes} are {}\ttt{Ptr}, {}\ttt{RCP},
{}\ttt{ArrayView}, and {}\ttt{ArrayRCP}.  A summary of the
capabilities of these classes is shown in Table
{}\ref{tbl:TypesSummary}.  What you can see from this table is that
raw pointer-like functionality is partitioned across these various
sets of classes in logical and safe ways.  For example, array-related
operations are not defined on the single-object classes {}\ttt{Ptr}
and {}\ttt{RCP} but implicit conversion from derived types to base
types is allowed.  Alternatively, the array classes {}\ttt{ArrayView},
and {}\ttt{ArrayRCP} do {}\underline{not} support the dangerous and
ill-conceived ability to implicitly convert arrays of derived types to
arrays of base types that is discussed in Section
{}\ref{sec:problem-with-raw-array-pointers}.  Note that the class
{}\ttt{ArrayView} does not support all of the raw pointer
iterator-like operations that {}\ttt{ArrayRCP} supports like the
dereference operator {}\ttt{operator*()} or the pointer offset
functions that change the pointer.  The reason that {}\ttt{ArrayRCP}
does support these iterator-like operations is so that it can be used
as a general purpose iterator implementation while {}\ttt{ArrayView}
objects do not need to be used in this way.  Note that all of the
array classes defined in Teuchos all support a basic iterator
interface with the {}\ttt{[const]\_iterator} member typedefs and the
functions {}\ttt{begin()} and {}\ttt{end()}.  In optimized mode, these
iterators are simply raw C++ pointers yielding maximum performance.
However, in debug mode, the iterators are implemented as
{}\ttt{ArrayRCP} objects resulting in fully checked iterators.

\begin{table}
\begin{center}
\input{ArrayContainersTable}
\end{center}
\caption{\label{tbl:ExtendedArrayTypes}
Teuchos array container classes.}
\end{table}

In addition to the four basic memory management classes shown in Table
{}\ref{tbl:BasicSingleArrayTypes} which provide the most fundamental
replacements for all raw C++ pointers in all high-level code, Teuchos
also contains a few other array container classes for a few more
specific use cases shown in Table {}\ref{tbl:ExtendedArrayTypes}.  The
array container classes {}\ttt{Array} and {}\ttt{Tuple} pretty much
cover the majority of use cases in C++ where raw C++ pointer arrays
are used for containers.  The class {}\ttt{Array} is a directly
replacement for {}\ttt{std::vector} and actually wraps it internally.

Note that all of these classes are templated on value types and are
themselves value-types (see Section
{}\ref{sec:value-and-reference-types}).  This means that you can embed
these types in each other in any arbitrary order to create any type of
data structure that you would like.  For example, you could have
{}\ttt{Array<RCP<ArrayRCP<ArrayView<Tuple<Ptr<T>,5> > > > > >}.  By
understanding what each of these types provide and what each type
means (in terms of the idioms defined in Section {}\ref{sec:idioms}),
you can achieve almost anything you want in a way that is self
documenting.

These classes all work together to provide a high level of debug-mode
runtime checking to catch the majority of common programming errors
and report these errors gracefully with informative error messages.  A
debug-mode build of the code is facilitated by defining the
preprocessor macro {}\ttt{TEUCHOS\_DEBUG} (through the CMake
configuration varible {}\ttt{Teuchos\_ENABLE\_DEBUG=ON}).  When
{}\ttt{TEUCHOS\_DEBUG} is not defined, the Teuchos memory management
classes are configured to impart minimal overhead and yield fast
performance.  When {}\ttt{TEUCHOS\_DEBUG} is defined, these classes
are configured to perform maximal debug runtime checking.  These
classes are also carefully designed so that if a program is
implemented correctly using these classes and executes correctly in
the optimized mode, the program compiled with the debug checking
turned on will execute in exactly the same way.  However, if any
undefined, dangerous, or just plain wrong behavior is being used, then
these memory management classes will throw exceptions and the
exception objects will have very good error messages embedded in them
making it easier to debug and fix the problem.

What is important to understand is that all of these memory management
classes must be developed together with knowledge of each other's
internal implementations in order to provide for solid debug-mode
runtime checking.  For example, in general, you cannot mix in other
memory management classes like {}\ttt{boost::shared\_ptr} (i.e.\
{}\ttt{std::shared\_ptr} in C++0x) and {}\ttt{std::vector} and provide
for the level of runtime checking that is supported by the complete
set of Teuchos memory management classes described here.  More details
about why this is so are given in Section
{}\ref{sec:debug-mode-runtime-checking} in the context of debug-mode
runtime checking for and reporting of dangling references.

As with the development of any set of C++ classes, a set of
accompanying idioms must also be developed for maximizing their
effective use.  The idioms described in this paper involving the
Teuchos memory management classes result in code with maximum
compile-time checking, maximum debug-mode runtime checking, and
maximally self-documenting.


%
{}\subsection{The proper role of raw C++ pointers}
\label{sec:role-of-raw-pointers}
%

The thesis of this paper is that we should eliminate the use of all
raw C++ pointers in all of our high-level C++ code and instead use a
system of specially designed types for the right situations.  Does
that mean that we should never use raw C++ pointers in any C++ code?
The answer of course is {}\underline{no}, since we will always have to
use raw C++ pointers in special situations.

Here are the valid situations where it is appropriate (or required)
to use raw C++ pointers in our C++ programs:

\begin{itemize}

{}\item{}\textit{Use raw C++ pointers (indirectly) for extremely
well-encapsulated, low-level, high-performance algorithms}

In order to achieve high performance in computationally intensive
code, we will always have to use raw C++ pointers in a non-debug
optimized build.  This includes using raw C++ pointers to build
complex specialized data structures and similar purposes.  In this
context, we can think of raw C++ pointers as a fairly compact and
efficient way to communicate with the compiler about how we want to
manage memory at the hardware level.  The ability to do this type if
fine-grained manipulation of memory has always been one of the
strengths of C and C++ in systems-level programming.  Therefore, we
can think of using raw pointers in C++ as a kind of portable assembly
language that we always have at our disposal on every platform and
with every compiler.  However, note that our use of raw C++ pointers
in the name of performance must be very well encapsulated and we must
thoroughly review (by our best programmers) and exhaustively test this
code.  However, instead of using raw pointers, one can always use the
types {}\ttt{Ptr}, {}\ttt{ArrayView} or
{}\ttt{Array[RCP,View]::iterator} to yield raw pointer performance
in a non-debug optimized build but still maintain strong debug-mode
runtime checking.  This is discuss in more detail in Section
{}\ref{sec:perf-tuning-strategies}.  Therefore, optimized performance
use for raw pointers described next.

{}\item{}\textit{Use raw C++ pointers to communicate with legacy C++
code and with other languages through C bindings}

The only remaining valid reason to use a raw C++ pointer is to reuse
and communicate with legacy C++ code and to call functions in other
languages through the now-universal approach of using C bindings.
However, we must endeavor to minimize the amount of C++ code that has
naked raw C++ pointers and we should only expose a raw C++ pointer at
the last possible moment (such as in the call to the external
functions themselves).  Again, we must carefully encapsulate our
access to this non-compliant code that requires us to expose raw C++
pointers.

\end{itemize}

One point is worth nothing here which is that in our new modern C++
software we must never use raw C++ pointers in the basic interfaces
between our various modules as that is where a majority of mistakes in
the use of memory will be made.  This goes somewhat contrary to the
advice in Item 63 ``Use sufficiently portable types in a module's
interface'' in {}\cite{C++CodingStandards05}.  If our new modern safe
C++ software must be called by non-compliant software that uses raw
C++ pointers, then we can provide specialized C-like interfaces for
those clients that use raw C++ pointers for communication.  Of course,
once we do this, we will have to rely on our clients to pass in memory
correctly and keep it valid as long as our modules need it.

%
{}\subsection{Common aspects of all Teuchos memory management classes}
\label{sec:common-aspects}
%

Table {}\ref{tbl:common-type-members} gives the common member and
non-member functions common all the Teuchos memory management classes
{}\ttt{Ptr}, {}\ttt{RCP}, {}\ttt{Array}, {}\ttt{ArrayView},
{}\ttt{ArrayRCP}, and {}\ttt{Tuple}.  The comparison operators allows
all of these types to be used as keys in assoicative containers like
{}\ttt{std::map}.

\begin{table}
{\small\begin{center}
\begin{tabular}{|l|}
\hline
{}\textbf{Common member functions} \\
\hline
{}\ttt{[const\_]pointer getRawPtr() [const]} \\
\hline
{}\textbf{Common nonmember functions} \\
\hline
{}\ttt{void swap(Type<T>\&, Type<T>\&)} \\
{}\ttt{bool is\_null(const Type<T>\&)} \\
{}\ttt{bool nonnull(const Type<T>\&)} \\
{}\ttt{bool operator==(const Type<T>\&, ENull)} \\
{}\ttt{bool operator!=(const Type<T>\&, ENull)} \\
{}\ttt{bool operator==(const Type<T>\&, const Type<T>\&)} \\
{}\ttt{bool operator!=(const Type<T>\&, const Type<T>\&)} \\
{}\ttt{bool operator<(const Type<T>\&, const Type<T>\&)} \\
{}\ttt{bool operator<=(const Type<T>\&, const Type<T>\&)} \\
{}\ttt{bool operator>(const Type<T>\&, const Type<T>\&)} \\
{}\ttt{bool operator>=(const Type<T>\&, const Type<T>\&)} \\
\hline
\end{tabular}
\caption{\label{tbl:common-type-members}
Common members and non-members for {}\ttt{Ptr}, {}\ttt{RCP},
{}\ttt{Array[RCP,View]}, {}\ttt{Tuple}.}
\end{center}}
\end{table}

% ToDo: Implement all of the ``Common nonmember functions'' in all
% Teuchos memory management classes.


%
{}\subsection{Memory management classes replacing raw pointers for
single objects}
%

Here we describe the templated classes {}\ttt{Ptr} and
{}\ttt{RCP} which are used to encapsulate raw C++ pointers to
single objects in more detail.  Again, {}\ttt{Ptr} is used for
non-persisting associations and {}\ttt{RCP} is for persisting
associations.  Below, and in all of the code listings, we assume that
they are enclosed in the {}\ttt{Teuchos} namespace or there are
appropriate {}\ttt{using Teuchos::XXX} declarations for the various
names in place.

%
{}\subsubsection{\ttt{Teuchos::Ptr<T>}}
\label{sec:Ptr}
%

The templated class {}\ttt{Ptr} is the simplest of all the Teuchos
memory management classes.  In optimized mode it is just the thinnest
of wrappers around a raw C++ pointer.  Listing {}\ref{listing:Ptr}
shows what the implementation of {}\ttt{Ptr} looks like in
optimized mode:

\begin{listing}: Teuchos::Ptr class\\
\label{listing:Ptr}
{\small\begin{verbatim}
  template<class T>
  class Ptr {
  public:
    Ptr( ENull null_in = null ) : ptr_(0) {}
    explicit Ptr( T *ptr ) : ptr_(ptr) {}
    Ptr(const Ptr<T>& ptr) : ptr_(ptr.ptr_) {}
    template<class T2> Ptr(const Ptr<T2>& ptr) : ptr_(ptr.ptr_) {}
    Ptr<T>& operator=(const Ptr<T>& ptr) { ptr_=ptr.ptr_; return *this; }
    T* operator->() const { return ptr_; }
    T& operator*() const { return *ptr_; }
    T* get() const { return ptr_; }
    T* getRawPtr() const { return ptr_; }
    const Ptr<T>& assert_not_null() const;
  private:
    T *ptr_;
  };
\end{verbatim}}
\end{listing}

In optimized mode, the only overhead imparted by {}\ttt{Ptr} is the
default initialization to null.  All other functions are just inline
assessors to the underlying raw C++ pointer member {}\ttt{ptr\_}.
Therefore, the performance when using this type is the same as when
using a raw C++ pointer.

However, in debug mode (enabled when {}\ttt{TEUCHOS\_DEBUG} is
defined), then the {}\ttt{Ptr} becomes more complex and performs a
number of runtime checks like for null dereferences and dangling
references (see Section {}\ref{sec:detection-dangling-references}).

One note about the default null constructor shown in Listing
{}\ref{listing:Ptr} which is:

{\small\begin{verbatim}
  template<class T>
  Ptr<T>::Ptr( ENull null_in = null ) : ptr_(0) {}
\end{verbatim}}

{}\noindent{}is that the type {}\ttt{ENull} is the simple enum in
the {}\ttt{Teuchos} namespace:

{\small\begin{verbatim}
  enum ENull { null };
\end{verbatim}}

This simple enum allows for the safe implicit conversion from the enum
value {}\ttt{null} to any {}\ttt{Ptr<T>} object.  For example,
you can write code like:

{\small\begin{verbatim}
  Ptr<A> a_ptr = null;
\end{verbatim}}

This implicit conversion from {}\ttt{null} is shared by the other
Teuchos memory management classes {}\ttt{RCP<T>},
{}\ttt{ArrayView<T>}, and {}\ttt{ArrayRCP<T>}.  This allows you
to call functions that accept one of these objects and just pass in
{}\ttt{null} when appropriate and the implicit conversion will be
done automatically if possible.

The main purpose for the existence of the {}\ttt{Ptr} class is to
replace raw C++ pointers in function calls for typical input,
input/output, and output arguments where no persisting relationship is
present.  (the class {}\ttt{Ptr} should also be used for
semi-persisting associations where single objects are involved.)  For
example, consider the function that modifies a type {}\ttt{A}
object shown in Listing {}\ref{listing:modifyA-rawPtr}.

\begin{listing}:\\
\label{listing:modifyA-rawPtr}
{\small\begin{verbatim}
  void modifyA( A *a )
  {
    a->increment();
  }
\end{verbatim}}
\end{listing}

Using {}\ttt{Ptr}, the function {}\ttt{modifyA(...)} in Listing
{}\ref{listing:modifyA-rawPtr} would be changed to the form shown in
Listing {}\ref{listing:modifyA-Ptr}.

\begin{listing}:\\
\label{listing:modifyA-Ptr}
{\small\begin{verbatim}
  void modifyA( const Ptr<A> &a )
  {
    a->increment();
  }
\end{verbatim}}
\end{listing}

In this context, the primary advantage of the form shown in Listing
{}\ref{listing:modifyA-Ptr} as apposed to Listing
{}\ref{listing:modifyA-rawPtr} is that in debug mode, a check for a
null pointer would be performed automatically.  If a null dereference
occurred, then an exception would be thrown with a very good error
message. I have seen platforms where a null dereference did not
automatically result in a graceful assert, stopping the program.  I
have seen cases where somehow memory was corrupted and the program
continued!  My general philosophy is to make as few assumptions as
possible about the behavior of the compiler and platform because I
have found that ``typical and obvious'' behavior is not universal.  I
have learned the hard way that you will pay a price for such
assumptions in lost time debugging obscure things like a null pointer
dereference that should have stopped the program but did not.  Don't
take chances with your code, take control!

When all of the high-level code has been converted over to use these
memory management classes and there are no more raw C++ pointers, then
client code should never have to construct a {}\ttt{Ptr} using a
raw C++ pointer.  However, as code is being transitioned over and
when such code is called by non-compliant code, construction from a
raw pointer is needed.  The recommended way to convert from a raw C++
pointers to {}\ttt{Ptr} is to use the following templated
non-member function:

\begin{listing}: Teuchos::ptr(...)\\
\label{listing:ptr}
{\small\begin{verbatim}
  template<class T>  Ptr<T> ptr(T *p);
\end{verbatim}}
\end{listing}

Using this non-member constructor function, client code would then be
written as shown in Listing {}\ref{listing:using-ptr}.

\begin{listing}:\\
\label{listing:using-ptr}
{\small\begin{verbatim}
  void foo( A* a )
  {
    using Teuchos::ptr;
    modifyA(ptr(a));
  }
\end{verbatim}}
\end{listing}

A more typical use case for the construction of a {}\ttt{Ptr}
object is from a C++ object/reference.  This type of construction
should always be performed using one of the non-member constructor
functions shown in Listing
{}\ref{listing:ptr-from-ref-nonmember-constructors}.

\begin{listing}: Safe nonmember constructors for Teuchos::Ptr\\
\label{listing:ptr-from-ref-nonmember-constructors}
{\small\begin{verbatim}
  template<typename T> Ptr<T>        ptrFromRef( T& arg );
  template<typename T> Ptr<T>        inOutArg( T& arg );
  template<typename T> Ptr<T>        outArg( T& arg );
  template<typename T> Ptr<T>        optInArg( T& arg );
  template<typename T> Ptr<const T>  constOptInArg( T& arg );
\end{verbatim}}
\end{listing}

The different forms of non-member constructor functions shown in
Listing {}\ref{listing:ptr-from-ref-nonmember-constructors} are to
allow for self-documenting code for calls to functions that accept
{}\ttt{Ptr}-wrapped objects.

A complete and comprehensive set of idioms for using {}\ttt{Ptr}
along with the other Teuchos memory management types is given in
Section {}\ref{sec:idioms}.


%
{}\subsubsection{\ttt{Teuchos::RCP<T>}}
\label{sec:RCP}
%

The class {}\ttt{RCP}, the real workhorse of the Teuchos memory
management classes, is used to manage single objects in persisting
associations.  {}\ttt{RCP} is very similar to other high-quality
reference-counted smart pointer classes like
{}\ttt{boost::shared\_ptr} and of course the upcoming standard
C++0x class {}\ttt{std::shared\_ptr}.  However, {}\ttt{RCP} has
some key features that differentiate it from these other better known
smart pointer classes.  In particular, {}\ttt{RCP} has built in
support for the detection of circular references (Section
{}\ref{sec:circular-references-weak-pointers}), has built in support
for resolving circular references with built-in weak pointers (Section
{}\ref{sec:basic-reference-counting-machinery}), and other strong
debug runtime checking such as detecting multiple non-related
{}\ttt{RCP} objects owning the same reference-counted objects and
other types of checks.

Because the class {}\ttt{RCP} is described in
{}\cite{RefCountPtrBeginnersGuide} and is so similar in use to
{}\ttt{boost::shared\_ptr}, this class will not be described in too
much detail here.  However, a fairly complete definition of the class
{}\ttt{RCP} is shown in Listing {}\ref{listing:RCP} (the full
listing can be found in the Doxygen documentation).

\begin{listing}: Class and helper function listing for {}\ttt{RCP} \\
\label{listing:RCP}
{\small\begin{verbatim}
  template<class T>
  class RCP {
  public:

    // General functions
    RCP(ENull null_arg = null);
    explicit RCP(T* p, bool has_ownership = false);
    template<class Dealloc_T> RCP(T* p, Dealloc_T dealloc, bool has_ownership);
    RCP(const RCP<T>& r_ptr);
    template<class T2> RCP(const RCP<T2>& r_ptr);
    ~RCP();
    RCP<T>& operator=(const RCP<T>& r_ptr);
    bool is_null() const;
    T* operator->() const;
    T& operator*() const;
    T* getRawPtr() const;
    Ptr<T> ptr() const;
  
    // Other shared_ptr compariblity functions
    ...
  
    // Reference counting member functions
    ...
  
  private:
    T *ptr_;
    RCPNode node_;
    ...
  };

  // General non-member constructor functions
  template<class T> RCP<T> rcp(T* p, bool owns_mem = true);
  template<class T> RCP<T> rcpFromRef(T& r);
  template<class T> RCP<T> rcpFromUndefRef(T& r);

  // Deallocation policy functions
  ...

  // Embedded objects functions
  ...

  // Extra data functions
  ...
 
  // Conversion functions
  ...

  // Other common non-member functions
  ...

\end{verbatim}}
\end{listing}

Again, basic usage of the {}\ttt{RCP} class is described in
{}\cite{RefCountPtrBeginnersGuide}.  The basic idiom of smart pointers and
reference counting is fairly well known and is well documented in the
literature and there is a good overview in {}\cite{RefCountPtrBeginnersGuide}
so basic information will not be replicated here.  However, some of the more
advanced functionality for {}\ttt{RCP} is described in later chapters that
is not described in {}\cite{RefCountPtrBeginnersGuide} or an any of the
existing C++ literature.


%
{}\subsubsection{Raw C++ references}
\label{sec:raw-C++-references}
%

Why do we have a subsection on raw C++ references under the section
for Teuchos Memory Management classes?  The reason is that raw C++
references to single objects are used in the idioms described in this
paper for non-persisting associations for single objects and this was
a reasonable place to discuss them.

While this paper argues that raw C++ pointers have no place in
application-level code because they are fundamentally unsafe does that
also mean that raw C++ references are also unsafe in application-level
code?  After all, under the covers raw C++ references really are just
raw C++ pointers in disguise.  While this is true, in practice raw C++
references are significantly safer than raw C++ pointers, especially
if the idioms outlined in this paper are carefully followed.  In
addition, the use of raw C++ references is exploited (as explained in
Section {}\ref{sec:raw-C++-references}) in defining idioms that
increase the self-documenting nature of C++ code and play a role in
defining non-persisting associations related to function formal
arguments and return objects.

Basically, a raw C++ reference is relatively safe as long as a) it is
always initialized to a valid object, and b) it is only used for
non-persisting relationships (especially as const input arguments in
C++ functions).  If a raw C++ reference is initialized directly from an
object or from dereferencing a smart pointer, then you are guaranteed
that the object will be valid when the reference is first created (at
least in a debug build where dereferencing null smart pointers
throws).  While raw C++ references are fairly safe when used with the
idioms described in this paper, there are no 100\% guarantees.  There
is typically no guarantee that the object pointed to by a raw reference
will stay valid, even in cases where you would assume that it should
be if other idioms outlined in this paper are broken or in rare other
cases even if no specific idiom rule is broken.

Note that raw C++ references should never be used for representing
semi-persisting associations because it is impossible to catch invalid
usage like dangling references.  Instead, when a semi-persisting
association is involved, always use {}\ttt{Ptr} instead of a raw C++
reference.


%
{}\subsection{Memory management classes replacing raw pointers for
arrays of objects}
\label{sec:array-classes}
%

The Teuchos memory management module actually defines four different
C++ classes for dealing with contiguous arrays of objects:
{}\ttt{ArrayView}, {}\ttt{ArrayRCP}, {}\ttt{Array}, and
{}\ttt{Tuple}.  As stated in Section
{}\ref{sec:overview_of_basic_approach} each of these classes is needed
in order to address different important use cases for dealing with
contiguous arrays of objects.  The conventions outlined in the paper
never have you exposing a raw C++ pointer to an array or directly
using built-in (statically sized) C++ arrays.

In addition to the common members shown in Table
{}\ref{tbl:common-type-members}, all of the Teuchos array classes
provide a common subset of the interface of {}\ttt{std::vector} which
includes the typedefs and member functions shown in Table
{}\ref{tbl:common-array-type-members}.

\begin{table}
{\small\begin{center}
\begin{tabular}{|l|}
\hline
{}\textbf{std::vector compatible member typedefs} \\
\hline
{}\ttt{value\_type} \\
{}\ttt{size\_type} \\
{}\ttt{difference\_type} \\
{}\ttt{pointer} \\
{}\ttt{const\_pointer} \\
{}\ttt{reference} \\
{}\ttt{const\_reference} \\
{}\ttt{iterator} \\
{}\ttt{const\_iterator} \\
{}\ttt{element\_type} \\
\hline
{}\textbf{std::vector compatible member functions} \\
\hline
{}\ttt{size\_type size()} \\
{}\ttt{[const\_]reference operator{}(size\_type) [const]} \\
{}\ttt{[const\_]reference front() const} \\
{}\ttt{[const\_]reference back() const} \\
{}\ttt{[const\_]iterator begin() [const]} \\
{}\ttt{[const\_]iterator end() [const]} \\
\hline
{}\textbf{ArrayView returning member functions} \\
\hline
{}\ttt{ArrayView<[const] T> view(size\_type offset, size\_type size) [const]} \\
{}\ttt{ArrayView<[const] T> operator[]()(size\_type offset, size\_type size) [const]} \\
{}\ttt{ArrayView<[const] T> operator()() [const]} \\
\hline
{}\textbf{Additionaly common member functions} \\
\hline
{}\ttt{[const\_]pointer getRawPtr() [const]} \\
{}\ttt{std::string toString() const} \\
\hline
\end{tabular}
\caption{\label{tbl:common-array-type-members}
Common members and non-members for {}\ttt{ArrayView},
{}\ttt{ArrayRCP}, {}\ttt{Array}, and {}\ttt{Tuple} .}
\end{center}}
\end{table}

A few things to note about the array interface components shown in
Table {}\ref{tbl:common-array-type-members}:

\begin{itemize}

{}\item{}All of the Teuchos array classes are drop-in replacements for
any code that uses {}\ttt{std::vector} that does not grow or shrink
the container by supporting the necessary typedefs, query functions,
element access, and iterator access.  This helps in migrating current
code that uses {}\ttt{std::vector} but should be using
{}\ttt{Array}, {}\ttt{ArrayView}, {}\ttt{ArrayRCP} or
{}\ttt{Tuple}.

{}\item{}All of the array classes support returning \ttt{ArrayView}
subviews of contiguous ranges of elements.

{}\item{}All of the array classes support a handy
{}\ttt{getRawPtr()} function that allows a client to get the base
pointer address, or null, to the array.  The standard
{}\ttt{std::vector} class supports no such function which is very
painful for users.

\end{itemize}

The exact functions shown in Table
{}\ref{tbl:common-array-type-members} for {}\ttt{ArrayView} and
{}\ttt{ArrayRCP} and a little different than for {}\ttt{Array}
due to the different nature of these view classes as apposed to the
container class {}\ttt{Array}.  As described in Section
{}\ref{sec:teuchos-const-nonconst-pointer-objects}, the classes
{}\ttt{ArrayView} and {}\ttt{ArrayRCP} can encapsulate both
non-const and const types {}\ttt{T} as their template argument
while {}\ttt{Array} can only accept a non-const type {}\ttt{T}.
Therefore, the {}\ttt{std::vector} compatible functions in
{}\ttt{ArrayView} and {}\ttt{ArrayRCP} are all {}\ttt{const}
functions since they don't change what data these objects point to,
but only change the data themselves.

One other aspect to note about the Teuchos array classes is that they
deviate from the standard C++ library convention of using an unsigned
integer for {}\ttt{size\_type}.  Instead, they use a signed integer
for {}\ttt{size\_type} typedefed to the signed type
{}\ttt{Teuchos\_Ordinal} which is 32 bit on a 32 bit machine and 64
bit on a 64 bit machine\footnote{{}\ttt{Teuchos\_Ordinal} is
typedefed to the standard C library type {}\ttt{ptrdiff\_t} which
is always signed and 32 bit or 64 bit which are always 32 bit or 64
bit machines, respectively.}.  The reasoning for breaking from the
{}\ttt{std::vector} standard for {}\ttt{size\_type} is described
in Appendix {}\ref{sec:unsigned_size_type}.


%
{}\subsubsection{\ttt{Teuchos::ArrayView<T>}}
\label{sec:ArrayView}
%

The class {}\ttt{ArrayView}, the simplest of the Teuchos array
memory management classes, is designed to replace raw pointers in
non-persisting associations primarily for formal function array
arguments.  ({}\ttt{ArrayView} is also to be used for semi-persisting
assocations as well.)  In an optimized build, an {}\ttt{ArrayView}
object simply holds a raw base array pointer and an integer size.  In
an optimized build, {}\ttt{ArrayView} looks like in Listing
{}\ref{listing:ArrayView}.

{}\begin{listing}: {}\ttt{Teuchos::ArrayView} declaration (See
Table {}\ref{tbl:common-array-type-members} for common array members.)
\label{listing:ArrayView}
{\small\begin{verbatim}

  template<class T>
  class ArrayView {
  public:

    // Constructors/Assignment/Destructors
    ArrayView( ENull null_arg = null );
    ArrayView( T* p, size_type size );
    ArrayView(const ArrayView<T>& array);
    ArrayView(std::vector<typename ConstTypeTraits<T>::NonConstType>& vec);
    ArrayView(const std::vector<typename ConstTypeTraits<T>::NonConstType>& vec);
    ArrayView<T>& operator=(const ArrayView<T>& array);
    ~ArrayView();

    // Implicit conversion to const
    operator ArrayView<const T>() const;

    // Deep copy  
    void assign(const ArrayView<const T>& array) const;

    // Common array class members (see above) and other functions
    ...

  private:
    T *ptr_;     // Optimized implementation
    int size_;

  };

  // Non-member helpers

  template<class T>
  ArrayView<T> arrayView( T* p, typename ArrayView<T>::size_type size );

  template<class T>
  ArrayView<T> arrayViewFromVector( std::vector<T>& vec );

  template<class T>
  ArrayView<const T> arrayViewFromVector( const std::vector<T>& vec );

  template<class T>
  std::vector<T> createVector( const ArrayView<T> &av );

  template<class T>
  std::vector<T> createVector( const ArrayView<const T> &av );

  template<class T>
  bool is_null( const ArrayView<T> &av );

  template<class T>
  bool nonnull( const ArrayView<T> &av );

  template<class T>
  std::ostream& operator<<( std::ostream& out, const ArrayView<T>& av );

  template<class T2, class T1>
  ArrayView<T2> av_reinterpret_cast(const ArrayView<T1>& p1);

\end{verbatim}}
\end{listing}

% ToDo: In the code, match up the above set of declarations with the
% class ArrayView itself.  Also, test all the typedefs to make sure they
% work correctly.

A few things to note about {}\ttt{ArrayView} shown in
{}\ref{listing:ArrayView} in addition to the comments in Section
{}\ref{sec:array-classes} include:

\begin{itemize}

{}\item{}{}\ttt{ArrayView} is extremely lightweight in an optimized
build, carrying only a pointer and in integer size.  This allows you
to replace the typical pointer and separate size argument with a
single aggregate light weight object.  Therefore, it yield very
efficient code.

{}\item{}\ttt{ArrayView} in optimized mode has all trivial inlined
functions that work with the raw pointer so it is as efficient has raw
pointer code.

{}\item{}{}\ttt{ArrayView} is a drop in replacement for any code
that uses {}\ttt{std::vector} that does not grow or shrink the
container by supporting the necessary typedefs, query functions, and
iterator access.  This helps in migrating current code that uses
{}\ttt{std::vector} but should be using {}\ttt{ArrayView}.

{}\item{}{}\ttt{ArrayView} implicitly converts from an
{}\ttt{std::vector} so functions called by existing client code
that uses {}\ttt{std::vector} can be safely and transparently
refactored to use {}\ttt{ArrayView} instead of
{}\ttt{std::vector}.

{}\item{}\ttt{ArrayView} directly supports the creation of subviews
of contiguous ranges of elements.

{}\item{}\ttt{ArrayView} Supports all safe raw array pointer
implicit conversions such as from non-const to a const but does not
support implicit conversion from derived to base types which is almost
always a programming error (see Section
{}\ref{sec:problem-with-raw-array-pointers}).  Also supported is
{}\ttt{reinterpret\_cast} which is not safe but is a valid type of
conversion of array types ins low-level code.

{}\item{}\ttt{AraryView}s of {}\ttt{Array} and
{}\ttt{ArrayRCP} objects are fully supported as subviews and
implicit conversions (see Section
{}\ref{sec:teuchos-type-conversions}).

{}\item{}\ttt{ArrayView} supports a handy {}\ttt{getRawPtr()}
function that allows a client to get the base pointer address, or
null, to the array.  The standard {}\ttt{std::vector} class
supports no such function which is very painful for users.

\end{itemize}

What makes {}\ttt{ArrayView} non-trivial and special, however, is
that in a debug build, the implementation takes on a variety of
runtime checking to catch all sorts of errors such as dangling
iterators and other sub-views (Section
{}\ref{sec:detection-dangling-references}), range checking (Section
{}\ref{sec:null-dereferences-range-checking}), and other types of
checking.

It should be noted that you should almost never create an
{}\ttt{ArrayView} object directly from a raw pointer but instead
create them as views of {}\ttt{Array}, {}\ttt{ArrayRCP},
{}\ttt{Tuple } and other {}\ttt{ArrayView} object.  If you are
routinely creating {}\ttt{ArrayView} from raw pointers, then your
code is not safe and you need to study the core idioms described in
Section {}\ref{sec:idioms}.

The class {}\ttt{ArrayView} has no equivalent in boost or the
current C++ or proposed C++0x standard.  This is a critical class
needed to allow for flexibility.


%
{}\subsubsection{\ttt{Teuchos::ArrayRCP<T>}}
\label{sec:ArrayRCP}
%

The class {}\ttt{ArrayRCP} is the counterpart to
{}\ttt{ArrayView} for general flexible array views except it is
used for persisting relationships where reference-counting machinery
is required.  An {}\ttt{ArrayRCP} object can provide a contiguous
view into any array of data allocated in any way possible and can
allow the user to define what is done to release memory any way they
would like.

The class declaration for {}\ttt{Teuchos::ArrayRCP} is shown in
Listing {}\ref{listing:ArrayRCP}.

\begin{listing}: {}\ttt{Teuchos::ArrayRCP} declaration (optimized build)\\
\label{listing:ArrayRCP}
{\small\begin{verbatim}
  template<class T>
  class ArrayRCP {
  public:
  
    // Constructors/initializers
    ArrayRCP(ENull null_arg=null);
    ArrayRCP(T* p, size_type lowerOffset, size_type upperOffset,
      bool has_ownership);
    template<class Dealloc_T>
      ArrayRCP( T* p, size_type lowerOffset, size_type upperOffset,
        Dealloc_T dealloc, bool has_ownership);
    explicit ArrayRCP(size_type lowerOffset, const T& val = T());
    ArrayRCP(const ArrayRCP<T>& r_ptr);
    ~ArrayRCP();
    ArrayRCP<T>& operator=(const ArrayRCP<T>& r_ptr);

    // Object/Pointer Access Functions 
    T* operator->() const;
    T& operator*() const;
    ArrayRCP<T>& operator++();
    ArrayRCP<T> operator++(int);
    ArrayRCP<T>& operator--();
    ArrayRCP<T> operator--(int);
    ArrayRCP<T>& operator+=(size_type offset);
    ArrayRCP<T>& operator-=(size_type offset);
    ArrayRCP<T> operator+(size_type offset) const;
    ArrayRCP<T> operator-(size_type offset) const;
  
    // ArrayRCP Views
    ArrayRCP<const T> getConst() const;
    ArrayRCP<T> persistingView(size_type lowerOffset, size_type size) const;
  
    // Implicit conversions
    operator ArrayRCP<const T>() const;

    // Explicit ArrayView
    ArrayView<T> operator()() const;
  
    // Size and extent query functions 
    size_type lowerOffset() const;
    size_type upperOffset() const;
    size_type size() const;
  
    // std::vector like and other misc functions
    void assign(size_type n, const T &val);
    template<class Iter>
      void assign(Iter first, Iter last);
    void deepCopy(const ArrayView<const T>& av);
    void resize(const size_type n, const T &val = T());
    void clear();

    // Common array class members (see above)
    ...
  
    // Reference counting (same as for RCP)
    ...
  
  private:
    T *ptr_; // NULL if this pointer is null
    RCPNodeHandle node_; // NULL if this pointer is null
    size_type lowerOffset_; // 0 if this pointer is null
    size_type upperOffset_; // -1 if this pointer is null
  };
  
  // Nonmember constructors
  
  template<class T>
  ArrayRCP<T> arcp(T* p, typename ArrayRCP<T>::size_type lowerOffset,
    typename ArrayRCP<T>::size_type size, bool owns_mem = true);
  
  template<class T, class Dealloc_T>
  ArrayRCP<T> arcp(T* p, typename ArrayRCP<T>::size_type lowerOffset,
    typename ArrayRCP<T>::size_type size, Dealloc_T dealloc, bool owns_mem);
  
  template<class T>
  ArrayRCP<T> arcp( typename ArrayRCP<T>::size_type size );
  
  template<class T>
  ArrayRCP<T> arcpClone( const ArrayView<const T> &v );
  
  template<class T>
  ArrayRCP<T> arcp(const RCP<std::vector<T> > &v);
  
  template<class T>
  ArrayRCP<const T> arcp(const RCP<const std::vector<T> > &v);
  
  template<class T>
  ArrayRCP<T> arcpFromArrayView(const ArrayView<T> &av);
  
  template<class T>
  RCP<std::vector<T> > get_std_vector(const ArrayRCP<T> &ptr);
  
  template<class T>
  RCP<const std::vector<T> > get_std_vector(const ArrayRCP<const T> &ptr);

  // Customized deallocators
  ...

  // Embedded object functions
  ...

  // Extra data functions
  ...

  // Conversion functions
  ...

  // Common non-member functions
  ...

  // Other nonmember functions
  
  template<class T>
  typename ArrayRCP<T>::difference_type
  operator-(const ArrayRCP<T> &p1, const ArrayRCP<T> &p2);
  
  template<class T>
  std::ostream& operator<<( std::ostream& out, const ArrayRCP<T>& p );
\end{verbatim}}
\end{listing}

Some of the main features of the {}\ttt{ArrayRCP} class are:

{}\ttt{ArrayRCP} allows the user to allocate the contiguous array
of data in any way they would like and can define how that array is
deallocated any way they would like.

{}\ttt{ArrayRCP} returns persisting subviews of data through the
member function {}\ttt{persistingView(...)}.  This means that the
underlying array of data will not be deleted until all the subviews
are destroyed.

{}\ttt{ArrayRCP} is a full replacement for a general raw
pointer and can be used as a general iterator that always remembers
the allowed upper and lower bounds.  It supports all the appropriate
pointer array-like operations including {}\ttt{ptr+i},
{}\ttt{i+ptr}, {}\ttt{ptr-i}, {}\ttt{ptr+=i},
{}\ttt{ptr-=i}, , {}\ttt{ptr++}, {}\ttt{ptr--},
{}\ttt{*ptr}, {}\ttt{ptr->member()}, and of course
{}\ttt{ptr[i]}.  This is what allows {}\ttt{ArrayRCP} to be used
as a checked iterator implementation in debug build.

{}\ttt{ArrayRCP} can be used safely as a contiguous array by
using it through its {}\ttt{const} interface which disables all of
the pointer-like functions that change the frame of reference
(e.g. {}\ttt{ptr+=i}, {}\ttt{ptr-=i}, , {}\ttt{ptr++}, and
{}\ttt{ptr--} are disabled).

{}\ttt{ArrayRCP} can be used in place of
{}\ttt{std::vector} (and therefore {}\ttt{Array}) that only
needs to size or resize the array in baulk and does not need to
flexibly grow or shrink the array.  It does this by supporting
functions like {}\ttt{assign(...)}, {}\ttt{resize(...)}, and
{}\ttt{clear()}.  Because of the reference counting machinery that
is always part of {}\ttt{ArrayRCP}, you may not want to use
{}\ttt{ArrayRCP} instead of {}\ttt{Array} but if the overhead is
not going to be significant, then going with {}\ttt{ArrayRCP}
instead of {}\ttt{Array} can be a good choice because it is much
more flexible and allows for shared ownership.

{}\ttt{ArrayRCP} supports explicit shallow conversion to
{}\ttt{ArrayView}.  Requiring an explicit conversion from
{}\ttt{ArrayRCP} to {}\ttt{ArrayView} in consistent with
{}\ttt{RCP} and {}\ttt{Ptr}.  As explained in Section
{}\ref{sec:idioms-for-passing-arguments}, this is meant to increase
the self-documenting nature of the code.  Note that the
{}\ttt{ArrayRCP::operator()()} function is a very short-hand way to
perform this conversion.

{}\ttt{ArrayRCP} supports owning conversions from
{}\ttt{RCP}-wrapped {}\ttt{Array} and {}\ttt{std::vector}
objects.  This allows for better interoperability between code that
still uses solid reference-counting ownership semantics.

Some of the other features of the {}\ttt{ArrayRCP} class that are
common with the other classes are discussed in Sections
{}\ref{sec:conversions}, {}\ref{sec:reference-counting-machinary}, and
{}\ref{sec:debug-mode-runtime-checking}.


%
{}\subsubsection{\ttt{Teuchos::Array<T>}}
\label{sec:Array}
%

The class {}\ttt{Array} is a complete drop-in replacement for
{}\ttt{std::vector} that is integrated with the
{}\ttt{ArrayView} class for debug-mode runtime checking.  In an
optimized build, {}\ttt{Array} is nothing but an inline wrapper
around a fully encapsulated {}\ttt{std::vector} object.  This means
that in an optimized build, {}\ttt{Array} takes advantage of all of
the platform-specific optimizations contained in the native
{}\ttt{std::vector} implementation and imparts no extra space/time
overhead.  However, in a debug build, a full set of
platform-independent runtime checking is performed that is as strong
or stronger than any checked STL implementation (see {}\cite[Item
{}\#83]{C++CodingStandards05}) and in addition includes dangling
reference detection of {}\ttt{ArrayView} views (see Section
{}\ref{sec:detection-circular-references}).  {}\ttt{Array} also
supports better runtime debug output with better exception error
messages.

The class declaration for the {}\ttt{Array} class is shown in
Listing {}\ref{listing:Array}.

\begin{listing}: {}\ttt{Teuchos::Array} declaration (optimized build) \\
\label{listing:Array}
{\small\begin{verbatim}
  template<typename T>
  class Array {
  public:
  
    // Constructors/initializers
    Array();
    explicit Array(size_type n, const value_type& value = value_type());
    Array(const Array<T>& x);
    template<ypename InputIterator> Array(InputIterator first, InputIterator last);
    Array(const ArrayView<const T>& a);
    template<int N> Array(const Tuple<T,N>& t);
    ~Array();
    Array& operator=(const Array<T>& a);
  
    // Other std::vector functions
    void assign(size_type n, const value_type& val);
    template<typename InputIterator> void assign(InputIterator first,
      InputIterator last);
    iterator begin();
    iterator end();
    const_iterator begin() const;
    const_iterator end() const;
    reverse_iterator rbegin();
    reverse_iterator rend();
    const_reverse_iterator rbegin() const;
    const_reverse_iterator rend() const;
    size_type size() const;
    size_type max_size() const;
    void resize(size_type new_size, const value_type& x = value_type());
    size_type capacity() const;
    bool empty() const;
    void reserve(size_type n);
    reference operator[](size_type i);
    const_reference operator[](size_type i) const;
    reference at(size_type i);
    const_reference at(size_type i) const;
    reference front();
    const_reference front() const;
    reference back();
    const_reference back() const;
    void push_back(const value_type& x);
    void pop_back();
    iterator insert(iterator position, const value_type& x);
    void insert(iterator position, size_type n, const value_type& x);
    template<typename InputIterator> void insert(iterator position,
      InputIterator first, InputIterator last);
    iterator erase(iterator position);
    iterator erase(iterator first, iterator last);
    void swap(Array& x);
    void clear();
  
    // Conversions to and from std::vector
    Array( const std::vector<T> &v );
    std::vector<T> toVector() const;
    Array& operator=( const std::vector<T> &v );

    // Implicit conversion to ArrayView
    operator ArrayView<T>();
    operator ArrayView<const T>() const;
  
    // Common array class members (see above)
    ...
  
  private:
    std::vector<T> vec_; // Optimized implementation
  };
  
  
  // Non-member helper functions
  template<class T> ArrayRCP<T> arcp( const RCP<Array<T> > &v );
  template<class T> ArrayRCP<const T> arcp( const RCP<const Array<T> > &v );
  template<class T> ArrayRCP<T> arcpFromArray( Array<T> &a );
  template<class T> ArrayRCP<const T> arcpFromArray( const Array<T> &a );
  template<typename T> std::ostream& operator<<(std::ostream& os,
    const Array<T>& array);
  template<typename T> int hashCode(const Array<T>& array);
  template<typename T> std::vector<T> createVector( const Array<T> &a );
  std::string toString(const Array<T>& array);
  template<typename T> Array<T> fromStringToArray(const std::string& arrayStr);

  // Other common nonmember functions
  ...
\end{verbatim}}
\end{listing}

The usage of the {}\ttt{Array} class is identical to the usage of
{}\ttt{std::vector} except that it natively supports the creation
of {}\ttt{AraryView} objects that can detect and report dangling
references or attempts to resize the container when one or more
{}\ttt{ArrayView} objects are active.  The unit tests for
{}\ttt{Array} provide a complete catalog of all the debug-mode
runtime checking that {}\ttt{Array} performs.  A more general
discussion of this can be found at
{}\ref{sec:debug-mode-runtime-checking}.


%
{}\subsubsection{\ttt{Teuchos::Tuple<T,N>}}
%

The last array class discussed here is the {}\ttt{Tuple} class
which represents a compile-time sized array that implicitly converts
into a {}\ttt{ArrayView} object.  The class listing for
{}\ttt{Tuple} is shown in Listing {}\ref{listing:Tuple}.

\begin{listing}: {}\ttt{Teuchos::Tuple} declaration (optimized build) \\
\label{listing:Tuple}
{\small\begin{verbatim}
  template<typename T, int N>
  class Tuple {
  public:
    
    // Constructors/initializers
    inline Tuple();
    Tuple( const Tuple<T,N> &t );
  
    // Implicit conversion to ArrayView
    operator ArrayView<T>();
    operator ArrayView<const T>() const;
    
    // Common array class members (see above)
    ...
  
  private:
    T array_[N]; // Optimized implementation
  };
  
  // Non-member constructors
  
  template<typename T>
  Tuple<T,1> tuple(const T& a);
  
  template<typename T>
  Tuple<T,2> tuple(const T& a, const T& b);
  
  template<typename T>
  Tuple<T,3> tuple(const T& a, const T& b, const T& c);
  
  ...
  
  template<typename T>
  Tuple<T,15> tuple(const T& a, const T& b, const T& c, const T& d, const T& e,
    const T& f, const T& g, const T& h, const T& i, const T& j, const T& k,
    const T& l, const T& m, const T& n, const T& o);
\end{verbatim}}
\end{listing}

The class {}\ttt{Tuple} is very small and efficient in an optimized
build.  All the functions are inline and all data is allocated on the
stack (or statically) and does not use the free store.  In an debug
build, however, {}\ttt{Tuple} takes on all the debug checking of
all the other Teuchos array classes including the detection of
dangling {}\ttt{ArrayView} views and dangling iterators.

One of the most useful features of {}\ttt{Tuple} is that a number
of overloaded non-member constructor functions with name
{}\ttt{tuple(...)} are provided to make it easy to pass in arrays
to functions that accept them as {}\ttt{ArrayView} arguments.
Overloads of {}\ttt{tuple(...)} are currently provided from one up
through 15 arguments.  For an example using {}\ttt{tuple(...)} in a
function call, consider the function:

{\small\begin{verbatim}
  template<typename T>
  void doSomething(const ArrayView<const T>&);
\end{verbatim}}

To call the function with three int arguments, one would use:

{\small\begin{verbatim}
  doSomething<int>(tuple(1, 2, 3));
\end{verbatim}}

Note that in order to make the above function call happen and allow
the implicit conversion from {}\ttt{Tuple<int>} to
{}\ttt{ArrayView<const int>} that we had to explicitly provide the
template argument to the {}\ttt{doSomething()} function.  If
{}\ttt{doSomething()} was not a template function, this would have
not been necessary.

Also note that in an optimized build for above function call that all
data would be allocated on the stack and would not involve the
free-store.  This results in very efficient code which is important
when this is being used in an inner loop.


%
{}\subsubsection{Array views}
\label{sec:array-views}
%

One of the most powerful features of the Teuchos memory management
array types is that they allow for the creation of arbitrary
contiguous subviews of data that have the strongest debug-mode runtime
checking possible.  All of the array classes {}\ttt{ArrayView},
{}\ttt{ArrayRCP}, {}\ttt{Array}, and {}\ttt{Tuple} provide
contiguous views as {}\ttt{ArrayView} objects.  The functions the
provide {}\ttt{ArrayView} views are shown in Table
{}\ttt{tbl:common-array-type-members}.  The {}\ttt{ArrayRCP}
class can also provide persisting contiguous subviews as new
{}\ttt{ArrayRCP} objects using the function
{}\ttt{ArrayRCP::persistingView(...)}.  Persisting views will
remain even if the parent {}\ttt{ArrayRCP} objects have been deleted.

As soon as a contiguous array of data is correctly captured in
{}\ttt{Array} or and owning {}\ttt{ArrayRCP} object, all
children {}\ttt{ArrayView} objects will be protected in that if the
parent array gets selected, a debug-mode runtime check will detect and
report a problem if a client tries to access the data after the parent
has gone away (see Section {}\ref{sec:detection-dangling-references}
for details).

To demonstrate the elegance and superior error checking of
{}\ttt{ArrayView} subviews, consider a refactored version of code
in Listings {}\ref{listing:addArrayIntoArray-std-vector} and
{}\ref{listing:someBlockAlgo-std-vector} that tried to use
{}\ttt{std::vector} but resulted in verbose clumsy code that was
really no more correct or safe than the raw C++ pointer version.  This
refactored version to use {}\ttt{Array} and {}\ttt{ArrayView} is
shown in Listings {}\ref{listing:addArrayIntoArray-ArrayView} and
{}\ref{listing:someBlockAlgo-ArrayView}.

\begin{listing}: Refactored version of Listing
  {}\ref{listing:addArrayIntoArray-std-vector} to use {}\ttt{ArrayView} \\
\label{listing:addArrayIntoArray-ArrayView}
{\small\begin{verbatim}
  template<class T>
  void addArrayIntoArray( const ArrayView<const T> &a, const ArrayView<T> &b )
  {
    DEBUG_MODE_ASSERT_EQUALITY( a.size(), b.size() );
    for (int i = 0; i < a.size(); ++i)
      b[i] += a[i];
  }
\end{verbatim}}
\end{listing}

\begin{listing}: Refactored version of
  {}\ref{listing:someBlockAlgo-std-vector} to use {}\ttt{ArrayView} \\
\label{listing:someBlockAlgo-ArrayView}
{\small\begin{verbatim}
  void someBlockAlgo( const int numBlocks, const ArrayView<const double> &big_a,
    const ArrayView<double> &big_b )
  {
    DEBUG_MODE_ASSERT_EQUALITY( big_a.size(), big_b.size() );
    const int totalLen = big_a.size();
    const int blockSize = totalLen/numBlocks; // Assume no remainder!
    
    const int blockOffset = 0;
    for (int block_k = 0; block_k < numBlocks; ++block_k, blockOffset += blockSize)
    {
      if (big_a[blockOffset] > 0.0) {
        addArrayIntoArray(big_a(blockOffset, blockSize),
          big_b(blockOffset, blockSize));
      }
    }
  }
\end{verbatim}}
\end{listing}

The refactored code in Listings
{}\ttt{listing:addArrayIntoArray-ArrayView} and
{}\ttt{listing:someBlockAlgo-ArrayView} are that they are nearly as
compact as the raw pointer versions in
{}\ttt{listing:addArrayIntoArray-raw} and
{}\ttt{listing:someBlockAlgo-raw} but yet have better debug-mode
runtime error checking as the {}\ttt{std::vector} versions in
{}\ttt{listing:addArrayIntoArray-std-vector} and
{}\ttt{listing:someBlockAlgo-std-vector}.  To see the improved
safely, let's consider the case where the
{}\ttt{addArrayIntoArray(...)} function is incorrectly implemented
with an off-by-one error as shown in Listing
{}\ref{listing:addArrayIntoArray-ArrayViewError}.

\begin{listing}: Refactored version of off-by-one error in Listing
  {}\ref{listing:addArrayIntoArray_rawError} to use {}\ttt{ArrayView} \\
\label{listing:addArrayIntoArray-ArrayViewError}
{\small\begin{verbatim}
  template<class T>
  void addArrayIntoArray( const ArrayView<const T> &a, const ArrayView<T> &b )
  {
    DEBUG_MODE_ASSERT_EQUALITY( a.size(), b.size() );
    for (int i = 0; i <= a.size(); ++i)
      b[i] += a[i];
  }
\end{verbatim}}
\end{listing}

If the erroneous {}\ttt{addArrayIntoArray(...)} function in Listing
{}\ref{listing:addArrayIntoArray-ArrayViewError} were called from
Listing {}\ref{listing:someBlockAlgo-ArrayView} then in debug-mode, a
runtime exception would immediately be raised when the
{}\ttt{addArrayIntoArray(...)} function tried to access one past
the last element.  As mentioned in Section
{}\ref{sec:problems-with-mem-checkers}, memory checking tools like
Valgrind or Purify will never be able to catch semantic usage errors
like this but it is trivial to catch these mistakes when using the
Teuchos memory management classes.

As mentioned in Section {}\ttt{sec:conversions}, subviews can also
be used along with the reinterpret cast functions to create very
efficient memory management schemes for POD (plain old data) where
large untyped {}\ttt{char} arrays are created and then subviews are
broken off and reinterpret cast to specific data types.  Examples of
this can be found in the unit testing code.


%
{}\subsection{Const verses non-const pointers and objects}
\label{sec:teuchos-const-nonconst-pointer-objects}
%

The core pointer encapsulation classes {}\ttt{Ptr},
{}\ttt{RCP}, {}\ttt{ArrayView} and {}\ttt{ArrayRCP} allow for
the underlying object (or array of objects) to be const or non-const
and for the outer pointer type to be const or non-const, just like
with a regular C++ pointer.  To draw the analogy with raw pointers,
consider the equivalent declarations of a raw pointer and the pointer
encapsulation class (using {}\ttt{RCP} as a stand-in to represent
all four classes) in Table
{}\ref{tbl:teuchos-const-nonconst-pointer-objects}.

\begin{table}
%
%\fbox{
\begin{center}
%
%\begin{minipage}{{}\textwidth}
%
\input{RawPointerSmartPointerEquivalencies}
%
%\end{minipage}
%
\end{center}
%} % end fbox
\caption{\label{tbl:teuchos-const-nonconst-pointer-objects}
Equivalences between raw pointer and smart pointer types for const
protection.}
%
\end{table}

The majority of problems that beginners have with the Teuchos memory
management classes is related to the inability to make the basic
equivalencies between raw pointers and smart pointers shown in Table
{}\ref{tbl:teuchos-const-nonconst-pointer-objects} (see Section
{}\ref{sec:conversion-problems} for specific examples).  It is
critical that the programmer recognize this equivalence with raw
pointers because it impacts many things especially implicit type
conversions to satisfy function calls (again see Section
{}\ref{sec:conversions}).


%
{}\subsection{Conversions}
\label{sec:conversions}
%

Type conversions exist both for a single smart pointer type for the
embedded type argument (e.g.\ {}\ttt{RCP<Derived>} implicitly converts
to {}\ttt{RCP<const Derived>}, {}\ttt{RCP<Base>}, and {}\ttt{RCP<const
Base>}) and also between different smart pointer types (e.g.\
{}\ttt{Array} implicitly converts to {}\ttt{ArrayView}).  There are
implicit conversions and explicit conversions.  These two types of
conversions are shown in Figures {}\ref{fig:TeuchosPtrConversions} and
{}\ref{fig:TeuchosArrayConversions} and are described in the following
two sections.


{\bsinglespace
\begin{figure}[p]
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.50]{TeuchosPtrConversions}
%}
\end{center}
\caption{
\label{fig:TeuchosPtrConversions}
Conversions between different single-object memory management types.}
\end{figure}
\esinglespace}


{\bsinglespace
\begin{figure}[p]
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.50]{TeuchosArrayConversions}
%}
\end{center}
\caption{
\label{fig:TeuchosArrayConversions}
Conversions between array memory management types.  }
\end{figure}
\esinglespace}


%
{}\subsubsection{Implicit and explicit raw-pointer-like conversions}
\label{sec:raw-pointer-like-type-conversions}
%

The core Teuchos memory management types {}\ttt{Ptr},
{}\ttt{RCP}, {}\ttt{ArrayView} and {}\ttt{ArrayRCP} allow all
of the reasonable implicit and explicit type conversions that are
allowed by raw C++ pointers.  C++ defines implicit converts for raw
pointers from non-const to const and from derived to base type.  Table
{}\ref{tbl:implicit_explicit_conversions} shows what implicit and
explicit conversions are supported for the four core memory management
types.


\begin{table}
\begin{center}
\input{BasicSupportedImplicitExplictConversions}
\end{center}
\caption{\label{tbl:implicit_explicit_conversions}
Basic implicit and explicit conversions by smart-pointer types.}
\end{table}


As seen in Table {}\ref{tbl:implicit_explicit_conversions}, the smart
pointer types for single objects do not support the same implicit and
explicit conversions that are supported for the array smart pointer
types.  As explained in Section
{}\ref{sec:problem-with-raw-array-pointers}, it almost always
incorrect and dangerous to allow implicit conversions from derived to
base type for pointers that pointers that point into contiguous arrays
of objects.  Therefore, the types {}\ttt{ArrayView} and
{}\ttt{ArrayRCP} do not support implicit conversions from derived to
base types.  Due to similar logic, it almost never makes any sense to
perform a static cast or a dynamic on a pointer to an array of
contiguous objects so the types {}\ttt{ArrayView} and {}\ttt{ArrayRCP}
do not support static and dynamic casts.

In well formed programs, there is a justification to perform
reinterpret casts for contiguous arrays of POD (plain old data). It is
perfectly reasonable to allocate a large array of {}\ttt{char}
(untyped) data and then create subviews and reinterpret cast to
separate arrays of {}\ttt{double} and {}\ttt{int} data, for instance.
However, in a well formed program there is not single valid reason to
perform a reinterpret cast for single objects and therefore
reinterpret cast is not supported for the types {}\ttt{Ptr} and
{}\ttt{RCP}.

The allowed implicit conversions for {}\ttt{Ptr} and {}\ttt{RCP} are
supported templated copy constructors (see Sections {}\ref{sec:Ptr}
and {}\ref{sec:RCP}).  However, the only allowed implicit conversion
from {}\ttt{T*} to {}\ttt{const T*} for {}\ttt{ArrayView} and
{}\ttt{ArrayRCP} are instead supported through conversion member
functions (see Sections {}\ref{sec:ArrayView} and
{}\ref{sec:ArrayRCP}).  The supported explicit conversion operators
for these four types are shown in the Listings
{}\ref{listing:Ptr-conversions}, {}\ref{listing:RCP-conversions},
{}\ref{listing:ArrayView-conversions}, and
{}\ref{listing:ArrayRCP-conversions}.


{}\begin{listing}: Conversion functions for {}\ttt{Ptr}
\label{listing:Ptr-conversions}
{\small\begin{verbatim}
  template<class T2, class T1> Ptr<T2> ptr_implicit_cast(const Ptr<T1>& p1);
  template<class T2, class T1> Ptr<T2> ptr_static_cast(const Ptr<T1>& p1);
  template<class T2, class T1> Ptr<T2> ptr_const_cast(const Ptr<T1>& p1);
  template<class T2, class T1> Ptr<T2> ptr_dynamic_cast(const Ptr<T1>& p1,
    bool throw_on_fail = false);
\end{verbatim}}
\end{listing}


\begin{listing}: Conversion functions for RCP\\
\label{listing:RCP-conversions}
{\small\begin{verbatim}
  template<class T2, class T1> RCP<T2> rcp_implicit_cast(const RCP<T1>& p1);
  template<class T2, class T1> RCP<T2> rcp_static_cast(const RCP<T1>& p1);
  template<class T2, class T1> RCP<T2> rcp_const_cast(const RCP<T1>& p1);
  template<class T2, class T1> RCP<T2> rcp_dynamic_cast(const RCP<T1>& p1,
    bool throw_on_fail = false);
\end{verbatim}}
\end{listing}


\begin{listing}: Conversion functions for ArrayView\\
\label{listing:ArrayView-conversions}
{\small\begin{verbatim}
  template<class T2, class T1> ArrayView<T2> av_const_cast(const ArrayView<T1>& p1);
  template<class T2, class T1> ArrayView<T2> av_reinterpret_cast(const ArrayView<T1>& p1);
\end{verbatim}}
\end{listing}


\begin{listing}: Conversion functions for ArrayRCP\\
\label{listing:ArrayRCP-conversions}
{\small\begin{verbatim}
  template<class T2, class T1> ArrayRCP<T2> arcp_const_cast(const ArrayRCP<T1>& p1);
  template<class T2, class T1> ArrayRCP<T2> arcp_reinterpret_cast(const ArrayRCP<T1>& p1);
\end{verbatim}}
\end{listing}


Note that the dynamic cast conversion functions
{}\ttt{ptr\_dynamic\_cast()} and {}\ttt{ptr\_dynamic\_cast()}
both take an option extra argument {}\ttt{throw\_on\_fail} that if
set to {}\ttt{true} will result in an exception being thrown on a
dynamic cast failure along with a very helpful error message.


%
{}\subsubsection{Conversions between different memory management types}
\label{sec:teuchos-type-conversions}
%

It is critical that all conversions between the various Teuchos memory
management classes be performed using conversion code provided by the
memory management classes themselves or by associated helper
functions.  Client code should never convert between memory management
types by exposing a raw C++ pointer.  As soon as a raw C++ pointer is
exposed, nearly all of the debug-mode runtime checking will be
disabled.

Figures {}\ref{fig:TeuchosPtrConversions} and
{}\ref{fig:TeuchosArrayConversions} show many of the types of
conversions that are supported between the different memory management
types.  Specific conversions are shown in more detail in Tables
{}\ref{tbl:ConversionsTableSingleObjs} and
{}\ref{tbl:ConversionsTableArrays}.  For single objects, the
conversions between different {}\ttt{RCP} and {}\ttt{Ptr} objects of
various kinds shown in Figure {}\ref{fig:TeuchosPtrConversions} and
Table {}\ref{tbl:ConversionsTableSingleObjs} include both implicit and
explicit conversions.  Conversions between different array types shown
in Figure {}\ref{fig:TeuchosArrayConversions} and Table
{}\ref{tbl:ConversionsTableArrays} include both implicit and explicit
conversions and view and copy conversions yielding various types of
conversions.


\begin{table}
\begin{center}
\input{ConversionsTableSingleObjs}
\caption{\label{tbl:ConversionsTableSingleObjs}
Summary of basic conversions supported involving single objects.}
\end{center}
\end{table}


\begin{table}
\begin{center}
\input{ConversionsTableArrays}
\caption{\label{tbl:ConversionsTableArrays}
Summary of basic conversions supported for contiguous arrays.}
\end{center}
\end{table}

The conversions shown in Tables {}\ref{tbl:ConversionsTableSingleObjs}
and {}\ref{tbl:ConversionsTableArrays} are the most basic conversions
supported by the Teuchos memory managment types but are not the only
supported conversions.  The see the full set of type conversions
supported, consult the Doxygen generated
documentation\footnote{\ttt{http://trilinos.sandia.gov/packages/teuchos}}.
Note that full debug-mode runtime checking is fully enabled for every
conversion between Teuchos memory managment types, including full
dangling-reference detection and reporting when creating
non-reference-counting types {}\ttt{Ptr} and {}\ttt{ArrayView}.  In
general, dangling references cannot be detected when converting from
raw pointers and references or for {}\ttt{std::vector}.  However,
there are a few special cases where non-owning {}\ttt{Ptr},
{}\ttt{RCP}, and {}\ttt{ArrayView}, {}\ttt{ArrayRCP} objects created
from raw C++ pointers (or references) will be able to detect dangling
references through the sophisticated debug-mode node tracing system
(see Sections {}\ref{sec:detection-dangling-references} and
{}\ref{sec:limitations-debug-mode-checking} for details).


%
{}\subsubsection{Implicit type conversion problems and shortcomings}
\label{sec:conversion-problems}
%

Implicit conversions between different Teuchos memory management
types, especially in templated application code, is one of the most
confusing aspects of using these classes.  As shown in Figures
{}\ref{fig:TeuchosPtrConversions} and
{}\ref{fig:TeuchosArrayConversions}, many different implicit
conversions are defined.  An implicit conversion will only be
performed by the C++ compiler to satisfy the formal arguments for a
function call when several conditions are satisfied: a) when it is
needed to call a function where no other better functions provide a
better match, b) when a only a single implicit conversion for each
argument is sufficient, and c) when calling a non-template function
(or a template function where all of the template arguments are
explicitly specified).  Also, the C++ compiler will not be able to do
an implicit conversion when an ambiguous function call exists.
Explaining the behavior of these implicit conversions in C++ gets down
to the low-level details of the C++ type system that many C++
programmers take for grated or don't understand all that well.

Almost all of the problems that people have with implicit conversions
occur when trying to call functions where implicit conversions are
required to satisfy the signature of the function.  Some of these
problems occur when developers fail to understand the C++ type system.
Other problems are due to a fundamental handicap that smart pointer
types have with respect to raw C++ pointers.

Implicit conversions of the Teuchos memory management classes (or any
other C++ classes in any other library) needed to call a given
function fail for one of the following reasons:

\begin{enumerate}

{}\item{}Implicit conversions to functions fail because the memory
management types are not passed by const reference (or by value) and
are mistakenly (or on purpose) passed by non-const reference. (This is
a programming error.)

{}\item{}Implicit conversions fail because templated functions can not
perform implicit conversions in order to satisfy a call. (This is a
language usability annoyance associated with templates but also
represents a fundamental shortcoming of smart pointers compared to raw
C++ pointers.)

{}\item{}Implicit conversions fail due to ambiguous overloaded calls
to overloaded functions that would otherwise work just fine when raw
C++ pointers are involved. (This is a fundamental shortcoming of smart
pointers or any other class as compared to raw C++ pointers.)

\end{enumerate}

Let's consider each of these types of problems one at a time.  The
class hierarchy shown in Listing {}\ref{listing:Base-Derived-Classes}
will be used in demonstration code.


{}\begin{listing}: Basic base and derived classes
\label{listing:Base-Derived-Classes}
{\small\begin{verbatim}
  class Base { ... };
  class Derived : public Base { ... };
\end{verbatim}}
\end{listing}


%
{}\subsubsection*{Implicit conversions failing due to passing by
non-const reference}
%


First, consider implicit conversion problems caused by erroneously
passing Teuchos memory management objects by non-const references
instead of by const reference.  Consider the user-written function in
Listing {}\ref{listing:someUserFunction-pass-by-non-const-ref} that
mistakenly passes an {}\ttt{RCP} by non-const reference.


{}\begin{listing}: User function with a bad pass by non-const
reference problem
\label{listing:someUserFunction-pass-by-non-const-ref}
{\small\begin{verbatim}
  void someUserFunction(RCP<const Base> &base); // Should be 'const RCP<...>&'

  void someOtherUserFunction()
  {
     RCP<Derived> derived(new Derived);
     someUserFunction(derived);  // Compile error, no implicit conversion!
     RCP<const Derived> cderived = derived;
     someUserFunction(cderived); // Compile error, no implicit conversion!
     RCP<Base> base = derived;
     someUserFunction(base);     // Complile error, no implicit conversion!
     RCP<const Base> cbase = base;
     someUserFunction(cbase);    // Compliles fine, exact match!
  }
\end{verbatim}}
\end{listing}


When user code tries to call {}\ttt{someUserFunction(...)} as shown in
Listing {}\ref{listing:someUserFunction-pass-by-non-const-ref}, the
C++ compiler refuses to perform the implicit type conversions because
the compiler will never perform an implicit type conversion for an
argument passed by non-const reference.  This type of error is made at
least once by most developers when they first start using the Teuchos
memory management classes and they can't understand why the code does
not compile.  To understand why the implicit conversions in Listing
{}\ref{listing:someUserFunction-pass-by-non-const-ref} are not
occurring, one must understand the C++ type system in how it handles
basic type conversions.  The C++ standard specifies that implicit type
conversions to facilitate the call of a C++ function will only occur
for arguments passed by value or by {}\textit{const} reference.  For
example, a C++ compiler will convert an {}\ttt{int} into a
{}\ttt{double} to call a function taking a {}\ttt{double} argument but
only if the double is passed by value or by const reference (i.e.\
{}\ttt{const double\&}).  The same holds true for C++ pointer types.
Note that every pointer type (e.g.\ {}\ttt{int*}, {}\ttt{SomeType*})
is a new C++ value-type data type that is automatically defined by the
compiler for every defined type.  The C++ compiler also automatically
defines implicit conversions between pointer types for {}\ttt{T*} to
{}\ttt{const T*} and for {}\ttt{Base*} to {}\ttt{Derived*} (or
combinations of both {}\ttt{Derived*} to {}\ttt{const Derived*}).
While C++ pointer data types have a special place in the C++ language,
they behave exactly like every other data type in C++ with respect to
implicit conversions.  That is, if a pointer object is passed by
non-const reference instead of by value, the compiler will refuse the
perform the type conversion.  For example, the equivalent code to
Listing {}\ref{listing:someUserFunction-pass-by-non-const-ref}
replacing {}\ttt{RCP} with raw pointers shown in Listing
{}\ref{listing:someUserFunction-pass-by-non-const-ref-raw-ptr} will
also result in code that will not compile.


{}\begin{listing}: User function with a bad pass by non-const
reference problem using raw pointers
\label{listing:someUserFunction-pass-by-non-const-ref-raw-ptr}
{\small\begin{verbatim}
  typedef const Base* ptr_const_Base; // Equivalent to RCP<const Base>

  void someUserFunction(ptr_const_Base &base); // Bad pass by non-const ref!

  void someOtherUserFunction()
  {
     Derived *derived = new Derived;
     someUserFunction(derived);   // Compile error, no implicit conversion!
     const Derived *cderived = derived;
     someUserFunction(cderived); // Compile error, no implicit conversion!
     Base *base = derived;
     someUserFunction(base);     // Complile error, no implicit conversion!
     const Base *cbase = base;
     someUserFunction(cbase);    // Compliles fine, exact match!
  }
\end{verbatim}}
\end{listing}


The way to fix this problem is to pass the Teuchos memory management
types (or any other type you want the compiler to perform an implicit
conversion on) by const reference.  For example, fixing the code in
Listing {}\ref{listing:someUserFunction-pass-by-non-const-ref} to pass
by const reference shown in Listing
{}\ref{listing:someUserFunction-pass-by-const-ref} results in code
that compiles just fine with the C++ compiler performing all of the
expected implicit conversions.


{}\begin{listing}: User function with corrected pass by const
reference
\label{listing:someUserFunction-pass-by-const-ref}
{\small\begin{verbatim}
  void someUserFunction(const RCP<const Base> &base); // Now correct!

  void someOtherUserFunction()
  {
     RCP<Derived> derived(new Derived);
     someUserFunction(derived);  // Compiles fine, Derived* -> const Base*
     RCP<const Derived> cderived = derived;
     someUserFunction(cderived); // Compiles fine, const Derived* -> const Base*
     RCP<Base> base = derived;
     someUserFunction(base);     // Compiles fine, Base* -> const Base*
     RCP<const Base> cbase = base;
     someUserFunction(cbase);    // Compliles fine, exact match!
  }
\end{verbatim}}
\end{listing}


%
{}\subsubsection*{Implicit conversions failing due to templated function}
%

Another situation where implicit conversions will fail to be performed
to satisfy a function call are when the function being called is a
template function.  The C++98 standard does not the implicit
conversion of input arguments in order to call a template function
{}\cite[Item 45]{EffectiveC++ThirdEdition}.  For example, consider the
code in Listing {}\ref{listing:implicit-conv-fail-template-func} that
fails to compile:


{}\begin{listing}: Situation where implicit conversion fails due to a
template function.
\label{listing:implicit-conv-fail-template-func}
{\small\begin{verbatim}
  template<class T> class Base { ... };
  template<class T> class Derived : public Base<T> { ... };

  template<class T>
  void someTemplateUserFunction(const RCP<const Base<T> > &base);

  template<class T>
  void someOtherTemplateUserFunction()
  {
     RCP<Derived<T> > derived(new Derived<T>);
     someTemplateUserFunction(derived);   // No implicit conv, no compmile!
     RCP<const Derived<T> > cderived = derived;
     someTemplateUserFunction(cderived);  // No implicit conv, no compmile!
     RCP<Base<T> > base = derived;
     someTemplateUserFunction(base);      // No implicit conv, no compmile!
     RCP<const Base<T> > cbase = base;
     someTemplateUserFunction(cbase);     // Exact match, compiles!
  }
\end{verbatim}}
\end{listing}


What is frustrating and yet interesting about this situation is that
if the {}\ttt{RCP}s are replaced with raw pointers, as shown in
Listing {}\ref{listing:implicit-conv-pass-raw--template-func}, the C++
compiler will perform the implicit type conversions just fine.


{}\begin{listing}: Example where implicit conversion to call a
template function works fine when using raw C++ pointers.
\label{listing:implicit-conv-pass-raw--template-func}
{\small\begin{verbatim}
  template<class T>
  void someTemplateUserFunction(const Base<T> *base);
  
  template<class T>
  void someOtherTemplateUserFunction()
  {
    Derived<T> *derived = new Derived<T>;
    someTemplateUserFunction(derived);  // Okay, Derived<T>* -> const Base<T>*
    const Derived<T> *cderived = derived;
    someTemplateUserFunction(cderived); // Okay, const Derived<T>* -> const Base<T>*
    Base<T> *base = derived;
    someTemplateUserFunction(base);     // Okay, Base<T>* -> const Base<T>*
    const Base<T> *cbase = base;
    someTemplateUserFunction(cbase);    // Okay, exact match!
  }
\end{verbatim}}
\end{listing}


Comparing the templated code in Listing
{}\ref{listing:implicit-conv-fail-template-func} and Listing
{}\ref{listing:implicit-conv-pass-raw--template-func} it is clear that
C++ assigns special privileges and abilities to the conversion of
pointer data types that are not afforded to any other data type.  This
is the first example of where smart pointer classes in C++ are put at
a fundamental disadvantage with respect to raw C++ pointers.  This is
an unfortunate situation but the problem can be dealt with by either
forcing the conversion of the input arguments or by explicitly
specifying the template arguments as shown, for example, in Listing
{}\ref{listing:implicit-conv-pass-explicit-template-func}.


{}\begin{listing}: Explicitly specifying function template arguments
and forcing conversions to call templated function.
\label{listing:implicit-conv-pass-explicit-template-func}
{\small\begin{verbatim}
  template<class T>
  void someTemplateUserFunction(const RCP<const Base<T> > &base);

  template<class T>
  void someOtherUserTemplateFunction()
  {
     RCP<Derived<T> > derived(new Derived<T>);
     // Force the conversion Derived<T>* -> const Base<T>*
     someTemplateUserFunction(RCP<const Base<T> >(derived));
     // or, specify template argument allowing implicit conversion
     // Derived<T>* -> const Base<T>*
     someTemplateUserFunction<T>(derived);
     ...
  }
\end{verbatim}}
\end{listing}


As shown in Listing
{}\ref{listing:implicit-conv-pass-explicit-template-func} typically
the least verbose way to call a template function that requires a
conversion of {}\ttt{RCP} input arguments is to just explicitly
specify the template argument(s) which turns the template function
into a regular function in the eyes of the C++ compiler and then the
implicit conversion will be performed.


%
{}\subsubsection*{Implicit conversions failing due to ambiguous
overloaded function calls}
%

The last situation to discuss where implicit conversions will fail to
be performed for the Teuchos memory management types occurs when
calling overloaded functions that require a conversion of the internal
pointer type that would otherwise work just fine for raw C++ pointers.
Consider the example code in Listing
{}\ref{listing:overloaded-func-implicit-conv-problem} showing the use
of overloaded functions that differ in the const type of the object.


{}\begin{listing}: Example of ambiguous calls to overloaded functions
\label{listing:overloaded-func-implicit-conv-problem}
{\small\begin{verbatim}
  class Base { ... };
  class Derived : public Base { ... };

  void someUserFunction(const RCP<Base> &base);         // Overload #1
  void someUserFunction(const RCP<const Base> &base);   // Overload #2

  void someOtherUserFunction()
  {
     RCP<Derived> derived(new Derived);
     someUserFunction(derived);  // Compile error, ambiguous call
     RCP<const Derived> cderived = derived;
     someUserFunction(cderived); // Compile error, ambiguous call
     RCP<Base> base = derived;
     someUserFunction(base);     // Okay, exact match for Overload #1
     RCP<const Base> cbase = base;
     someUserFunction(cbase);    // Okay, exact match for Overload #2
  }
\end{verbatim}}
\end{listing}


The reason that the first two function calls in Listing
{}\ref{listing:overloaded-func-implicit-conv-problem} with
{}\ttt{RCP<Derived>} and {}\ttt{RCP<const Derived>} result in
ambiguous function call compile errors is that the C++ compiler is not
smart enough to know that a conversion from {}\ttt{RCP<Derived>} to
{}\ttt{RCP<Base>} is better than a conversion to {}\ttt{RCP<const
Base>} which would allow the first function call to result in a call
to Overload \#1.  However, if raw C++ pointers are used in same code,
as shown in Listing
{}\ref{listing:overloaded-func-implicit-conv-raw-pass}, the compiler
will make the right implicit conversions and call the right overloaded
functions just fine.


{}\begin{listing}: Example of implicit conversions for overloaded
functions that work just fine for raw pointers
\label{listing:overloaded-func-implicit-conv-raw-pass}
{\small\begin{verbatim}
  void someUserFunction(Base *base);         // Overload #1
  void someUserFunction(const Base *base);   // Overload #2

  void someOtherUserFunction()
  {
     Derived *derived = new Derived;
     someUserFunction(derived);  // Calls Overload #1: Derived* -> Base*
     const Derived *cderived = derived;
     someUserFunction(cderived); // Calls Overload #2: const Derived* -> const Base*
     Base *base = derived;
     someUserFunction(base);     // Okay, exact match for Overload #1
     const Base *cbase = base;
     someUserFunction(cbase);    // Okay, exact match for Overload #2
  }
\end{verbatim}}
\end{listing}


Again, similar to the templated function example given above,
comparing Listing
{}\ref{listing:overloaded-func-implicit-conv-problem} and Listing
{}\ref{listing:overloaded-func-implicit-conv-raw-pass}, it is clear
that the conversions of raw C++ pointer types to call overloaded
functions are given special privileges and abilities that are not
afforded to any type data type in C++.  The C++ compiler will resolve
overloaded functions for the conversion of C++ pointer types based on
the least required conversions (e.g.\ {}\ttt{Derived*} to
{}\ttt{Base*} is better than {}\ttt{Derived*} to {}\ttt{const Base*}).
This is wonderful behavior for raw C++ pointers (or perhaps confusing
depending on how you look at it) but such special abilities are not
afforded to smart pointer types like {}\ttt{Ptr} or {}\ttt{RCP} (or
any other smart pointer type including {}\ttt{boost::shared\_ptr}).

Problems in calling overloaded functions like this can be resolved but
only through explicitly converting the input arguments as shown in
Listing {}\ref{listing:overloaded-func-implicit-conv-explicit-pass}.


{}\begin{listing}: Example of resolving ambiguous calls to overloaded
functions through explicit argument conversions
\label{listing:overloaded-func-implicit-conv-explicit-pass}
{\small\begin{verbatim}
  void someUserFunction(const RCP<Base> &base);         // Overload #1
  void someUserFunction(const RCP<const Base> &base);   // Overload #2

  void someOtherUserFunction()
  {
     RCP<Derived> derived(new Derived);
     someUserFunction(RCP<Base>(derived));        // Calls Overload #1
     someUserFunction(RCP<const Base>(derived));  // Calls Overload #2
     ...
  }
\end{verbatim}}
\end{listing}


Having to explicitly convert input arguments to satisfy overloaded
function calls gets annoying very quickly for any reasonable-minded
programmer.  A much better way to deal with the problem of overload
functions and smart pointer types is to not use overloaded functions in
the first place as demonstrated in Listing
{}\ref{listing:overloaded-func-implicit-conv-nonoverload}.


{}\begin{listing}: Example of resolving ambiguous calls to overloaded
functions by not using overloaded functions in the first place
\label{listing:overloaded-func-implicit-conv-nonoverload}
{\small\begin{verbatim}
  void someNonconstUserFunction(const RCP<Base> &base);
  void someUserFunction(const RCP<const Base> &base);

  void someOtherUserFunction()
  {
     RCP<Derived> derived(new Derived);
     // Compiles fine, implicit conv: Derived* -> Base*
     someNonconstUserFunction(derived);
     // Compiles fine, implicit conv: Derived* -> const Base*
     someUserFunction(derived);
     ...
  }
\end{verbatim}}
\end{listing}


Avoiding problems with ambiguous function calls to overloaded
functions by avoiding overloaded functions (as demonstrated in Listing
{}\ref{listing:overloaded-func-implicit-conv-nonoverload}) may seem
like a bit of cop-out but in general function overloading tends to be
abused in C++ anyway.  In many cases, code can be much more clear by
using different function names in cases where most developers would
just use overloaded functions (perhaps because they cannot think of
better non-overloaded names).


%
{}\subsection{Core idioms for the use of memory management classes}
\label{sec:idioms}
%

Well designed C++ class libraries are created together with a set of
idioms for their use and this is especially true for the Teuchos
Memory Management classes.  This paper describes idioms related to the
creation of single dynamically allocated objects, for defining and
using local variables and data members, for passing objects and arrays
of objects to and from functions, and for returning objects and arrays
of objects as return values from functions.  It is critical that these
idioms be used consistently in order to yield the safest, highest
quality, clearest code.


%
{}\subsubsection{The non-member constructor function idiom}
\label{sec:nonmember-constructor-idiom}
%

The mainstream C++ literature espousing the use of smart
reference-counted pointers like {}\ttt{boost::shared\_ptr} seems to
lack a solution for an effective, safe, and clean way to create new
dynamically allocated objects.  To demonstrate the issues involved,
consider the C++ class {}\ttt{Blaget} shown in Listing
{}\ref{listing:BlagetClass}:

\begin{listing}: A class taking multiple dynamically allocatable objects \\
\label{listing:BlagetClass}
{\small\begin{verbatim}
  class Blaget {
  public:
    Blaget(const RCP<Widget> &widgetA, const RCP<Widget> const widgetB);
      widgetA_(widget), widgetB_(widget) {}
    ...
  private:
    RCP<Widget> widgetA_;
    RCP<Widget> widgetB_;
  };
\end{verbatim}}
\end{listing}

Now consider how you might go about constructing a {}\ttt{Blaget}
object on the stack given newly dynamically allocated
{}\ttt{Widget} objects.  A compact, clean, and seemingly safe way
to do so is shown in Listing {}\ref{listing:BlagetConstruct1}.

\begin{listing}: A leaky way to construct \\
\label{listing:BlagetConstruct1}
{\small\begin{verbatim}
  Blaget blaget( rcp(new Widget()), rcp(new Widget()) );
\end{verbatim}}
\end{listing}

The problem with the code in Listing {}\ref{listing:BlagetConstruct1}
is that it might result in a memory leak if an exception is thrown by
one of the constructors for {}\ttt{Widget} (see {}\cite[Item
13]{C++CodingStandards05}).  The reason that a memory leak might occur
is that a C++ compiler is allowed to evaluate both {}\ttt{new
Widget()} calls before calling the {}\ttt{rcp()} functions.
If the second constructor {}\ttt{Widget()} throws an exception
after the first {}\ttt{Widget()} constructor has been invoked
but before the {}\ttt{RCP} object wrapping the first
{}\ttt{Widget} object is constructed, then the memory created by
the first {}\ttt{new Widget()} will never be reclaimed.

The current C++ literature (see {}\cite[Item
13]{C++CodingStandards05}) recommends rewriting constructor code like
shown in Listing {}\ref{listing:BlagetConstruct1} using temporary local
variables as shown in Listing {}\ref{listing:BlagetConstruct2}.

\begin{listing}: A sound but verbose way to construct \\
\label{listing:BlagetConstruct2}
{\small\begin{verbatim}
  RCP<Widget> widgetA(new Widget());
  RCP<Widget> widgetB(new Widget());
  Blaget blaget(widgetA, widgetB);
\end{verbatim}}
\end{listing}

While the code in Listing {}\ref{listing:BlagetConstruct2} will avoid a
memory leak being created in case an exception is thrown, competent
Java and Python programs will rightfully be disgusted that they have
to create temporary variables just to call another constructor.  From
a software engineering perspective, it is undesirable to create
useless local {}\ttt{RCP} objects like {}\ttt{widgetA} and
{}\ttt{widgetB} because they might be inadvertently copied and used
for other purposes, resulting in undesirable side-effects.

The way to solve the problems described above is to provide non-member
constructor functions for all of your dynamically allocatable
reference-type classes and then always call them to create your
{}\ttt{RCP}-wrapped objects in client code.  In fact, to avoid
mistakes when using reference-type classes, you should disallow the
creation of the objects except through a provided non-member
constructor.  A {}\textit{non-member constructor} compliant
{}\ttt{Widget} class declaration is shown in Listing
{}\ref{listing:WidgetNonmemberConstructor}.

{}\begin{listing}: The non-member constructor idiom for reference-type
classes
\label{listing:WidgetNonmemberConstructor}
{\small\begin{verbatim}
  class Widget {
  public:
    static RCP<Widget> create() { return rcp(new Widget); }
    void display(std::ostream&);
  private: // or protected
    // Not for user's to call!
    Widget();
    Widget(const Widget&);
    Widget& operator=(const Widget&);
  };

  // Non-member constructor function
  inline RCP<Widget> widget()
  { return Widget::create(); }
\end{verbatim}}
\end{listing}

Using the non-member constructor function {}\ttt{widget()}, the unsafe
constructor call in Listing {}\ref{listing:BlagetConstruct1} can be
written as shown in Listing {}\ref{listing:BlagetConstruct3}.

{}\begin{listing}: Clean and bullet-proof way using the ``non-member
constructor function'' idiom
\label{listing:BlagetConstruct3}
{\small\begin{verbatim}
  Blaget blaget(widget(), widget());
\end{verbatim}}
\end{listing}

The code in Listing {}\ref{listing:BlagetConstruct3} will never result
in a memory leak if an exception is thrown because each argument is
returned as a fully formed {}\ttt{RCP} object which will clean up
memory if any exception is thrown.

Note that the use of the {}\textit{non-member constructor idiom} not
only means that raw calls to {}\ttt{delete} are eliminated from all
high-level C++ code, but it also means that raw calls to
{}\ttt{new} should be largely eliminated as well!

The non-member constructor idiom as shown in Listing
{}\ref{listing:WidgetNonmemberConstructor} where a reference-type
object can only be dynamically allocated and returned wrapped in an
{}\ttt{RCP} object is recommended for all reference-type objects.
The reason for this is that, as described in Section
{}\ref{sec:reference-counting-machinary}, when an object is
dynamically allocated in managed in an {}\ttt{RCP} object, a number
of important debug-mode runtime checks can be performed which cannot
be when the object is first allocated on the stack or managed as a
static object.


%
{}\subsubsection{General idioms for handling arrays of objects}
%

Before describing specific idioms for class data members, formal
function arguments, and function return types it is worth discussing
how arrays of objects are treated in a common way in all of these
idioms and why.  A common set of idioms that is used throughout is how
arrays of value-type objects and reference-types objects are handled.
When dealing with an array of value-type objects, typically a
contiguous array of objects will be allocated.  For example, to create
an array of value-type objects you would declare:

{\small\begin{verbatim}
  Array<S> valTypeArray;
\end{verbatim}}

In this case, the array holding value-type objects and the value-type
objects themselves are one in the same.  The same goes for persisting
and non-persisting views of array of value-type objects represented as
{}\ttt{ArrayRCP<[const] S>} and {}\ttt{ArrayView<[const] S>},
respectively.  It is common for numerical programs to create very
large arrays of value-type objects such as for integers and floating
point numbers.  Therefore, it is usually important to share these
arrays and pass them around instead of creating copies.  Because if
this, it is typical to see {}\ttt{ArrayRCP<[const] S>} being used
to share large value-type arrays of objects.

On the other hand, we can't generally allocate a contiguous array of
reference-type objects.  Instead, we have to allocate and use a
contiguous array of (smart) pointer objects that then point to
individually allocated reference-type objects.  For example, to store
an array of dynamically allocated reference-type objects, you would
declare:

{\small\begin{verbatim}
  Array<RCP<A> > refTypeArray;
\end{verbatim}}

Anyone familiar with object-oriented programming in C++ should already
knows this, but they might be used to allocating and working with
arrays of raw pointers like {}\ttt{std::vector<T*>}.  This is a
really bad idea of course which is mentioned in Item 79 ``Store only
values and smart pointers in containers'' in
{}\cite{C++CodingStandards05}.  In this case, we can think of the
array of {}\ttt{RCP} value-type objects and the reference-type
objects of type {}\ttt{A} themselves to be different objects.  For
example, you can change what {}\ttt{A} object is pointed to in the
{}\ttt{RCP<A>} object stored in the contiguous array to without
changing the {}\ttt{A} object itself such as with:

{\small\begin{verbatim}
  void foo(Array<RCP<A> > &refTypeArray, const RCP<A> &someA)
  {
    refTypeArray[0] = someA;
  }
\end{verbatim}}

Likewise, we can change an {}\ttt{A} object itself without
disturbing the {}\ttt{Array<RCP<A> >} object itself such as with:

{\small\begin{verbatim}
  void foo(const Array<RCP<A> > &refTypeArray)
  {
    refTypeArray[0]->someChange();
  }
\end{verbatim}}

As opposed to value-type arrays, we typically do not create large
arrays of reference-type objects.  As a result, we usually don't care
to share the array storage of {}\ttt{Ptr} or {}\ttt{RCP} objects
itself, only the reference-type objects they point to.  Because of
this, you typically will not see {}\ttt{ArrayRCP<[const]
RCP<[const] A> >} objects being passed around and stored.  Instead,
you would typically just pass {}\ttt{ArrayView<[const] RCP<[const]
A> >} objects and then use this array to create a new
{}\ttt{Array<[const] RCP<[const] A> >} object to copy the smart
pointers.  In general, we use arrays of {}\ttt{RCP} objects for
representing persisting associations and arrays of {}\ttt{Ptr}
objects for representing non-persisting associations when dealing with
reference-type objects.


%
{}\subsubsection{Idioms for class object data members and local
variables}
%

In general, class object data members and local variables represent a
persisting relationship and therefore should have unique ownership or
use reference counting.  That means that the types {}\ttt{Ptr} and
{}\ttt{ArrayView} should almost never be used for class object data
members or local variables (especially not for data members).
However, local variables of type {}\ttt{Ptr} and
{}\ttt{ArrayView} will be created in a function when that are
created off of other {}\ttt{Ptr} and {}\ttt{ArrayView} objects
(passed through the formal argument list).

\begin{table}
%
%\fbox{
\begin{center}
%
%\begin{minipage}{{}\textwidth}
%
\input{ValueTypeDataMembersTable}
%
%\end{minipage}
%
\end{center}
%} % end fbox
\caption{\label{fig:data_member_value_type}
Idioms for class data member declarations for value-type objects.}
%
\end{table}

\begin{table}
%
%\fbox{
\begin{center}
%
%\begin{minipage}{{}\textwidth}
%
\input{ReferenceTypeDataMembersTable}
%
%\end{minipage}
%
\end{center}
%} % end fbox
\caption{\label{fig:data_member_reference_type}
Idioms for class data member declarations for reference-types
objects.}
%
\end{table}


Tables {}\ref{fig:data_member_value_type} and
{}\ref{fig:data_member_reference_type} gives idioms for class object
data members.  Usages for local variables are similar.  Table
{}\ref{fig:data_member_value_type} shows a few use cases involving
value-type objects.  Table {}\ref{fig:data_member_reference_type}
shows use cases involving reference-type objects.  Every possible use
case is not shown in these tables, only the most common ones.  There
is almost no end to the number of different types of data structures
that can be created by embedding these memory management types in each
other.  When creating these composite data structures one just needs
to understand the implications for the selections of the class type
and the use of const.

It is important to note that we do not show an {}\ttt{RCP<S>} data
member for a value-type object in Table
{}\ref{fig:data_member_value_type}.  That is because once you declare
an {}\ttt{RCP} object pointing to a value-type object, at that
point you are treating the value-type object with reference Semitics
so we would consider it to be a reference-type object (which takes you
to Table {}\ref{fig:data_member_reference_type}).

Note that there are a few other important differences between the way
that value-type objects and reference-type objects are handled.  The
main difference, obviously, is that you can hold a value-type object
by value but not for a reference-type object.  We see this in how
single objects are stored and how arrays of objects are declared.


%
{}\subsubsection{Idioms for the specification of formal arguments for
C++ functions}
\label{sec:idioms-for-passing-arguments}
%

\begin{table}[p]
%
%\fbox{
\begin{center}
%
%\begin{minipage}{{}\textwidth}
%
\input{PassingValueObjectsTable}
%
%
%\end{minipage}
%
\end{center}
%} % end fbox
\caption{\label{fig:func_args_value_type}
Idioms for passing value-type objects to C++ functions.}
%
\end{table}


\begin{table}[p]
%
%\fbox{
\begin{center}
\input{PassingReferenceObjectsTable}
\end{center}
\caption{\label{fig:func_args_ref_type}
Idioms for passing reference-type objects to C++ functions.}
%} % end fbox
\end{table}


Described here are idioms for the specification of the formal
arguments for C++ functions that that maximizes compile-time and
run-time checking, yields near optimal performance, and is highly self
documenting.  A key component to this specification is that no raw C++
pointers are used.  Raw pointers are the cause of almost all memory
usage problems in C++.  Raw C++ references, on the other hand, are
safe to use as long as the object reference they are being used to
point to is valid and no persisting association exists.

Tables {}\ref{fig:func_args_value_type} and
{}\ref{fig:func_args_ref_type} give conventions for passing single
objects and arrays of objects for value-type {}\index{Types!Value
Type} and reference-type {}\index{Types!Reference Type} objects,
respectively.  In this specification, the Teuchos classes {}\ttt{Ptr},
{}\ttt{RCP}, {}\ttt{ArrayRCP}, and {}\ttt{ArrayView} are used as a
means to pass objects of another type (shown as {}\ttt{S} and
{}\ttt{A} in Tables {}\ref{fig:func_args_value_type} and
{}\ref{fig:func_args_ref_type}).  Conventions are shown for both
passing in objects and for passing out objects through the formal
arguments to C++ functions.  Note that value-type objects can always
be handled using reference semantics so all of the passing conventions
in Table {}\ref{fig:func_args_ref_type} apply equality well for
value-type objects as they do for reference-type objects.  However,
the conventions in Tables {}\ref{fig:func_args_value_type} only apply
to value-type objects that can be stored in contiguous arrays.

This specification addresses the five different properties that must
be considered when passing an object to a function:

\begin{itemize}

{}\item Is it a single object or an array of objects?

{}\item Does the object or array of objects use value semantics or
reference semantics?

{}\item Is the object or array of objects changeable or non-changeable
(i.e.\ const)?

{}\item Is this establishing a persisting or non-persisting (or
semi-persisting) association?

{}\item Is the object or array of objects optional or required?

\end{itemize}

The first four of these properties are directly expressed in the C++
code in all cases shown in Tables {}\ref{fig:func_args_value_type} and
{}\ref{fig:func_args_ref_type}.  The specification for whether an
argument or object is required or optional must be documented in the
function's interface specification (i.e.\ in a Doxygen documentation
{}\ttt{param} field).  Here we state that, by default, an argument
will be assumed to be required unless otherwise stated.  The only
exception for this implicit assumption for non-null objects is
{}\ttt{const Ptr<const T>\&} for single, non-changeable,
non-persisting, objects where these always mean that the argument is
optional.  If such an argument is required, it is specified as
{}\ttt{const T\&}.

An array of value objects is passed as contiguous storage through an
{}\ttt{ArrayView<S>} or {}\ttt{ArrayView<const S>} object.  An
array of reference objects, however, cannot be passed in contiguous
storage for the objects themselves and instead must be passed as
contiguous storage of (smart) pointers to the objects using
{}\ttt{ArrayView<const Ptr<const A> >} for non-persisting
associations or {}\ttt{ArrayView<const RCP<const A> >} for
persisting associations.  The {}\ttt{const} can be removed from the
either {}\ttt{Ptr}/{}\ttt{RCP} or {}\ttt{A} depending on what
is allowed to change or not change during the function call.

Note that in the case of {}\ttt{Ptr}, {}\ttt{RCP}, {}\ttt{ArrayView},
and {}\ttt{ArrayRCP} objects, that these can be treated as output
objects in their own right which is shown in Tables
{}\ref{fig:func_args_value_type} and {}\ref{fig:func_args_ref_type}
for passing out persisting and semi-persisting relationships to single
objects and arrays of objects.  For example, passing an {}\ttt{RCP<T>}
object into a function to be set to point to a different {}\ttt{A}
object would be specified in the function prototype as {}\ttt{const
Ptr<RCP<A> >\&} or {}\ttt{RCP<A>\&} depending on preference (only the
case {}\ttt{const Ptr<RCP<A> >\&} is shown in the tables).  Note that
semi-persisting associations are always passed out as {}\ttt{Ptr} and
{}\ttt{ArrayView} objects.  These types have essentially zero overhead
in an optimized build but yet have full runtime checking including
detection and reporting of dangling references in a debug-mode build
(see Section {}\ref{sec:perf-tuning-strategies} for a discussion of
the motivation and usage of semi-persisting associations).  The types
{}\ttt{RCP} and {}\ttt{ArrayRCP} are always used to establish
persisting associations.


%
{}\subsubsection*{Variations in passing single changeable objects}
\label{sec:vars-passing-single-objs}
%

The only area of contention in this specification is how to handle
arguments for required single changeable objects.  The specification
described here allows either passing them through a smart pointer as
{}\ttt{const Ptr<T>\&} or as a raw non-const object reference as
{}\ttt{T\&}.  In Item 25 in {}\cite{C++CodingStandards05}, the
authors recommend passing a raw non-const object reference
{}\ttt{T\&} for changeable required objects, which seems very
reasonable.  However, other notable authors {}\cite[Section Section
5.5]{stroustrup97} and {}\cite[Section 13.2]{CodeComplete2nd04}
recommend passing a pointer instead, as it provides a visual clue that
the object is being modified in the function call.  Of course, our
specification does not allow raw pointers so we pass a {}\ttt{const
Ptr<T>\&} object instead.  To consider the issues, for example, from
looking at the following function call which (if any) argument(s) is
being modified?

{\small\begin{verbatim}
  someFunction(a, b, c, d);
\end{verbatim}}

To tell for sure, one would have to look at the function prototype:

{\small\begin{verbatim}
  void someFunction(const A& a, const B& b, const C& c, D& d);
\end{verbatim}}

to see that it is the {}\ttt{d} argument is being modified in the
function call.

Now consider the convention that all changeable arguments be passed in
through a pointer as {}\ttt{const Ptr<T>\&}, giving the new
prototype:

{\small\begin{verbatim}
  void someFunction(const A& a, const B& b, const C& c,
    const Ptr<D>& d );
\end{verbatim}}

Now the function call looks like:

{\small\begin{verbatim}
  someFunction(a, b, c, outArg(d));
\end{verbatim}}

where {}\ttt{outArg(...)} is a templated non-member function that
returns a {}\ttt{Ptr<T>} object given a raw reference
{}\ttt{T\&}.  Now the client function call itself is self
documenting.  Also, given that this specification states that all
{}\ttt{Ptr<T>} arguments are required to be non-null by default,
this specifies that passing an argument as {}\ttt{const Ptr<T>\&}
has all of the same meaning by default that passing {}\ttt{T\&}
does.  Of course now we have given up a compile-time check for a
non-null argument for {}\ttt{T\&} with a debug-only runtime check
that {}\ttt{const Ptr<T>\&} is non-null.


%
{}\subsubsection*{Converting from non-persisting to persisting
references to satisfy the defined idioms}
%

There are legitimate instances where client code needs to convert a
non-persisting reference (i.e. {}\ttt{T\&}, {}\ttt{Ptr<T>}, or
{}\ttt{ArrayView<T>}) to a persisting reference (i.e.\ {}\ttt{RCP} or
{}\ttt{ArrayRCP}) in order to satisfy the idioms outlined in Tables
{}\ref{fig:func_args_value_type} and {}\ref{fig:func_args_ref_type}.
The most common case is when a function is passed a raw reference or a
{}\ttt{Ptr} to a C++ object (for a non-persisting assocation) but the
function's implementation must create (and destroy) and object what
has a persisting assoication with the passed in object.  Consider the
classes {}\ttt{A}, {}\ttt{B} and {}\ttt{C} shown in Listing
{}\ref{listing:NonPersistingPersistingAssociationsRCP} where {}\ttt{C}
maintains an {}\ttt{RCP} to {}\ttt{B}.  Now consider a client function
that needs an {}\ttt{A} and {}\ttt{B} object to perform its function
but also needs to create and destroy a {}\ttt{C} object internally
giving it the {}\ttt{B} object.  In order to be consistent with the
idioms defined here, the {}\ttt{B} object must be passed as a raw C++
reference or through a {}\ttt{Ptr} object.  Listing
{}\ref{listing:convert-from-raw-ref-to-RCP} shows how to convert from
a raw C++ reference to a non-owning {}\ttt{RCP} object to satisfy the
idioms.


{}\begin{listing}: Converting from a raw C++ reference to an
{}\ttt{RCP} object to satisfy function argument passing idiom
\label{listing:convert-from-raw-ref-to-RCP}
{\small\begin{verbatim}
  void doSomeOperation(B &b, const A &a)
  {
     ...
     C c;
     const RCP<B> b_rcp = rcpFromRef(b);
     c.fooC1(b_rcp, a);
     c.fooC2();
     ...
     // The C object is destroyed here!
  }
\end{verbatim}}
\end{listing}


In Listing {}\ref{listing:convert-from-raw-ref-to-RCP}, the standard
conversion function {}\ttt{rcpFromRef(...)} converts from a raw C++
reference to a non-owning {}\ttt{RCP} object.  Creating an {}\ttt{RCP}
like is perfectly safe and correct.  The lifetime of the created
{}\ttt{C} object is contained within the function
{}\ttt{doSomeOperation(...)} so the promise of not creating a
persisting assoication inherent in the functions prototype (i.e.\
passing the {}\ttt{B} object as a raw C++ referece) is being
corrrectly kept.  Note that if the created non-owning {}\ttt{RCP} is
accedentally used to create a persisting association then in many
cases, the dangling reference will be caught by the built-in
debug-mode runtime checking (see Section
{}\ref{sec:detection-dangling-references}).

A similar type of conversion is required when passing in an object
through a {}\ttt{Ptr} object.  For example, the function in Listing
{}\ref{listing:convert-from-raw-ref-to-RCP} may instead pass in a
{}\ttt{Ptr<B>} object instead of a raw C++ reference {}\ttt{B\&} and
the refactored function is shown in Listing
{}\ref{listing:convert-from-Ptr-to-RCP}.


{}\begin{listing}: Converting from a {}\ttt{Ptr} object to an
{}\ttt{RCP} object to satisfy function argument passing idiom
\label{listing:convert-from-Ptr-to-RCP}
{\small\begin{verbatim}
  void doSomeOperation(const Ptr<B> &b, const A &a)
  {
     ...
     C c;
     const RCP<B> b_rcp = rcpFromPtr(b);
     c.fooC1(b_rcp, a);
     c.fooC2();
     ...
     // The C object is destroyed here!
  }
\end{verbatim}}
\end{listing}


Again, if a persisting association is accedentally created by copying
the {}\ttt{RCP<B>} object created in Listing
{}\ref{listing:convert-from-Ptr-to-RCP} then this can be detected in a
debug-mode build.


%
{}\subsubsection{Idioms for returning objects from C++ functions}
\label{sec:idioms-returning-objects}
%

Idioms for how objects are returned from C++ functions are also
important in order to achieve C++ code that is efficient, safe (both
compile-time and debug-mode run-time checking), and is as
self-documenting as possible.  Tables
{}\ref{fig:func_return_value_type} and
{}\ref{fig:func_return_reference_type} give common specifications for
returning single objects and arrays of objects for both value-type and
reference-type objects for non-persisting, persisting, and
semi-persisting associations..  Five different types of properties
that must be defined and considered when returning an object (or array
of objects) from a function are:

\begin{itemize}

{}\item Is it a single object or an array of objects?

{}\item Does the object or array of objects use value semantics or
reference semantics?

{}\item Is the object or array of objects changeable or non-changeable
(i.e.\ const)?

{}\item Is this establishing a persisting or non-persisting (or
semi-persisting) association?

{}\item Is the object or array of objects optional or required?

\end{itemize}


\begin{table}
%
%\fbox{
\begin{center}
%
%\begin{minipage}{{}\textwidth}
%
\input{ReturningValueObjectsTable}
%
%
%\end{minipage}
%
\end{center}
%} % end fbox
\caption{\label{fig:func_return_value_type}
Idioms for returning value-type objects from C++ functions.}
%
\end{table}


\begin{table}
%
%\fbox{
\begin{center}
%
%\begin{minipage}{{}\textwidth}
%
\input{ReturningReferenceObjectsTable}
%
%
%\end{minipage}
%
\end{center}
%} % end fbox
\caption{\label{fig:func_return_reference_type}
Idioms for returning reference-type objects from C++ functions.}
%
\end{table}


These five different properties are the same five described for formal
function arguments described in Section
{}\ref{sec:idioms-for-passing-arguments}.  Again, the first four of
these properties are mostly clearly defined in the C++ code itself.
However, again, it is not always possible to directly state in the C++
code declarations whether the object (or array of objects) is optional
or required (but in some cases for value-type objects it is as shown
in Table {}\ref{fig:func_return_value_type}).

The semantics of return objects is different than for formal function
arguments and the specifications described in Tables
{}\ref{fig:func_return_value_type} and
{}\ref{fig:func_return_reference_type}.  There are several differences
that you can see from looking at Tables
{}\ref{fig:func_args_value_type} and {}\ref{fig:func_args_ref_type},
and Tables {}\ref{fig:func_return_value_type} and
{}\ref{fig:func_return_reference_type}.

The first difference to discuss between formal functions arguments and
return values relates to using constant references for formal
arguments versus returning objects by value as return types.  While
the memory management objects of type {}\ttt{Ptr}, {}\ttt{RCP},
{}\ttt{ArrayView}, and {}\ttt{ArrayRCP} are all passed by constant
reference in Tables {}\ref{fig:func_args_value_type} and
{}\ref{fig:func_args_ref_type}, alternatively they are always returned
as objects (i.e.\ by value) in Tables
{}\ref{fig:func_return_value_type} and
{}\ref{fig:func_return_reference_type}.  The reason that these memory
management objects should always be returned by value is that this is
needed to correctly set up the reference counting machinery to
properly set up persisting relationships and to enable debug runtime
checking (e.g.\ to detect dangling references).  Note that it is
critical that semi-persisting associations for single objects must
always be returned as {}\ttt{Ptr<T>} objects and never as raw
references {}\ttt{T\&} which is acceptable for non-persisting
associations.  The reason that {}\ttt{Ptr<T>} objects must always be
used for semi-persisting associations is that in a debug-mode build,
the runtime checking machinery will be able to detect dangling
references or changes in the parent object that would otherwise
invalidate the semi-persisting view that is impossible to catch when
using raw C++ references.

In order to understand the importance of returning memory management
objects by value instead of by reference, first consider Listing
{}\ref{listing:unsafe_raw_C++_reference1} that looks to be perfectly
safe code.

\begin{listing}: A seemingly safe use raw C++ references that is not \\
\label{listing:unsafe_raw_C++_reference1}
{\small\begin{verbatim}
  void seeminglySafeFoo(Blob &blob, const Flab &flab)
  {
    blob.doGoodStuff(flab);
  }
\end{verbatim}}
\end{listing}

The code in Listing {}\ref{listing:unsafe_raw_C++_reference1} does not
itself look unsafe.  However, the reason that it unsafe comes from the
code that calls {}\ttt{seeminglySafeFoo(...)} and the code that
implements {}\ttt{Blob} shown in Listing
{}\ref{listing:unsafe_raw_C++_reference2}.

\begin{listing}: Code that makes seeminglySafeFoo(...) fail\\
\label{listing:unsafe_raw_C++_reference2}
{\small\begin{verbatim}
  class Blob
  {
    RCP<Flab> flab_;
  public:
    Blob() : flab_(flab()) {}
    const RCP<Flab>& getFlab() { return flab_; }
    void doGoodStuff(const Flab &flab_in)
    {
      flab_ = flab(); // Using non-member constructor
      flab_->conflab(flab_in);
    }
  };


  void badCallingFunction()
  {
    Blob blob;
    seeminglySafeFoo(blob, *blob.getFlab());
  }
\end{verbatim}}
\end{listing}

When the code in Listings {}\ref{listing:unsafe_raw_C++_reference1}
and {}\ref{listing:unsafe_raw_C++_reference2} executes, it will most
likely cause a segfault when it runs, if we are lucky.  If we are
unlucky, the code will actually seem to be working correctly on the
machine where we test it but will explode later (perhaps years later)
when run under different circumstances.  The reason that the code in
Listings {}\ref{listing:unsafe_raw_C++_reference1} and
{}\ref{listing:unsafe_raw_C++_reference2} is faulty is because the
{}\ttt{Flab} object that is passed through the call
{}\ttt{seeminglySafeFoo(blob, *blob.getFlab())} to
{}\ttt{blob.doGoodStuff(flab)} is invalidated before it is used
because it gets destroyed and is replaced by a new object in the
expression {}\ttt{flab\_ = flab()}.  When this happens, the object
now represented as the raw C++ reference {}\ttt{flab\_in} is
deleted which causes the code in the expression
{}\ttt{flab\_->conflab(flab\_in)} to be in error, and the behavior
of the program is undefined (and again will segfault if we are lucky).

How did we get into this situation?  What if we changed the code to
replace the raw C++ references with RCP-wrapped objects?  Well,
consider the updated code in Listing
{}\ref{listing:unsafe_raw_C++_reference3}.

\begin{listing}: Still unsafe code  \\
\label{listing:unsafe_raw_C++_reference3}
{\small\begin{verbatim}
  class Blob
  {
    RCP<Flab> flab_;
  public:
    Blob() : flab_(flab()) {}
    const RCP<Flab>& getFlab() { return flab_; }
    void doGoodStuff(const RCP<Flab> &flab_in)
    {
      flab_ = flab(); // Using non-member constructor
      flab_->conflab(flab_in);
    }
  };


  void seeminglySafeFoo(Blob &blob, const RCP<Flab> &flab)
  {
    blob.doGoodStuff(flab);
  }


  void badCallingFunction()
  {
    Blob blob;
    seeminglySafeFoo(blob, blob.getFlab());
  }
\end{verbatim}}
\end{listing}

Is the code in Listing {}\ref{listing:unsafe_raw_C++_reference3}
correct?  The sad answer is no, it is not.  The {}\ttt{Flab} object
returned from {}\ttt{blob.getFlab()} will still get deleted before
it is used in the expression {}\ttt{flab\_->conflab(flab\_in)}.
What is going on here?  The core of the problem is that the function
{}\ttt{Blob::getFlab()} is incorrectly implemented.  Functions must
always return {}\ttt{RCP} objects by value and never by reference
as shown in Tables {}\ref{fig:func_return_value_type} and
{}\ref{fig:func_return_reference_type}.  By returning a raw C++
reference to the RCP object, a persisting association with the client
is never properly established and this is the root cause the whole
problem.

Now consider the updated code in Listing
{}\ref{listing:safe_raw_C++_reference3} that goes back to using raw
C++ references where appropriate but now returns the
{}\ttt{RCP<Flab>} object by value as it should.

\begin{listing}: Correctly returning RCP by value yielding safe code \\
\label{listing:safe_raw_C++_reference3}
{\small\begin{verbatim}
  class Blob
  {
    RCP<Flab> flab_;
  public:
    Blob() : flab_(flab()) {}
    RCP<Flab> getFlab() { return flab_; } // Returns by value now!
    void doGoodStuff(const RCP<Flab> &flab_in)
    {
      flab_ = flab(); // Using non-member constructor
      flab_->conflab(flab_in);
    }
  };


  void seeminglySafeFoo(Blob &blob, const Flab &flab)
  {
    blob.doGoodStuff(flab);
  }


  void goodCallingFunction()
  {
    Blob blob;
    seeminglySafeFoo(blob, *blob.getFlab());
  }
\end{verbatim}}
\end{listing}

Is the code represented in Listing
{}\ref{listing:safe_raw_C++_reference3} now safe and correct?  Yes it
is.  The reason that it is now safe and correct is that a persisting
relationship is now being correctly created by the function call
{}\ttt{blob.getFlab()} in that a new temporary {}\ttt{RCP<Flab>}
object is created.  From this new temporary {}\ttt{RCP<Flab>}
object, a raw C++ reference is then returned from
{}\ttt{*blob.getFlab()} and passed through.  In this case, since
the reference count on the existing {}\ttt{Flab} object is now two
instead of one, the expression {}\ttt{flab\_ = flab()} will not
delete the existing {}\ttt{Flab} object and the following
expression {}\ttt{flab\_->conflab(flab\_in)} will have two valid
{}\ttt{Flab} objects.  After the function
{}\ttt{seeminglySafeFoo(blob, *blob.getFlab())} exits, the first
{}\ttt{Flab} object will finally be deleted but that is just fine.

The second difference between formal function arguments and return
values is what persisting and non-persisting associations mean related
to function returns.  In the case of objects returned from C++
functions, a persisting association is one where the object returned
from a C++ function is remembered past the end of the statement where
the C++ function returning the objects is called.  For example,
consider the code in Listing {}\ref{listing:persisting-func-return-1}.

\begin{listing}:\\
\label{listing:persisting-func-return-1}
{\small\begin{verbatim}
  void foo(Blob& blob)
  {
    const Flab &flab = blob.getFlab();
    blob.doStuff();
    flab.doMoreStuff();
  }
\end{verbatim}}
\end{listing}

The code in Listing {}\ref{listing:persisting-func-return-1}
represents a persisting association because because the
{}\ttt{Flab} object returned in the expression {}\ttt{const Flab
\&flab = blob.getFlab()} is remembered past the statement where it is
called and is used later in calling {}\ttt{flab.doMoreStuff()}.
This type of code is all too common in C++ programs (including a lot
of code I have written over the last 10 years) but it is not safe
because it is not properly respecting the notion of persisting
associations.  To see why the code in Listing
{}\ref{listing:persisting-func-return-1} is so bad, consider a
possible unfortunate implementation of the {}\ttt{Blob} class shown
in Listing {}\ref{listing:bad-Blob-non-persisting}:

\begin{listing}:\\
\label{listing:bad-Blob-non-persisting}
{\small\begin{verbatim}
  class Blob {
    RCP<Flab> flab_;
  public:
    Blob() : flab_(flab()) {}
    const Flab& getFlab() const { return *flab_; }
    void doStuff()
      {
        flab_ = flab(); // Non-member constructor
        ...
      }
  };
\end{verbatim}}
\end{listing}

What happens of course is that the behavior of the code in Listings
{}\ref{listing:persisting-func-return-1} and
{}\ref{listing:bad-Blob-non-persisting} is undefined and will most
likely result in a segfault (if we are lucky).  The reason this is bad
code is that the {}\ttt{Flab} object reference that gets returned
from {}\ttt{blob.getFlab()} is not used until after the function
{}\ttt{Blob::doStuff()} gets called which will delete the
{}\ttt{Flab} object and replace it with another one.  This results
in {}\ttt{flab.doMoreStuff()} being called on a deleted object.
Again, this will typically result in a segfault, but on some systems
in some cases the program might actually seem to run just fine,
perhaps even for years.  This of course is an error that a tool like
Valgrind or Purify would likely catch pretty easily which is why these
tools are very useful to have around.  So what rule did we break in
Listing {}\ref{listing:persisting-func-return-1}?  This now brings us
back to our definition of a persisting association related to a return
value which is:

\begin{itemize}

{}\item\textit{Persisting associations} are associations that exist
between two or more objects that extend past a single function call
for formal function arguments, or a single statement for function
return objects.

\end{itemize}

What this means is that any object that is returned as a raw C++
reference from a function must be used in the same statement from
where the returning function is called.  Therefore, the function in
Listing {}\ref{listing:persisting-func-return-1} should be rewritten
as shown in Listing {}\ref{listing:non-persisting-func-return-1}.

\begin{listing}:\\
\label{listing:non-persisting-func-return-1}
{\small\begin{verbatim}
  void foo(Blob& blob)
  {
    blob.getFlab().doMoreStuff();
    blob.doStuff();
  }
\end{verbatim}}
\end{listing}

Here, of course, we are assuming that the order of evaluation of the
functions is not important.

Note that functions returning raw C++ references are common and are
fairly safe to use as long as the returned object is used in the same
statement where the function is called.  For example, this is what is
commonly done when a non-const reference to an element from a
user-defined array class object is returned and set in the same
statements such as shown in Listing
{}\ref{listing:non-persisting-array-return-1}.

\begin{listing}:\\
\label{listing:non-persisting-array-return-1}
{\small\begin{verbatim}
  void foo(std::vector<int>& a)
  {
    a[0] = 5; // Non-persisting function return association
    ...
  }
\end{verbatim}}
\end{listing}

What is typically not safe, of course, is when you try to save a
reference to an object and then use it like in Listing
{}\ref{listing:bad-persisting-array-return-1}.

\begin{listing}:\\
\label{listing:bad-persisting-array-return-1}
{\small\begin{verbatim}
  void foo(std::vector<int>& a)
  {
    int &a_0 = a[0]; // Incorrect persisting association
    a.resize(20);
    a_0 = 5;         // Will likely segfault if we are lucky!
    ...
  }
\end{verbatim}}
\end{listing}

The problem with the code in Listing
{}\ref{listing:bad-persisting-array-return-1} is that the
{}\ttt{a.resize(20)} function might cause a new buffer to be
allocated and the existing buffer to be deleted.  This will of course
make the reference returned in {}\ttt{int \&a\_0 = a[0]} invalid
when it is later written to in {}\ttt{a\_0 = 5}.

The whole point of the example code Listings
{}\ref{listing:non-persisting-array-return-1} and
{}\ref{listing:bad-persisting-array-return-1} is to demonstrate the
working definition of persisting \& non-persisting associations as
they relate to objects returned from functions and support the idioms
shown in Tables {}\ref{fig:func_return_value_type} and
{}\ref{fig:func_return_reference_type}.


%
{}\subsection{Reference-counting machinery in-depth}
\label{sec:reference-counting-machinary}
%

In order to effectively use these memory management classes and to
debug problems when they occur, one must understand the basic
reference-counting approach being used.  Basic reference counting with
smart pointers is well established in the C++ literature
{}\cite{MoreEffectiveC++96} but a basic overview and specific details
about the approach used in the Teuchos memory management classes is
appropriate to describe here.  Of equal importance is to describe how
the reference-counting infrastructure can be used to address some
boundary cases that can help solve some fundamental problems with
reference counting.

The basic reference counting machinery being used by the classes is
first described.  Next, the issue of circular references and weak
pointers are described.  The last issue discussed is the general role
and responsibilities for the various actors in software using the
Teuchos reference counting classes.


%
{}\subsubsection{Basic reference counting machinery}
\label{sec:basic-reference-counting-machinery}
%

{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.65]{TeuchosRCPDesign}
%}
\end{center}
\caption{
\label{fig:TeuchosRCPDesign}
Basic design of the Teuchos reference-counting machinery.  }
\end{figure}
\esinglespace}

The foundation for the reference-counting machinery used by all of the
reference-counting classes is shown in Figure
{}\ref{fig:TeuchosRCPDesign} (UML class diagram).  The class
{}\ttt{RCPNode} is an abstract base class that contains two
different reference counts (a strong count and a weak count) and
inline functions for manipulating the counts as efficiently as
possible.  The templated concrete subclass {}\ttt{RCPNodeImpl} is
what actually stores the raw C++ pointer to the reference-counted
object.  This class is also templated on an deallocation policy object
that determines how the object is reclaimed.  {}\ttt{RCPNodeHandle}
is a simple handle class that automates the manipulation of the
reference counts by overloading the copy constructor and assignment
operator functions.  This avoids having to replicate reference
counting incrementing and decrementing in the user-level classes
{}\ttt{RCP} and {}\ttt{ArrayRCP} that contain it.  All of the
functions on {}\ttt{RCPNodeHandle} are inlined and the only data
members are a pointer to the underlying {}\ttt{RCPNode} object and
a {}\ttt{strength} attribute (with values {}\ttt{RCP\_STRONG}
and {}\ttt{RCP\_WEAK}).  The class {}\ttt{RCPNodeHandle} imparts
zero space and time overhead and removes all duplication in how the
reference count node object is handled.  In future UML diagrams, the
{}\ttt{RCPNodeHandle} class will be considered to be part of the
owning {}\ttt{RCP} or {}\ttt{ArrayRCP} classes to avoid clutter.
The classes {}\ttt{RCPNode}, {}\ttt{RCPNodeImpl}, and
{}\ttt{RCPNodeHandle}, are used unchanged for both the
{}\ttt{RCP} and {}\ttt{ArrayRCP} classes (however, only the
{}\ttt{RCP} class is shown for simplicity).

The member functions for {}\ttt{RCP} {}\ttt{ArrayRCP} related to
reference-counting are shown in Listing
{}\ref{listing:ref-count-mem-funcs}.  Most of these funtions are never
called by general clients except in despirate situations.  One
exception are the member functions {}\ttt{create\_weak()} (which is
used to create a {}\ttt{WEAK} {}\ttt{RCP} object from a
{}\ttt{STRONG} object) and and {}\ttt{create\_strong()} (which
is used to create a {}\ttt{STRONG} {}\ttt{RCP} object from a
{}\ttt{WEAK} object).  The function {}\ttt{create\_weak()} is
used to break a circular reference as described in Section
{}\ref{sec:circular-references-weak-pointers} while
{}\ttt{create\_strong()} is used in situations like the ``object
self-reference'' idiom described in Section
{}\ref{sec:self-references}.


\begin{listing}: Reference counting member functions for {}\ttt{RCP}
{}\ttt{ArrayRCP} \\
\label{listing:ref-count-mem-funcs}
{\small\begin{verbatim}
  template<class T>
  class [Array]RCP {
  public:
    ...
    // Reference counting member functions
    ERCPStrength strength() const;
    bool is_valid_ptr() const;
    int strong_count() const;
    int weak_count() const;
    int total_count() const;
    void set_has_ownership();
    bool has_ownership() const;
    Ptr<T> release();
    RCP<T> create_weak() const;
    RCP<T> create_strong() const;
    template<class T2> bool shares_resource(const RCP<T2>& r_ptr) const;
    const RCP<T>& assert_not_null() const;
    const RCP<T>& assert_valid_ptr() const;
    ...
  };
\end{verbatim}}
\end{listing}


Figure {}\ref{fig:TeuchosRCPDesign} also shows that every
{}\ttt{RCPNode} object has an optional {}\ttt{std::map} object
that can be used to store and retrieve arbitrary extra data
(represented as the {}\ttt{any} data-type which can handle any
value-type object).  A raw pointer is stored to the
{}\ttt{extra\_data\_map} object that is initalized to null by
default.  Therefore, if no extra data is used, the only overhead for
this feature is an extra pointer member and its initialization to
null.  The motivation for and the usage of extra data is discussed in
Section {}\ref{sec:extra-data}.


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.65]{RCPEx1}
%}
\end{center}
\caption{
\label{fig:RCPEx1}
Example of several {}\ttt{RCP} objects pointing to the same
{}\ttt{RCPNodeImpl} object.  }
\end{figure}
\esinglespace}


It is critical to understand that the foundation for sharing objects
using reference counting is that only one owning {}\ttt{RCPNode}
object can exist for any object that is shared.  Figure
{}\ref{fig:RCPEx1} (UML object diagram) shows an example of several
{}\ttt{RCP} objects pointing to the same concrete object of type
{}\ttt{C} through different base class interfaces.  If the
programmer follows the idioms described in Section {}\ref{sec:idioms}
and outlined in Appendix {}\ref{apdx:summary_of_idioms} and
{}\ref{apdx:commandments}, it will always be the case that only one
reference-counting node object will exist for a given
reference-counted object.  Exceptions to the one effective owning
{}\ttt{RCPNode} per reference-counted object guideline are allowed
to facilitate some more advanced use cases (see Section
{}\ref{sec:inverting-obj-ownership} for an example).  As mentioned
earlier, the {}\ttt{RCPNode} object stores both a strong and a weak
reference count.  The strong and weak reference counts are equal to
the number of strong and weak, respectively, {}\ttt{RCP} objects
pointing to the single {}\ttt{RCP} node object.  When the strong
count goes to zero, the underlying reference-counted object is
destroyed but the {}\ttt{RCPNodeImpl} object is not destroyed until
the strong and weak counts both go to zero.  The motivation and the
workings of strong verses weak reference counts is discussed in
Section {}\ref{sec:circular-references-weak-pointers}.

Finally, one of the key integrated debug-mode eanbled capabilities of
the Teuchos reference-counting machinery is the ability to trace the
{}\ttt{RCPNode} objects that are created and destroyed and put them
in a database.  The {}\ttt{RCPNodeTracer} object is a global object
that stores all of the {}\ttt{RCPNode} objects in active use.  An
{}\ttt{std::multimap} object is used to store raw pointers to the
{}\ttt{RCPNode} objects and the multi-map is keyed by the
{}\ttt{void*} address of the underlying reference-counted objects
themselves.  Therefore, one can query to see if any {}\ttt{RCPNode}
object already exists for a given object.  The cost of this query is
$O(log(n))$ where $n$ is the number of active {}\ttt{RCPNode}
objects currently in use.  Therefore, the cost of node tracing very
scalable with the number of {}\ttt{RCPNode} objects in use.  The
current implementation requires Boost which provides some trickery for
determining at compile-time if a type is polymorphic or not and
thereby allowing the use {}\ttt{dynamic\_cast<const void*>(p)} to
determine the true base address of any object (no matter if it uses
virtual base classes and multiple inheritance or not).  The ability to
trace active {}\ttt{RCPNode} objects and look them up basesd on an
objects address is crtical for many debug-mode runtime checking
capabilities including: a) reporting objects involved in circular
depencencies after a program ends (see Section
{}\ref{sec:detection-circular-references}), b) detection of dangling
references of non-owning {}\ttt{RCP} objects (see Section
{}\ref{sec:detection-dangling-references}), and c) detection of the
creation of multiple owning {}\ttt{RCPNode} objects (see Section
{}\ref{sec:detection-dual-owning-rcps}).

Note that node tracing is only an optional debug-mode feature and is
not required for the correct functioning of the reference-counting
machinery.  In fact, the observable behavior of correct programs will
be exactly whether debug-mode node tracing is enabled or not.  For
correct programs, the only observable consequence of having node
tracing enabled will be increased runtimes.


%
{}\subsubsection{Circular references and weak pointers}
\label{sec:circular-references-weak-pointers}
%

The fundamental weakness of low-overhead reference counting as
described in this paper and used in the Teuchos memory management
classes is that there is no bullet-proof way to address circular
references that otherwise result in memory leaks.  Because of possible
circular references, only system-level garbage-collection methods,
such as implemented in languages like Java and Python, can robustly
clean up memory in every case of circular reference.  As stated
earlier, given backward compatibility constraints, many existing C++
programs cannot be used with any C++ implementation that might
implement garbage collection, not now or ever.  A key issue is that
many programs require the side-effects of the deletion of objects as
specific points in the program and changing the time of deletion of
the object (and the call of the destructor) would break the program.

To understand the problem with circular references, consider the code
in Listing {}\ref{listing:CircularRCP_A_B} which sets up a simple
circular reference between two objects.


\begin{listing}: Setting up a simple circular reference between two objects \\
\label{listing:CircularRCP_A_B}
{\small\begin{verbatim}
  {
    RCP<A> a = createA();
    RCP<B> b = createB();
    a->set_B(b);
    b->set_A(a);
    RCP<ClientA> clientA = createClientA(a);
    RCP<ClientB> clientB = createClientB(b);
  }
  // The A and B objects will not be deleted when the above code block ends!
\end{verbatim}}
\end{listing}


The code fragement in Listing {}\ref{listing:CircularRCP_A_B} sets up
the objects in Figure {}\ref{fig:CircularRCP_A_B} showing the circular
reference.  Here object {}\ttt{a} contains an {}\ttt{RCP}
pointing to object {}\ttt{b}, and object {}\ttt{b} contains an
{}\ttt{RCP} pointing to object {}\ttt{a}.  In this situation,
when {}\ttt{ClientA} and {}\ttt{ClientB} destroy their
{}\ttt{RCP} objects pointing to the underlying {}\ttt{a} and
{}\ttt{b} objects, the reference counts will not go to zero because
of the circular reference between {}\ttt{a} and {}\ttt{b}.  This
will result in a memory leak that a tool like Valgrind or Purify
should complain about.  If lots of objects with circular references
are constantly being created and destroyed resulting in these types of
memory leaks, then obviously we have a problem and the system could
run out of memory and bring the program down.

{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.65]{CircularRCP_A_B}
%}
\end{center}
\caption{
\label{fig:CircularRCP_A_B}
Simple circular reference between two objects.  }
\end{figure}
\esinglespace}

When debug-mode node tracing is enabled, the system will print out the
remaining {}\ttt{RCPNode} objects when it exists (see Section
{}\ref{sec:detection-circular-references} for more details).

While there is no completely general and bullet proof way to address
the circular reference problem, there is a fairly simple and cheap
approach supported by the Teuchos reference-counting machinery that
can effectively resolve circular references in most cases.  The
approach described here supported by the Teuchos reference-counted
classes is to exploit the concept if weak reference-counted pointers.
As shown in Figure {}\ref{fig:TeuchosRCPDesign}, this is accomplished
through a {}\ttt{strength} attribute with values {}\ttt{STRONG}
and {}\ttt{WEAK}.  By default, all {}\ttt{RCP} objects are
{}\ttt{STRONG}.  When an {}\ttt{RCP} is {}\ttt{STRONG}, then
the underlying {}\ttt{ConcreteT} object is guaranteed to stay
around.  However, when the {}\ttt{RCP} is {}\ttt{WEAK}, the
underlying {}\ttt{ConcreteT} can get deleted when strong count goes
to zero (by the deletion of other {}\ttt{STRONG} {}\ttt{RCP}
objects).

{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.65]{CircularRCP_A_B_weak}
%}
\end{center}
\caption{
\label{fig:CircularRCP_A_B_weak}
Simple circular reference between two objects broken using a
{}\ttt{WEAK} {}\ttt{RCP}.  }
\end{figure}
\esinglespace}

So how can deal with circular references like this?  The answer in
this case is to use a weak {}\ttt{RCP} to break the circular
reference as shown in Listing {}\ref{listing:CircularRCP_A_B_weak}.


\begin{listing}: Breaking a simple circular reference using a weak
{}\ttt{RCP} \\
\label{listing:CircularRCP_A_B_weak}
{\small\begin{verbatim}
  {
    RCP<A> a = createA();
    RCP<B> b = createB();
    a->set_B(b);
    b->set_A(a.create_weak());
    RCP<ClientA> clientA = createClientA(a);
    RCP<ClientB> clientB = createClientB(b);
    if (deleteClientAFirst)
      clientA = null;
    else
      clientB = null;
  }
  // Now all the objects will be deleted correctly!
\end{verbatim}}
\end{listing}


The object structure set up by the code in listing Listing
{}\ref{listing:CircularRCP_A_B_weak} is depicted in Figure
{}\ref{fig:CircularRCP_A_B_weak}.  With the weak pointer in place, all
of the objects will get destroyed when {}\ttt{ClientA} and
{}\ttt{ClientB} remove their {}\ttt{RCP} objects, no mater what
order they remove them.  The critical assumption is that the
``useful'' lifetime of {}\ttt{a} is a superset of the ``useful''
lifetime of {}\ttt{b}.  If {}\ttt{a} gets deleted before
{}\ttt{b}, then {}\ttt{b} had better not try to access
{}\ttt{a} anymore!  However, the goal is that whoever gets deleted
first (i.e.\ {}\ttt{clientA} or {}\ttt{clientB}) the objects
will go away gracefully and not result in memory leaks.


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.65]{CircularRCP_A_B_ClientA_1}
%}
\\[2ex] a) {}\ttt{ClientA} goes away first \\[3ex]
%\fbox{
\includegraphics*[angle=270,scale=0.65]{CircularRCP_A_B_ClientA_2}
%}
\\[2ex] b) {}\ttt{ClientB} goes away second \\[3ex]
\end{center}
\caption{
\label{fig:CircularRCP_A_B_ClientA}
Scenario where {}\ttt{ClientA} is deleted first.  }
\end{figure}
\esinglespace}


Consider first the scenario where the {}\ttt{clientA} object goes
away first (i.e.\ {}\ttt{deleteClientAFirst=true}) as shown in
Figure {}\ref{fig:CircularRCP_A_B_ClientA} (a UML communication
diagram).  This scencario is shown in two phases in two separate UML
communication diagrams:

\begin{description}

{}\item[a)] {}\ttt{ClientA} is deleted

  \begin{description}

  {}\item[a.1)] As {}\ttt{rcpA2} goes away, it deincrements
  {}\ttt{nodeA::strongCount} from 1 to 0.

  {}\item[a.2)] Since {}\ttt{nodeA::weakCount > 0}, then
  {}\ttt{nodeA} is not deleted but since
  {}\ttt{nodeA::strongCount==0} the object {}\ttt{a} gets
  deleted.

  {}\item[a.3)] As {}\ttt{a} is deleted, it deletes its
  {}\ttt{RCP} object {}\ttt{rcpB1}.

  {}\item[a.4)] Since {}\ttt{rcpB1} is a strong pointer, it
  deincrements {}\ttt{nodeB::strongCount} from 2 to 1.  Therefore,
  neither {}\ttt{nodeB} or {}\ttt{b} gets deleted at this point.

  NOTE: At this point, the object {}\ttt{a} has been deleted and
  {}\ttt{nodeA}~s internal pointer has been set to {}\ttt{NULL}.
  If the {}\ttt{b} object trys to access {}\ttt{a} after this,
  it will result in an exception being thrown in a debug build.  In a
  non-debug build, any access of {}\ttt{a} from {}\ttt{b} will
  result in a segfault.

  \end{description}

{}\item[b)] {}\ttt{ClientB} is deleted

  \begin{description}

  {}\item[b.1)] As {}\ttt{clientB} goes away, it takes
  {}\ttt{rcpB2} with it.  Since rcpB2 is a strong pointer, it
  deincrements {}\ttt{nodeB::strongCount} from 1 to 0.  Since
  {}\ttt{nodeB::strongCount} and {}\ttt{nodeB::weakCount} are
  both 0 this results in {}\ttt{nodeB} being deleted.

  {}\item[b.2)] As {}\ttt{nodeB} is being deleted, it deletes the
  {}\ttt{b} object.

  {}\item[b.3)] As {}\ttt{b} is being deleted, it deletes its
  {}\ttt{RCP} object {}\ttt{rcpA1}.

  {}\item[b.4)] With {}\ttt{rcpA1} being deleted it reduces
  {}\ttt{nodeA::weakCount} from 1 to 0.  Since
  {}\ttt{nodeA::strongCount} and {}\ttt{nodeA::weakCount} are
  both 0, this results in {}\ttt{nodeA} being deleted.  Since the
  object {}\ttt{a} is already deleted, nothing more happens.

  \end{description}

\end{description}


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.65]{CircularRCP_A_B_ClientB_1}
%}
\\[2ex] a) {}\ttt{ClientB} goes away first \\[3ex]
%\fbox{
\includegraphics*[angle=270,scale=0.65]{CircularRCP_A_B_ClientB_2}
%}
\\[2ex] b) {}\ttt{ClientA} goes away second \\[3ex]
\end{center}
\caption{
\label{fig:CircularRCP_A_B_ClientB}
Scenario where {}\ttt{ClientB} is deleted first.  }
\end{figure}
\esinglespace}


Now consider the scenario where the {}\ttt{clientB} object goes
away first (i.e.\ {}\ttt{deleteClientAFirst=false}) depicted in
Figure {}\ref{fig:CircularRCP_A_B_ClientB}:

\begin{description}

{}\item[a)] {}\ttt{ClientB} is deleted

  \begin{description}

  {}\item[a.1)] The {}\ttt{clientB} object goes away first and takes
  its {}\ttt{RCP} {}\ttt{rcpB2} with it.  This reduces
  {}\ttt{nodeB::strongCount} from 2 to 1.  No other objects are
  deleted yet.

  \end{description}

{}\item[b)] {}\ttt{ClientA} is deleted

  \begin{description}

  {}\item[b.1)] When {}\ttt{rcpA2} goes away, it deincrements
  {}\ttt{nodeA::strongCount} from 1 to 0.  At this point, since
  {}\ttt{nodeA::weakCount > 0}, the node is not deleted but the
  referenced object {}\ttt{a} is deleted.

  {}\item[b.2)] {}\ttt{a} is deleted.

  {}\item[b.3)] As {}\ttt{a} is deleted, it deletes its
  {}\ttt{RCP} object {}\ttt{rcpB1}.

  {}\item[b.4)] As {}\ttt{rcpB1} is deleted, it deincrements
  {}\ttt{nodeB::strongCount} from 1 to 0. Since
  {}\ttt{nodeB::weakCount==0}, then {}\ttt{nodeB} is deleted.

  {}\item[b.5)] As {}\ttt{nodeB} is deleted, it deletes the
  {}\ttt{b} object.

  {}\item[b.6)] As {}\ttt{b} is deleted, it deletes its
  {}\ttt{RCP} object {}\ttt{rcpA1}.  What is critical here is
  that {}\ttt{b} must not try to access {}\ttt{a} which is
  already in the process of being deleted.  If {}\ttt{b} were to
  try to access {}\ttt{a} as it is being deleted, in debug mode an
  exception would be thrown.  In non-debug mode, this would segfault.
  It is rare, however, that one object tries to access another as they
  are deleted.

  {}\item[b.7)] When {}\ttt{rcpA1} is removed, it deincrements
  {}\ttt{nodeA::weakCount} from 1 to 0.  Since
  {}\ttt{nodeA::strongCount} is already 0, this results in
  {}\ttt{nodeA} being deleted.  Since {}\ttt{a} is already in
  the process of being deleted, nothing extra happens here.

  \end{description}

\end{description}

What is espeically interesting about the second scenario is how
deleting the {}\ttt{a} object in Figure
{}\ref{fig:CircularRCP_A_B_ClientB}.b triggers a chain reaction that
causes the {}\ttt{b} object to be deleted which recursively causes
the {}\ttt{nodeA} object to be deleted, all in the call stack where
the {}\ttt{a} object is being deleted.  To accomplish this
correctly, the {}\ttt{RCPNodeImpl::deleteObj()} function has some
special logic to avoid a double delete call being performed on the
reference-counted object.

With respect the weak pointers, the Teuchos class {}\ttt{RCP}
differs substantially from the Boost and therefore C++0x standard
reference-counting classes.  With the class {}\ttt{RCP}, the
attribution of strong or weak is made at runtime.  At runtime, an
external client can decide to make {}\ttt{a}'s reference to
{}\ttt{b} weak or {}\ttt{b}'s reference to {}\ttt{a} weak
depending on the given circumstance.  With the Boost and C++0x
{}\ttt{shared\_ptr} class, you have to use a separate class
{}\ttt{weak\_ptr} to represent a weak pointer.  The problem with
the Boost approach then is that you have to decide at compile time if
a particular reference is going to be weak or strong.  While there are
some cases where you can always assume the reference needs be weak
(like in the self-reference case described in Section
{}\ref{sec:self-references}), there are more complex cases where you
cannot decide this so easily at compile time.  For example, if we were
to use the {}\ttt{shared\_ptr} and {}\ttt{weak\_ptr} classes, we
would have to decide at compile time to make {}\ttt{a}'s reference
or {}\ttt{b}'s reference weak.  The decision you make might work
for one set of use cases that you currently know about, but for more
complex use cases you have not discovered yet you may need to switch
it.  In fact, in the same compiled program you may have some use cases
where {}\ttt{a} will be deleted before {}\ttt{b} and other use
cases where {}\ttt{b} will be deleted before {}\ttt{a}.  With
the classes {}\ttt{shared\_ptr} and {}\ttt{weak\_ptr}, this is
impossible (at least not without storing both smart pointer types in
each class {}\ttt{A} and {}\ttt{B} object and then using one or
the other which is not very elegant or efficient).  The only argument
for the compile-time approach used by Boost and C++0x is performance
in both speed and memory overhead but the results in Section
{}\ref{sec:reference-counting-overhead} show that this extra runtime
overhead is minimal.  Overall, the overhead induced by the flexible
runtime approach of the {}\ttt{[Array]RCP} classes is well worth
the minimal extra overhead.  Typically, the classes
{}\ttt{[Array]RCP} are used to manage objects (or blocks of array
data) much larger than what is contained in the infrastructure for the
{}\ttt{[Array]RCP} objects so the additional memory is
insignificant.


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=0.65]{CircularChain}
%}
\end{center}
\caption{
\label{fig:CircularChain}
Example of a circular chain involving many objects and many classes.}
\end{figure}
\esinglespace}


While this section has focused on a simple example involving a circular
reference between two classes and to objects, in reality circular
references typically involve many different objects and classes which
may be in very distant parts of the code base which makes spotting
them very difficult.  For example, Figure {}\ref{fig:CircularChain} (a
UML object diagram) depicts a circular reference involving eight
objects.  When the external {}\ttt{someClient} object removes its
{}\ttt{RCP<H>} object, the chain of objects from {}\ttt{a} to
{}\ttt{h} will not be deleted an will leak memory.  These types of
chains of circular references can be very difficult to track down and
that is where the debug-mode runtime node tracing described in Section
{}\ref{sec:detection-circular-references} comes in most handy.

Section {}\ref{sec:detection-dangling-references} describes how weak
pointers are used in runtime debug checking for dangling
non-persisting references.  Section {}\ref{sec:self-references}
describes how weak pointers are used in dealing with object
self-references.  In summary, the Teuchos reference-counting machinery
addressing both strong and weak references is a very powerful tool but
to use it effectively, you need to understand the basic semantics.
The good news is that 99\% of the people who use the classes
{}\ttt{[Array]RCP} will never need to know the difference between a
strong and weak reference and will by default use just strong
references.  Weak references will get used under the hood for some
debug-mode runtime checking but they are totally transparent to client
code and the programmer.  It is only in cases of circular references
do typical programmers need to know anything about weak pointers.


%
{}\subsubsection{Customized deallocators}
\label{sec:deallocators}
%

The most common use of {}\ttt{RCP} is to manage the lifetime of
objects allocated using operator {}\ttt{new} and deallocated using
operator {}\ttt{delete} (or {}\ttt{new []} and {}\ttt{delete
[]} for {}\ttt{ArrayRCP}).  For these use cases, the built-in
behavior in {}\ttt{RCP} does exactly the right thing for this
average case.  However, there are situations when one cannot simply
call {}\ttt{delete} to deallocate an object.  Some examples of
these situations include:

\begin{enumerate}

{}\item When reference counts for objects are managed by requiring
clients to explicitly call increment and decrement functions.  This
situation occurs when using CORBA {}\cite{ref:corba} and COM
{}\cite{ref:com} for instance.  Such an approach is also presented in
{}\cite[Item 29]{MoreEffectiveC++96} in the subsection ``A
Reference-Counting Base Class''.  In these protocols, deallocation
occurs automatically behind the scenes when this other reference count
goes to zero and does not occur through an explicit call to operator
{}\ttt{delete} as with the default behavior for {}\ttt{RCP}.

{}\item When objects are managed by certain types of object databases.
In some object databases, an object that is grabbed from the database
must be explicitly returned to the database in order to allow proper
object deletion to take place later.

{}\item A different reference-counted pointer class is used to
initially get access to the managed object.  For example, suppose some
piece of peer software works with {}\ttt{boost::shared\_ptr} (see
{}\cite{ref:boost}) referenced-counted objects while the resident
software works with {}\ttt{RCP} objects.  It then becomes critical
no object is deleted until all the clients using either of these smart
pointer types remove their references (i.e.\ destroy their smart
pointers) to this underlying object.

\end{enumerate}

There are also other situations where one cannot simply assume that
calling operator {}\ttt{delete} is used to release an object.  The
bottom line is that in order to be general, one must allow arbitrary
policies to be used to deallocate an object after clients are finished
using the object.

Perhaps the key differentiating property between a flexible high
quality reference-counted pointer implementation and a poor
implementation is the capability to allow the user to define an
arbitrary deallocator policy that defines exactly what it means to
release a reference-counted object (or array of objects).  The
reference-counted Teuchos classes {}\ttt{RCP} and
{}\ttt{ArrayRCP}, as well as {}\ttt{boost::shared\_ptr} all
allow the client to specify a user-defined deallocation policy object
when the first reference-counted object is constructed.

The code associated with customized deallocation policies for
{}\ttt{RCP} (what are identical for {}\ttt{ArrayRCP}) are shown
in Listing {}\ref{listing:RCP-dealloc}.

\begin{listing}: Declarations for customized deallocation policies
for {}\ttt{RCP} \\
\label{listing:RCP-dealloc}
{\small\begin{verbatim}
  // Default decallocation policy for RCP
  template<class T>
  class DeallocDelete
  {
  public:
    typedef T ptr_t;
    void free( T* ptr ) { if(ptr) delete ptr; }
  };

  template<class T>
  class RCP {
  public:
    ...
    template<class Dealloc_T>
    RCP(T* p, Dealloc_T dealloc, bool has_ownership);
    ...
  };
  
  template<class T, class Dealloc_T>
  RCP<T> rcp(T* p, Dealloc_T dealloc, bool owns_mem);
  
  template<class Dealloc_T, class T>
  const Dealloc_T& get_dealloc(const RCP<T>& p);
  
  template<class Dealloc_T, class T>
  Dealloc_T& get_nonconst_dealloc(const RCP<T>& p);
  
  template<class Dealloc_T, class T>
  Ptr<const Dealloc_T> get_optional_dealloc(const RCP<T>& p);
  
  template<class Dealloc_T, class T> 
  Ptr<Dealloc_T> get_optional_nonconst_dealloc(const RCP<T>& p);

\end{verbatim}}
\end{listing}

All deallocator objects must support the typedef member
{}\ttt{ptr\_t} and function member {}\ttt{free()}.  The concept
of a template policy interface (also called a function object
\cite[Section 18.4]{stroustrup97}) should be familiar to
semi-advanced users of the STL (part of the standard C++ library).

To demonstrate the use of a deallocator object, let us assume that we
must wrap objects of type {}\ttt{A} managed by the the following
object database

{\small\begin{verbatim}
  class ObjectADB {
    ...
    A& get(int id);
    void release(int id);
    ...
  };
\end{verbatim}}

In the above object database, objects are accessed and released using
an id.  How this id is specified and determined is not important here.
Let us suppose that we want to define an abstract factory that returns
objects of type {}\ttt{A} wrapped in {}\ttt{RCP<A>} objects
using a database object of type {}\ttt{ObjectADB} shown above.  For
this abstract factory, objects of type {}\ttt{A} will be allocated
from a list of ids given to the factory.  The outline of this abstract
factory subclass looks like:

{\small\begin{verbatim}
  class ObjectADBFactory : public AbstractFactory<A> {
  public:
    ObjectADBFactory(const RCP<ObjectADB>& db, const ArrayView<int>& ids)
     : db_(db), ids_(ids) {}
    RCP<A> create() { ... };  // Overridden from AbstractFactory
  private:
    RCP<ObjectjADB> db_;
    Array<int> ids_;
  };
\end{verbatim}}

The above abstract factory subclass {}\ttt{ObjectADBFactory}
inherits from a generic {}\ttt{AbstractFactory} base class that
defines a pure virtual method {}\ttt{create()}.  In order to
implement the {}\ttt{create()} function, a deallocator class must
be defined and used.  For this purpose we define:

{\small\begin{verbatim}
  class DeallocObjectADB
  {
  public:
    DeallocObjectADB(const RCP<ObjectjADB>& db, int id)
      : db_(db), id_(id) {}
    typedef A ptr_t;
    void free(A* ptr) { db_->release(id_); }
  private:
    RCP<ObjectjADB> db_;
    int id_;
    DeallocObjectADB(); // not defined and not to be called!
  };
\end{verbatim}}

Now we can define the implementation of the {}\ttt{create()}
function override as:

{\small\begin{verbatim}
  RCP<A> ObjectADBFactory::create()
  {
    TEST_FOR_EXCEPTION(ids_.size()==0, std::runtime_error, "No ids are left!");
    const int id = ids_.pop();
    return rcp(&db_->get(id), DeallocObjectADB(db_, id), true);
  }
\end{verbatim}}

The following program shows the use of the above factory class:

{\small\begin{verbatim}
  int main()
  {
    // Create the object database and populate it (and save the ids)
    RCP<ObjectADB> db;
    Array<int> ids;
    ...
    // Create the abstract factory object
    ObjectADBFactory  ftcy(db, ids());
    // Create some A objects and use them
    RCP<A> a_ptr1 = fcty.create();
    ...
    return 0;
  }
\end{verbatim}}

In the above program, all of the objects of type {}\ttt{A} are
created and removed seamlessly without the client code that interacts
with {}\ttt{RCP} and {}\ttt{AbstractFactory} knowing anything
about what is going on under the hood.


%
{}\subsubsection{Embedded objects}
\label{sec:embedded-objecs}
%

Support for customized deallocator policy objects described in Section
{}\ref{sec:deallocators} turns out to be a pretty flexible feature.
The ability to embed any arbitrary object in the {}\ttt{RCPNode}
object gives you an efficient way to define a different deallocation
policy that is invoked by the destructor on the object instead of
requiring an explicit deallocation policy object.  In addition, you
can also tack on any extra data that you would like and embed in the
underlying {}\ttt{RCPNodeImpl} object.  The only restriction is
that you have to make the choice of what you want to embed it in the
{}\ttt{RCPNode} object when the very first {}\ttt{RCP} object is
created (which in turn creates the concrete templated
{}\ttt{RCPNodeImpl} object ).  If you want the flexibility to embed
other data in the underlying {}\ttt{RCPNode} object after it has
been created then you will have to use the ``extra data'' feature
which is described in Section {}\ref{sec:extra-data}.  The advantage
of embedding objects in the {}\ttt{RCPNodeImpl} object is that it
can be quite a bit more efficient than using the ``extra data''
feature which requires more runtime-support.

The functions that are used to embed objects when creating
{}\ttt{RCP} objects and retrieve them again are shown in Listing
{}\ref{listing:RCP-embedded-obj} (identical functions exist for the
{}\ttt{ArrayRCP} class).

\begin{listing}: Embedded object functions for RCP \\
\label{listing:RCP-embedded-obj}
{\small\begin{verbatim}
 
  template<class T, class Embedded>
  RCP<T> rcpWithEmbeddedObjPreDestroy(T* p, const Embedded &embedded,
    bool owns_mem=true);
  
  template<class T, class Embedded>
  RCP<T> rcpWithEmbeddedObjPostDestroy(T* p, const Embedded &embedded,
    bool owns_mem=true);
  
  template<class T, class Embedded>
  RCP<T> rcpWithEmbeddedObj(T* p, const Embedded &embedded, bool owns_mem=true);
  
  template<class TOrig, class Embedded, class T> 
  const Embedded& getEmbeddedObj(const RCP<T>& p);
  
  template<class TOrig, class Embedded, class T>
  Embedded& getNonconstEmbeddedObj(const RCP<T>& p);
  
  template<class TOrig, class Embedded, class T>
  Ptr<const Embedded> getOptionalEmbeddedObj( const RCP<T>& p );
  
  template<class TOrig, class Embedded, class T>
  Ptr<Embedded> getOptionalNonconstEmbeddedObj( const RCP<T>& p );
\end{verbatim}}
\end{listing}

The embedded object functions in Listing
{}\ref{listing:RCP-embedded-obj} simply use a custom templated
deallocator class shown in Listing
{}\ref{listing:RCP-EmbeddedObjDealloc} along with the public
deallocator functions in Listing {}\ttt{listing:RCP-dealloc}.

\begin{listing}: RCP Decallocator using an embedded object \\
\label{listing:RCP-EmbeddedObjDealloc}
{\small\begin{verbatim}
  template<class T, class Embedded, class Dealloc>
  class EmbeddedObjDealloc
  {
  public:
    typedef typename Dealloc::ptr_t ptr_t;
    EmbeddedObjDealloc(
      const Embedded &embedded, EPrePostDestruction prePostDestroy,
      Dealloc dealloc, bool hasOwnership )
      : embedded_(embedded), prePostDestroy_(prePostDestroy), dealloc_(dealloc),
        hasOwnership_(hasOwnership)
      {}
    void setObj( const Embedded &embedded ) { embedded_ = embedded; }
    const Embedded& getObj() const { return embedded_; }
    Embedded& getNonconstObj() { return embedded_; }
    void hasOwnership(bool hasOwnership_in) { hasOwnership_ = hasOwnership_in; }
    bool hasOwnership() const { return hasOwnership_; }
    void free( T* ptr )
      {
        if (prePostDestroy_ == PRE_DESTROY)
          embedded_ = Embedded();
        if (hasOwnership_)
          dealloc_.free(ptr);
        if (prePostDestroy_ == POST_DESTROY)
          embedded_ = Embedded();
      }
  private:
    Embedded embedded_;
    EPrePostDestruction prePostDestroy_;
    Dealloc dealloc_;
    bool hasOwnership_;
    EmbeddedObjDealloc(); // Not defined and not to be called!
  };
\end{verbatim}}
\end{listing}

The customized deallocator class in Listing
{}\ref{listing:RCP-EmbeddedObjDealloc} is them templated with
{}\ttt{DeallocDelete} (see Listing {}\ref{listing:RCP-dealloc}) is
set by the non-member constructor functions in Listing
{}\ref{listing:RCP-embedded-obj}.  The distiction between pre- and
post-destroy can be critical depending on how the embedded data is
used (many examples will be given here).  In most cases, the order the
embedded object is reset to the default value is not important and
therefore the client would just use {}\ttt{rcpWithEmbeddedObj(...)} 
to set the extra data (in which case it uses post-destruction by
default).  As shown in Listing {}\ref{listing:RCP-EmbeddedObjDealloc},
the official ownership of the underlying reference-counted object of
type {}\ttt{T} that is freed using {}\ttt{dealloc\_} is
controlled by the {}\ttt{bool} member {}\ttt{hasOwnership\_}.
If ownership of the object is given to the embedded object itself,
then you set {}\ttt{hasOwnership=false}.

Typically, the embedded object will be some {}\ttt{RCP} such that
when the embedded object is default constructed as in
{}\ttt{embedded\_ = Embedded()} then the destructor on that object
will be called.  A simple example of embedding an {}\ttt{RCP} that
controls the memory is shown below:

\begin{listing}: \\
{\small\begin{verbatim}
  RCP<A> a_ptr1(new A);
  RCP<A> a_ptr2 = rcpWithEmbeddedObj(a_ptr1.getRawPtr(), a_rcp1, false);
\end{verbatim}}
\end{listing}

The use case used in the above example looks silly and trivial but it
is the foundation for several more advanced use cases (see Section
{}\ref{sec:inverting-obj-ownership} for a related example).  As a
result of this code, the underlying {}\ttt{A} object will not be
deleted until the {}\ttt{RCPNodeImpl} object associated with
{}\ttt{a\_ptr2} (and all of the {}\ttt{RCP} objects created from
it) is destroyed.  Even the above simple use case can be useful if you
want to be able to use the reference count on {}\ttt{RCP} objects
derived from {}\ttt{a\_ptr2} to determine usage of the object by
other clients.  There are concrete examples of this exact usage in
Trilinos code.

A more general usage of embedded objects to perform arbitrary actions
is demonstrated in the context of the ``generalized view'' design
pattern in Section {}\ref{sec:generalized-view-design-pattern}.


%
{}\subsubsection{Extra data}
\label{sec:extra-data}
%

As mentioned in Section
{}\ref{sec:basic-reference-counting-machinery}, the Teuchos
reference-counting machinery supports storing and retrieving arbitrary
objects as extra data stored on the {}\ttt{RCPNode} object itself.
The functions supporting extra data for the {}\ttt{RCP} class are
shown in Listing {}\ref{listing:RCP-extra-data} (the functions for
{}\ttt{ArrayRCP} are identical).

\begin{listing}:  {}\ttt{RCP} extra data functions \\
\label{listing:RCP-extra-data}
{\small\begin{verbatim}
  template<class T1, class T2>
  void set_extra_data(const T1 &extra_data, const std::string& name,
    const Ptr<RCP<T2> > &p, EPrePostDestruction destroy_when = POST_DESTROY,
    bool force_unique = true);
  
  template<class T1, class T2> 
  const T1& get_extra_data(const RCP<T2>& p, const std::string& name);
  
  template<class T1, class T2>
  T1& get_nonconst_extra_data(RCP<T2>& p, const std::string& name);
  
  template<class T1, class T2>
  Ptr<const T1> get_optional_extra_data(const RCP<T2>& p, const std::string& name);
  
  template<class T1, class T2>
  Ptr<T1> get_optional_nonconst_extra_data(RCP<T2>& p, const std::string& name);
\end{verbatim}}
\end{listing}

Given the support for embedded objects as described in Section
{}\ref{sec:embedded-objecs}, extra data rarely needs to be used.
Embedding and retrieving objects in the templated
{}\ttt{RCPNodeImpl} object is more efficient that using the more
general {}\ttt{std::map} object and {}\ttt{any} wrapper that are
used to implement the ``extra data'' feature and therefore embedded
objects should be used whenever possible instead of extra data.
However, there are a few advantages to using extra data over embedded
objects that may be worth the performance overhead or extra data may
be the only way to address an issue:

\begin{itemize}

{}\item\textit{You can associate data after the RCPNode object is
created.}  With embedded objects, you can only select the data-type
for the embedded object at the time when the first {}\ttt{RCP}
object is created.

{}\item\textit{You can retrieve data without having to know the
concrete template types in the {}\ttt{RCPNodeImpl} object.}  With
extra data, you only need to know the string name and the type of the
extra data that you are looking to retrieve.  With embedded objects,
you also need to know the origianl type of the underling
reference-counted object that is used to template the
{}\ttt{RCPNodeImpl} class.  If this type changes (i.e.\ if the
creating code changes the subclass implementation used), then this
will break the code that tries to retrieve the embedded object.
Therefore, client code that retrieves embedded object data is more
fragile that code that retrieves extra data.

{}\item\textit{You can completely change the deallocation policy at
runtime after the RCPNode object has been created.}  With embedded
objects, you can not change the deallocation policy of a
reference-counted object after the initial {}\ttt{RCPNodeImpl}
object has been created; with extra data you can.

\end{itemize}

To demonstrate the power and flexibility of extra data, let's consider
a (unlikely) scenario where some piece of code incorrectly associates
the wrong deallocation policy to an allocated object shown in Listing
{}\ref{listing:createRCPWithBadDealloc}.

\begin{listing}: Example of incorrect deallocator \\
\label{listing:createRCPWithBadDealloc}
{\small\begin{verbatim}
  RCP<A> createRCPWithBadDealloc()
  {
    return rcp(new A[1]); // Will use delete but should use delete []!
  }
\end{verbatim}}
\end{listing}

Hopefully no-one would write code like is shown in Listing
{}\ref{listing:createRCPWithBadDealloc}.  However, let's suppose that
you have to use the function {}\ttt{createRCPWithBadDealloc()} to
allocate {}\ttt{A} objects and are stuck with a pre-compiled
library and you can't access the soruce code to fix the problem.  On
most systems an error like this will be tolerated and not cause
problems but tools like Valgrind and Purify will complain about code
like this to no end and there may be some platforms where this will
actually cause the program to crash (since this is undefined
behavior).

With {}\ttt{RCP} and extra data, you can replace the deallocation
policy on the fly to use the correct policy.  The first step is to
create a class that will call {}\ttt{delete []} on the pointer
correctly as shown in Listing
{}\ref{listing:DeallocArrayDeleteExtraData}.

\begin{listing}: Dealllocator class for extra data deallocation \\
\label{listing:DeallocArrayDeleteExtraData}
{\small\begin{verbatim}
  template<typename T>
  class DeallocArrayDeleteExtraData {
  public:
    static RCP<DeallocArrayDeleteExtraData<T> > create(T *ptr)
      { return rcp(new DeallocArrayDeleteExtraData(ptr)); }
    ~DeallocArrayDeleteExtraData() { delete [] ptr_; }
  private:
    T *ptr_;
    DeallocArrayDeleteExtraData(T *ptr) : ptr_(ptr) {}
    // Not defined!
    DeallocArrayDeleteExtraData();
    DeallocArrayDeleteExtraData(const DeallocArrayDeleteExtraData&);
    DeallocArrayDeleteExtraData& operator=(const DeallocArrayDeleteExtraData&);
  };
\end{verbatim}}
\end{listing}

The client code can then fix the deallocation policy as shown in
Listing {}\ref{listing:using-DeallocArrayDeleteExtraData}.

\begin{listing}: Using {}\ttt{DeallocArrayDeleteExtraData} as extra data \\
\label{listing:using-DeallocArrayDeleteExtraData}
{\small\begin{verbatim}
  // Create object with bad deallocator
  RCP<A> a = createRCPWithBadDealloc();

  // Disable default (incorrect) dealloc and set a new deallocation policy as extra data!
  a.release();
  set_extra_data( DeallocArrayDeleteExtraData<A>::create(a.getRawPtr()), "dealloc",
    inOutArg(a));
\end{verbatim}}
\end{listing}

The kind of flexibility shown in the above example is not possible
with using embedded objects and is not possible with classes like
{}\ttt{boost:shared\_ptr}.  There are numerous other uses for extra
data to fix nasty memory management problems and you will just have to
use your imagination.  However, in well designed software, there is no
need for a feature like this so count yourself lucky if you never need
to use it.


%
{}\subsubsection{General roles and responsibilities: Factories and
general clients}
%

There are two fundamentally different sets of actors that play two
different roles in the use of the reference-counted classes: a)
factory entities that first create the reference-counted object, and
b) general clients that accept and use a shared reference counted
object through a passed-in reference-counted class.

Factory entities first create the reference-counted object/array
and/or construct the first {}\ttt{[Array]RCP} object containing it.
The most basic type of factory are the non-member constructor
functions described in Section
{}\ref{sec:nonmember-constructor-idiom}.  When the first
{}\ttt{[Array]RCP object} is created, the factory gets to decide
exactly how object/array will be released when the last reference
count goes to zero.  The default, of course, is to just simply call
{}\ttt{delete} or {}\ttt{delete []} on the contained raw pointer
which is the default behavior.  However, the factory can also choose
any arbitrary action imaginable to occur when the reference-count goes
to zero.  This is set up using a template deallocator policy object as
described in Section {}\ref{sec:deallocators}.

On the other side, the responsibilities of the general client that
shares and uses a reference-counted object are very simple.  These
responsibilities are:

\begin{itemize}

{}\item Accept the persisting relationship for a shared
reference-counted object/array through an {}\ttt{[Array]RCP} object
(as described in Section {}\ref{sec:idioms-for-passing-arguments}).

{}\item Share the reference-counted object/array with other clients by
creating a copy if your {}\ttt{[Array]RCP} object and giving it to
them.

{}\item When you are finished using the object, simply delete or set
to null all of your {}\ttt{[Array]RCP} objects.  If some other
client is still using the object, it will still remain.  If yours is
the last reference, then the deallocator policy object that is
embedded in the underlying {}\ttt{RCPNodeImpl} object will know
exactly how to clean up and reclaim the object/array.

\end{itemize}

That is all there is to it.  Factories create the underlying object(s)
wrapped in the first {}\ttt{[Array]RCP} object and define how the
referenced object(s) will be reclaimed when it is time.  General
clients just accept and maintain their references to shared
objects/arrays by accepting and storing {}\ttt{[Array]RCP} object
and then setting them to null when they are finished using the
object(s).


%
{}\subsection{Debug-mode runtime checking}
\label{sec:debug-mode-runtime-checking}
%

The primary reason that these Teuchos memory management classes need
to be developed in tandem and know each other's internal
implementations to some extend is to be able to implement robust and
effective debug-mode runtime testing.  The debug-mode runtime testing
that is built into these classes is very strong and will catch nearly
every type of programmer error that is possible, as long as raw C++
pointers are never externally exposed and if raw C++ references are
only used for persisting associations.  The different categories of
debug-mode runtime testing are described below along with what the
typical diagnostic error messages look like.


%
{}\subsubsection{Detection of null dereferences and range checking}
\label{sec:null-dereferences-range-checking}
%

One of the most basic types of debug-mode runtime checking performed
by the Teuchos memory management classes are for attempts to
dereference a null pointer and range checking of arrays and iterators.

\begin{listing}: Debug-mode null dereference checking (all types) \\
\label{listing:null-deref}
{\small\begin{verbatim}
  RCP<A> a_ptr;
  A &a_ref = *a_ptr;   // Throws!
  a_ptr->someFunc();   // Throws!

  ArrayRCP<int> aa;
  a[0];                    // Throws!
  int &i_ref = *a.begin(); // Throws!

  ...  
\end{verbatim}}
\end{listing}

All of the Teuchos memory management classes throw on null
dereferences.  While most systems will abort the program on null
dereferences there are some platforms (some Intel C++ compilers) that
will not and it will result in memory errors that may not be seen
until later in the program.

The Teuchos array classes {}\ttt{Array}, {}\ttt{ArrayView},
{}\ttt{ArrayRCP}, and {}\ttt{Tuple} all perform array bounds
checking in debug-mode builds:

\begin{listing}: Debug-mode array-bounds checking (all Teuchos array types) \\
\label{listing:array-bounds-checking}
{\small\begin{verbatim}
  Array a(n);
  a[-1];   // Throws!
  a[n];    // Throws!
\end{verbatim}}
\end{listing}

In a debug-mode build of the code, all the iterators returned by the
{}\ttt{begin()} and {}\ttt{end()} functions of the classes
{}\ttt{Array}, {}\ttt{ArrayView}, {}\ttt{ArrayRCP}, and
{}\ttt{Tuple} are of the type {}\ttt{ArrayRCP} which is a fully
ranged checked iterator.  For example:

\begin{listing}: Debug-mode iterator range checking (all Teuchos array types) \\
\label{listing:iterator-checking}
{\small\begin{verbatim}
  Array a(n);
  *(a.begin()-1);           // Throws!
  *(a.begin() + a.size());  // Throws!
  *a.end();                 // Throws!
\end{verbatim}}
\end{listing}

This type of checking is fairly straightforward but is extremely
useful and works on every platform.  This checking is built into your
programs automatically in a debug build of the code.  However, in an
non-debug build of the code, there is none of this checking to yield
the fastest code.


%
{}\subsubsection{Detection of circular references}
\label{sec:detection-circular-references}
%

One of the more sophisticated types of debug-mode runtime checking is
the detection and reporting of circular {}\ttt{RCP} references that
results in memory leaks.  The issue of circular references and the
concept of weak pointers was outlined in Section
{}\ref{sec:circular-references-weak-pointers}.  When debug-mode node
tracing is enabled, the reference-counting machinery keeps track of
all the {}\ttt{RCPNode} objects that are created and destroyed.  If
node tracing is enabled and the program ends and there are one or more
{}\ttt{RCPNode} objects that are still remaining, then a error
message is printed to {}\ttt{std::cerr} that gives all the details
of the objects involved in the cicular reference.

For example, consider the simple circular reference shown in Figure
{}\ref{fig:CircularRCP_A_B}.  If left this way, if debug-mode node
tracing is enbled, then the program ends an error message like the
following will be printed to {}\ttt{std::cerr}:

\begin{listing}: Example error message for circular references \\
\label{listing:curcular-ref-error-msg}
{\small\begin{verbatim}
  ***
  *** Warning! The following Teuchos::RCPNode objects were created but have
  *** not been destroyed yet.  This may be an indication that these objects may
  *** be involved in a circular dependency!  A memory checking tool may complain
  *** that these objects are not destroyed correctly.
  ***
  
    0: RCPNode (map_key_void_ptr=0x4a3ff50)
         Information = {T=A, ConcreteT=A, p=0x4a3ff50, has_ownership=1}
         RCPNode address = 0x4a3ffa8
         Call number = 23
    1: RCPNode (map_key_void_ptr=0x4a40548)
         Information = {T=B, ConcreteT=B, p=0x4a40548, has_ownership=1}
         RCPNode address = 0x4a405f0
         Call number = 24
\end{verbatim}}
\end{listing}

This error message is enough information to allow you to open a
debugger, and set a breakpoint in the function
{}\ttt{RCPNodeTracer::addNewRCPNode(...)} and then exame where
these objects are getting created that result in the cicular reference
(Note: you will need to run the program again in the debugger which
will produce different pointer addresses).

Note that in reality, the cicular references will involve many objects
(sometimes more than a dozen) and therefore this output will contain
many {}\ttt{RCPNode} objects.


%
{}\subsubsection{Detection of dangling references}
\label{sec:detection-dangling-references}
%

Another useful and necessary form of debug-mode runtime checking
involves detection and reporting of access to invalid objects and
arrays made through dangling references.  A dangling reference is a
catch-all term that refers to any pointer or reference that points to
a no-longer valid object or array.  For example, the following code
fragement shows invalid access to a dangling iterator to an array that
has changed shape:

\begin{listing}: Example of a dangling iterator \\
\label{listing:Array-dangling-iterator}
{\small\begin{verbatim}
  Array<int> a(n);
  Array<int>::iterator itr = a.begin();
  a.resize(0);
  *itr = 1; // Invalid access of dangling iterator (throws)!
\end{verbatim}}
\end{listing}

In debug-mode, the above example would result in an exception being
thrown with an error message like shown below:

{\small\begin{verbatim}
  Teuchos_RCPNode.hpp:515:
  
  Throw number = 3
  
  Throw test that evaluated to true: true
  
  Error, an attempt has been made to dereference the underlying object
  from a weak smart pointer object where the underling object has already
  been deleted since the strong count has already gone to zero.
  
  Context information:
  
    RCP type:             Teuchos::ArrayRCP<int>
    RCP address:          0x7fbfffec98
    RCPNode type:         Teuchos::RCPNodeTmpl<int,
      Teuchos::EmbeddedObjDealloc<int,
        Teuchos::RCP<__gnu_debug_def::vector<int, std::allocator<int> > >,
        Teuchos::DeallocArrayDelete<int> > >
    RCPNode address       0xab65a0
    RCP ptr address:      0xab4c50
    Concrete ptr address: 0xab4c50
  
  Hint: Open your debugger, run the program again (which will result in
  new pointer addresses) and then set conditional breakpoints using these
  pointer addresses in the various routines involved where this node object
  is first created with this concrete object and in all of the RCP objects
  of the type given above use this node object.  Debugging an error like this
  may take a little work in setting up your debugging session but at least
  you don't have to try to track down a segfault that would occur otherwise!
\end{verbatim}}

The above error message contains all the information needed to open a
debugger, run the program again to create new pointer addresses, set
up breakpoints and break conditions, and debug the problem (see
Section {}\ref{sec:except-handling-debugging}).

A few other examples of dangling references are shown in Listings
{}\ref{listing:Array-dangling-ArrayView}--{}\ref{listing:RCP-dangling-Ptr}.

\begin{listing}: Example of a dangling {}\ttt{ArrayView} \\
\label{listing:Array-dangling-ArrayView}
{\small\begin{verbatim}
  ArrayView<int> av;
  {
    Array<int> a(n);
    av = a;
  }
  av[0] = 1; // Invalid access to dangling ArrayView (throws)
\end{verbatim}}
\end{listing}

\begin{listing}: Example of a dangling {}\ttt{Ptr} \\
\label{listing:RCP-dangling-Ptr}
{\small\begin{verbatim}
  Ptr<A> a_ptr;
  {
    RCP<A> a_rcp = createA();
    a_ptr = a_rcp.ptr();
  }
  a_ptr->someFunction(); // Invalid access to dangling Ptr (throws)
\end{verbatim}}
\end{listing}

In general, {}\ttt{Ptr}, {}\ttt{ArrayView} and iterators
(returned from the {}\ttt{begin()} member functions) all can be
involved in dangling references since they lack support for
reference-counting machinery in a non-debug build.  Therefore, anytime
a {}\ttt{Ptr}, {}\ttt{ArrayView}, or iterator object is created
from some other Teuchos memory management object, you can expect that
in a debug build that dangling references will checked for.

Note that the ability to detect a dangling {}\ttt{ArrayView} of an
{}\ttt{Array} object as shown in Listing
{}\ref{listing:Array-dangling-ArrayView} is due to the fact that the
debug-mode internal implementation of {}\ttt{Array} is designed to
support this.  Compare this to {}\ttt{ArrayView} views of
{}\ttt{std::vector}, as shown in Listing
{}\ref{listing:vector-dangling-ArrayView}, here dangling references
can not be detected.

\begin{listing}: Dangling {}\ttt{ArrayView} of {}\ttt{std::vector}
(can not detect dangling references) \\
\label{listing:vector-dangling-ArrayView}
{\small\begin{verbatim}
  ArrayView<int> av;
  {
    std::vector<int> v(n);
    av = v;
  }
  av[0] = 1; // Invalid access to dangling ArrayView (does *not* throw)
\end{verbatim}}
\end{listing}

The code in Listing {}\ref{listing:vector-dangling-ArrayView} will
most likely segfault if we are lucky.  If we are unlucky, the program
may actually appear to run correctly on our main development and
testing platforms and it will not be until we move to a production
platform that the ill-effects of this erroneous code will seen.  This
is one example of why it is so important to use {}\ttt{Array}
instead of raw {}\ttt{std::vector} objects.  Strong debug-mode
runtime checking with {}\ttt{Array} object is not possible with
{}\ttt{std::vector}.

Another type of more sophisitcated debug-mode dangling reference
detection involves non-owning {}\ttt{RCP} objects to existing
reference-counted objects.  Consider like shown in Listing
{}\ref{listing:RCP-nonowning-dangling-ref}.

\begin{listing}: Example of a dangling non-owning {}\ttt{RCP} object
(node tracing only) \\
\label{listing:RCP-nonowning-dangling-ref}
{\small\begin{verbatim}
  RCP<A> a_ptr = createA();
  A &a_ref = *a_ptr;
  RCP<A> a_ptr2 = rcpFromRef(a_ref);  // Same as rcp(a_ref.getRawPtr(), false)
  a_ptr = null;   // The 'A' object gets deleted (a_ptr2 is a dangling pointer)
  a_ptr2->someFunction();  // Invalid reference to deleted 'A' object (throws)
\end{verbatim}}
\end{listing}

In a debug-mode build with node tracing turned on, the dangling
non-owning {}\ttt{RCP} reference in Listing
{}\ref{listing:RCP-nonowning-dangling-ref} will be caught by the
system.  This works because the statement
{}\ttt{rcpFromRef(a\_ref)} results in a call to
{}\ttt{RCPNodeTracer::getExistingRCPNode(...)} to lookup the
existing {}\ttt{RCPNode} object that points to the same
{}\ttt{A} object.  In this case, the existing {}\ttt{RCPNode}
object is found and it is used to create a weak {}\ttt{RCP} object
(see Section {}\ref{sec:circular-references-weak-pointers}) that can
then detect if the original {}\ttt{RCP} object has been deleted.
Again, this more sophisicated type of debug-mode runtime checking
requires that node tracing be enabled\footnote{In order to handle
multiple inheritance and virtual bases classes and still get the
correct base object address, Boost support must also be configured
which is needed to use {}\ttt{boost::is\_polymophic} to allow the
use of {}\ttt{dynamic\_cast<void*>(...)} to determine the true base
address of an object.  Otherwise, without this, the system will not be
able to determine if two abstract interfaces really point to the same
object and therefore the lookup of the {}\ttt{RCPNode} object will
fail.}.

Debug-mode runtime detection and reporting of dangling references is
built on the foundation of weak {}\ttt{RCP} and {}\ttt{ArrayRCP}
objects.  Basically, all non-perisisting views use a weak
{}\ttt{RCP} or {}\ttt{ArrayRCP} object (see Section
{}\ref{sec:circular-references-weak-pointers}) internally to allow the
parent object to be changed or be deleted and to detect this if a
client tries to access the now invalid object through the dangling
reference view.


%
{}\subsubsection{Detection of multiple owning {}\ttt{RCP} objects}
\label{sec:detection-dual-owning-rcps}
%

{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.65]{RCPEx2}
%}
\end{center}
\caption{
\label{fig:RCPEx2}
Example of duplicate owning {}\ttt{RCPNodeImpl} objects}
\end{figure}
\esinglespace}

There are other types of invalid usage that can be detected and caught
in debug-mode with node tracing enabled.  Consider, for example, what
happens when one or more of the commandments are broken and more than
one owning {}\ttt{RCPNode} object exists pointing to the same
underlying {}\ttt{ConcreteT} object as shown if Figure
{}\ref{fig:RCPEx2}.  This type of structure can be generated with the
sloppy code shown in Listing {}\ref{listing:duplicate_owning_rcp}.

{}\begin{listing}: Invalid creation of dual owning {}\ttt{RCPNodeImpl}
objects
\label{listing:duplicate_owning_rcp}
{\small\begin{verbatim}
  C *c_raw_ptr = new C;
  RCP<C> c_ptr(c_raw_ptr);
  RCP<A> a_ptr1 = c_ptr;
  ...
  A *a_raw_ptr = c_raw_ptr;
  RCP<A> a_ptr2(a_raw_ptr);
\end{verbatim}}
\end{listing}

The problem is that the two {}\ttt{RCPNodeImpl} objects shown in
Figure {}\ref{fig:RCPEx2} generated by Listing
{}\ref{listing:duplicate_owning_rcp} do not know about each other and
the first one who has its strong reference count go to zero will
result in the underlying {}\ttt{C} object being deleted.  In this
case, the other remaining {}\ttt{RCPNodeImpl<A>} object, and all of
the resulting {}\ttt{RCP} objects pointing to it will be left with
a non-null pointer to a now deleted {}\ttt{C} object.  If the
client tries to access the underlying object through one of these now
invalid references, it will likely result in a segfault (if we are
lucky).  Or, if we are unlucky, the program might seem to work okay on
the platform we are currently testing on but will eventually explode
at the worst possible time.

Not to fear, in a debug-mode build with node tracing enabled, the
{}\ttt{RCPNodeTracing} object automatically detects the creation of
the second owning {}\ttt{RCPNodeImpl<A>} object and will thrown an
exception with an error message that looks something like:

{\small\begin{verbatim}
  Trilinos/packages/teuchos/src/Teuchos_RCPNode.cpp:240:
  
  Throw number = 1
  
  Throw test that evaluated to true: rcp_node_already_exists && rcp_node->has_ownership()
  
  Teuchos::add_new_RCPNode(node_ptr): Error, the client is trying to create a new
  RCPNode object to an existing managed object in another RCPNode:
  
    New RCPNode {address=0x9cb3e0, base_obj_map_key_void_ptr=0x9cac40,
      base_obj_type_name=A, map_key_void_ptr=0x9cac40, has_ownership=1}
  
    Existing RCPNode {address=0x9cb2b0, base_obj_map_key_void_ptr=0x9cac40,
     base_obj_type_name=C, map_key_void_ptr=0x9cac40, has_ownership=1}
  
    Number current nodes = 6
  
  This may indicate that the user might be trying to create a weak RCP to an existing
  object but forgot make it non-ownning.  Perhaps they meant to use rcpFromRef(...)
  or an equivalent function.
\end{verbatim}}

A debugger can be opened, a breakpoint can be set in the function
{}\ttt{TestForException\_break(...)}, and the program can be run
again to see the context under which the second illegal
{}\ttt{RCPNodeImpl} is created.

If you are willing to pay for a little extra overhead of
{}\ttt{RCPNode} tracing (see Section
{}\ref{sec:reference-counting-overhead} for some timing results of the
overhead), then node tracing will detect the erroneous creation of
multiple owning {}\ttt{RCPNode} objects and respond in a graceful
way.  Note that creating multiple {}\underline{non-owning}
{}\ttt{RCPNode} objects is just fine and is allowed both when node
tracing is enabled and when it is not enabled.


%
{}\subsubsection{Performance of debug-mode checking versus memory
checking tools}
%

One of the common criticisms of debug-mode runtime checking is that it
incurs an unacceptably large runtime overhead of the code.  However,
this overhead is only incurred for debug-mode builds and does not
affect non-debug optimized builds.  To speed up debug-mode runtime
checking, you can compile with optimized compiler options (e.g.\
{}\ttt{-O3}) which significantly speeds up the code.  Also, one has
to consider the relative cost of built-in debug-mode runtime checking
verses running a memory checking tool like valgrind or purify.

To investigate the cost of debug-mode runtime checking we use the
Trilinos package
Tpetra\footnote{{}\ttt{http://trilinos.sandia.gov/packages/tpetra/}}
since it uses the Teuchos memory management classes at a very low
level and therefore would be expected to show the largest runtime
overhead of debug-mode checking.  Table
{}\ref{tbl:overhead-of-runtime-checking} shows the runtime of the
Tpetra serial test suite (12 test programs) for several different
build and runtime configurations.  In all of these builds, optimized
compiler options were used.  All of these timing tests were performed
on an a 3.2GHz AMD machine with 8 cores running Linux
2.6.9-78.0.1.ELsmp using GCC 3.4.6.  Valgrind tests were run using
version 3.2.1.  All of the test executables were run in serial with an
unloaded machine.

\begin{table}
%
\begin{center}
%
{\small\begin{tabular}{|l|r|r|r|}
\hline
Configuration
& Runtime (sec)
& Multiplier
& Valgrind Mult \\
\hline
\hline
1) Optimized build (base-line)
& 0.16
& 1.0
& - \\
\hline
2) Debug-mode runtime checking
& 0.49
& 3.1
& - \\
\hline
3) Debug-mode runtime checking + node tracing
& 1.08
& 6.8
& - \\
\hline
4) Valgrind optimized build
& 56.21
& 351.3
& 351.3 \\
\hline
5) Valgrind debug-mode runtime checking
& 214.01
& 1337.6
& 431.5 \\
\hline
6) Valgrind debug-mode runtime checking + node tracing
& 378.54
& 2365.9
& 347.9 \\
\hline
\end{tabular}}
%
\end{center}
%
\caption{\label{tbl:overhead-of-runtime-checking}
Overhead of runtime checking for serial Tpetra test suite.}
%
\end{table}

The results in Table {}\ref{tbl:overhead-of-runtime-checking} give the
total runtimes as well as the relative runtimes for debug-mode
checking and valgrind.  The second column 'Runtime' gives the raw CPU
time in seconds (as reported by CTest) for all 12 test executables in
the Tpetra test suite.  The third column 'Muliplier' gives the ratio
of the runtime relative to the base-line optimized build case.  The
fourth column 'Valgrind Multi' gives the fractional increase in the
runtime of the test suite run with valgrind relative to running the
same executables without valgrind.

The results in Table {}\ref{tbl:overhead-of-runtime-checking} show
that while the cost incured by debug-mode runtime checking can be
significant (a factor of 3.1 for basic debug-mode runtime checking) it
is still quite reasonable.  When node tracing is enabled, the cost
more than doubles to a factor of 6.8 times the basic optimized build.
While to cost of full debug-mode runtime checking with node tracing is
a factor of 6.8 over the basic optimized build, the cost of running
with valgrind is a factor of over 300!  The increased cost of running
valgrind is a factor of 431.5 for the basic debug-mode executables.  A
factor of 300 can make running a tool like valgrind prohibitive for
reasonable sized problems while a factor of 6.8 may be quite
reasonable.  For example, a test problem that takes 20 minutes to run
in a standard optimized build may take 2 hours 15 minutes to run with
full debug-mode runtime checking with node tracing enabled but that
same program may take 100 hours or more than 4 days to run with
valgrind!  Also, as has been mentioned several times before, the level
of runtime checking provided in a Teuchos debug-mode is arguably more
effective that what you get with just valgrind\footnote{However,
valgrind does perform a number of other types of checks including
usage of uninitialized memory that are very useful and can not be
duplicated by the Teuchos memory management classes.}.  In order to
perform the most detailed runtime checking possible, you can run with
valgrind with debug-mode runtime checking with node tracing enabled.
However, the overhead of this maximal checking is staggering at more
than 23K times the cost of the basic optimized build!  At this level
of overhead, only very small test problems can be run.

What these timing results suggest is that the cost of debug-mode
runtime checking for programs using the Teuchos memory management
classes will be less than a factor of 10 more than the basic optimized
build in the worst case while the overhead of running a tool like
Valgrind can be as much as a factor of 400 or more.  This means that
enabling debug-mode runtime checking in regular development and
automated testing is quite reasonable.  Note that the Tpetra package
used in this example is likely an extreme case in the usage of the
Teuchos memory management classes.  Other types of software that don't
use the Teuchos memory mangement classes for such low-level
computations will see much less of a slow-down.  However, note that
theses tests were only performed on one machine using one compiler so
results on other platforms using different compilers may vary
significantly.


%
{}\subsubsection{Limitations of debug-mode runtime checking}
\label{sec:limitations-debug-mode-checking}
%

Once memory is dynamically allocated and owned by one of the Teuchos
memory mangaement class objects, the debug-mode runtime checking will
catch every imaginable type of programming error as long a raw C++
pointer or raw C++ reference is not exposed.  If all the idioms and
rules outlined in this paper are followed, then the only issue the
developer will have to address that is not 100\% obvious are circular
references.  However, if programmers never made any mistakes, there
would be no need for debug-mode runtime testing in the first place.
While the level of debug-mode runtime testing implemented in the
Teuchos memory management classes is unmatched, code that converts
from raw pointers (and raw references) to Teuchos memory management
objects and vice versa is vulnerable to programming errors that the
debug-mode runtime checking cannot catch.

The first category of programming errors that cannot be detected
involve some types of conversions of raw pointers (and raw references)
to Teuchos memory management objects.  However, before discussing
situations where the debug-mode runtime checking will not catch
errors, first note that if an object is dynamically allocated and is
immediately given over to a strong owning {}\ttt{RCP} object (or
{}\ttt{ArrayRCP} object in the case of arrays) then many different
types of bad conversions from raw pointers (and raw references) to
memory management types will be caught.  That is because when an
object's address is associated with a strong owning RCP, it gets added
to the debug-mode {}\ttt{RCPNode} tracing system discussed in Section
{}\ref{sec:basic-reference-counting-machinery}.  Given this tracking,
future conversions from a raw pointer or raw reference to a Teuchos
memory management class object that result in multiple owning
{}\ttt{RCP}s or dangling references from {}\ttt{Ptr}s and non-owning
{}\ttt{RCP}s will all be detected and cleanly reported (see Sections
{}\ref{sec:detection-dangling-references} and
{}\ref{sec:detection-dual-owning-rcps}).  One way to guarantee this is
to require that a classes' objects be dynamically allocated through
its non-member constructors (Section
{}\ref{sec:nonmember-constructor-idiom}) which returned the new
objects wrapped in {}\ttt{RCP}s.  In this way, the object is
immediately tracked under the debug-mode node tracing system.

However, not every class can or should employ the non-member
constructor idiom to force the creation of strong owning {}\ttt{RCP}
objects.  In particular, value-type classes (Section
{}\ref{sec:value-and-reference-types}) such as {}\ttt{std::vector} and
{}\ttt{Teuchos::Array} must be allowed to be generally constructed on
the stack or globally but we still need to be able to dynamically
allocate them in many different situations.  The downside to allowing
value-type class objects to be dynamically allocated and managed with
{}\ttt{RCP} is that it allows client code to try to create an owning
{}\ttt{RCP} to a stack (or otherwise non-dynamically) allocated object
which the debug-mode runtime checking will not be able to detect as
shown, for example, in Listing {}\ref{listing:bad-delete-error}.


{}\begin{listing}: Example where debug-mode checking cannot detect an
erroneous delete issue
\label{listing:bad-delete-error}
{\small\begin{verbatim}
  {
     std::vector<int> vec(n);
     const RCP<std::vector<int> > vec_rcp(&vec); // Gives ownership to delete!
     ...
     // When vec_rcp is destroyed it will call delete on the address &vec
     // resulting in a segfault!
  }
\end{verbatim}}
\end{listing}


In this case, the owing {}\ttt{RCP<std::vector<int> >} object will try
to call {}\ttt{delete} on the address {}\ttt{\&vec} at the end of the
block which will result in a segfault.  The lack of debug-mode
checking shown in Listing {}\ref{listing:bad-delete-error} is
unfortunate but it is very hard to detect if an address is for a
dynamically allocated object where it is okay to call
{}\ttt{delete}\footnote{Perhaps in the future a portable library
function can be written and used that will be able to detect the
difference between a stack address and a heap address so an exception
can be thrown right when the bad owning {}\ttt{RCP} is first created.
}.  Note that the code in this example violates Commandment
{}\ref{cmnd:rcp-new} in Appendix {}\ref{apdx:commandments} that states
that owning {}\ttt{RCP} (and {}\ttt{ArrayRCP}) objects should only be
created by passing in the address directly returned from {}\ttt{new}
(or {}\ttt{new[]} for {}\ttt{ArrayRCP}) unless a customized
deallocation policy object is attached.  The good news though is that
memory checking tools like Valgrind and Purify usually do a good job
of detecting and reporting erroneous calls to {}\ttt{delete} (i.e.\
{}\ttt{free(...)}) that try to free stack-owned memory.  But again if
the idioms outlined in Section {}\ref{sec:idioms} and the commandments
defined in Appendix {}\ref{apdx:commandments} are followed, this
problem should never occur.

% ToDo: Look into overloading global new and delete in a debug-mode
% build in order to log every new and delete and be able to determine if
% an address is on the stack or the heap.  This could be very hard to
% pull off.

The other category of programming errors that the debug-mode runtime
checking cannot detect and report involves exposing and then misusing
raw C++ pointers and references.  As soon as you expose a raw C++
pointer and start copying it around, all bets are off.  However, even
if you never expose a C++ pointer, you can still get into trouble.
One unfortunate case involves the use of raw C++ references.  If C++
references are only used as formal arguments to C++ functions, you
will almost never have a problem.  However, incorrectly returning an
{}\ttt{RCP} object by reference instead of by value, as is described
in Section {}\ref{sec:idioms-returning-objects}, can result in invalid
C++ references.  Also, if you use references like in Listing
{}\ref{listing:raw-ref-dangling-ref}, then you can of course have
dangling raw C++ references that the Teuchos debug-mode runtime
checking can never catch.

{}\begin{listing}: Example of where holding on to a raw C++ references
disables debug-mode runtime checking
\label{listing:raw-ref-dangling-ref}
{\small\begin{verbatim}
  RCP<A> a_ptr = newA();
  A &a = *a_ptr;
  ...
  a->someFunc();
  // This above object may not be valid anymore and may result in a segfault!
\end{verbatim}}
\end{listing}

The code in Listing {}\ref{listing:raw-ref-dangling-ref} violates the
use of raw C++ references only for non-persisting associations.  The
statement {}\ttt{A \&a = *a\_ptr} results in the creation of a
persisting relationship in that it extends past the statement where it
was created.

In summary, as soon as an object reference is exposed through a raw
C++ pointer or a raw C++ reference, in general the Teuchos debug-mode
runtime checking can no longer detect errors.  Therefore, never expose
a raw C++ pointer (except for the situations described in Section
{}\ref{sec:role-of-raw-pointers}) and only expose and use raw C++
references in strictly non-persisting associations.  Also, great care
must be taken in first constructing Teuchos memory management class
objects such they have the correct memory management properties.


%
{}\subsubsection{Exception handling and debugging}
\label{sec:except-handling-debugging}
%

The debug-mode runtime checking performed by the Teuchos memory
management classes throw exceptions when violations are detected.  As
has been shown throughout this document, these exceptions have
associated messages that are fairly detailed with lots of information
about the nature and context of the problem.

All exceptions thrown by the Teuchos memory management classes (and
the rest of Trilinos for that matter) all use a system of macros in
the file {}\ttt{Teuchos\_TestForException.hpp}.  All of these
macros call the function {}\ttt{TestForException\_break(...)} just
before an exception is thrown.  Therefore, if the error is repeatable
(and most errors are), then you can open a debugger (e.g.\ GDB) and
set breakpoint in that function and run the program.  Several
exceptions can be thrown before the exception that you need to debug.
To make it easier to break on the exception that you care about, every
exception message has a {}\ttt{Thrown number} associated with it
embedded in the error message of the exception object.  You can set a
conditional breakpoint in {}\ttt{TestForException\_break(...)} to
only stop when {}\ttt{throwNumber} has the right value.  For
example, if you need to stop on {}\ttt{Throw number = 10}, then in
GDB you can set:

{\small\begin{verbatim}
  (gdb) b 'TestForException_break [TAB] [ENTER]
  (gdb) cond 1 throwNumber==10
  (gdb) run
\end{verbatim}}

When the program stops at this breakpoint, you can then examine the
call stack to troubleshoot the problem.

Many exception messages contain other types of information that would
have you set breakpoints in other functions.  For example, a dangling
reference exception (as shown in Section
{}\ref{sec:detection-dangling-references}) would contain addresses of
objects that you would use to set conditional breakpoints.  For
example, to examine the context under which a {}\ttt{RCPNode} is
first created, you would set a breakpoint in the function
{}\ttt{Teuchos::RCPNodeTracer::addNewRCPNode(...)} and set a
condition to only break when the {}\ttt{RCPNode} has the address
that is printed in the exception message.  For example, for the
exception message shown in Section
{}\ref{sec:detection-dangling-references}, you would set the
breakpoint in GDB as:

{\small\begin{verbatim}
  (gdb) b 'Teuchos::RCPNodeTracer::addNewRCPNode [TAB] [ENTER]
  (gdb) cond 1 rcp_node==((void*)0xab65a0)
  (gdb) run
\end{verbatim}}

When the debugger breaks you would then be able to examine the call
stack to see the context under which this {}\ttt{RCPNode} object is
first created.

NOTE: Before entering a conditional breakpoint like this, you must
first run the program again in the debugger which will typically
produce an exception message with different addresses because the
debugger moves things around in memory.  You will need to use these
new pointer addresses when setting conditional breakpoints like this.

The Teuchos memory management classes are all fully exception safe in
that they provide either the basic guarantee (retain some valid object
state and no leaked memory when exception is thrown), the strong
guarantee (retain original state when exception is thrown), or the
no-throw guarantee (see {}\cite[Item 71]{C++CodingStandards05}).
However, if exceptions are thrown from destructors when objects are
being destroyed, then the classes are only fully exception safe in a
debug-mode build.  This does not really break exception safety since
destructors should not be throwing exceptions in most valid C++
programs (see {}\cite[Item 51]{C++CodingStandards05}).  The Teuchos
memory management classes provide the foundation for allowing the
wide-spread and consistent use of C++ exception handling in all of
your programs in such a way as memory will not be leaked when
exceptions are thrown.  However, achieving a truly an exception safe
program means more than just not leaking memory; it means that all
code provides at least one of the fundamental exception guarantees
(again, see {}\cite[Item 71]{C++CodingStandards05}).

Note that throwing exceptions differs from what other class libraries
do which is typically to call {}\ttt{assert(...)} when a runtime
failure is discovered.  For example, the checked STL for g++ will call
assert when a usage violation is discovered.  There are pros and cons
for throwing exceptions versus halting the program but if you can make
your code exception safe, then one can argue that throwing exceptions
is better because it allows the program to recover in case of a
catastrophic failure of a submodule while calling
{}\ttt{assert(...)} does not.  Also, writing unit tests for code
that throws exceptions is much easier and more efficient than trying
to write unit tests for code that halts the program.  This issue of
testability is a huge advantage of exception handling over calling
{}\ttt{assert(...)} or {}\ttt{exit(...)} when an error occurs.


%
{}\subsection{Optimized performance}
\label{sec:optimized-performance}
%

While debug-mode runtime checking is of great importance, of equal
importance is speed in a optimized non-debug build.  It is critical
that the wise use of the Teuchos memory management classes lead to
optimized performance that is nearly identical to the performance of
raw pointers.  Otherwise, if there is always a performance gap with
using the Teuchos memory management classes, then there will always be
an excuse to go back to using raw pointers will all of the disastrous
consequences discussed in Section
{}\ref{sec:problems-with-raw-pointers}.

In this section, we look at the optimized performance of the Teuchos
memory management classes.  In an optimized build, all of the runtime
checking is disabled but there is still some non-trivial overhead
associated with the reference-counting machinery.  If used at too fine
a granularity, reference-counting overhead can become a significant
performance problem on real-world problems.

The optimized performance of several different types of operations are
examined in the next few sections.  All of these performance timing
tests were run on three different compilers shown in Table
{}\ref{tbl:PerfTestPlatforms} that represent two mainstream platforms.
The GCC 4.1.2 and Intel ICC 10.1 results where run on the same Linux
machine and therefore one can directly compare the optimizing
capability of these two compilers on this platform.  Note that the
processor used for the Microsoft Vista platform is also Intel and has
the same clock speed as for the Linux platform.  Therefore, one can
make fairly direct comparisions of runtimes between the three
different compilers.  Timings on other compilers may give different
results, especially for compilers that have a bad history at
optimizing C++ code (e.g.\ PGI, Sun, AIX etc.).  All of these
performance timing tests are driven by a performance testing framework
in Teuchos and there are nightly test that strictly enforce relative
performance timing targets.

\begin{table}
%\fbox{\begin{minipage}{\textwidth}
\begin{description}
%
{}\item[GCC 4.1.2:] GNU GCC 4.1.2 (compiler options {}\ttt{-O3
-DBOOST\_SP\_DISABLE\_THREADS}) running under Linux 2.6.18-128.1.6.el5
on 2 Quad Intel Xeon CPUs at 2.93GHz and 4MB L1 Cache and 16 GB RAM.
%
{}\item[ICC 10.1:] Intel ICC C++ 10.1 (compiler options {}\ttt{-O3
-DBOOST\_SP\_DISABLE\_THREADS}) running under Linux 2.6.18-128.1.6.el5
on 2 Quad Intel Xeon CPUs at 2.93GHz and 4MB L1 Cache and 16 GB RAM.
%
{}\item[MSVC++ 2008:] Microsoft Visual C++ 2008 (compiler options
{}\ttt{/D\_SECURE\_SCL=0 /DBOOST\_SP\_DISABLE\_THREADS /Ox})
running under Windows Vista Enterprise on an Intel Core 2 Duo CPU
T9800 at 2.93GHz and 2.00 MB RAM.
%
\end{description}
%\end{minipage}}
\caption{\label{tbl:PerfTestPlatforms}
Performance testing platforms.}
\end{table}

This section is broken up into subsections as follows.  First, the
optimized performance of the reference-counting machinery is looked at
in Section {}\ref{sec:reference-counting-overhead}.
Reference-counting overhead will never go to zero with respect to raw
pointers but it is constant-time overhead and therefore its impact can
be minimized by not applying it at too low a level.  The optimized
performance of the Teuchos array classes is given in Section
{}\ref{sec:array-overhead}.  The timing results shown that the basic
bracket operator (i.e.\ {}\ttt{a[i]}) and iterator (i.e.\
{}\ttt{a.begin()}) access methods all yield raw pointer
performance.  Finally, in Section {}\ref{sec:perf-tuning-strategies},
performance tuning strategies are discussed, including the need to
relax the strict use of reference-counting classes {}\ttt{RCP} and
especially {}\ttt{ArrayRCP} in use cases where technically
persisting associations are present but reference-counting machinery
is not needed and the overhead of reference-counting is too high.


%
{}\subsubsection{Reference counting overhead}
\label{sec:reference-counting-overhead}
%

While the reference-counting machinery used by the {}\ttt{RCP} and
{}\ttt{ArrayRCP} classes significantly improves software
development productivity and quality in many respects, it also has a
certain amount of space and time overhead that needs to be considered
in design decisions.  Here, the cost of the various operations
associated with the {}\ttt{RCP} class are compared to raw pointers
and to the {}\ttt{boost::shared\_ptr} class.  Timings are performed
for creating and destroying the {}\ttt{RCPNode} object and
reference-counted object, for manipulating the reference count, and
for accessing the underlying reference-counted object.  These are the
core operations of the {}\ttt{RCP} class that are most likely to
affect performance.

All of the operations being timed are very low-level and therefore it
is difficult to get meaningful unbiased timing results.  To get
accurate timings, one must perform the operation in loop and average
the times.  With naive code, some compilers (e.g.\ Microsoft Visual
C++) will just optimize away the entire loop.  Therefore, the
operation must be performed in the context of a loop over an array
where the result of the loop gets used in some way to accumulate a
final result.  Otherwise, some compilers will just optimize away the
entire loop.  Examples of these types of timing loops will be given
below.  Because of the loop and iterator overhead and this extra
(minimal) computation, the timings listed for each operation are
higher that what they would be otherwise.  Therefore, the overhead
reported is lower that what it really is but by how much one can't be
sure.  Also, when performing loops, issues of loop initialization and
cache issues come into play.  In order to avoid these issues, a single
loop size from all the results of 1024 was selected to display in the
figures and tables in this section.  The raw timing results for other
loops sizes are given in Appendix {}\ref{apdx:raw-rcp-perf-data}.

The first type of overhead to consider is the memory overhead of the
reference-counting machinery shown in Figure
{}\ref{fig:TeuchosRCPDesign}.  Table {}\ref{tbl:RCP-SP-sizes} shows
the sizes of some important objects associated with {}\ttt{RCP} and
{}\ttt{boost::shared\_ptr} (on a 64 bit platform where pointers are
8 bytes).  The sizes are shown for allocating
{}\ttt{std::vector<double>} objects but the memory used by the
reference counting machinery only depends on pointers so the memory
usage overhead is the same no mater what type of object is used.  From
looking at Table {}\ref{tbl:RCP-SP-sizes}, one can see that the static
size of {}\ttt{std::vector<double>} is 24 bytes for this compiler.
Consider allocating an {}\ttt{std::vector<double>} with only one
element.  This would dynamically allocate one {}\ttt{double} object
in an array giving a total of 32 bytes.  Now consider the
reference-counting machinery overhead.  For every allocated
{}\ttt{std::vector<double>} object, there is a reference-counting
node object of type {}\ttt{RCPNodeImpl<std::vector<double>, ... >}
which is 48 bytes.  In addition there is also an
{}\ttt{RCP<std::vector<double> >} object of size 24 bytes.  That
gives a total of 24+48=72 bytes of reference-counting overhead to
manage an object that only consumes 32 bytes.  That is memory overhead
of 225\%!  However, when the {}\ttt{std::vector<double>} is
allocated to hold 100 elements, the memory consumed by the
{}\ttt{std::vector<double>} object is 24+8*(100) = 824 bytes.  Now
the 72 bytes of reference-counting overhead is only 8.7\%.  By the
time you get to 1000 elements, the overhead drops to 0.8\%.  The point
is that the reference-counting machinery imparts a storage overhead
that is non-trivial for small objects.  Therefore, {}\ttt{RCP}
should not be used to manage large numbers small objects.  Likewise,
{}\ttt{ArrayRCP} should not be used to manage small arrays for the
same reason.

Table {}\ref{tbl:RCP-SP-sizes} also shows the sizes of comparable
objects associated with the {}\ttt{boost::shared\_ptr} class.  The
boost node object only consumes 32 bytes on this machine as apposed to
the 48 bytes for the {}\ttt{RCPNodeImpl} object.  The increased
overhead of the {}\ttt{RCPNodeImpl} object is due to the pointer
for the extra data map, an extra ownership Boolean, and storage of the
deallocator object.  Also, the {}\ttt{boost::shared\_ptr} object
itself only consumes 16 bytes wile the equivalent {}\ttt{RCP}
object uses 24 bytes.  This increase in storage is due to having to
store a {}\ttt{strength} enum to dynamically handle
{}\ttt{STRONG} and {}\ttt{WEAK} references.  This is the storage
cost of increase flexibility of the {}\ttt{RCP} class over the
{}\ttt{boost::shared\_ptr} class.

\begin{table}
\begin{center}
\begin{tabular}{|l|r|}
\hline
Type
& {}\ttt{sizeof(Type)} \\
\hline
{}\ttt{bool}
& 1 \\
\hline
{}\ttt{double*}
& 8 \\
\hline
{}\ttt{double}
& 8 \\
\hline
{}\ttt{std::vector<double>}
& 24 \\
\hline
{}\ttt{boost::shared\_ptr<std::vector<double> >}
& 16 \\
\hline
{}\ttt{boost::detail::sp\_counted\_impl\_p<std::vector<double> >}
& 32 \\
\hline
{}\ttt{RCP<std::vector<double> >}
& 24 \\
\hline
{}\ttt{RCPNodeImpl<std::vector<double>, ... >}
& 48 \\
\hline
\end{tabular}
\end{center}
\caption{\label{tbl:RCP-SP-sizes}
Sizes of RCP and boost::shared\_ptr objects for 64 bit GCC 4.1.2.}
\end{table}


Now consider the runtime overhead associated with dynamic allocation
and deallocation.  Figure {}\ref{fig:RCPAllocTimings} shows the
timings for dynamically allocating and deleting
{}\ttt{std::vector<double>} objects for different numbers of vector
elements on the three compilers shown in Table
{}\ref{tbl:PerfTestPlatforms}.  Figure {}\ref{fig:RCPAllocTimings}.a
shows the timings for allocating {}\ttt{std::vector<double>}
objects with only one element.  This shows that there is some runtime
overhead needed to dynamically allocate the new node objects for
{}\ttt{RCP}.  The extra overhead is due to an extra call to
{}\ttt{new} in order to allocate the node object.  Note that the
extra overhead for {}\ttt{RCP} is quite small with respect to
{}\ttt{boost::shared\_ptr} for all three compilers.  However, this
is constant time overhead so as larger {}\ttt{std::vector<double>}
objects are allocated (with associated initialization of the vector
elements in an inner loop) the relative overhead goes to zero, as
shown in Figure {}\ref{fig:RCPAllocTimings}.b.  Therefore, the runtime
overhead of the reference-counting machinery for allocating and
deallocating large objects is very small.


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=1.00]{RCPAllocTimings}
%}
\end{center}
\caption{
\label{fig:RCPAllocTimings}
Timings for allocating and deallocating objects using RCP}
\end{figure}
\esinglespace}


Finally, timings for dereferencing ({}\ttt{RCP::operator*()}),
member access through the arrow operator
{}\ttt{RCP::operator->()}, and assignment
({}\ttt{RCP::operator=(...)}) which changes the reference counts)
are shown in Figure {}\ref{fig:RCPTimings}.  These timings are the
average CPU time (in seconds) per inner loop iteration (see Listing
{}\ref{listing:RCP-assignment-timing} for example of loops).  These
timing results show that dereferencing and member access for
{}\ttt{RCP} yield raw pointer performance on all the compilers
because these member functions are trivially inlined to expose the raw
pointer.

The assignment operator, however, imposes significant overhead because
of the need to increment and deincrement the reference counts.  The
timing code fragment that exercises {}\ttt{RCP::operator=(...)} is
shown in Listing {}\ref{listing:RCP-assignment-timing}.


\begin{listing}: Performance timing loops for {}\ttt{RCP::operator=(...)} \\
\label{listing:RCP-assignment-timing}
{\small\begin{verbatim}
  {
    RCP<char> p(new char('n'));
    std::vector<RCP<char> > p_vec(arraySize);
    TEUCHOS_START_PERF_OUTPUT_TIMER_INNERLOOP(outputter, numActualLoops, arraySize)
    {
      for (int i=0; i < arraySize; ++i) {
        p_vec[i] = p;
        // NOTE: This assignment operation tests the copy constructor and
        // the swap function.  This calls both bind() and unbind()
        // underneath.
      }
    }
  }
  TEUCHOS_END_PERF_OUTPUT_TIMER(outputter, rcpTime);
\end{verbatim}}
\end{listing}


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=1.00]{RCPTimings}
%}
\end{center}
\caption{
\label{fig:RCPTimings}
Timings of basic RCP operations on for three compilers}
\end{figure}
\esinglespace}


Timing results for the code in Listing
{}\ref{listing:RCP-assignment-timing} for
{}\ttt{numActualLoops=338498} and {}\ttt{arraySize=1024} are
shown in Figure {}\ref{fig:RCPTimings} along with similar timings for
raw pointers and {}\ttt{boost::shared\_ptr}.  The full timing
results for other sizes are show in in Appendix
{}\ref{apdx:raw-rcp-perf-data}.

There are a few interesting points to note about these timing results.

First, the array timing results shown in Section
{}\ref{sec:array-overhead} suggest that these two machines have nearly
identical processors.  Therefore, the CPU times on the Y-axis for each
of these compiler/machine bar charts is made to same to allow for
absolute comparisons.  This allows for direct comparisons of the
optimizing capabilities of these three compilers.  This suggests that
GCC 4.1.2 is better than the rest and that MSVC++ 2008 is quite bad at
optimizing {}\ttt{RCP} code.

Second, note that the cost of manipulating the reference count in
{}\ttt{RCP::operator=(...)} is an order of magnitude higher than
the dereference and arrow operators which have raw-pointer
performance.  The real overhead of manipulating the reference counts
may not actually be this high due to the simple nature of the raw
pointer code run in a loop getting better optimization.  The
reference-count manipulation code involves if statements that may
disable certain loop optimizations.

Third, node that {}\ttt{RCP::operator=(...)} is about 30\% slower
on GCC 4.1.2 than for {}\ttt{boost::shared\_ptr} due to the extra
overhead of dynamically handling a strong and weak reference counts.
The overhead of {}\ttt{RCP} over {}\ttt{boost::shared\_ptr} goes
up to 50\% on on ICC 10.1 and then falls off a cliff going up to 300\%
for MSVC++ 2008.  Clearly the MSVC++ compiler is not inlining the
{}\ttt{RCP} functions as well in this case.  However, there may be
compiler options that would cause the MSVC++ compiler to be more
aggressive in inlining.

Fourth, note that for GCC 4.1.2, the cost of manipulating the
reference count (at {}\ttt{5.59-09 sec}) is two orders of magnitude
less than the cost to allocate and deallocate an
{}\ttt{std::vector<double>} object with only one element (at
{}\ttt{1.39-07 sec}) and is three orders of magnitude less for
16384 elements (at {}\ttt{5.84-06 sec}) as shown in Appendix
{}\ref{apdx:raw-rcp-perf-data}.  Therefore, just the memory allocation
overhead can dominate these other costs in some cases.  Also, if a
large object is being used with expensive operations, the the
reference-counting overhead will be insignificant.  Again, this argues
that classes like {}\ttt{RCP} should only be used to manage larger
objects that have more expensive operations associated with them.  The
same argument can be made that {}\ttt{ArrayRCP} should only be used
for managing larger arrays of data where the cost of loops over the
data overwhelm the reference-counting costs.

Lastly, note that the {}\ttt{RCP::operator=(...)} implementation
both deincrements and increments the reference count while the copy
constructor only has to increment the reference count.  Therefore, we
might expect that the copy constructor would be about twice as fast as
the assignment operator.  The performance of the copy constructor is
not measured in a loop because it is hard write a loop that tests it
without other overhead.  However, the fastest approach is to avoid the
copy of the {}\ttt{RCP} object at all by passing in a constant
reference the {}\ttt{RCP} object as formal function arguments as
advocated in Section {}\ref{sec:idioms-for-passing-arguments}.


%
{}\subsubsection{Array access and iterator overhead}
\label{sec:array-overhead}
%

Another important type of performance (perhaps more important than the
performance of {}\ttt{RCP} for handling single objects) is the
performance of the Teuchos array classes.  In an optimized debug build
these classes must yield the same performance as using raw pointers or
the performance of the application will definitely be affected.

Performance timing experiments for the braket operator
{}\ttt{operator[](size\_type)} and iterators (returned from the
{}\ttt{begin()} and {}\ttt{end()} functions) were performed
using simple timing loops.  Unlike the performance tests for
{}\ttt{RCP} described in the previous section, timing array
operations naturally lends themselves to performance timings.  The
performance timing code fragments for the {}\ttt{Array} class are
shown in Listing {}\ref{listing:Array-bracket-timing} and
{}\ref{listing:Array-iterator-timing}.  The timing loops for raw
pointers and the {}\ttt{ArrayRCP} and {}\ttt{ArrayView} classes
are identical.


\begin{listing}: Performance timing loops for
{}\ttt{Array::operator[](size\_type)} \\
\label{listing:Array-bracket-timing}
{\small\begin{verbatim}
  Teuchos::Array<double> a(arraySize); 
  TEUCHOS_START_PERF_OUTPUT_TIMER_INNERLOOP(outputter, numActualLoops, arraySize) 
  { 
    for (Ordinal i=0; i < arraySize; ++i) 
      a[i] = 0.0; 
  }
  TEUCHOS_END_PERF_OUTPUT_TIMER(outputter, arrayTime); 
\end{verbatim}}
\end{listing}


\begin{listing}: Performance timing loops for {}\ttt{Array} iterators \\
\label{listing:Array-iterator-timing}
{\small\begin{verbatim}
  Teuchos::Array<double> a(arraySize); 
  TEUCHOS_START_PERF_OUTPUT_TIMER_INNERLOOP(outputter, numActualLoops, arraySize) 
  { 
    Teuchos::Array<double>::iterator a_itr = a.begin(), a_end = a.end(); 
    for ( ; a_itr < a_end; ++a_itr) 
      *a_itr = 0.0; 
  }
  TEUCHOS_END_PERF_OUTPUT_TIMER(outputter, arrayTime); 
\end{verbatim}}
\end{listing}


Figure {}\ref{fig:ArrayTimings} shows the CPU timings for
{}\ttt{operator[](size\_type)} and iterators for the performance
tests with sizes {}\ttt{numActualLoops=230574} and
{}\ttt{arraySize=1600} shown in Listing
{}\ref{listing:Array-bracket-timing} and
{}\ref{listing:Array-iterator-timing}.


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=1.00]{ArrayTimings}
%}
\end{center}
\caption{
\label{fig:ArrayTimings}
Timings for basic Array, ArrayRCP, and ArrayView operations}
\end{figure}
\esinglespace}

These timing results are fairly interesting and there are a few
important details to note.

First, the performance of the raw pointer iterator loops on all three
platforms is almost identical.  The CPU time per inner loop iteration
for the raw iterator form of the loop for all three compilers on the
two different Linux and Windows machines is about {}\ttt{3.5e-10}.
This suggests that the CPUs on these two machines are basically
identical for low level operations.  It is therefore only the
compilers that result in different performance for the other
operations.

Second, the ICC 4.1.2 compiler does not optimize the GNU
{}\ttt{std::vector::iterator} type\footnote{The data-type for the
optimized iterator for {}\ttt{std::vector::iterator} on GNU is not
a raw pointer.  Instead it is a library-defined data type with all
inline functions that should in theory be optimized as well as the raw
pointer but not always.} as well as it optimizes raw pointer iterator
syntax.  The GNU GCC 4.1.2 compiler itself does not even quite fully
optimize its own {}\ttt{std::vector::iterator} type!

Third, the ICC 4.12 compiler is not optimizing the array indexing form
of the inner loops shown in Listing
{}\ref{listing:Array-bracket-timing} as well as the other two
compilers even for the use of raw pointers.  The performance is even
worse for the abstract data types {}\ttt{std::vector},
{}\ttt{Array}, {}\ttt{ArrayRCP}, and {}\ttt{ArrayView}.

Forth, for some reason the MSVC++ 2008 compiler is not optimizing the
loop using {}\ttt{ArrayRCP::operator[](size\_type)} as well as for
the other array types.  Several different compiler options and
variations on the {}\ttt{ArrayRCP} and perforamnce timing code
where experimented with without any impact (except to make every
operation slower).  However, the perforamnce timing loop using
iterator for {}\ttt{ArrayRCP} yield optimal performance (not
surprising given that {}\ttt{ArrayRCP::iterator} is just a raw
pointer in a non-debug build).

The take-away points from these timing results are that all compilers
do not fully optimize the array indexing form of the loops and only
raw pointers used as iterators will yield the optimal performance.
The Teuchos array classes perform at least as well as
{}\ttt{std::vector} and actually out-perform {}\ttt{std::vector}
in some cases.  This is only because the Teuchos array classes use raw
C++ pointers in an optimized non-debug build.


%
{}\subsubsection{Performance tuning strategies (semi-persisting
associations)}
\label{sec:perf-tuning-strategies}
%

The timing results shown in the prior two sections lead to a few
different conclusions related to peformance issues in the use of the
Teuchos memory management types:

\begin{itemize}

{}\item The reference-counting machinery of the {}\ttt{RCP} class
imparts at least 72 bytes of overhead for every reference-counted
object (the overhead for {}\ttt{ArrayRCP} is slightly higher) and
therefore {}\ttt{RCP} should not be used to manage massive numbers
of small objects, just from a memory usage standpoint.  Likewise,
{}\ttt{ArrayRCP} should not be used to mange large collections of
small arrays since the memory overhead could be significant.

{}\item The extra runtime overhead of reference-counting machinery
does not significantly increase dynamic memory allocation and
deallocation runtime costs.

{}\item The runtime reference-counting overhead of {}\ttt{RCP} with
respect to {}\ttt{boost::shared\_ptr} can vary from as little as
30\% on a good optimizing compiler (e.g.\ GCC 4.1.2) to as much as
300\% or more on a poor optimizing compiler (e.g.\ MSVC++ 2008).
Therefore, if portable peformance of your application is critical,
make sure and use the reference-counting types at as high a level of
granularity as you can such that it does not damage the quality of the
software (i.e.\ flexibility, usability, maintainability).

{}\item The most portable way to achieve high performance of raw array
operations is to use iterators on {}\ttt{ArrayRCP} and
{}\ttt{ArrayView} objects.  The timing results on ICC 10.1 show
that some compilers will not even given optimize performace for
{}\ttt{std::vector::iterator}!  Also, all compilers do not
automatically fully optimize the array bracket form of an array-based
loop so an iterator loop is the only full-proof way to get optimized
performance across platforms.

\end{itemize}

The performance tests described above show that the memory and runtime
overhead of the reference-counting machinery can be high when used
with small cheap objects.  Therefore, if the reference counted types
{}\ttt{RCP} and {}\ttt{ArrayRCP} are used at too low a level of
granularity, the overall performance of the program may suffer and may
use significantly more memory than it would with raw pointers.  In
such low-level code, strictly adhering to the idioms described in
Sections {}\ref{sec:idioms-for-passing-arguments} and
{}\ref{sec:idioms-returning-objects} with respect to persisting
relationships can significantly degrade performance.  Therefore, in
low-level performance-critical code, the strict idioms related to
persisting associations need to be relaxed or the design must be
changed to raise the level of granularity where the reference-counted
types are used.

However, just because one can not use {}\ttt{RCP} and
{}\ttt{ArrayRCP} and still achieve high performance does not mean
that this code should use raw pointers.  Instead, {}\ttt{Ptr} can
be used instead of {}\ttt{RCP} and {}\ttt{ArrayView} can be used
instead of {}\ttt{ArrayRCP} when the full semantics of persisting
relationships are not needed and instead only semi-persisting
relationships are needed (see Section
{}\ref{sec:persisting-nonpersisting-associations}).  By using the
types {}\ttt{Ptr} and {}\ttt{ArrayView} instead of raw pointers
for all semi-persisting associations we still get all of the strong
debug-mode runtime checking that is described in Section
{}\ref{sec:debug-mode-runtime-checking} (e.g.\ dangling reference
checking, null checking, range checking, etc.) yet remove all
reference-counting overhead in a non-debug optimized build.

As an example, consider the design of a sparse matrix class that
stores its data as compressed sparse rows and allows access to the
sparse rows.  The client of the sparse matrix class would obtain
handles to the sparse row data, make modifications to it, and then
release the handles.  Performing all of these operations in a single
statement (as is stictly required for a non-presisting relationship as
defined in Section {}\ref{sec:persisting-nonpersisting-associations})
is impractical.  Therefore, the handles for the interal sparse row
data represent a persisting relationship and the strict interpretation
of the idioms defined in Sections
{}\ref{sec:idioms-for-passing-arguments} and
{}\ref{sec:idioms-returning-objects} would require the use of
{}\ttt{ArrayRCP} yielding the sparse matrix class interface shown
in Listing {}\ref{listing:SparseMatrix-ArrayRCP}.


\begin{listing}: Sparse matrix class interface adhering to strict
interpretation of idioms for persisting relationships  \\
\label{listing:SparseMatrix-ArrayRCP}
{\small\begin{verbatim}
  class SparseMatrix {
  public:
    ...
    int getNumRows() const;
    void getSparseRow( int rowId, const Ptr<ArrayRCP<double> > &values,
      const Ptr<ArrayRCP<const int> > &colIds);
    ...
\end{verbatim}}
\end{listing}


The {}\ttt{SparseMatrix} class shown in Listing
{}\ref{listing:SparseMatrix-ArrayRCP} would be used as shown in
Listing {}\ref{listing:zeroOutSparseMatrix-ArrayRCP}.


\begin{listing}: Client code using {}\ttt{ArrayRCP} form of the
 {}\ttt{SparseMatrix} class  \\
\label{listing:zeroOutSparseMatrix-ArrayRCP}
{\small\begin{verbatim}
  void zeroOutSparseMatrix(const Ptr<SparseMatrix> &M)
  {
    const int numRows = M->getNumRows();
    for (int row_i = 0; row_i < numRows; ++row_i) {
      ArrayRCP<double> values;
      M->getSparseRow(row_i, outArg(values), null);
      typedef ArrayRCP<double>::iterator itr_t;
      for (itr_t itr = values.begin(); itr != values.end(); ++itr)
        *itr = 0.0;
    }
  }
\end{verbatim}}
\end{listing}


While the interface and the user code shown in Listing
{}\ref{listing:zeroOutSparseMatrix-ArrayRCP} strictly satisfies that
safe and bullet-proof idioms on persisting associations described in
Section {}\ref{sec:idioms-for-passing-arguments}, the reference
counting overhead (in memory size and speed) of this code can be quite
high if the rows are very sparse.  Looking at code such as shown in
Listing {}\ref{listing:zeroOutSparseMatrix-ArrayRCP} and similar use
cases, it never seems reasonable that a client would grab
{}\ttt{ArrayRCP} objects to internal rows and expect to have the
row data persist even if the matrix changed structure or was deleted.
Instead, we just need to set up the infrastructure for semi-persisting
associations to be able to detect those types of invalid usage in a
debug-mode build but yield high performance in an optimized build.
Therefore, it seems reasonble to replace {}\ttt{ArrayRCP} in
{}\ttt{SparseMatrix::getSparseRow(...)} in Listing
{}\ref{listing:SparseMatrix-ArrayRCP} with {}\ttt{ArrayView}
yielding the new {}\ttt{SparseMatrix} interface shown in Listing
{}\ref{listing:SparseMatrix-ArrayView}.


\begin{listing}: Sparse matrix class interface using a semi-persisting
assocation for row views for the sake of performance \\
\label{listing:SparseMatrix-ArrayView}
{\small\begin{verbatim}
  class SparseMatrix {
  public:
    ...
    int getNumRows() const;
    void getSparseRow( int rowId, const Ptr<ArrayView<double> > &values,
      const Ptr<ArrayView<const int> > &colIds);
    ...
\end{verbatim}}
\end{listing}


The updated client code zeroing out the rows of the matrix would then
look like Listing {}\ref{listing:zeroOutSparseMatrix-ArrayView}.


\begin{listing}: Client code using {}\ttt{ArrayView} form of the
{}\ttt{SparseMatrix} class with semi-persisting row views  \\
\label{listing:zeroOutSparseMatrix-ArrayView}
{\small\begin{verbatim}
  void zeroOutSparseMatrix(const Ptr<SparseMatrix> &M)
  {
    const int numRows = M->getNumRows();
    for (int row_i = 0; row_i < numRows; ++row_i) {
      ArrayView<double> values;
      M->getSparseRow(row_i, outArg(values), null);
      typedef ArrayView<double>::iterator itr_t;
      for (itr_t itr = values.begin(); itr != values.end(); ++itr)
        *itr = 0.0;
    }
  }
\end{verbatim}}
\end{listing}


Now the client code in Listing
{}\ref{listing:zeroOutSparseMatrix-ArrayView} will have no
reference-counting overhead in a non-debug optimized build but in a
debug-mode build, all invalid usage will be detected.  For example,
consider invalid code such as shown Listing
{}\ref{listing:SparseMatrix-dangling-ref} where the client code trys
to hold on to sparse row data after the matrix is deleted.


\begin{listing}: Example of invalid usage of {}\ttt{SparseMatrix} leading
to a dangling reference exception in a debug-mode build  \\
\label{listing:SparseMatrix-dangling-ref}
{\small\begin{verbatim}

  // Create and initialize the matrix
  RCP<SparseMatrix> M = sparseMatrix(...); // Non-member constructor
  ...

  // Grab a sparse row to the matrix
  ArrayView<double> values_row_0;
  ArrayView<const int> colIds_row_0;
  M->getSpaseRow(0, outArg(values_row_0), outArg(colIds_row_0));

  // Delete the matrix (leaving dangling values_row_0 and colIds_row_0)
  M = null;

  // Try to access the row
  ArrayView<double>::iterator
    itr = values.begin(),     // Throws exception in debug-mode build!
    itr_end = values.end();
  for ( ; itr != itr_end; ++itr)
    *itr = 0.0; 
\end{verbatim}}
\end{listing}


As shown in Listing {}\ref{listing:SparseMatrix-dangling-ref}, using
{}\ttt{ArrayView} allows all types of programming errors to be
detected in a debug-mode build.  If raw pointers would have been used,
this dangling reference may not be detected right away.  On some
platforms for some problem sizes, the program using raw pointers may
seem to run just fine and valgrind may not complain (especially if
sophisticated memory management is used inside the
{}\ttt{SparseMatrix} class).  The error may not present itself
until months or years later where it will do untold harm.

Note that there may be some extreme cases where the overhead of an
extra size data member in {}\ttt{ArrayView} is too high.  In these
cases, one can instead use an iterator type such as
{}\ttt{Array::iterator} or {}\ttt{ArrayRCP::iterator} (depending
on type type of the underlying container class).  In a debug-mode
build, the iterator objects will be fully checked {}\ttt{ArrayRCP}
objects while in a non-debug optimized build, the iterators will be
raw pointers (or {}\ttt{std::vector::iterator} in the case of
{}\ttt{Array::iterator}).  This yields raw pointer performance in a
non-debug optimized build with no space or time overhead (becuase all
the object actually are raw pointers in this case).

The point of this section is to acknowlege that there will be
situations in low-level code where the strict adherence to using
reference-counted types {}\ttt{RCP} and {}\ttt{ArrayRCP} for
persisting associations may yield acceptable performance and therefore
we must instead provide for semi-persisting views.  However, as
demonstrated above, the solution to the performance problem is not to
ever fall back to using raw pointers but instead to fall back on the
non-reference-counted types {}\ttt{Ptr} and {}\ttt{ArrayView}
(or {}\ttt{Array[RCP]::iterator}).  By using the types
{}\ttt{Ptr} and {}\ttt{ArrayView} (or
{}\ttt{Array[RCP]::iterator}), we maintain all the desirable
debug-mode runtime checking without any of the reference-counting
overhead in a non-debug optimized build.  We can have our cake and eat
it too!


%
{}\subsection{Related idioms and design patterns}
%

There are a number of important idioms related to the usage of the
Teuchos memory management classes and most specifically the
{}\ttt{RCP} class.  The power and flexibility of the
reference-counting machinery built in to the {}\ttt{RCP} class
opens the door the a whole host of interesting idioms, a few of which
are described in the following subsections.


%
{}\subsubsection{The inverted object ownership idiom}
\label{sec:inverting-obj-ownership}
%

A rare situation that can occur is when you have an object that
maintains an {}\ttt{RCP} to another object but you want to expose
the second object and have it remember the first object; in other
words, you want to invert the object ownership.  To demonstrate,
consider the two classes in Listing {}\ref{listing:B_owns_A_decl}.

\begin{listing}: Two classes where one maintains an RCP to the other \\
\label{listing:B_owns_A_decl}
{\small\begin{verbatim}
  class A { ... };

  RCP<A> createA(...);

  class B {
  public:
    static RCP<B> create(const RCP<A> &a)
      {return rcp(new B(a)); }
    RCP<A> getA() { return a_; }
    void unsetA() { a_ = null; }
    ...
  private:
    RCP<A> a_;
    B(const RCP<A> &a) a_(a) {}
  };

  RCP<B> createB(const RCP<A> &a)
  {return B::create(a);}
\end{verbatim}}
\end{listing}

The class {}\ttt{A} in Listing {}\ref{listing:B_owns_A_decl} may
involve some complex initialization or it may only be an abstract
interface with multiple subclasses.  In either case, it may make sense
to provide a factory function (or a set of such functions) that
creates and initializes a {}\ttt{B} object for different complex
initializations of {}\ttt{A} objects as shown in Listing
{}\ref{listing:createBFactory}.

\begin{listing}: A factory function that creates a {}\ttt{B} object
wrapping a complex {}\ttt{A} object \\
\label{listing:createBFactory}
{\small\begin{verbatim}
  RCP<B> createBFactory(...)
  {
     // Complex initialization of A
     RCP<A> a;
     ...
     // Wrapped B
     return createB(a);
  }
\end{verbatim}}
\end{listing}

Up to now, this is pretty standard code.  The client would typically
hold an {}\ttt{RCP<B>} object to the {}\ttt{B} object and would
manage the lifetime of the {}\ttt{A} object implicitly wrapped in
the {}\ttt{B} object.

However, now consider a rare use case where a client may only want to
deal directly with the {}\ttt{A} object but still maintain the
{}\ttt{B} object for later use.  There are a few approaches that
one could try to implement this inversion of RCP ownership but there
is a way to enable this that is 100\% bullet-proof without having to
change the existing {}\ttt{A} or {}\ttt{B} classes or any other
code at all.  The way to do this is to use the
{}\ttt{rcpWithInvertedObjOwnership(...)} function (defined in
Listing {}\ref{listing:rcpWithInvertedObjOwnership}) as shown in
Listing {}\ref{listing:A_owns_B_owns_A}.

\begin{listing}: A factory function that returns an {}\ttt{A} object
embedded with a {}\ttt{B} object (inverting the ownership relationship) \\
\label{listing:A_owns_B_owns_A}
{\small\begin{verbatim}
  RCP<A> createAFactory(...)
  {
    RCP<B> b = createBFactory(...);
    return rcpWithInvertedObjOwnership(b->getA(), b);
  }
\end{verbatim}}
\end{listing}


\begin{listing}: Standard helper function implementing the ``inverted
object ownership'' idiom \\
\label{listing:rcpWithInvertedObjOwnership}
{\small\begin{verbatim}
  template<class T, class ParentT>
  RCP<T> rcpWithInvertedObjOwnership(const RCP<T> &child, const RCP<ParentT> &parent)
  {
    using std::make_pair;
    typedef std::pair<RCP<T>, RCP<ParentT> > Pair_t;
    return rcpWithEmbeddedObj(child.getRawPtr(), make_pair(child, parent), false);
  }
\end{verbatim}}
\end{listing}


% ToDo: Show UML object diagram that shows the two RCPNode objects.


Without going into a lot of detail, what the code in Listings
{}\ref{listing:A_owns_B_owns_A} and
{}\ref{listing:rcpWithInvertedObjOwnership} accomplishes is that it
defines a new {}\ttt{RCP<A>} object with a new {}\ttt{RCPNode}
object that uses the other existing {}\ttt{RCP<A>} and
{}\ttt{RCP<B>} objects to define ownership and ensure that the
underlying {}\ttt{A} object and {}\ttt{B} do not go away until
the last {}\ttt{RCP<A>} object copied from the object returned by
the function {}\ttt{createAFactory(...)} has gone away.  The reason
that {}\ttt{false} is passed into the
{}\ttt{rcpWithEmbeddedObj(...)} is because it is the embedded
objects {}\ttt{RCP<A>} and {}\ttt{RCP<B>} that define the
deallocation and not the default behavior which calls
{}\ttt{delete}.  The reason that both {}\ttt{RCP<A>} and
{}\ttt{RCP<B>} are passed as an embedded object (stored in an
{}\ttt{std::pair} object) is that we need to make sure the
{}\ttt{A} object does not get deleted in case some client calls the
{}\ttt{B::unsetA()} function.

Given this data-structure, another piece of code can then extract the
underlying {}\ttt{RCP<B>} object as shown in Listing
{}\ref{listing:Extract_B_from_A} which uses the standard Teuchos
function {}\ttt{getInvertedObjOwnershipParent(...)} defined in
Listing {}\ref{listing:getInvertedObjOwnershipParent}.

\begin{listing}: A function that extracts the B object from the A object \\
\label{listing:Extract_B_from_A}
{\small\begin{verbatim}
  RCP<B> extractBFromA(const RCP<A> &a)
  {
    return getInvertedObjOwnershipParent<B>(a);
  }
\end{verbatim}}
\end{listing}


\begin{listing}: Standard helper grabbing the inverted parent \\
\label{listing:getInvertedObjOwnershipParent}
{\small\begin{verbatim}
  template<class ParentT, class T>
  Teuchos::RCP<ParentT>
  Teuchos::getInvertedObjOwnershipParent(const RCP<T> &invertedChild)
  {
    typedef std::pair<RCP<T>, RCP<ParentT> > Pair_t;
    Pair_t pair = getEmbeddedObj<T, Pair_t>(invertedChild);
    return pair.second;
  }
\end{verbatim}}
\end{listing}


That is all there is to it.  Now this is not the sort of thing that
you want to expose to general clients but it can be very handy to have
this type of flexibility when implementing the guts of your library
code.  Note that the function {}\ttt{createAFactory(...)} in
Listing {}\ref{listing:A_owns_B_owns_A} has to expose a raw C++
pointer but it does so only in a single statement and therefore is not
to serious a violation of the idioms defined in this paper.  This
would be consider specialized low level code and is not recommended
unless it is absolutely necessary.

However, The example shown above just shows the flexibility of these
memory management classes and what some of the possibilities if you
understand the underlying reference-counting machinery a little.


%
{}\subsubsection{The separate construction and just-in-time
initialization idioms}
\label{sec:separate-construct-init}
%

The ``separate construction and initialization'' and ``just-in-time
initialization'' idioms described here are not specific to the use of
the Teuchos memory management classes but it does provide the basic
foundation for the next idiom described, the ``object self-reference''
idiom.  The set up the context for the discussion, consider a typical
design for a class shown in Listing
{}\ref{listing:sci:SomeClass-before}.


\begin{listing}: Example of a typical C++ class that uses constructors for all
initialization  \\
\label{listing:sci:SomeClass-before}
{\small\begin{verbatim}
  class SomeClass : public SomeBaseClass {
  public:
    SomeClass(): member1_(1), member2_(5.0) {}
    SomeClass(const RCP<A> &a) : member1_(1), member2_(5.0), a_(a)
      { finalInitialization(); }
    SomeClass(const RCP<B> &b) : member1_(1), member2_(5.0), b_(b)
      { finalInitialization(); }
    SomeClass(const RCP<A> &a, const RCP<B> &b, const int someValue)
      : member1_(1), member2_(5.0), a_(a), b_(b)
      { c_ = createC(rcp(this, false), a, b, someValue);
        finalInitialization(); }
    RCP<A> get_A() { return a_; }
    RCP<B> get_B() { return b_; }
    RCP<C> get_C() { return c_; }
    void doSomeOperation(...) {}
  private:
    int member1_;
    double member2_;
    RCP<A> a_;
    RCP<B> b_;
    RCP<C> c_;
    void finalInitialization() { ...} // Can't call virtual functions on SomeBaseClass
  };

\end{verbatim}}
\end{listing}


So what is wrong with the design of {}\ttt{SomeClass} in Listing
{}\ref{listing:sci:SomeClass-before}?  First, there is the duplication
of default values for {}\ttt{member1\_}, {}\ttt{member2\_} in
all of the constructors.  This makes it labor intensive and
error-prone to change the values later.  Yes, one could create static
constants of some type to be reused in all the constructor
initialization lists but you still have to list all of these arguments
in every constructor\footnote{The C++0x will address the problem of
duplicate constructor initialization lists by allowing constructors to
call each other but we will not see such a feature in wide spread use
until many years after the C++0x standard is finalized.}.

The second problem with the class {}\ttt{SomeClass} that it can not
call any virtual functions in the base class {}\ttt{SomeBaseClass} to
help initialize its state in the constructors {}\cite[Item
49]{C++CodingStandards05}.

The third problem with the design of {}\ttt{SomeClass} shown in
Listing {}\ref{listing:sci:SomeClass-before} is that the {}\ttt{C}
object that is created in the thrid constructor that takes
{}\ttt{A} and {}\ttt{B} objects is not properly setting up a
persisting relationship between the {}\ttt{C} object and the
{}\ttt{SomeClass} object.  When this {}\ttt{C} object is exposed
through the {}\ttt{get\_C()} member function, this sets up a
dangerous situration where the {}\ttt{SomeClass} object may be
deleted leaving a client with a dangling {}\ttt{RCP<C>} object with
no way for the reference-counting machinery described in Section
{}\ref{sec:reference-counting-machinary} do detect the the problem.
This issue will be discussed more in the context of the ``object
self-reference'' idiom in Section {}\ref{sec:self-references}.

Lastly, the class {}\ttt{SomeClass} is inflexible in that it
requires the client creating the {}\ttt{SomeClass} object to know
the concrete types of {}\ttt{A} and or {}\ttt{B} (which could be
abstract interfaces in this example) right when the
{}\ttt{SomeClass} object is first created.  This creates a
three-way coupling of the client with a) defining the time when the
{}\ttt{SomeClass} object is first created, b) needing fully
constructed {}\ttt{A} and {}\ttt{B} objects right when
{}\ttt{SomeClass} is first created.  In complex programs, it is
very hard to and very constraining have to fully initialized a web
interconnected objects before constructing the downstream objects.

Without further ado, the use of the ``separate construction and
initialization'' idiom applied to {}\ttt{SomeClass} shown in
Listing {}\ref{listing:sci:SomeClass-before} gives the new refactored
class in Listing {}\ref{listing:sci:SomeClass-refactored}.


\begin{listing}: Example of the use of the ``separate construction and
initialization'' and ``just-in-time initialization'' idioms  \\
\label{listing:sci:SomeClass-refactored}
{\small\begin{verbatim}
  class SomeClass : public SomeBaseClase {
  public:
    SomeClass(): isIntialized_(false), member1_(1), member2_(5.0) {}
    void set_A(const RCP<A> &a) { a_ = a; isIntialized_=false; }
    void set_B(const RCP<B> &b) { b_ = b; isIntialized_=false; }
    RCP<A> get_A() { return a_; }
    RCP<B> get_B() { return b_; }
    RCP<C> get_C() { justInTimeInitialization(); return c_; }
    void uninitialize() { a_ = null, b_ = null; c_ = null; }
    void doSomeOperation(...)
      {
        justInTimeInitialization();
        ...
       }
  private:
    bool isIntialized_;
    int member1_;
    double member2_;
    RCP<A> a_;
    RCP<B> b_;
    RCP<C> c_;
    void justInTimeInitialization()
      {
        if (isIntialized_) return;
        // We can call virtual functions on SomeBaseClass (someBaseFunc())!
        if (nonnull(a_) && nonnull(b_))
          c_ = createC(rcp(this, false), a, b, this->getSomeValue());
        ...
        isIntialized_ = true;
      }
  };

  // Non-member constructors
  RCP<SomeClass> someClass()
    { return rcp(new someClass()); }
  RCP<SomeClass> someClass(const RCP<A> &a)
    { RCP<someClass> sc(new someClass()); sc->set_A(a); return sc; }
  RCP<SomeClass> someClass(const RCP<B> &b)
    { RCP<someClass> sc(new someClass()); sc->set_B(b); return sc; }
  RCP<SomeClass> someClass(const RCP<A> &a, const RCP<B> &b)
    { RCP<someClass> sc(new someClass()); sc->set_A(a); sc->set_B(b);  return sc; }
\end{verbatim}}
\end{listing}


Side Note: Before describing the specific advantages of the refactored
class in Listing {}\ref{listing:sci:SomeClass-refactored}, first
note that the issue of the creation of the {}\ttt{C} object and
dangling references of {}\ttt{c\_} returned from
{}\ttt{get\_C()} have not been addressesd in this design.  That
issue will be addressed with the ``object self-reference'' idiom
described in Section {}\ref{sec:self-references}.

Now, some of the specific advantages of the usage of the ``separate
construction and initailization'' idiom as applied to the design of
{}\ttt{SomeClass} shown in Listing
{}\ref{listing:sci:SomeClass-refactored} are described below.

a) The default values for {}\ttt{member1\_} and
{}\ttt{member2\_} are defined in only one constructor
initialization list.  This massively simplifies the maintenance of of
large comlex classes with lots of data members.

b) The private initialization function
{}\ttt{justInTimeInitialization()} can now call a virtual function on
the base class {}\ttt{SomeBaseClass::getSomeValue()} to get the
value of {}\ttt{someValue} instead of requiring the client to pass
it into the constructor.

c) The objects {}\ttt{a} and {}\ttt{b} can constructed and
injected into the {}\ttt{SomeClass} object in different parts of
the code by different clients.  This breaks a fundamental dependency
which couples these objects and the clients together and can massively
simplify the structure of complex programs.

d) The ``separate construction and initialization'' idiom naturally
leads to the ``just-in-time initialization'' idiom where the
{}\ttt{justInTimeInitialization()} function is not called until the
functions {}\ttt{doSomeOperation(...)} or {}\ttt{get\_C()} are
called by a client.  This allows the objects {}\ttt{a} and/or
{}\ttt{b} to be passed into the functions {}\ttt{set\_A(...)} 
and {}\ttt{set\_B(...)} in a partially-initialized state.  These
objects do not need to be fully initialized until the
{}\ttt{doSomeOperation(...)} or {}\ttt{get\_C()} functions are
called.  This can massively simplify and robustify the design of
complex problems by separating code that creates the links between
objects and the code that fully initializes the objects.  This avoids
the constraints of needing to use a factory object to create fully
initialized ``aggregate'' objects as described in
{}\cite{DomainDrivenDesign}.

e) An object of type {}\ttt{SomeClass} is not any harder to create
since the non-member constructor functions allow the object to be
constructed in a single function call (see Section
{}\ref{sec:nonmember-constructor-idiom}).

The only real disadvantage of the ``separate construction and
initialization'' idiom is some small decrease in performance in using
assignment instead of member initialization lists.  However, this type
of low-level perforamnce is almost never an issue in higher-level
classes like {}\ttt{SomeClass} shown in Listing
{}\ref{listing:sci:SomeClass-refactored}.  Most classes in a complex
program are higher-level classes where low-level perforamnce
considerations like this are not an issue so the the ``separate
construction and initialization'' idiom is applicable in more cases
than not.

The main disadvantage of the ``just-in-time initialization'' idiom is
the need to have a call to a function like
{}\ttt{justInTimeInitialization()} in every operation that requires the
object to be fully initialized.  This is minor programming
inconvenience and a minor perforamnce overhead.  The more significant
disadvantage is that more unit testing is needed to test the behavior
of the user functions for when the object is not ready to be fully
initialized.  However, good class design makes this fairly easy.


%
{}\subsubsection{The object self-reference idiom}
\label{sec:self-references}
%

There are occasions where an object needs to provide an {}\ttt{RCP}
to itself with the full protection of the debug-mode checking with
node-tracing enabled.  However, for an object to hold a strong
{}\ttt{RCP} to itself would set up a cicular reference and the
object would never be deleted.  The issue of self references was
mentioned in the previous section in the context of the ``separate
construction and initialization'' idiom.

The most straightforward example of where the ``object
self-reference'' idiom is needed is when a factory object creates a
product that must in turn store a strong owning {}\ttt{RCP} to the
factory that created it.  This is the exact use case that exists in
the Thyra packages for {}\ttt{VectorBase} and {}\ttt{VectorSpaceBase}
objects {}\cite{ThyraOperatorVectorSAND}.  In this case,
{}\ttt{VectorSpaceBase} acts as the factory and {}\ttt{VectorBase}
acts as the product.  Also, every {}\ttt{VectorBase} object has a
function {}\ttt{space()} that returns the {}\ttt{VectorSpaceBase}
object that created it to be used to create other {}\ttt{VectorBase}
objects.

A simplified version of the implemention of the
{}\ttt{VectorSpaceBase} standard subclass
{}\ttt{DefaultSpmdVectorSpace} using the ``object self-reference''
idiom is shown in Listing {}\ref{listing:osr:DefaultSpmdVectorSpace}.


\begin{listing}: Exsample of the ``object self-reference'' idiom where a
factory must give a strong owning {}\ttt{RCP} self reference to its products.  \\
\label{listing:osr:DefaultSpmdVectorSpace}
{\small\begin{verbatim}
  class DefaultSpmdVectorSpace : public VectorSpaceBase {
  public:
    static RCP<DefaultSpmdVectorSpace> create()
      {
        RCP<DefaultSpmdVectorSpace> vs(new DefaultSpmdVectorSpace);
        vs.weakSelfPtr_ = vs.create_weak();
        return vs;
      }
    void initialize(const Ordinal localDim)
      {  localDim_ = localDim; }
    RCP<VectorBase> createMember()
      {
         return defaultSpmdVector(weakSelfPtr_.create_strong());
       }
  private:
    RCP<DefaultSpmdVectorSpace> weakSelfPtr_;
    Ordinal localDim_;
    DefaultSpmdVectorSpace() : localDim_(0) {}
  };

  // Nonmeber constructor
  RCP<DefaultSpmdVectorSpace> defaultSpmdVectorSpace(const Ordinal localDim)
  {
    RCP<DefaultSpmdVectorSpace> vs = DefaultSpmdVectorSpace::create();
    vs->initialize(localDim);
    return vs;
  }
\end{verbatim}}
\end{listing}


The way the ``object self-reference'' idiom works is that a static
function {}\ttt{create()} allocates an default-initialized
{}\ttt{DefaultSpmdVectorSpace} object and stores it in a strong
owning {}\ttt{RCP} object.  It then creates a weak {}\ttt{RCP}
object that it sets as the self reference on the newly created
{}\ttt{DefaultSpmdVectorSpace} object.  The default constructor is
made private so the only way for a client to create an
{}\ttt{DefaultSpmdVectorSpace} object is to use use the static
{}\ttt{create()} function (or call it indirectly through the
non-member constructor {}\ttt{defaultSpmdVectorSpace()} function).
Because this self reference is a weak tracing {}\ttt{RCP}, it can
detect dangling references or can be used to create a strong
{}\ttt{RCP} when needed while at the same time not creating a
circular reference that would result in a memory leak.

The code in Listing {}\ref{listing:osr:DefaultSpmdVectorSpace} shows
the creation of a strong owning {}\ttt{RCP} which is given to the
newly created {}\ttt{DefaultSpmdVector} object in the statement
{}\ttt{defaultSpmdVector( weakSelfPtr\_.create\_strong())}.  This
allows the resulting product {}\ttt{DefaultSpmdVector} object to
outlive the client's code that created the factory
{}\ttt{DefaultSpmdVectorSpace} object.  A simple example of this is
shown in Listing
{}\ref{listing:osr:DefaultSpmdVectorSpace-use-delete}.


\begin{listing}: Example of client code that creates a factory, uses it to
create a product and lets the factory go away.  \\
\label{listing:osr:DefaultSpmdVectorSpace-use-delete}
{\small\begin{verbatim}
  RCP<VectorBase> createMyector(const Ordinal localDim)
  {
     RCP<DefaultSpmdVectorSpace> vs = defaultSpmdVectorSpace();
     return vs.createMember();
  }
\end{verbatim}}
\end{listing}


Code like shown in Listing
{}\ref{listing:osr:DefaultSpmdVectorSpace-use-delete} may seem
contrived but there have been several use cases for Thyra over the
years that required code just like this to work or it would have
resulted in a much more complex design of the client's code.

There are also other less obvious examples where the ``object
self-reference'' idiom is useful.  For one such case, consider Listing
{}\ref{listing:osr:SomeClass-before} which shows a simplified version
of the class shown in Listing {}\ref{listing:sci:SomeClass-before}
that has to pass a self reference to an object it creates and holds
internally.


\begin{listing}: Example of an class with {}\ttt{RCP} to self problems  \\
\label{listing:osr:SomeClass-before}
{\small\begin{verbatim}
  class SomeClass : public SomeBaseClass {
  public:
    SomeClass() {}
      { c_ = createC(rcp(this, false)); finalInitialization(); }
    RCP<C> get_C() { return c_; }
    ...
  private:
    RCP<C> c_;
    void finalInitialization() { ...}
  };
\end{verbatim}}
\end{listing}


The problem with the code in Listing
{}\ref{listing:osr:SomeClass-before} is that it gives up an
{}\ttt{RCP<C>} object to its internal {}\ttt{C} object that is
constructed internally but a proper node tracing relationship has not
been established between the {}\ttt{C} object and the
{}\ttt{SomeClass} object.  (Even if {}\ttt{SomeClass} does not
intentionally give up its {}\ttt{RCP<C>} object, it is still very
easy to do it by accident so this scencario still applies.)  The see
problem with this, consider the client code in Listing
{}\ref{listing:osr:bad-use-SomeClass}.


\begin{listing}: Client code that results in a segfault  \\
\label{listing:osr:bad-use-SomeClass}
{\small\begin{verbatim}
  RCP<SomeClass> sc(new SomeClass);
  RCP<C> c = sc->get_C();
  sc = null; // The SomeClass object is destroyed which invalidates 'c'!
  c->someFunc(); // Calls on the now deleted SomeClass object pointed to inside!
\end{verbatim}}
\end{listing}


The problem with the code in Listing
{}\ref{listing:osr:bad-use-SomeClass} is that when the
{}\ttt{SomeClass} object {}\ttt{sc} is destroyed, there is no
way for the reference-counting machinery in to catch the dangling
reference.  This code will segfault if you are lucky but like any
memory usage error, if you are unlucking the code will appear to work
correctly but will be a ticking time-bomb that will go off eventually.
The reason for this behavior is that the statement {}\ttt{c\_ =
createC(rcp(this, false))} in the constructor {}\ttt{SomeClass()}
creates a non-owing {}\ttt{RCPNode} object {}\underline{before} the
owning {}\ttt{RCPNode} object is created by the client code
{}\ttt{RCP<SomeClass> sc(new SomeClass)}.  This violates
Commandment {}\ref{cmnd:owning-rcp-first} in Section
{}\ref{apdx:commandments}.  The node-tracing reference-counting
machinery would have to be {}\underline{much} more complex and
expensive to catch dangling reference errors where the strong owning
{}\ttt{RCPNode} object was not the first created.

The solution to this problem is to use a variation of the ``object
self-reference'' idiom.  The updated design that accomplishes this is
shown in Listing {}\ref{listing:osr:SomeClass-refactored}.


\begin{listing}:  Example of the ``object self-reference'' idiom for
detecting dangling references to internally held objects  \\
\label{listing:osr:SomeClass-refactored}
{\small\begin{verbatim}
  class SomeClass : public SomeBaseClass {
  public:
    static RCP<SomeClass> create()
      {
        RCP<SomeClass> sc(new SomeClass);
        sc.weakSelfPtr_ = sc.create_weak();
        return sc;
      }
    RCP<C> get_C() { justInTimeInitialization(); return c_; }
    ...
  private:
    RCP<SomeClass> weakSelfPtr_;
    RCP<C> c_;
    SomeClass() {}
    void justInTimeInitialization() { c_ = createC(weakSelfPtr_); }
    // Note defined and not to be called
    SomeClass(const SomeClass&);
    SomeClass operator=(const SomeClass&);
  };

  // Nonmeber constructor
  RCP<SomeClass> someClass() { return SomeClass::create(); }
\end{verbatim}}
\end{listing}

The advantage of the design in Listing
{}\ref{listing:osr:SomeClass-refactored} is that now client code like
shown in Listing {}\ref{listing:osr:dangling-ref-SomeClass} below will
result in a dangling reference exception in a node-tracing debug-mode
build.


\begin{listing}: Client code that results a clean dangling-reference exception  \\
\label{listing:osr:dangling-ref-SomeClass}
{\small\begin{verbatim}
  RCP<SomeClass> sc = someClass();
  RCP<C> c = sc->get_C();
  sc = null; // The SomeClass object is destroyed which invalidates 'c'!
  c->someFunc(); // Now the dangling reference is detected and throws!
\end{verbatim}}
\end{listing}


Note that the implementation of {}\ttt{SomeClass} in Listing
{}\ref{listing:osr:SomeClass-refactored} means that the nature of the
relationship between the {}\ttt{C} object returned from
{}\ttt{SomeClass::get\_C()}, the {}\ttt{SomeClass} object, and the
client code represents a semi-presisting association as defined in
Section {}\ref{sec:persisting-nonpersisting-associations}.  In this
case, the usage of the {}\ttt{C} object is only valid while the parent
{}\ttt{SomeClass} object still exists.  However, if the client
mistakenly tries to use a dangling {}\ttt{C} object after its parent
{}\ttt{SomeClass} object is destroyed, then a clean runtime
dangling-reference exception is thrown as descrbed in Section
{}\ref{sec:detection-dangling-references}.

Alternatively, if you want the {}\ttt{SomeClass::get\_C()} function
to create a true presisting association where the {}\ttt{C} object
can outlive all of the client references to the parent
{}\ttt{SomeClass} object, then the implementation of
{}\ttt{SomeClass::get\_C()} can be modified to what is shown in
Listing {}\ref{listing:osr:SomeClass-get_C-persisting}.


\begin{listing}:  Implementation of the ``object self-reference'' idiom
using a true presisting association  \\
\label{listing:osr:SomeClass-get_C-persisting}
{\small\begin{verbatim}
  RCP<C> SomeClass::get_C()
  {
    justInTimeInitialization();
    return rcpInvertedObjOwnership(c, weakSelfPtr_.create_strong());
  }
\end{verbatim}}
\end{listing}


It is required to create a strong {}\ttt{RCP} in this case and
invert the object ownership using in
{}\ref{listing:osr:SomeClass-get_C-persisting} (which is an instance
of the ``inverted object ownership'' idiom which is described in
Section {}\ref{sec:inverting-obj-ownership}).

Given the implementation in Listing
{}\ref{listing:osr:SomeClass-get_C-persisting}, client code like in
Listing {}\ref{listing:osr:dangling-ref-SomeClass} will allow the
{}\ttt{C} object can be used after the client's
{}\ttt{RCP<SomeClass>} object is made {}\ttt{null} without
thrown a dangling reference exception.


%
{}\subsubsection{The generalized view design pattern}
\label{sec:generalized-view-design-pattern}
%

One of the most useful and powerful idioms / design-patterns related
to the use of the Teuchos memory management classes is the
``generalized view'' design pattern\footnote{Here we use the term
'design pattern' and not 'idiom' to describe the ``generalized view''
design pattern.  The reason that the more general term 'design
pattern' is being used is that the majority of the pattern is really
language independent and the behaviors are more general that what you
will find in a typical language-specific idiom.  It is only the
{}\ttt{RCP} details that would classify this as a C++ idiom.  However,
this is an important example of the use of {}\ttt{RCP} so it is worthy
to be discussed in this document.}.  In this context, a ``view'' is
some object that is created off of a parent object and provides some
type of access to some part of the the parent.  Views can be const or
non-const and can be persisting or semi-persisting (see Section
{}\ref{sec:persisting-nonpersisting-associations} for the definition
of persisting and semi-persisting associations).  Views can also be
direct views or ``generalized views'' (i.e.\ potentially detached
non-direct views).

A direct view is one which directly points into the the internal data
structures of the parent so a change of the view instantaneously
changes the parent and changes to the parent instantaneously changes
the view.  An example of a direct view is an iterator into an
container such as is returned from {}\ttt{std::vector::begin()} or
{}\ttt{std::list::begin()}.  Other examples of direct views include
{}\ttt{ArrayView}s of {}\ttt{Array} and {}\ttt{ArrayRCP}
objects.  Direct views can be non-const and const as is demonstrated
with iterators and {}\ttt{ArrayView}s.  Direct views are a pleasure
to work with but they also fundamentally constrain the implementation
of the parent objects that they are providing the views into.  In the
case of contiguous array containers like {}\ttt{std::vector} and
{}\ttt{ArrayRCP}, constraining the implementation to store a
pointer to a contiguous array of data internally is not a problem,
that is an important and proper design constraint for these classes.
However, for more general classes, the rigid constraints imposed by
direct views are unacceptable and break the abstraction in most cases.
For example, if an abstract matrix object provides direct views of the
rows of a matrix then the matrix must necessarily be stored in a
row-major data-structure, precluding other possibilities.  Once a
direct row-based view is supported by such a matrix class, it becomes
impossible to change the internal representation of the matrix to
anything other than a row-oriented implementation and still maintain
high performance and a reasonable implementation.


%
{}\subsubsection*{Basic overview of the ``generalized view'' design
pattern}
%

Because direct views can overly constrain the implementation freedom
of the parent, in order to allow for the fullest freedom to pick the
internal implementations of the parent and the view separately, we
must instead consider using potentially detached non-direct views
defined here as ``generalized views''.  A ``generalized view'' is a
view of a parent object that is not guaranteed to be a direct view
such that changes to the view are not guaranteed to be instantaneously
propagated to the parent and vice versa.  One example of a case where
a ``generalized view'' is needed is when creating a view of
non-contiguous columns of a dense matrix where for the sake of
efficiency one must create a temporary contiguous copy as a new dense
matrix.  This type of generalized view is used in the implementation
of Thyra MultiVector non-contiguous column views
{}\ref{ThyraOperatorVectorSAND} which is depicted in Figure
{}\ref{fig:MultiVectorView}. In the Thyra MultiVector implementation,
when the client requests a view of a set of non-contiguous columns,
the implementation will create a temporary contiguous copy which
results in improved performance of many types of
operations\footnote{Using contiguous columns of a Fortran-style
column-major dense matrix is require in order to take advantage of
high performance BLAS routines.}.  The Thyra example of non-contiguous
column views is a good example because it is a simple case to describe
yet has all the features needed to demonstrate the workings and the
generalized view design pattern.


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.50]{MultiVectorView}
%}
\end{center}
\caption{
\label{fig:MultiVectorView}
Depiction of contiguous and non-contiguous multi-vector column views.}
\end{figure}
\esinglespace}


Before describing the Thyra MultiVector example in more detail, first,
a generic description of the ``generalized view'' design pattern is
presented.  The most general description of the ``generalized view''
design pattern is shown in Figure
{}\ref{fig:GeneralizedViewClassDiagram} (UML class diagram) and Figure
{}\ref{fig:GeneralizedViewStateDiagram} (UML state diagram).  Figure
{}\ref{fig:GeneralizedViewClassDiagram} shows two generic classes, a
{}\ttt{Parent} and a {}\ttt{View}.  In this case, only one type of
the view is shown but in reality there can be several different types
of views into a single parent object (as there are in the Thyra
MultiVector case).  A view is created using either the
{}\ttt{createNonconstView(...)} or the {}\ttt{createView(...)} 
functions.  In either case, the returned view is wrapped in an
{}\ttt{RCP} object.  There are two purposes for wrapping the view in
an {}\ttt{RCP} object.  First, a new {}\ttt{View} object may need to
be dynamically allocated to satisfy the view request (and therefore
needs {}\ttt{RCP} to take care to control the lifetime of the
dynamically allocated object).  Second, the action needed to re-sync
the parent up with the view can be set as an embedded object (see
Section {}\ref{sec:embedded-objecs}).  In fact, the {}\ttt{Parent}
object is not guaranteed to be updated after changes to the view are
made until the view is destroyed.  To demonstrate, consider the client
code in Listing {}\ref{listing:generalized-view-ex1}.


{\bsinglespace
\begin{figure}[p]
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=0.65]{GeneralizedViewClassDiagram}
%}
\end{center}
\caption{
\label{fig:GeneralizedViewClassDiagram}
Parent and child classes for ``generalized view'' design pattern.}
\end{figure}
\esinglespace}


{\bsinglespace
\begin{figure}[p]
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=0.65]{GeneralizedViewStateDiagram}
%}
\end{center}
\caption{
\label{fig:GeneralizedViewStateDiagram}
State behavior for parent object in ``generalized view'' design
pattern.}
\end{figure}
\esinglespace}


\begin{listing}:  Example of the use of a generalized view  \\
\label{listing:generalized-view-ex1}
{\small\begin{verbatim}
  void changeParent(const Ptr<Parent> &parent)
  {
    // Create a non-const view
    const RCP<View> view = parent->createNonconstView(...);

    // Chnage the parent through the view
    view->makeChange(...);
    view->makeChange(...);
    ...

    // Destroy the view which resycs the view with the parent
    view = null

    // Now the parent has been updated for changes through the view!

  }
\end{verbatim}}
\end{listing}


The code in Listing {}\ref{listing:generalized-view-ex1} demonstrates
that the parent is only guaranteed to be updated after the non-const
generalized view has been destroyed.  The state of the parent is
undefined while a non-const view is active.  One of three
possibilities exist for the state of the parent while a non-const view
is active.  First, if the view just happens to be a direct view, then
changes to the view instantaneously are reflected in the parent.
Second, if the view is a completely separate chunk of data, changes to
the view do not affect the state of the parent at all until the view
is destroyed and the data in the view is copied into the parent in the
appropriate way.  The third option is somewhere in between the first
two; part of the view's data may directly point back into the parent's
internal data structures and the rest of the view's data may be
separate from the parent.  In this case, the state of the parent
object may actually violate its internal invariants and the parent
object would not even be usable while the non-const view is active.

In order to allow complete freedom in how a generalized view is
implemented and to allow the implementation to change at will, a
relatively strict usage protocol must be defined as shown in the
parent's state diagram in Figure
{}\ref{fig:GeneralizedViewStateDiagram}.  With respect to generalized
views, the {}\ttt{Parent} has one of three states; 'no views', only
'has const views(s)', and 'has non-const view'.  The default state of
the parent is 'no views'.  In this state, either a const or a
non-const view can be created.  When a const view is created, the
parent enters the state 'has const view(s)'.  In this state, the
parent object is still allowed to be queried and other const-views can
be created.  However, while there are active const views, a non-const
view can not be created.  The reason that non-const views can not be
allowed while const views are created is that creating a non-const
view and then changing it while const views are active would put the
const views into an undefined state.  If the const and non-const views
happened to be implemented as direct views, then changes to the
non-const view would not only change the parent but it would also
change the const views.  However, if the views are implemented as
detached copies of data, then changes to the non-const view would not
be expected to be propagated to the existing const
views\footnote{Actually, one could implement a OBSERVER
{}\cite{AgileSoftwareDevelopment} type of implementation where changes
to the views would automatically be written back and forth to keep the
parent and the views in sync but this would lead to complex possibly
fragile implementations and could significantly degrade performance if
frequent small changes to data resulted in lots of syncs.  Therefore,
to allow for a simple implementation and the highest performance, the
generalized view design pattern discourages this type of more complex
less efficient OBSERVER-type of implementation.}.  Since this type of
ambiguity would destroy the abstraction, the generalized view design
pattern simply states that creating non-const views on the parent
while const views are active is just not allowed.  Likewise, any
operations on the parent that might change the state in a way that
would affect the views must also be disallowed.  In summary, when
non-const views are active, the non-const interface of the parent must
be locked down.  When the last const view is destroyed, the parent
goes back to the 'no views' state.

When a non-const view is created the parent goes into the 'has
non-const view' state.  In this state, no other non-const or const
views can be created and the entire const and non-const interface of
the parent must be locked down.  In essence, when a non-const view is
active, the parent object has to be completely left along.  The reason
for this should be obvious.  When a non-const view is represented as a
separate copy of data, then the state of the parent is undefined until
the non-const view is destroyed and the data is written back.  In this
case, a query of the parent would not show the changes made in the
active non-const view.  Again, this type of ambiguity would destroy
the abstraction and therefore the parent object must be totally locked
down while a non-const view is active.  Likewise, only one non-const
view can be allowed at any one time due to similar arguments.  When
the non-const view is destroyed, any changes in the data are written
back to the parent's internal data structures and the parent goes back
to the state 'no views'.

In order to allow for the highest performance and the simplest
implementations of the parent and the view classes in all cases, and
to help catch errors in client code, the generalized view design
pattern states that views should be semi-persisting; that is, the
views are only valid while the client's {}\ttt{RCP} to the parent
is still active and the view is not expected to live on past the
lifetime of the parent.  Therefore, any generalized views that remain
after the last strong {}\ttt{RCP<Parent>} object is released should
result in dangling references and throw exceptions in a debug-mode
build.  For example, the code in Listing
{}\ref{listing:generalized-view-dangling} would result in a dangling
reference exception in a debug-mode build.


\begin{listing}:  Example of a dangling reference generalized view  \\
\label{listing:generalized-view-dangling}
{\small\begin{verbatim}
  // Create and initialize parent
  RCP<Parent> parent = createParent(...);
  ...

  // Create a view
  RCP<const View> view = parent->createView(...);

  // Destroy the parent (invalidating the existing view)
  parent = null;

  // Try to access the now dangling view
  view->makeChange(...); // Throws dangling reference exception!
\end{verbatim}}
\end{listing}


Even if a generalized view can be made persisting (which it is in the
MultiVector example given later), the implementation should still
prefer to implement the view as a semi-persisting view.  The main
purpose of a view is to change the parent object so if the parent is
released before the view is written to and written back, then that is
most likely a programming error in the client's code.  For example,
the code in Listing {}\ref{listing:generalized-view-dangling} is most
likely an error because if the parent has been deleted then there is
no use in modifying the view and that is most likely an error in
program logic that needs to fixed.  By implementing generalized views
and semi-persisting views the objects help to better catch errors in
client code.

However, if it makes sense in the particular setting, an
implementation of the generalized view design pattern can choose to
implement the views as full persisting views that will persist even
after all the external parent references are removed, thereby avoiding
dangling-reference exceptions.  Note that if the parent class
implements the ``object self-reference'' idiom described in Section
{}\ref{sec:self-references} then a strong {}\ttt{RCP} to the parent
object can always be attached to the {}\ttt{RCP} of the view, thereby
providing for persisting generalized views no mater what the internal
data structures are used.

Another aspect of the generalized view design pattern is that it is
important to distinguish between non-const views and const views.  In
the case of const views, if a separate copy of the data must be
created to support the view, the data does not have to be written back
to the parent when the view is destroyed.  This makes const views
fundamentally more efficient than non-const views (which must write
back their data when they are destroyed).  Because const views are
potentially more efficient, the unadorned name {}\ttt{createView(...)} 
is given to create const views while the longer name
{}\ttt{createNonconstView(...)} is used to create non-const views.
The idea is that a developer is more likely to call the shorter
{}\ttt{createView(...)} function creating a more efficient and safe
const view.  If a const view is all the client code requires, then all
is good.  However, if the client code really needs to change the
parent object through the view, then the code will not compile and the
developer will need to change the client code to create a non-const
view through {}\ttt{createNonconstView(...)}.

Because the parent object gets locked down (or is in an undefined
state when checking is not enabled) when generalized views are active,
it is important that client code only create views at the last
possible moment and then release them at the earliest possible moment.
The best way to do this, when possible, is to create the view in the
same statement where the view will be used as demonstrated in Listing
{}\ref{listing:generalized-view-min-lifetime}.


\begin{listing}:  Example of minimizing the lifetime of a generalized
view  \\
\label{listing:generalized-view-min-lifetime}
{\small\begin{verbatim}
  void changeParentThroughView(const Ptr<Parent> &parent)
  {
    changeTheView(*parent-createNonconstView());
    queryTheView(*parent->createView());
    ...
  }
\end{verbatim}}
\end{listing}


The client code in Listing
{}\ref{listing:generalized-view-min-lifetime} works just fine because
the temporary {}\ttt{RCP<[const] View>} objects managed by the
compiler are guaranteed to exist until the full statement they are
created in ends.  This is one case where using an {}\ttt{RCP} to
manage the memory is very convenient.

The last issue to discuss related to the generalized view design
pattern is that, depending on the nature of the parent and the view
classes, it may be reasonable to have the parent object partitioned
into different logical pieces and then apply the behaviors shown in
Figure {}\ref{fig:GeneralizedViewStateDiagram} to each of these
logical pieces separately.  For example, we can treat each row or each
column in a matrix object as a separate logical piece such that we can
allow separate views of each of the rows or columns independent of
each other.  This is the case with the Thyra MultiVector example
(mentioned earlier to be described in more detail below).  However,
any bulk query operations on the parent object (like taking an induced
matrix norm) must be locked out while non-const views are active.
Likewise, any bulk modifying operation (like assigning all the matrix
entries to zero) must be locked out when any views are active.


%
{}\subsubsection*{Example implementation of generalized views for
MultiVector non-contiguous column views}
%

Now that a basic overview of the generalized view design pattern has
been given, the Thyra MultiVector non-contiguous column view example
mentioned earlier and depicted in Figure {}\ref{fig:MultiVectorView}
is described in more detail.  This is a good example to highlight the
features of the generalized view design pattern and the usage of the
{}\ttt{RCP} class to manage detached view semantics.  A simplified
class declaration for the Thyra MultiVector subclass showing the
relevant class members is given in Listing
{}\ref{listing:DefaultSpmdMultiVector-decl}.


\begin{listing}:  Class declaration for Thyra MultiVector implementation
of multi-vector views as ``generalized views''  \\
\label{listing:DefaultSpmdMultiVector-decl}
{\small\begin{verbatim}
  template<class Scalar>
  class DefaultSpmdMultiVector : virtual public SpmdMultiVectorBase<Scalar> {
  public:
  
    ...
  
    DefaultSpmdMultiVector(
      const RCP<const SpmdVectorSpaceBase<Scalar> > &spmdRangeSpace,
      const RCP<const ScalarProdVectorSpaceBase<Scalar> > &domainSpace,
      const ArrayRCP<Scalar> &localValues,
      const Ordinal leadingDim = -1
      );
  
    ...
  
  protected:
  
    ...
  
    RCP<const MultiVectorBase<Scalar> >
    nonContigSubViewImpl(const ArrayView<const int> &cols) const;
  
    RCP<MultiVectorBase<Scalar> >
    nonconstNonContigSubViewImpl(const ArrayView<const int> &cols);
  
    ...
    
  private:
  
    RCP<const SpmdVectorSpaceBase<Scalar> > spmdRangeSpace_;
    RCP<const ScalarProdVectorSpaceBase<Scalar> > domainSpace_;
    ArrayRCP<Scalar> localValues_;
    Ordinal leadingDim_;
  
    ArrayRCP<Scalar> createContiguousCopy(const ArrayView<const int> &cols) const;
    
  };
  
  // Non-member constructor
  template<class Scalar>
  RCP<DefaultSpmdMultiVector<Scalar> >
  defaultSpmdMultiVector(
    const RCP<const SpmdVectorSpaceBase<Scalar> > &spmdRangeSpace,
    const RCP<const ScalarProdVectorSpaceBase<Scalar> > &domainSpace,
    const ArrayRCP<Scalar> &localValues,
    const Ordinal leadingDim = -1
    )
  {
    return Teuchos::rcp(
      new DefaultSpmdMultiVector<Scalar>(
        spmdRangeSpace, domainSpace, localValues, leadingDim
        )
      );
  }
\end{verbatim}}
\end{listing}


The internal private data-structure for a multi-vector is very simple
as shown in Listing {}\ref{listing:DefaultSpmdMultiVector-decl}.  A
standard column-major Fortran-style dense matrix format is used where
all of the data in the local processes is stored in a single
contiguous {}\ttt{ArrayRCP<Scalar>} object.  The number of rows in the
local process is given by {}\ttt{spmdRangeSpace\_->localSubDim()} and
{}\ttt{leadingDim\_} is the stride between columns.

The generalized views returned by the functions
{}\ttt{nonContigSubViewImpl(...)} and
{}\ttt{nonconstNonContigSubViewImpl(...)} are of the type
{}\ttt{MultiVectorBase} which is the upper-most base class for
{}\ttt{DefaultSpmdMultiVector}.  (As shown below, the concrete types
of the views are actually {}\ttt{DefaultSpmdMultiVector}.) Therefore,
this is an instance where the class types of the parent and view are
actually the same.

The implementations of the functions {}\ttt{nonContigSubViewImpl(...)} 
and {}\ttt{nonconstNonContigSubViewImpl(...)} are given in Listing
{}\ref{listing:DefaultSpmdMultiVector-subivew-impl}.


{}\begin{listing}: Implementation of {}\ttt{DefaultSpmdMultiVector}
functions {}\ttt{nonContigSubViewImpl(...)} and
{}\ttt{nonconstNonContigSubViewImpl(...)} \\
\label{listing:DefaultSpmdMultiVector-subivew-impl}
{\small\begin{verbatim}
  template<class Scalar>
  RCP<const MultiVectorBase<Scalar> >
  DefaultSpmdMultiVector<Scalar>::nonContigSubViewImpl(
    const ArrayView<const int> &cols
    ) const
  {
    THYRA_DEBUG_ASSERT_MV_COLS("nonContigSubViewImpl(cols)", cols);
    const int numCols = cols.size();
    const ArrayRCP<Scalar> localValuesView = createContiguousCopy(cols);
    return defaultSpmdMultiVector<Scalar>(
      spmdRangeSpace_,
      createSmallScalarProdVectorSpaceBase<Scalar>(spmdRangeSpace_, numCols),
      localValuesView
      );
  }
  
  template<class Scalar>
  RCP<MultiVectorBase<Scalar> >
  DefaultSpmdMultiVector<Scalar>::nonconstNonContigSubViewImpl(
    const ArrayView<const int> &cols )
  {
    THYRA_DEBUG_ASSERT_MV_COLS("nonContigSubViewImpl(cols)", cols);
    const int numCols = cols.size();
    const ArrayRCP<Scalar> localValuesView = createContiguousCopy(cols);
    const Ordinal localSubDim = spmdRangeSpace_->localSubDim();
    RCP<CopyBackSpmdMultiVectorEntries<Scalar> > copyBackView =
      copyBackSpmdMultiVectorEntries<Scalar>(cols, localValuesView.getConst(),
        localSubDim, localValues_.create_weak(), leadingDim_);
    return Teuchos::rcpWithEmbeddedObjPreDestroy(
      new DefaultSpmdMultiVector<Scalar>(
        spmdRangeSpace_,
        createSmallScalarProdVectorSpaceBase<Scalar>(spmdRangeSpace_, numCols),
        localValuesView),
      copyBackView
      );
  }
\end{verbatim}}
\end{listing}


The implementation of the sub-view functions in Listing
{}\ref{listing:DefaultSpmdMultiVector-subivew-impl} is fairly simple.
First, the private helper function {}\ttt{createContiguousCopy(...)}
creates an {}\ttt{ArrayRCP<Scalar>} object for a contiguous copy of
the non-contiguous columns being requested.  This contiguous copy of
data is then given over to to create a new
{}\ttt{DefaultSpmdMultiVector} object which represents the view.  The
implementation of the function {}\ttt{createContiguousCopy(...)} is
simple enough and is given in Listing
{}\ref{listing:DefaultSpmdMultiVector-createContiguousCopy}.


{}\begin{listing}: Implementation of {}\ttt{DefaultSpmdMultiVector}
function {}\ttt{createContiguousCopy(...)}
\label{listing:DefaultSpmdMultiVector-createContiguousCopy}
{\small\begin{verbatim}
  template<class Scalar>
  ArrayRCP<Scalar>
  DefaultSpmdMultiVector<Scalar>::createContiguousCopy(
    const ArrayView<const int> &cols ) const
  {
    typedef typename ArrayRCP<Scalar>::const_iterator const_itr_t;
    typedef typename ArrayRCP<Scalar>::iterator itr_t;
    const int numCols = cols.size();
    const Ordinal localSubDim = spmdRangeSpace_->localSubDim();
    ArrayRCP<Scalar> localValuesView = Teuchos::arcp<Scalar>(numCols*localSubDim);
    // Copy to contiguous storage column by column
    const const_itr_t lv = localValues_.begin();
    const itr_t lvv = localValuesView.begin();
    for (int k = 0; k < numCols; ++k) {
      const int col_k = cols[k];
      const const_itr_t lv_k = lv + leadingDim_*col_k;
      const itr_t lvv_k = lvv + localSubDim*k;
      std::copy(lv_k, lv_k+localSubDim, lvv_k);
    }
    return localValuesView;
  }
\end{verbatim}}
\end{listing}


Note how iterators are used to perform the raw data copy in Listing
{}\ref{listing:DefaultSpmdMultiVector-createContiguousCopy}.  This
results in very well checked code in a debug-mode build (see Section
{}\ref{sec:debug-mode-runtime-checking}) but very high performance
code in a non-debug optimized build (see Section
{}\ref{sec:optimized-performance}).

Note that the key difference between the implementation of the
functions {}\ttt{nonContigSubViewImpl(...)} and
{}\ttt{nonconstNonContigSubViewImpl(...)} in Listing
{}\ref{listing:DefaultSpmdMultiVector-subivew-impl} is that
{}\ttt{nonconstNonContigSubViewImpl(...)} creates an {}\ttt{RCP} to an
object of type {}\ttt{CopyBackSpmdMultiVectorEntries} and attaches it
to the created {}\ttt{RCP<DefaultSpmdMultiVector<Scalar> > } as an
embedded object (see Section {}\ref{sec:embedded-objecs}).  The
destructor for {}\ttt{CopyBackSpmdMultiVectorEntries} performs the
copy-back of the non-const view after the last {}\ttt{RCP} to the view
is destroyed.  The implementation of the class
{}\ttt{CopyBackSpmdMultiVectorEntries} is given in Listing
{}\ref{listing:CopyBackSpmdMultiVectorEntries}.


{}\begin{listing}: Implementation of the class
{}\ttt{CopyBackSpmdMultiVectorEntries}
\label{listing:CopyBackSpmdMultiVectorEntries}
{\small\begin{verbatim}
  template<class Scalar>
  class CopyBackSpmdMultiVectorEntries {
  public:
    CopyBackSpmdMultiVectorEntries(
      const ArrayView<const int> &cols,
      const ArrayRCP<const Scalar> &localValuesView, const Ordinal localSubDim,
      const ArrayRCP<Scalar> &localValues, const Ordinal leadingDim
      )
      : cols_(cols), localValuesView_(localValuesView), localSubDim_(localSubDim),
        localValues_(localValues), leadingDim_(leadingDim)
      {}
    ~CopyBackSpmdMultiVectorEntries()
      {
        typedef typename ArrayRCP<const Scalar>::const_iterator const_itr_t;
        typedef typename ArrayRCP<Scalar>::iterator itr_t;
        // Copy from contiguous storage column by column
        if (localValues_.strong_count()) {
          const int numCols = cols_.size();
          const const_itr_t lvv = localValuesView_.begin();
          const itr_t lv = localValues_.begin();
          for (int k = 0; k < numCols; ++k) {
            const int col_k = cols_[k];
            const const_itr_t lvv_k = lvv + localSubDim_*k;
            const itr_t lv_k = lv + leadingDim_*col_k;
            std::copy( lvv_k, lvv_k + localSubDim_, lv_k );
          }
        }
      }
  private:
    Array<int> cols_;
    ArrayRCP<const Scalar> localValuesView_;
    Ordinal localSubDim_;
    ArrayRCP<Scalar> localValues_;
    Ordinal leadingDim_;
  };

  // Non-member constructor  
  template<class Scalar>
  RCP<CopyBackSpmdMultiVectorEntries<Scalar> >
  copyBackSpmdMultiVectorEntries(
    const ArrayView<const int> &cols,
    const ArrayRCP<const Scalar> &localValuesView, const Ordinal localSubDim,
    const ArrayRCP<Scalar> &localValues, const Ordinal leadingDim
    )
  {
    return Teuchos::rcp(
      new CopyBackSpmdMultiVectorEntries<Scalar>(
        cols, localValuesView, localSubDim, localValues, leadingDim));
  }
\end{verbatim}}
\end{listing}


The implementation of {}\ttt{CopyBackSpmdMultiVectorEntries} in
Listing {}\ref{listing:CopyBackSpmdMultiVectorEntries} is
straightforward.  When the destructor is called, it copies the data in
the non-const view back to the native storage of the parent
{}\ttt{DefaultSpmdMultiVector} object.

The only twist in the implementation of
{}\ttt{nonconstNonContigSubViewImpl(...)} and
{}\ttt{CopyBackSpmdMultiVectorEntries} is that a weak {}\ttt{ArrayRCP}
is used for the parent's {}\ttt{localValues\_} data in the
{}\ttt{CopyBackSpmdMultiVectorEntries} object.  It is created in the
function {}\ttt{nonconstNonContigSubViewImpl(...)} with
{}\ttt{localValues\_.create\_weak()}.  If the parent goes away before
the view, then the weak pointer {}\ttt{localValues\_} in the
destructor for {}\ttt{CopyBackSpmdMultiVectorEntries} will have a
strong count of 0, thereby resulting in the skipping of the copy-back
of data.  This this a performance optimization since there is no point
in copying back the data if the parent object is gone.  This design
allows both const and non-const multi-vector views to be persisting
and still have the highest performance.

% ToDo: Write a Teuchos utility class to implement the guts of the
% debug-mode runtime checking needed to enforce the semantics of the
% generalized view design pattern.  Use this utility class in a mock Teuchos
% object and in the Thyra::DefaultSpmdMultiVector class.

There are several things that are interesting about this example.
First, by using the embedded object feature of {}\ttt{RCP} the code is
able to implement the copy-back-to-parent functionality without having
to write a new {}\ttt{MultiVector} subclass just for the view.  The
{}\ttt{DefaultSpmdMultiVector} objects that are returned as views have
no idea they are being used as views into other
{}\ttt{DefaultSpmdMultiVector} objects and they need not care.
Without the embedded object feature described in Section
{}\ref{sec:embedded-objecs}, a different {}\ttt{MultiVector} subclass
would have to be created with a destructor that would copy back the
data.  Second, the constraints imposed by the generalized view design
pattern shown in Figure {}\ref{fig:GeneralizedViewStateDiagram} ensure
that no problems will arise due to the fact that the views are stored
in detached copies of the data.  If changes to the parent
{}\ttt{DefaultSpmdMultiVector} were allowed while a non-const
{}\ttt{DefaultSpmdMultiVector} view was active, then all of the
changes in the parent would be overwritten when the
{}\ttt{DefaultSpmdMultiVector} view was destroyed.  Third, this
example demonstrates why const views are fundamentally more efficient
than non-const views.  In the case of a const view, the temporary
contiguous copy of data must just be released and does not need to be
copied back to the parent.  This saves the work imposed by the
destructor on the {}\ttt{CopyBackSpmdMultiVectorEntries} object.

In summary, the main properties and features of the generalized view
design pattern are:

\begin{itemize}

{}\item Generalized views allow for complete abstraction,
encapsulation, and the highest performance in all cases.  This is
simply not possible to achieve with direct views.

{}\item Non-const generalized views are only guaranteed to update the
state of the parent after the view object has been released.

{}\item A single parent object can provide more than one type of
generalized view and views can be applied separately to different
logically distinct parts of the parent object (e.g.\ views to the rows
or columns of an abstract matrix object can be create and handled
separately).

{}\item It is important to differentiate between non-const views and
const views.  While detached non-const views must be copied back to
parent when the view is released, const views do not (therefore
improving the performance of const views).

{}\item It is critical that {}\ttt{RCP} objects be used to wrap the
created view objects in order to allow the views to be dynamically
allocated and to allow for specialized copy-back behavior when
non-const views are destroyed.

{}\item The flexibility and performance gains allowed by the
generalized view design pattern come at the expense of more restricted usage
patterns of the parent and views.

  \begin{itemize}

  {}\item Only one non-const view can be active for any logically
  district part of the parent object at any one time and the parent
  object must be locked down (or at least any functionality that
  relates to the viewed part) while a non-const view is active.

  {}\item Multiple const views can be active for any logically
  district part of the parent object at any one time but the non-const
  interface of the parent object (at least functionality that relates
  to that viewed part) must be locked down while any const views are
  active.

  \end{itemize}

\end{itemize}


%
{}\subsection{Comparison with other class libraries and the standard
C++ library}
%

Comparisons between the Teuchos memory management classes and other
classes in Boost and the standard C++ library have been made
throughout this document.  Here, these comparisons are summarized and
extended.  Comparisons with Boost classes are for version 1.40.

The Teuchos class {}\ttt{RCP} is almost identical in most respects to
the {}\ttt{boost::shared\_ptr} class and therefore the
{}\ttt{std::shared\_ptr} class in C++0x.  The first version of the
class {}\ttt{RCP} was developed back in 1998 under the name
{}\ttt{MemMngPack::ref\_count\_ptr} as part of the development of the
rSQP++ package {}\cite{rSQP++} (now called MOOCHO {}\cite{MOOCHO}).
At that time, there was no general purpose high quality reference
counted pointer class available and most compilers at the time could
not even support template member functions needed for implicit
smart-pointer conversions.  After 1998, the first
{}\ttt{boost::shared\_ptr} class appeared (which did not allow a
customized deallocation policy and was therefore not very flexible).
Over the years, the two classes independently evolved in very similar
ways.  The current version of {}\ttt{boost::shared\_ptr} is a high
quality flexible reference-counted pointer class.  Because it support
custom template deallocator policy objects (which are called
``deleters'' in {}\ttt{boost::shared\_ptr}) it allows for great
flexibility in how it is used.

The key advantages of the {}\ttt{RCP} class over the current
{}\ttt{boost::shared\_ptr} class are greater functionality, greater
flexibility, and better debug-mode runtime checking. The few of the
key advantages of the {}\ttt{RCP} class that can not be replicated
with the {}\ttt{boost::shared\_ptr} class without changing its design
include:

\begin{itemize}

{}\item The {}\ttt{RCP} class has built-in support for debug-mode
runtime tracing of reference-counting nodes which is used to implement
a whole host runtime checking including the detection and reporting of
circular references (Section
{}\ref{sec:detection-circular-references}), and multiple owning
reference-counted objects (Section
{}\ref{sec:detection-dual-owning-rcps}).

{}\item The {}\ttt{RCP} class allows the association and retrieval of
extra data attached to an already created reference-counting node
object (see Section {}\ref{sec:extra-data}).

{}\item The {}\ttt{RCP} class allows a client call {}\ttt{release()}
to remove the deletion ownership from an already created {}\ttt{RCP}
object (the need for this is described in Section
{}\ref{sec:extra-data}).

{}\item The {}\ttt{RCP} class has built-in support for both strong and
weak reference-counted pointer handles right in the same class (see
Section {}\ref{sec:circular-references-weak-pointers}).  The
{}\ttt{boost::shared\_ptr} class uses a separate
{}\ttt{boost::weak\_ptr} class to represent weak references which is
less flexible.  The {}\ttt{RCP} approach allows the debug-mode runtime
detection and reporting of dangling non-owning references while
{}\ttt{boost::shared\_ptr} class can not when using a null deleter
(see Section {}\ref{sec:detection-dangling-references})

\end{itemize}

The key advantages of the current {}\ttt{boost::shared\_ptr} class
over the current {}\ttt{RCP} class are that it has lower storage and
runtime overhead (see Section
{}\ref{sec:reference-counting-overhead}), and it has native support
for shared reference-counting nodes across different threads in a
multi-threaded program.  The {}\ttt{RCP} class does not yet have
support for thread-safe sharing across multiple threads but some
reasonable solution will be implemented (perhaps borrowing form the
{}\ttt{boost::shared\_ptr} implementation) when it is needed.  The
{}\ttt{RCP} class has been developed in the context of computational
science and engineering applications where parallelism is handled
using distributed memory MPI implementations where no
multi-threading is used.  Given that even the best non-locking
{}\ttt{boost::shared\_ptr} implementation imparts a significant
overhead in manipulating the reference count, it is not clear if the
right solution to the multi-threading problem is to make all
{}\ttt{RCP} objects thread safe in an entire program.

Because both the Teuchos {}\ttt{RCP} and {}\ttt{boost::shared\_ptr}
classes support customized deallocation policy objects, one can embed
an {}\ttt{RCP} object in a {}\ttt{boost::shared\_ptr} object and vice
versa.  This is already supported in Teuchos using the overloaded
non-member helper functions {}\ttt{Teuchos::rcp(const
boost::shared\_ptr \&p)} and {}\ttt{Teuchos::shared\_pointer(const
RCP<T> \&rcp)}.  This allows the developer to mix and match
{}\ttt{RCP} and {}\ttt{boost::shared\_ptr} in the same code and still
have correct memory management.  However, since {}\ttt{RCP} has better
debug-mode runtime checking and is more flexible it should be preferred
to {}\ttt{boost::shared\_ptr} in most high-level code.  However,
because {}\ttt{boost::shared\_ptr} has lower overhead and has native
support for sharing across threads is has valid uses.  Also, of
course, one may need to convert back and forth between {}\ttt{RCP} and
{}\ttt{boost::shared\_ptr} to glue together different pieces of
separately developed code.

Another smart pointer class for single objects is
{}\ttt{std::auto\_ptr}.  This class does not support sharing and has
only the minimal functionality needed to support the RAII idiom
{}\cite[Item 13]{C++CodingStandards05}.  Given that reference-counting
overhead is low compared to raw allocations and deallocations (see
Section {}\ref{sec:reference-counting-overhead}) there is little
reason to ever use {}\ttt{std::auto\_ptr} instead of {}\ttt{RCP} (or
{}\ttt{boost::shared\_ptr} for that matter).

The Teuchos class {}\ttt{Array} is of course equivalent to
{}\ttt{std::vector} by design and uses an {}\ttt{std::vector}
internally.  The main advantages of using {}\ttt{Array} instead of
directly using {}\ttt{std::vector} are a) {}\ttt{Array} has better
debug-mode runtime checking and produces better exception messages, b)
conversion to the other Teuchos array types {}\ttt{ArrayView} and
{}\ttt{ArrayRCP} includes full runtime debug-mode detection and
reporting of dangling references (which is not possible with with
{}\ttt{std::vector}, and c) is more consistent with the usage of the
other Teuchos array types.  A major difference between {}\ttt{Array}
and {}\ttt{std::vector} is that {}\ttt{Array} uses an unsigned integer
for its {}\ttt{size\_type} (see Appendix
{}\ref{sec:unsigned_size_type} for the justification).

The Teuchos class {}\ttt{ArrayRCP} really has not equivalent class in
Boost or the C++0x standard libraries.  There is a Boost class called
{}\ttt{boost::shared\_array} which uses the {}\ttt{boost::shared\_ptr}
reference-counting machinery and has an overloaded
{}\ttt{operator[](size\_type)} function but his class does not support
iterators (which are critical for safety and performance) and does not
support persisting sub-views (see Section {}\ref{sec:array-views}).

The Teuchos compile-time sized array class {}\ttt{Tuple} is more or
less equivalent to the class {}\ttt{boost::array}.  Both contain an
iterator interface and other STL compliant functions.  The key
advantage of {}\ttt{Tuple} is that conversions to the other Teuchos
array types {}\ttt{ArrayView} and {}\ttt{ArrayRCP} support full
runtime debug-mode detection and reporting of dangling references.

Finally, the Teuchos classes {}\ttt{Ptr} and {}\ttt{ArrayView} have no
equivalent classes in Boost or C++0x.  As described throughout this
paper, these classes are key to creating C++ code that is maximally
self documenting (by distinguishing between persisting and
non-persisting associations), maximally safe in terms of debug-mode
runtime checking, and while at the same time allowing for the highest
performance in non-debug optimized builds.  You can not plug the
remaining holes in safety and performance without the {}\ttt{Ptr} and
{}\ttt{ArrayView} classes.

What makes the Teuchos memory management classes unique across all
other class libraries is that they form a complete coordinated system
of types to replace all raw C++ pointers in high-level code.  This is
only possible because these classes are developed as a system and the
level of debug-mode runtime checking that exists is only possible
because these types have access to each others private implementation
(in some appropriate way).  In general, One can not mix and match
Boost, standard C++, and Teuchos classes together at the top level and
get a safe C++ program with the full extend of debug-mode runtime
checking that the integrated set of Teuchos classes provide.  Many
examples of this have been given through this document.  For example,
if you create a {}\ttt{ArrayView} object from a {}\ttt{std::vector}
object it can not detect a dangling reference (see Section
{}\ref{sec:detection-dangling-references}).  However, there are some
specialized cases where Boost and standard C++ types can be used
safely with the Teuchos memory management classes and some of these
cases have already been discussed above.


%
{}\subsection{Advice on refactoring existing software}
%

ToDo: Fill in!


%
{}\section{Miscellaneous topics}
%

When thinking about memory management in C++ it is helpful to take a
step back and consider a few different higher-level issues.  In the
following section, I discuss the philosophy of memory management and
use some analogies to help put things in perspective and provide a
solid foundation for the approach used in the Teuchos memory
management classes.  Then, the issue essential and accedential
complexity is discussed and what role the Teuchos memory management
classes play in addressing accidental complexity.


%
{}\subsection{Philosophy of memory management: Safety, speed,
generality and 100\% guarantees}
\label{sec:phylosophy-of-mem-mng}
%

When looking at different strategies for memory management in C++ and
in other languages, I believe it helps to think a little on the
philosophical level which can actually help ground us.

When looking at the different memory management approaches implemented
in various programming languages, the core issues come down to trade-offs
in safety and correctness versus speed and generality.  For example, a
language like C sacrifices safety and correctness for speed and
generality.  Because C is so ``close'' to the hardware, you can
implement very specialized memory management approaches tailored to
very specific types of domains.  However, the price one pays for this
raw speed and flexibility in C is the fact that there is very little
compiler-supported checking needed to assert correct memory usage.

Now take Python on the other extreme.  If you write code only in
Python, you will almost never experience and memory leak or segfault
of any kind due to code that you directly write.  Here we have a
language which is nearly 100\% safe (assuming the language
implementation is 100\% correct) but offers less flexibility in how
memory is managed and results in very slow native code as compared to
C in many cases (e.g.\ for computationally intensive loops).

So how important is a 100\% guarantee that memory will always be used
correctly like is provided in a language like Python?  How important
is a 100\% guarantee in any area?  Well, if you can get a 100\%
guarantee without having to pay a significant price for it then you
would be a fool not to accept it.  For example, if you have a choice
between two vendors selling the same product for the same price but
one vendor will give you a 100\% money-back guarantee, with all things
being equal, it would probably be foolish not to go with the vendor
with the 100\% guarantee.

However, in most areas, greater safety (not to mention a 100\%
guarantee) comes with greater costs.  Instead of demanding a 100\%
guarantee, we typically accept some level of extra risk as long as we
have taken basic precautions to protect ourselves.  To demonstrate
this, let's consider another analogy which I like to refer to as the
{}\textit{Transportation Analogy}.  When considering modes of
transportation, we accept that we are not 100\% safe when driving our
cars on the road but we do it anyway.  The reason that we get into our
cars every day is that we take reasonable precautions like purchasing
a car with a good safely design, wearing seat-belts, obeying the
traffic laws, driving a reasonable speed, and practicing defensive
driving.  What I am going to argue is that the approach to memory
management that I am advocating in this paper is the equivalent of
driving a car, wearing your seat belt, and taking other reasonable
safety precautions.

Now let's talk about the safety versus speed/efficiently extremes in
the Transportation Analogy and in the areas of memory management.  At
one extreme, writing all high-level code in C++ (or C) using raw
pointers for everything is like riding a high-performance motorcycle
on a crowded interstate going 150 mph, without wearing a helmet or
any other safety gear, while doing a wheelie.  At this extreme, one
wrong move and you are dead.

At the other extreme, writing all code in a language like Python is
like driving around in a reinforced tank that does a maximum of 10
mph where you sit inside wearing a car racing helmet with the Hans
device, full racing safety gear, and have a massive air bag system to
encase your entire body in foam three feet thick in case of a
collision.  On this side of extreme safely, we could hit a Mac truck
head on and be just fine.  The only way to really kill ourselves is if
we were to dive off of a shear cliff.

If we all required a near 100\% safely guarantee, we would all be
driving around in reinforced tanks like the one described above but we
don't.  We don't because we are not willing to pay the price of the
near 100\% guarantee provided by the tank.  We can't afford it
financially and it would take forever to get back and forth to
work. Instead, we are content with our less than 100\% safe cars
because they are affordable and fast and do not pose unreasonable
risks.

Now, we can incrementally go from either extreme to the more balanced
position in both the Transportation Analogy and with memory management
in C++ and Python.

From the extreme of safety with less speed and flexibility represented
by the reinforced tank (and Python) you can incrementally move toward
the middle ground of the car. You can start by removing the racing
helmet and Hans device, followed by decreasing the weight and
increasing the speed of the tank, and so on.  Continuing on this trend
of sacrificing safety in favor of greater speed and agility leads us
to our typical car.  Likewise, moving from an extreme of safety to a
more reasonable balance between safety and speed/flexibility in Python
involves taking pieces of computationally intensive Python code,
rewriting them in C/C++, and then calling them from Python.  This is
an approach that many Python enthusiasts are advocating
{}\cite{PythonForSCPerforamnce08} but make no mistake that in going
down this road that you are sacrificing safety in Python in the name
of speed and flexibility.  You are giving up Python's nearly 100\%
guarantee when you do this.

From the extreme of speed and flexibility with little regard for
safety represented by the motorcycle (and C/C++ raw pointers) you can
also incrementally move toward the car.  You can start by putting on a
helmet, followed by slowing down some, and so on.  Continuing on this
trend of adding safety will eventually see you morphing the motorcycle
into the typical car.  Likewise, moving from an extreme of less safety
toward a more reasonable balance between speed/flexibility and safety
in C++ involves adding more and more utility classes to hide more and
more uses of raw C++ pointers in our high-level C++ code.  This is the
trend that the C++ community has been following for more than the last
decade.  We see it first in the introduction of
{}\ttt{std::auto\_ptr} and {}\ttt{std::vector}.  This was then
followed by the development of {}\ttt{boost::shared\_ptr} (and
therefore {}\ttt{std::shared\_ptr} in C++0x) and
{}\ttt{boost::array\_ptr}.  What I am suggesting in this paper is
the logical conclusion of this journey which is the development of a
complete set of utility classes in order to remove all raw C++
pointers from our high-level C++ code; i.e.\ complete the transition
from the motorcycle (C/C++ raw pointers) to the car (Teuchos C++
memory management classes).

With the approach being advocated in this paper for the Teuchos Memory
Management classes, using the debug mode is like driving around in the
tank where you are protected from almost any danger.  However, using
the optimized mode is like driving around with the high-performance
motorcycle.  Try that with a car!


%
{}\subsection{Essential and accidental complexity}
\label{sec:essentail-accidental-complexity}
%

While the idioms described in this document (outlined in Section
{}\ref{sec:idioms}) may look complex, one has to consider that it is
not really the idioms that are complex but the essential attributes of
object relationships that are complex.  Frederick Brooks refers to
this as {}\textit{essential complexity} as opposed to
{}\textit{accidental complexity} {}\cite{MythicalManMonth95}.
{}\textit{Accidental complexity} in programming refers to complexity
resulting from the details of the programming language or environment
which are not directly related to solving the problem at hand.
Accidental complexity has largely been removed as higher level
languages have been developed {}\cite[Chapter 16]{MythicalManMonth95}.
However, raw pointers in C and C++ and manual resource management
(when that is not the main focus of the program) are definitely a
lingering category of accidental complexity\footnote{
{}\ttt{http://discuss.joelonsoftware.com/default.asp?joel.3.278613.51}}.
Alternatively, {}\textit{essential complexity} exists because of the
nature of the problem at hand and no programming language will remove
it (but we can use object-oriented and other design approaches to
partition and abstract this essential complexity such that we can
write and maintain large-scale programs).

What the Teuchos Memory Management classes do is that they remove much
of the accidental complexity of using raw pointers and manual resource
management and instead they more directly address the essential
complexity of writing programs in making important concepts explicit
that are implicit in most languages (including raw C++).  Dealing with
the nature of relationships between objects is essential complexity
and for every relationship between two classes (for example in a UML
class diagram {}\cite{UMLDistilledThirdEdition04}) one must answer the
essential questions:

\begin{itemize}

{}\item\textit{What is the multiplicity of the relationship?}  (i.e.\
is there just one object or are there more than one object at the
other end of the association?).  In UML class diagrams, a singular
multiplicity relationship is represented using a {}\ttt{1} and
multiplicity greater than one is represented using {}\ttt{1..*}
(See Figure {}\ref{fig:TeuchosRCPDesign} for examples).

{}\item\textit{Is the object optional or required?}  In a UML class
diagram, an optional object is represented using {}\ttt{0..1} while
a required object is represented as {}\ttt{1} (see Figure
{}\ref{fig:TeuchosRCPDesign} for examples).

{}\item\textit{Is the object changeable or non-changeable?}  In UML
class diagrams, a non-changeable object is given the attribute
{}\ttt{\{readOnly\}}.  In UML, by default, all objects at the end
of an association are assumed changeable.

{}\item\textit{Is the association persisting or non-persisting?}  In a
UML class diagram, non-persisting associations are referred to as
``dependency associations'' and can be given the keyword
{}\ttt{$\ll$parameter$\gg$} and are represented with a dotted line.
Persisting associations are referred to as ``relationships'' and are
represented as solid lines (see Figure {}\ref{fig:TeuchosRCPDesign}
for examples)?

\end{itemize}

Note that while UML is an expressive language that allows you to
explicitly represent the above essential information, most programming
languages cannot (at least not the raw language).  Consider that in
Java and Python that it is impossible to distinguish between
persisting and non-persisting associations because every user-defined
object is always managed through an indirect reference handed by the
garbage-collected language.  This causes big problems when it comes
time to try to understand a complex program written in these
languages.  For example, consider the agony that Feathers goes through
in many refactorings described in
{}\cite{WorkingEffectivelyWithLegacyCode05} in trying to determine the
nature of objects as to whether they are actually embedded in each
other (persisting) or are just passed to each other (non-persisting).
Python has no user-definable concept of {}\ttt{const} but the
Python language itself understands the need for {}\ttt{const} by
having built-in immutable data-types like strings and tuples.

One of the goals of the idioms defined in this paper is to change the
above essential complexities from implicit concepts to explicit
concepts directly stated in code (see ``Making Implicit Concepts
Explicit'' in {}\cite[Chapter 9]{DomainDrivenDesign}).  The essential
attributes of object relationships (i.e.\ multiplicity, persistent
vs.\ non-persistent, changeable vs.\ non-changeable) are present in
every program no mater what high-level programming language is used
{}\cite{MythicalManMonth95, CodeComplete2nd04,
WorkingEffectivelyWithLegacyCode05}.  The issue is that most
executable languages (not withstanding executable XML {}\cite[Chapter
1]{UMLDistilledThirdEdition04}) lack the expressiveness to make these
concepts explicit.  The Teuchos memory management classes and the
associated idioms described in this paper provide a means to make many
of these essential concepts explicit in C++ in a way that is not
possible in any other widely used high-level programming language,
period.  

While the Teuchos memory management classes go a long way in
removing some of the accidental complexity of programing in C++ due to
manual memory management, some of the (of the many others) types of
remaining accidental complexity include:

\begin{itemize}

{}\item\textit{Value semantics verses\ reference semantics}: The
distinction between value semantics verses reference semantics in a
C++ concept that does not directly relate to solving a problem or
representing a model in code and is therefore accidental complexity.
In Java and Python, all user-defined types use reference semantics but
in C++ we can take advantage of objects with value semantics which
gives us more efficient code and more control in C++ than what is
possible in Java or Python.  However, this extra control could be
classified as Accidental complexity (which we tolerate for the sake
of added control and improved performance).

{}\item\textit{Pointer syntax for memory management types
{}\ttt{Ptr}, and {}\ttt{RCP}}: In order to access the underlying
object through the types {}\ttt{Ptr}, and {}\ttt{RCP}, you have
to use pointer syntax using {}\ttt{*a} and
{}\ttt{a->someMember()}.  The C++ language makes it impossible to
allow direct access to the underlying type like raw C++ references
allow.  Pointer syntax is not essential to the nature of problem
solving (as proven by all the languages that don't have pointers
including Java and Python) and must therefore be categorized as
accidental complexity.  Note, however, that the types
{}\ttt{ArrayView} and {}\ttt{ArrayRCP} were not listed in this
category because you can use these array classes using just the
{}\ttt{operator[](size\_type)} function and do not need to use any
pointer syntax.  In fact, {}\ttt{ArrayView} does not even support
any pointer-like functions and the pointer-like functions on
{}\ttt{ArrayRCP} are only really there to allow it to be used as a
general purpose checked iterator in a debug build.  While pointer
syntax is not an essential concept they do actually come in handy to
define iterators into containers and present a much more compact
iterator interface that what you will find in other languages.
Pointers syntax are not all bad.

\end{itemize}

%
{}\section{Conclusions}
\label{sec:conclusions}
%

Using reference-counting in Teuchos Memory Management classes allows
you to remove unnecessary constraints in the use of objects in
removing arbitrary lifetime ordering constraints which are a type of
unnecessary coupling {}\cite{CodeComplete2nd04}.  The code you write
with these classes will be more likely to be correct on first writing,
will be less likely to contain silent (but deadly) memory usage
errors, and will be much more robust to later refactoring and
maintenance.

The level of debug-mode runtime checking provided by the Teuchos
memory management classes is stronger in many respects than what is
provided by memory checking tools like valgrind and purify while being
much less expensive.  However, tools like valgrind and purify perform
a number of types of checks (like usage of uninitialized memory) that
makes these tools very valuable and therefore complement the Teuchos
memory management debug-mode runtime checking.

The Teuchos memory management classes and idioms largely address the
technical issues in resolving the fragile built-in C++ memory
management model (with the exception of circular references which has
no easy solution but can be managed as discussed).  All that remains
is to teach these classes and idioms and expand their usage in C++
codes.  The long-term viability of C++ as a usable and productive
language depends on it.  Otherwise, if C++ is no safer than C, then is
the greater complexity of C++ worth what you get as extra features?  C
is smaller and easier to learn and since most programmers don't know
object-orientation all that well anyway then what are they really
getting out of C++ other than more complexity?  C++ zealots will argue
this point but the reality is that C++ is becoming less popular while
the popularity of C has remained fairly stable over the last decade.
I believe that idioms like are advocated here can help to avert this
trend but it will require wide community buy-in and a change in the
way we teach C++.

To make our programs more secure, compiler vendors or static analysis
tools (e.g.\ klocwork) could implement a preprocessor-like language
similar to OpenMP\footnote{{}\ttt{http://openmp.org}} that would allow
the programmer to declare (in comments) that certain blocks of code
should be ``pointer-free'' or allow smaller blocks to be ``pointers
allowed''.  This would significantly improve the robustness of code
that uses the memeory management classes described here.



% ---------------------------------------------------------------------- %
% References
%

\clearpage
% If hyperref is included, then \phantomsection is already defined.
% If not, we need to define it.
\providecommand*{\phantomsection}{}
\phantomsection
\addcontentsline{toc}{section}{References}
\bibliographystyle{plain}
\bibliography{references}

% ---------------------------------------------------------------------- %
% Appendices should be stand-alone for SAND reports. If there is only
% one appendix, put \setcounter{secnumdepth}{0} after \appendix
%
\appendix


%
{}\section{Summary of the Teuchos memory management classes and
idioms}
\label{apdx:summary_of_idioms}
%

\begin{center}

\input{BasicTeuchosSmartPointerClasses}

\input{ArrayContainersTable}

\input{RawPointerSmartPointerEquivalencies}

\input{OperationsSummaryTable}

\input{BasicSupportedImplicitExplictConversions}

\input{ValueTypeDataMembersTable}

\input{ReferenceTypeDataMembersTable}

\pagebreak

\input{PassingValueObjectsTable}

\pagebreak

\input{PassingReferenceObjectsTable}

\pagebreak

\input{ReturningValueObjectsTable}

\input{ReturningReferenceObjectsTable}

\pagebreak

{}\textbf{Conversions of data-types for single objects}
\includegraphics*[angle=270,scale=0.65]{TeuchosPtrConversions} \\[5ex]

{}\textbf{Conversions of data-types for contiguous arrays}
\includegraphics*[angle=270,scale=0.65]{TeuchosArrayConversions}

\pagebreak

\input{ConversionsTableSingleObjs}

\pagebreak

\input{ConversionsTableArrays}

\end{center}


%
{}\section{Commandments for the use of the Teuchos memory management
classes}
\label{apdx:commandments}
%

Here are stated commandments (i.e.\ very strongly recommended
guidelines) that if followed, along with the idioms defined in
Section {}\ref{sec:idioms}, then client code will be 100\% safe
through debug-mode runtime checking and will never result in a
segfault or other memory usage error (except for circular references
as described in Section {}\ref{sec:detection-circular-references}).
While there will be situations where it is justified to violate almost
all of these commandments, they should be valid in 99\% of a well
written code base.

\begin{commandment}
Thou shall not expose raw pointers in any high-level C++ code.
\end{commandment}

{}\textit{Exception:} Only expose raw pointers when interfacing with
non-compliant code or momentarily in order to construct a Teuchos
memory management class object.  However, these cases should be
encapsulated as low-level code.

\begin{commandment}
Thou shall only use raw C++ references for non-persisting associations
(see Section {}\ref{sec:persisting-nonpersisting-associations}).
\end{commandment}

\begin{commandment}
Thou shall use {}\ttt{RCP} for handling single objects for all
persisting associations (see Section
{}\ref{sec:persisting-nonpersisting-associations}).
\end{commandment}

\begin{commandment}\label{cmnd:rcp-new}
Thou shall put a pointer for an object allocated with operator
{}\texttt{new} into a strong owning {}\texttt{RCP} whenever possible
by directly calling {}\ttt{new} right in the constructor for the
{}\ttt{RCP} object itself or construct from {}\ttt{rcp(...)}.
\end{commandment}

\begin{commandment}\label{cmnd:owning-rcp-first}
When wrapping an object inside of an {}\ttt{RCP}, thou shall create
a strong owning {}\ttt{RCP} object first before any non-owning
{}\ttt{RCP} objects.
\end{commandment}
{}\textit{Justification:} In order for the reference-counting
machinery to detect dangling non-owning references in a debug-mode
build, the first {}\ttt{RCP} object created must have ownership to
delete.  The system can not detect dangling references from non-owning
{}\ttt{RCPNode} objects created before the owning
{}\ttt{RCPNode} object is created.

\begin{commandment}\label{cmnd:ptr-semi-persisting}
Thou shall use {}\ttt{Ptr} for handling single objects for all
semi-persisting associations (see Section
{}\ref{sec:persisting-nonpersisting-associations}).
\end{commandment}
{}\textit{Justification:} When performance constraints do not allow
the reference-counting overhead of {}\ttt{RCP}, then {}\ttt{Ptr}
can be used instead to form a semi-persisting association which should
be accompanied with the appropriate documentation about the
performance optimization.  You should never have to retreat back to
using a raw pointer in these cases.  At least with {}\ttt{Ptr},
invalid usage will be checked for in a debug build so you don't loose
any debug-mode runtime checking when using {}\ttt{Ptr} instead of
{}\ttt{RCP} if you really don't need reference-counting machinery.

\begin{commandment}
Thou shall use {}\ttt{ArrayRCP} for handling contiguous arrays of
objects for all persisting associations (see Section
{}\ref{sec:persisting-nonpersisting-associations}).
\end{commandment}

\begin{commandment}\label{cmnd:arrayview-semi-persisting}
Thou shall use {}\ttt{ArrayView} for handling contiguous arrays of
objects for all semi-persisting associations (see Section
{}\ref{sec:persisting-nonpersisting-associations}).
\end{commandment}
{}\textit{Justification:} When performance constraints do not allow
the reference-counting overhead of {}\ttt{ArrayRCP}, then
{}\ttt{ArrayView} can be used instead to form a semi-persisting
association which should be accompanied with the appropriate
documentation about the performance optimization.  You should never
have to retreat back to using a raw pointer in these cases.  At least
with {}\ttt{ArrayView}, invalid usage will be checked for in a
debug build so you don't loose any debug-mode runtime checking when
using {}\ttt{ArrayView} instead of {}\ttt{ArrayRCP} if you
really don't need reference-counting machinery.

\begin{commandment}
Thou shall not call raw {}\ttt{new} or {}\ttt{delete} in any
high-level C++ code to dynamically allocate and destroy single
objects.  Instead, create memory using a user-defined non-member
constructor function (see Section
{}\ref{sec:nonmember-constructor-idiom}).
\end{commandment}

\begin{commandment}
Thou shall not call raw operator {}\ttt{new []} or {}\ttt{delete
[]} in any high-level C++ code to dynamically allocate and destroy
contiguous arrays of data.  Instead, use functions such as
{}\ttt{Teuchos::Array<T>(n)} and {}\ttt{Teuchos::arcp<T>(n)}.
\end{commandment}

\begin{commandment}
Thou shall not directly create and use compile-time fixed sized arrays
with {}\ttt{T[N]}.  Instead, create compile-time fixed-sized arrays
using {}\ttt{Teuchos::Tuple<T,N>} and convert to
{}\ttt{Teuchos::ArrayView<T>} for more general usage.
\end{commandment}

\begin{commandment}
Thou shall use {}\ttt{Teuchos::Array} as a general purpose
contiguous container instead of {}\ttt{std::vector} (see Section
{}\ref{sec:Array}).
\end{commandment}

\begin{commandment}
Thou shall only convert between different memory management objects
using the provided implicit and explicit conversion functions.  Thou
shall never expose a raw C++ pointer to perform a conversion.
\end{commandment}
{}\textit{Exception}: Some very advanced and rare use cases might have
you exposing a raw C++ pointer (see Section
{}\ref{sec:inverting-obj-ownership} for the only example described in
this paper).

\begin{commandment}
Thou shall only pass in the types {}\ttt{Teuchos::Ptr},
{}\ttt{Teuchos::RCP}, {}\ttt{Teuchos::ArrayView}, and
{}\ttt{Teuchos::ArrayRCP} by constant reference (e.g.\
{}\ttt{const RCP<T> \&a}) and never by non-const reference (e.g.\
never do {}\ttt{RCP<T> \&a}).
\end{commandment}
{}\textit{Exception}: The only time you should ever pass in a
non-const reference to one of these types (e.g.\ {}\ttt{RCP<T>
\&a}) is when the function will modify what data the object points to.
However, if this is the case, it is typically better and more clear to
pass in the object through a {}\ttt{Teuchos::Ptr} object (e.g.\
{}\ttt{const Ptr<RCP<T> > \&a}) using the {}\ttt{outArg(...)} function
(see Section {}\ref{sec:vars-passing-single-objs}).

\begin{commandment}\label{cmnd:conversions}
Thou shall only cast between the different Teuchos memory management
types using the provided implicit and explicit conversion functions
(see Section {}\ref{sec:conversions}).  Thou shall never cast between
types by exposing raw C++ pointers.
\end{commandment}


%
{}\section{Argument for using an signed integer for
{}\ttt{size\_type} in the Teuchos array classes}
\label{sec:unsigned_size_type}
%

The Teuchos array memory management classes {}\ttt{Array},
{}\ttt{ArrayRCP}, and {}\ttt{ArrayView} all use an unsigned integer
for {}\ttt{size\_type} ({}\ttt{ptrdiff\_t} by default).  This breaks
from the C++ standard library convention of the standard containers
like {}\ttt{std::vector} that all use an unsigned integer for
{}\ttt{std::vector::size\_type} (which is {}\ttt{size\_t} on most
machines).  The primary disadvantage for using an unsigned integral
type is that subtractions that would normally produce a negative number
instead rolls over into a huge positive number, making it more
difficult to debug problems.  For example, consider the simple program
shown in Listing {}\ref{listing:unsigned-int-problem}:


{}\begin{listing}: Example program showing the problem with unsigned
integral types
\label{listing:unsigned-int-problem}
{\small\begin{verbatim}
  #include <iostream>
  #include <string>
  
  typedef unsigned long int size_type ;
  
  void print_val(const std::string &valName, const size_type val)
  { std::cout << valName << " = " << val << "\n";}
  
  int main()
  {
    const size_type a = 5, b = 7;
    const size_type c = b - a;
    const size_type d = a - b;
    print_val("a", a);
    print_val("b", b);
    print_val("b - a", c);
    print_val("a - b", d);
    return 0;
  }
\end{verbatim}}
\end{listing}


When the above program is compiled with GCC 3.4.6 on a 64 bit Linux
machine and run it produces the output:


{\small\begin{verbatim}
  a = 5
  b = 7
  b - a = 2
  a - b = 18446744073709551614
\end{verbatim}}


In the above program, the subtraction of {}\ttt{a - b} is a programming
error but that error results in the number
{}\ttt{18446744073709551614} when using an unsigned type.  Getting a
number like {}\ttt{18446744073709551614} in program output or in the
debugger does not exactly give you a great hint as to what the problem
might be.  Was uninitialized memory used to produce this result?  Is
there some other memory usage problem that would cause the program to
produce a ridiculous result such as this?  It is problems like this
that greatly contribute to the accidental complexity that is C/C++
programing (see Section {}\ref{sec:essentail-accidental-complexity}).

However, when you replace {}\ttt{unsigned long int} with {}\ttt{long
int} in Listing {}\ref{listing:unsigned-int-problem} and rebuild and
run you get:


{\small\begin{verbatim}
  a = 5
  b = 7
  b - a = 2
  a - b = -2
\end{verbatim}}


Now, getting output like {}\ttt{-2} when a positive number is expected
is much easier to debug.  The chance of getting {}\ttt{-2} as the
result of a memory usage error is very unlikely.  This would
immediately be flagged as a subtraction error in the program and
quickly traced down.  Therefore, from a program correctness and
debugging perspective, signed integral types are far superior to
unsigned types and signed types maintain basic mathematical properties
of integral numbers.

So if programs with unsigned integers are harder to debug when things
go wrong, then what are the advantages of using an unsigned type?
Well, some might argue that using an unsigned type for integral
objects that that can only be non-negative in valid programs helps to
make the code self documenting.  This is partially true but you can
achieve the same result by using a typedef to make the usage clear
(e.g.\ {}\ttt{size\_type}).

So then what then is left as the real advantage for using an unsigned
integral type?  The only real advantage of an unsigned integral type
(e.g.\ {}\ttt{unsigned int}) over a signed integral type (e.g.\
{}\ttt{int}) is that object of the unsigned integral type can
represent twice the positive range.  For smaller integral types like
{}\ttt{char} and and {}\ttt{short int} having twice the range can be
quite useful.  However, on 32 bit and 64 bit modern computers, using a
an {}\ttt{unsigned int} instead of an {}\ttt{int} as the size for a
container is quite worthless.  On a 64 bit Linux machine with GCC
3.4.6, the sizes of several integral types pertinent to this
discussion are shown in Listing {}\ref{listing:integral-type-sizes}.


{}\begin{listing}: Sizes and ranges of some common integral types of
GCC on a 64 bit Linux machine
\label{listing:integral-type-sizes}
{\small\begin{verbatim}
  sizeof(int) = 4
  std::numeric_limits<int>::min()= -2147483648
  std::numeric_limits<int>::max()= 2147483647
  std::log10(std::numeric_limits<int>::max())= 9.33193
  
  sizeof(unsigned int) = 4
  std::numeric_limits<unsigned int>::min()= 0
  std::numeric_limits<unsigned int>::max()= 4294967295
  std::log10(std::numeric_limits<unsigned int>::max())= 9.63296
  
  sizeof(long long int) = 8
  std::numeric_limits<long long int>::min()= -9223372036854775808
  std::numeric_limits<long long int>::max()= 9223372036854775807
  std::log10(std::numeric_limits<long long int>::max())= 18.9649
  
  sizeof(unsigned long long int) = 8
  std::numeric_limits<unsigned long long int>::min()= 0
  std::numeric_limits<unsigned long long int>::max()= 18446744073709551615
  std::log10(std::numeric_limits<unsigned long long int>::max())= 19.2659
  
  sizeof(size_t) = 8
  std::numeric_limits<size_t>::min()= 0
  std::numeric_limits<size_t>::max()= 18446744073709551615
  std::log10(std::numeric_limits<size_t>::max())= 19.2659
  
  sizeof(ptrdiff_t) = 8
  std::numeric_limits<ptrdiff_t>::min()= -9223372036854775808
  std::numeric_limits<ptrdiff_t>::max()= 9223372036854775807
  std::log10(std::numeric_limits<ptrdiff_t>::max())= 18.9649
\end{verbatim}}
\end{listing}


On a 32 bit machine, {}\ttt{size\_t} is a 4 bit {}\ttt{unsigned int}
and {}\ttt{ptrdiff\_t} is a 4 bit {}\ttt{int}.  The standard C library
typedef {}\ttt{size\_t} is guaranteed to be the largest possible
object size returned from {}\ttt{sizeof(...)} and is also used for
functions like {}\ttt{malloc(...)}.  The standard C library typedef
{}\ttt{ptrdiff\_t} is supposed to be guaranteed to hold the difference
between the subtraction of any two pointers in the largest allocatable
array.  Right here lies the first problem with this approach as shown
in the simple program in Listing
{}\ref{listing:size_t-ptrdiff_t-incompatibility}.


{}\begin{listing}: Simple program showing the fundamental
incompatibility of {}\ttt{size\_t} and {}\ttt{ptrdiff\_t}.
\label{listing:size_t-ptrdiff_t-incompatibility}
{\small\begin{verbatim}
  #include <iostream> 
  #include <string> 
  #include <limits> 
   
  template<typename T> 
  void print_val(const std::string &valName, const T val) 
  { std::cout << valName << " = " << val << "\n";} 
   
  int main() 
  { 
    const size_t maxSize = std::numeric_limits<size_t>::max(); 
    const size_t size = static_cast<size_t>(0.75 * maxSize); 
    char *a = new char[size]; 
    ptrdiff_t a_diff = (a+size) - a; 
    print_val("maxSize", maxSize); 
    print_val("size", size); 
    print_val("a+size - a", a_diff); 
    delete a;
    return 0; 
  }
\end{verbatim}}
\end{listing}


The program in Listing
{}\ref{listing:size_t-ptrdiff_t-incompatibility} allocates a
{}\ttt{char} array 75\% the size of the maximum.  In this program,
{}\ttt{size} is 50\% larger than the largest value that can be
represented by the signed type {}\ttt{ptrdiff\_t} (which is the same
thing as {}\ttt{int}).  When this program is compiled with GCC 3.4.6
in 32 bit mode (i.e.\ with {}\ttt{-m32}) and run it produces the
following output:

{\small\begin{verbatim}
  maxSize = 4294967295
  size = 3221225471
  a+size - a = -1073741825
\end{verbatim}}

What the above 32 bit output confirms is that it false to claim that
{}\ttt{ptrdiff\_t} can store the difference between any two pointers
in a single array of data.  Perhaps that was true on the machines when
C was first developed the early 1970's but it is not true today where
machines with 4+ GB of memory are common.

Now consider practical usage of types like {}\ttt{std::vector} modern
machines.  First, consider what it would mean to allocate the largest
{}\ttt{std::vector} of even {}\ttt{char}s.  A {}\ttt{char} is 1 byte
so on a 32 bit machine, an {}\ttt{std::vector<char>} of max size would
have {}\ttt{4294967295 / 1e+9} = 4.3 GB of memory.  That would exhaust
all of the memory of a 4 GB machine and more.  Being limited to only
half the range of {}\ttt{size\_t} (which is the same thing as
{}\ttt{ptrdiff\_t}) would give an {}\ttt{std::vector<char>} that takes
up 2.3 GB of memory.  No real 32 bit program is ever going to allocate
a single {}\ttt{std::vector} of {}\ttt{char}s takes up more than half
of the addressable memory!  It is hard to imagine what useful task
such a program would perform.

When you move up to an {}\ttt{std::vector<int>} for a 32 bit (4 byte)
{}\ttt{int} the maximum size of array that you can create is
{}\ttt{4294967295 * 4 / 1e+9} = 17.2 GB.  Being limited to the
{}\ttt{unsigned int} {}\ttt{ptrdiff\_t} would limit you to an
{}\ttt{std::vector<int>} of size 8.6 GB which is already twice the
addressable memory of a 32 bit system.

Therefore, even on a 32 bit machine, limiting the maximum size of
{}\ttt{std::vector} objects to have only
{}\ttt{std::numeric\_limits<ptrdiff\_t)>::max()} elements is really
not any kind of real limit at all.  For any reasonable program on any
reasonable machine you cannot even store that much memory.

On a 64 bit machine this of course becomes silly.  By limited the
maximum number of elements in an {}\ttt{std::vector<char>} to be
{}\ttt{std::numeric\_limits<ptrdiff\_t)>::max()} on 64 bit machine
would mean that you would take up {}\ttt{(18446744073709551615 / 2 /
1e+9)} = {}\ttt{9.2e+9} GB of memory!

In summary, limiting the maximum number of elements in an
{}\ttt{std::vector} (and therefore {}\ttt{Teuchos::Array}) to be half
of {}\ttt{size\_t} with a {}\ttt{signed int} {}\ttt{ptrdiff\_t} is
not any kind of limit at all in any realistic 32 bit program and
especially not a 64 bit program.

Therefore, the Teuchos array memory management classes all use by
default {}\ttt{ptrdiff\_t} as {}\ttt{size\_type} because of the
inherent advantages of using a signed integral type instead of an
unsigned type and with no real advantages at all for using
{}\ttt{size\_t} over {}\ttt{ptrdiff\_t}.


%
{}\section{Raw performance data}
\label{apdx:raw-perf-data}
%

%
{}\subsection{Raw RCP performance data}
\label{apdx:raw-rcp-perf-data}
%

\begin{listing}: Raw {}\ttt{RCP} timing data on GCC 4.1.2  \\
\label{listing:RCP-GCC-Timings}
{\scriptsize\begin{verbatim}
0. RCP_createDestroyOverhead_UnitTest ... 
 
 Messuring the overhead of creating and destorying objects of different sizes
 using raw C++ pointers, shared_ptr, and using RCP.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.001 = 5e+06
 
   obj size   num loops  raw             shared_ptr      RCP             shared_ptr/raw  RCP/raw       
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
           1    3465735    7.407462e-08    1.215497e-07    1.398462e-07    1.640909e+00    1.887910e+00
           4    2011797    7.450006e-08    1.239370e-07    1.413890e-07    1.663582e+00    1.897838e+00
          16     885379    8.031363e-08    1.284388e-07    1.467530e-07    1.599215e+00    1.827249e+00
          64     326124    1.130889e-07    1.589150e-07    1.792815e-07    1.405222e+00    1.585315e+00
         256     108380    2.369718e-07    2.786677e-07    2.359753e-07    1.175953e+00    9.957949e-01
        1024      33849    5.029395e-07    5.578008e-07    5.812875e-07    1.109081e+00    1.155780e+00
        4096      10153    1.552546e-06    1.608293e-06    1.630947e-06    1.035907e+00    1.050498e+00
       16384       2961    5.759541e-06    5.821344e-06    5.840932e-06    1.010731e+00    1.014132e+00
       65536        846    2.503073e-05    2.513239e-05    2.515721e-05    1.004061e+00    1.005053e+00

1. RCP_dereferenceOverhead_UnitTest ... 
 
 Messuring the overhead of dereferencing RCP, shared_ptr and a raw pointer.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64    3261240    7.765547e-10    1.037752e-09    6.958626e-10    8.960896e-01    6.705479e-01
         256    1083803    7.295887e-10    8.572714e-10    7.611003e-10    1.043191e+00    8.878173e-01
        1024     338498    7.117812e-10    8.238572e-10    7.125746e-10    1.001115e+00    8.649249e-01
        4096     101538    7.187575e-10    1.155846e-09    1.192136e-09    1.658607e+00    1.031397e+00
       16384      29614    8.350258e-10    1.155404e-09    1.190919e-09    1.426207e+00    1.030739e+00
       65536       8461    8.362559e-10    1.155293e-09    1.199785e-09    1.434711e+00    1.038512e+00

2. RCP_memberAccessOverhead_UnitTest ... 
 
 Messuring the overhead of dereferencing RCP, shared_ptr and a raw pointer.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64    3261240    7.794917e-10    1.037733e-09    6.954218e-10    8.921479e-01    6.701355e-01
         256    1083803    7.295743e-10    8.639896e-10    7.611075e-10    1.043221e+00    8.809221e-01
        1024     338498    7.115158e-10    8.325987e-10    7.242242e-10    1.017861e+00    8.698358e-01
        4096     101538    7.252928e-10    1.156058e-09    1.192244e-09    1.643811e+00    1.031302e+00
       16384      29614    8.369755e-10    1.154404e-09    1.190985e-09    1.422963e+00    1.031688e+00
       65536       8461    8.364092e-10    1.154440e-09    1.199527e-09    1.434139e+00    1.039056e+00

3. RCP_referenceCountManipulationOverhead_UnitTest ... 
 
 Messuring the overhead of incrementing and deincrementing the reference count
 comparing RCP to raw pointer and boost::shared_ptr.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64      65224    1.554978e-09    4.145809e-09    6.009579e-09    3.864736e+00    1.449555e+00
         256      21676    7.138151e-10    4.221439e-09    5.832524e-09    8.170916e+00    1.381644e+00
        1024       6769    6.919181e-10    4.224365e-09    5.589158e-09    8.077773e+00    1.323076e+00
        4096       2030    6.863599e-10    4.226880e-09    6.094856e-09    8.879972e+00    1.441928e+00
       16384        592    6.854083e-10    4.224623e-09    6.234040e-09    9.095367e+00    1.475644e+00
       65536        169    6.848397e-10    4.228219e-09    6.216828e-09    9.077785e+00    1.470318e+00
\end{verbatim}}
\end{listing}

\pagebreak

\begin{listing}: Raw {}\ttt{RCP} timing data on Intel ICC 10.1  \\
\label{listing:RCP-ICC-Timings}
{\scriptsize\begin{verbatim}
0. RCP_createDestroyOverhead_UnitTest ... 
 
 Messuring the overhead of creating and destorying objects of different sizes
 using raw C++ pointers, shared_ptr, and using RCP.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.001 = 5e+06
 
   obj size   num loops  raw             shared_ptr      RCP             shared_ptr/raw  RCP/raw       
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
           1    3465735    1.157942e-07    1.941906e-07    2.041379e-07    1.677032e+00    1.762938e+00
           4    2011797    1.194609e-07    1.984465e-07    2.031149e-07    1.661184e+00    1.700263e+00
          16     885379    1.200751e-07    2.013262e-07    2.105720e-07    1.676669e+00    1.753668e+00
          64     326124    1.390085e-07    2.170309e-07    2.277876e-07    1.561279e+00    1.638660e+00
         256     108380    3.299409e-07    4.036446e-07    4.223381e-07    1.223384e+00    1.280041e+00
        1024      33849    6.118349e-07    7.350291e-07    7.567432e-07    1.201352e+00    1.236842e+00
        4096      10153    1.724909e-06    1.833645e-06    1.851472e-06    1.063039e+00    1.073374e+00
       16384       2961    6.138467e-06    6.252955e-06    6.269504e-06    1.018651e+00    1.021347e+00
       65536        846    2.482151e-05    2.497754e-05    2.505437e-05    1.006286e+00    1.009381e+00

1. RCP_dereferenceOverhead_UnitTest ... 
 
 Messuring the overhead of dereferencing RCP, shared_ptr and a raw pointer.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64    3261240    6.909757e-10    3.551453e-09    1.027399e-09    1.486881e+00    2.892897e-01
         256    1083803    7.113406e-10    3.384829e-09    7.973226e-10    1.120873e+00    2.355577e-01
        1024     338498    6.914017e-10    2.841675e-09    7.658747e-10    1.107713e+00    2.695152e-01
        4096     101538    6.864300e-10    3.701316e-09    9.940787e-10    1.448187e+00    2.685744e-01
       16384      29614    7.319499e-10    3.367334e-09    9.934011e-10    1.357198e+00    2.950112e-01
       65536       8461    7.317167e-10    2.931704e-09    9.912099e-10    1.354636e+00    3.381003e-01

2. RCP_memberAccessOverhead_UnitTest ... 
 
 Messuring the overhead of dereferencing RCP, shared_ptr and a raw pointer.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64    3261240    6.899839e-10    6.952541e-10    8.252660e-10    1.196066e+00    1.186999e+00
         256    1083803    7.112650e-10    7.159684e-10    7.949727e-10    1.117688e+00    1.110346e+00
        1024     338498    6.911940e-10    6.924634e-10    7.741691e-10    1.120046e+00    1.117993e+00
        4096     101538    6.863435e-10    7.000054e-10    9.928501e-10    1.446579e+00    1.418346e+00
       16384      29614    7.326919e-10    8.507246e-10    9.953219e-10    1.358445e+00    1.169970e+00
       65536       8461    7.315725e-10    8.489935e-10    9.923713e-10    1.356491e+00    1.168880e+00

3. RCP_referenceCountManipulationOverhead_UnitTest ... 
 
 Messuring the overhead of incrementing and deincrementing the reference count
 comparing RCP to raw pointer and boost::shared_ptr.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64      65224    1.032260e-09    5.619576e-09    8.805472e-09    8.530285e+00    1.566928e+00
         256      21676    7.246278e-10    5.881181e-09    8.692109e-09    1.199527e+01    1.477953e+00
        1024       6769    7.678041e-10    6.050677e-09    8.797574e-09    1.145810e+01    1.453982e+00
        4096       2030    7.621277e-10    5.988180e-09    8.991230e-09    1.179754e+01    1.501496e+00
       16384        592    8.004678e-10    6.102691e-09    8.966497e-09    1.120157e+01    1.469269e+00
       65536        169    7.999578e-10    6.108933e-09    8.973161e-09    1.121704e+01    1.468859e+00
\end{verbatim}}
\end{listing}

\pagebreak

{}\begin{listing}: Raw {}\ttt{RCP} timing data on MSVC++ 2009
\label{listing:RCP-MSVC-Timings}
{\scriptsize\begin{verbatim}
0. RCP_createDestroyOverhead_UnitTest ... 
 
 Messuring the overhead of creating and destorying objects of different sizes
 using raw C++ pointers, shared_ptr, and using RCP.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+003/0.001 = 5e+006
 
   obj size   num loops  raw             shared_ptr      RCP             shared_ptr/raw  RCP/raw       
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
           1    3465735   2.628591e-007   3.641363e-007   4.117453e-007   1.385291e+000   1.566411e+000
           4    2011797   2.390897e-007   3.718069e-007   4.130635e-007   1.555094e+000   1.727651e+000
          16     885379   2.484812e-007   3.885342e-007   4.303242e-007   1.563636e+000   1.731818e+000
          64     326124   2.882339e-007   4.262182e-007   4.660804e-007   1.478723e+000   1.617021e+000
         256     108380   4.336593e-007   5.628345e-007   5.997416e-007   1.297872e+000   1.382979e+000
        1024      33849   9.749180e-007   1.093090e-006   1.122633e-006   1.121212e+000   1.151515e+000
        4096      10153   3.250271e-006   3.250271e-006   3.348764e-006   1.000000e+000   1.030303e+000
       16384       2961   1.182033e-005   1.350895e-005   1.215805e-005   1.142857e+000   1.028571e+000
       65536        846   4.609929e-005   4.609929e-005   4.609929e-005   1.000000e+000   1.000000e+000

1. RCP_dereferenceOverhead_UnitTest ... 
 
 Messuring the overhead of dereferencing RCP, shared_ptr and a raw pointer.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64    3261240   1.034882e-009   1.034882e-009   6.995039e-010   6.759259e-001   6.759259e-001
         256    1083803   1.052428e-009   1.052428e-009   7.136329e-010   6.780822e-001   6.780822e-001
        1024     338498   1.035711e-009   1.038596e-009   6.952820e-010   6.713092e-001   6.694444e-001
        4096     101538   1.021881e-009   1.043521e-009   1.012263e-009   9.905882e-001   9.700461e-001
       16384      29614   1.088221e-009   1.141807e-009   1.020207e-009   9.375000e-001   8.935018e-001
       65536       8461   1.082056e-009   1.141569e-009   1.011722e-009   9.350000e-001   8.862559e-001

2. RCP_memberAccessOverhead_UnitTest ... 
 
 Messuring the overhead of dereferencing RCP, shared_ptr and a raw pointer.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64    3261240   1.039674e-009   1.044465e-009   1.015718e-009   9.769585e-001   9.724771e-001
         256    1083803   1.045220e-009   1.048824e-009   7.136329e-010   6.827586e-001   6.804124e-001
        1024     338498   1.032826e-009   1.038596e-009   6.923970e-010   6.703911e-001   6.666667e-001
        4096     101538   1.029094e-009   1.053139e-009   1.009859e-009   9.813084e-001   9.589041e-001
       16384      29614   1.077915e-009   1.135624e-009   1.007841e-009   9.349904e-001   8.874773e-001
       65536       8461   1.080252e-009   1.137962e-009   1.018936e-009   9.432387e-001   8.954041e-001

3. RCP_referenceCountManipulationOverhead_UnitTest ... 
 
 Messuring the overhead of incrementing and deincrementing the reference count
 comparing RCP to raw pointer and boost::shared_ptr.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64      65224   7.186772e-010   5.270299e-009   1.413398e-008   1.966667e+001   2.681818e+000
         256      21676   3.604217e-010   4.144849e-009   1.261476e-008   3.500000e+001   3.043478e+000
        1024       6769   1.442698e-010   4.183825e-009   1.269575e-008   8.800000e+001   3.034483e+000
        4096       2030   2.405326e-010   4.089055e-009   1.274823e-008   5.300000e+001   3.117647e+000
       16384        592   3.092998e-010   4.227097e-009   1.278439e-008   4.133333e+001   3.024390e+000
       65536        169   2.708661e-010   4.153280e-009   1.291128e-008   4.766667e+001   3.108696e+000
\end{verbatim}}
\end{listing}

\pagebreak

%
{}\subsection{Raw Array performance data}
\label{apdx:raw-array-perf-data}
%

\begin{listing}: Raw Array timing data on GCC 4.1.2  \\
\label{listing:Array-GCC-Timings}
% From ./results/UnitTimings/GCC4/results2/Teuchos_Array_PeformanceTest.out
{\scriptsize\begin{verbatim}
0. Array_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the Array braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         vector          Array           vector/raw      Array/raw     
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
         100    2307560    4.244007e-10    4.244137e-10    4.244440e-10    1.000031e+00    1.000102e+00
         400     749245    3.631856e-10    3.629053e-10    3.629787e-10    9.992283e-01    9.994304e-01
        1600     230574    3.475457e-10    3.475999e-10    3.476270e-10    1.000156e+00    1.000234e+00
        6400      68470    5.450882e-10    5.452091e-10    5.367154e-10    1.000222e+00    9.846397e-01

1. Array_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the Array iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         vector          Array           vector/raw      Array/raw     
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
         100    2307560    4.620638e-10    4.725251e-10    4.757363e-10    1.022640e+00    1.029590e+00
         400     749245    3.722247e-10    3.979673e-10    3.989416e-10    1.069159e+00    1.071776e+00
        1600     230574    3.498009e-10    3.796775e-10    3.797046e-10    1.085410e+00    1.085488e+00
        6400      68470    5.465578e-10    5.450813e-10    5.454967e-10    9.972986e-01    9.980585e-01

2. ArrayRCP_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560    4.620552e-10    4.449722e-10    9.630283e-01
         400     749245    3.722748e-10    3.680972e-10    9.887783e-01
        1600     230574    3.498687e-10    3.486869e-10    9.966221e-01
        6400      68470    5.456381e-10    6.259333e-10    1.147158e+00

3. ArrayRCP_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560    4.414750e-10    4.451065e-10    1.008226e+00
         400     749245    3.670995e-10    3.679571e-10    1.002336e+00
        1600     230574    3.485405e-10    3.488902e-10    1.001003e+00
        6400      68470    5.448531e-10    5.452068e-10    1.000649e+00

4. ArrayRCP_selfIteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP as a self iterataor relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560    4.587616e-10    8.386087e-10    1.827984e+00
         400     749245    3.713705e-10    7.234583e-10    1.948077e+00
        1600     230574    3.497250e-10    6.945384e-10    1.985956e+00
        6400      68470    5.297461e-10    6.887003e-10    1.300057e+00

5. ArrayView_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayView braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayView       ArrayView/raw 
   ---------  ---------  --------------  --------------  --------------
         100    2307560    4.621072e-10    4.244570e-10    9.185250e-01
         400     749245    3.722814e-10    3.627618e-10    9.744291e-01
        1600     230574    3.499283e-10    3.474156e-10    9.928192e-01
        6400      68470    5.455994e-10    5.369824e-10    9.842065e-01

6. ArrayView_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayView iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayView       ArrayView/raw 
   ---------  ---------  --------------  --------------  --------------
         100    2307560    4.588396e-10    4.552254e-10    9.921232e-01
         400     749245    3.716074e-10    3.705230e-10    9.970818e-01
        1600     230574    3.495732e-10    3.493184e-10    9.992711e-01
        6400      68470    5.299196e-10    5.453255e-10    1.029072e+00
\end{verbatim}}
\end{listing}

\pagebreak

\begin{listing}: Raw Array timing data on ICC 10.1  \\
\label{listing:Array-ICC-Timings}
% From ./results/UnitTimings/ICC/results2/Teuchos_Array_PerformanceTest.out
{\scriptsize\begin{verbatim}
0. Array_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the Array braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         vector          Array           vector/raw      Array/raw     
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
         100    2307560    9.041672e-10    1.092201e-09    1.092210e-09    1.207964e+00    1.207973e+00
         400     749245    8.995689e-10    1.207742e-09    1.121359e-09    1.342579e+00    1.246551e+00
        1600     230574    8.816611e-10    1.154434e-09    1.172907e-09    1.309385e+00    1.330338e+00
        6400      68470    9.466212e-10    1.240822e-09    1.252366e-09    1.310790e+00    1.322986e+00

1. Array_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the Array iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         vector          Array           vector/raw      Array/raw     
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
         100    2307560    6.093189e-10    6.334830e-10    5.921796e-10    1.039657e+00    9.718714e-01
         400     749245    6.862308e-10    6.941621e-10    6.795441e-10    1.011558e+00    9.902559e-01
        1600     230574    6.543805e-10    6.653910e-10    6.629027e-10    1.016826e+00    1.013023e+00
        6400      68470    7.261278e-10    7.312829e-10    7.259452e-10    1.007099e+00    9.997486e-01

2. ArrayRCP_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560    7.565177e-10    1.091967e-09    1.443413e+00
         400     749245    7.061542e-10    1.116170e-09    1.580633e+00
        1600     230574    6.943432e-10    1.171088e-09    1.686613e+00
        6400      68470    6.937756e-10    1.305848e-09    1.882234e+00

3. ArrayRCP_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560    3.658930e-10    3.765406e-10    1.029100e+00
         400     749245    3.789682e-10    3.671329e-10    9.687698e-01
        1600     230574    3.575045e-10    3.575994e-10    1.000265e+00
        6400      68470    5.485934e-10    5.484793e-10    9.997920e-01

4. ArrayRCP_selfIteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP as a self iterataor relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560    3.729480e-10    1.878863e-09    5.037869e+00
         400     749245    3.919746e-10    1.754433e-09    4.475884e+00
        1600     230574    3.606841e-10    1.922398e-09    5.329866e+00
        6400      68470    5.474158e-10    2.262937e-09    4.133853e+00

5. ArrayView_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayView braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayView       ArrayView/raw 
   ---------  ---------  --------------  --------------  --------------
         100    2307560    7.635771e-10    1.092032e-09    1.430153e+00
         400     749245    7.155570e-10    1.121049e-09    1.566680e+00
        1600     230574    7.017405e-10    1.160129e-09    1.653217e+00
        6400      68470    7.770807e-10    1.261093e-09    1.622860e+00

6. ArrayView_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayView iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayView       ArrayView/raw 
   ---------  ---------  --------------  --------------  --------------
         100    2307560    3.629461e-10    3.765493e-10    1.037480e+00
         400     749245    3.772431e-10    3.936763e-10    1.043561e+00
        1600     230574    3.589737e-10    3.622779e-10    1.009205e+00
        6400      68470    5.477992e-10    5.479590e-10    1.000292e+00
\end{verbatim}}
\end{listing}

\pagebreak

\begin{listing}: Raw Array timing data on MSVC++ 2008  \\
\label{listing:Array-MSVC-Timings}
% From ./results/UnitTimings/MSVC/results1/Teuchos_Array_PerformanceTest.out
{\scriptsize\begin{verbatim}
0. Array_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the Array braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+003/0.0001 = 5e+007
 
   array dim  num loops  raw ptr         vector          Array           vector/raw      Array/raw     
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
         100    2307560   7.757111e-010   6.110350e-010   5.243634e-010   7.877095e-001   6.759777e-001
         400     749245   3.803829e-010   3.837196e-010   4.037398e-010   1.008772e+000   1.061404e+000
        1600     230574   3.523814e-010   3.605133e-010   3.550921e-010   1.023077e+000   1.007692e+000
        6400      68470   5.203009e-010   5.157368e-010   5.225829e-010   9.912281e-001   1.004386e+000

1. Array_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the Array iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+003/0.0001 = 5e+007
 
   array dim  num loops  raw ptr         vector          Array           vector/raw      Array/raw     
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
         100    2307560   5.416977e-010   5.373641e-010   5.546985e-010   9.920000e-001   1.024000e+000
         400     749245   3.903930e-010   3.837196e-010   3.903930e-010   9.829060e-001   1.000000e+000
        1600     230574   3.550921e-010   3.794877e-010   3.659346e-010   1.068702e+000   1.030534e+000
        6400      68470   5.294289e-010   5.203009e-010   5.225829e-010   9.827586e-001   9.870690e-001

2. ArrayRCP_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+003/0.0001 = 5e+007
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560   5.330306e-010   8.753835e-010   1.642276e+000
         400     749245   4.938305e-010   8.642033e-010   1.750000e+000
        1600     230574   3.605133e-010   8.375836e-010   2.323308e+000
        6400      68470   5.317110e-010   8.169636e-010   1.536481e+000

3. ArrayRCP_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+003/0.0001 = 5e+007
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560   5.460313e-010   5.460313e-010   1.000000e+000
         400     749245   4.170865e-010   4.037398e-010   9.680000e-001
        1600     230574   3.578027e-010   3.578027e-010   1.000000e+000
        6400      68470   5.203009e-010   5.339930e-010   1.026316e+000

4. ArrayRCP_selfIteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP as a self iterataor relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+003/0.0001 = 5e+007
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560   5.460313e-010   2.452807e-009   4.492063e+000
         400     749245   4.904938e-010   2.375725e-009   4.843537e+000
        1600     230574   3.578027e-010   2.355534e-009   6.583333e+000
        6400      68470   5.362750e-010   2.471429e-009   4.608511e+000

5. ArrayView_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayView braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+003/0.0001 = 5e+007
 
   array dim  num loops  raw ptr         ArrayView       ArrayView/raw 
   ---------  ---------  --------------  --------------  --------------
         100    2307560   5.330306e-010   5.286970e-010   9.918699e-001
         400     749245   3.803829e-010   4.004031e-010   1.052632e+000
        1600     230574   3.550921e-010   3.605133e-010   1.015267e+000
        6400      68470   5.111728e-010   5.180188e-010   1.013393e+000

6. ArrayView_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayView iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+003/0.0001 = 5e+007
 
   array dim  num loops  raw ptr         ArrayView       ArrayView/raw 
   ---------  ---------  --------------  --------------  --------------
         100    2307560   5.373641e-010   5.460313e-010   1.016129e+000
         400     749245   3.970664e-010   3.970664e-010   1.000000e+000
        1600     230574   3.550921e-010   3.523814e-010   9.923664e-001
        6400      68470   5.294289e-010   5.408391e-010   1.021552e+000
\end{verbatim}}
\end{listing}


\begin{SANDdistribution}[NM]
% \SANDdistCRADA	% If this report is about CRADA work
% \SANDdistPatent	% If this report has a Patent Caution or Patent Interest
% \SANDdistLDRD	% If this report is about LDRD work
% External Address Format: {num copies}{Address}
%\SANDdistExternal{}{}
%\bigskip
%% The following MUST BE between the external and internal distributions!
%\SANDdistClassified % If this report is classified
% Internal Address Format: {num copies}{Mail stop}{Name}{Org}
%\SANDdistInternal{}{}{}{}
% Mail Channel Address Format: {num copies}{Mail Channel}{Name}{Org}
%\SANDdistInternalM{}{}{}{}
%\SANDdistInternal{2}{MS 9018}{Central Technical Files}{8944}
%\SANDdistInternal{2}{MS 0899}{Technical Library}{4536}
\end{SANDdistribution}

\end{document}
