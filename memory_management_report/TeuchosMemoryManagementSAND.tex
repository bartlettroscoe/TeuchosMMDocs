\documentclass[pdf,ps2pdf,11pt]{SANDreport}
\usepackage{pslatex}
%Local stuff
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{color}
%\usepackage[light]{draftcopy}
\input{rab_commands}
\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}
\newtheorem{listing}{Listing}
\usepackage[colorlinks]{hyperref}

\newtheorem{commandment}{Commandment}
\newtheorem{anticommandment}{Anti-Commandment}

\raggedright

% If you want to relax some of the SAND98-0730 requirements, use the "relax"
% option. It adds spaces and boldface in the table of contents, and does not
% force the page layout sizes.
% e.g. \documentclass[relax,12pt]{SANDreport}
%
% You can also use the "strict" option, which applies even more of the
% SAND98-0730 guidelines. It gets rid of section numbers which are often
% useful; e.g. \documentclass[strict]{SANDreport}

% ---------------------------------------------------------------------------- %
%
% Set the title, author, and date
%

\title{\center
Teuchos C++ Memory Management Classes, Idioms, and Related Topics
\\[2ex] The Complete Reference \\[2ex] {\Large A Comprehensive Strategy for
Safe and Efficient Memory Management in C++ for High Performance
Computing}  \\ {\Large (Compatible with Teuchos in Trilinos version 11.0 and forward)} }

\author{
Roscoe Bartlett
}

\date{}

%Sandia National
%Laboratories\footnote{ Sandia is a multiprogram laboratory operated by Sandia
%Corporation, a Lockheed-Martin Company, for the United States Department of
%Energy under Contract DE-AC04-94AL85000.}, Albuquerque NM 87185 USA


% ---------------------------------------------------------------------------- %
% Set some things we need for SAND reports. These are mandatory
%
\SANDnum{2010-2234}
\SANDprintDate{September 2012}
\SANDauthor{
Roscoe Bartlett
}

% ---------------------------------------------------------------------------- %
% Build your markings. See example files and SAND Report Guide
%

\SANDreleaseType{Unlimited Release}
%\SANDreleaseType{Not approved for general release}
%\SANDmarkTopBottomCoverBackTitle{}
%\SANDmarkBottomCover{}
%\SANDmarkTopBottomCoverTitle{}
%\SANDmarkTop{}
%\SANDmarkBottom{}
%\SANDmarkTopBottom{}
%\SANDmarkCover{}
%\SANDmarkCoverTitle{}


% ---------------------------------------------------------------------------- %
%
% Start the document
%

\begin{document}

\pagenumbering{roman}

\maketitle


% ------------------------------------------------------------------------ %
% An Abstract is required for SAND reports
%

%\clearpage

%
\begin{abstract}
%


The ubiquitous use of raw pointers in higher-level code is the primary
cause of all memory usage problems and memory leaks in C++
programs. This paper describes what might be considered a radical
approach to the problem which is to encapsulate the use of all raw
pointers and all raw calls to {}\ttt{new} and {}\ttt{delete} in
higher-level C++ code.  Instead, a set of cooperating template classes
developed in the Trilinos package Teuchos are used to encapsulate
every use of raw C++ pointers in every use case where it appears in
high-level code.  Included in the set of memory management classes is
the typical reference-counted smart pointer class similar to
{}\ttt{boost::shared\_ptr} (and therefore C++0x
{}\ttt{std::shared\_ptr}).  However, what is missing in boost and the
new standard library are non-reference counted classes for remaining
use cases where raw C++ pointers would need to be used.  These classes
have a debug build mode where nearly all programmer errors are caught
and gracefully reported at runtime, i.e. essentially eliminating
undefined behavior related to memory usage.  The default optimized
build mode strips all runtime checks and allows the code to perform as
efficiently as raw C++ pointers with reasonable usage.  Also included
is a novel approach for dealing with the circular references problem
that imparts little extra overhead and is almost completely invisible
to most of the code (unlike the boost and therefore C++0x approach).
Rather than being a radical approach, encapsulating all raw C++
pointers is simply the logical progression of a trend in the C++
development and standards community that started with
{}\ttt{std::auto\_ptr} and is continued (but not finished) with
{}\ttt{std::shared\_ptr} in C++0x.  The goal is nothing short of
eliminating undefiend behavior related to memory usage from C++
programs without destroying the low-level control and performance of
C++ programs.

%
\end{abstract}
%

% ------------------------------------------------------------------------ %
% An Acknowledgement section is optional but important, if someone made
% contributions or helped beyond the normal part of a work assignment.
% Use \section* since we don't want it in the table of context
%
%\clearpage
%\section*{Acknowledgment}
%
%
%The format of this report is based on information found
%in~\cite{Sand98-0730}.


% ------------------------------------------------------------------------ %
% The table of contents and list of figures and tables
% Comment out \listoffigures and \listoftables if there are no
% figures or tables. Make sure this starts on an odd numbered page
%
\cleardoublepage   % TOC needs to start on an odd page
\tableofcontents
\listoffigures
\listoftables


% ---------------------------------------------------------------------- %
% An optional preface or Foreword
\clearpage
\section*{Preface}
\addcontentsline{toc}{section}{Preface}

This document describes the basic problems with raw memory management
in C++ and presents an approach to addressing the problems by
encapsulating all raw C++ pointers in a system of cooperating types.
Almost every aspect is presented and issues of detailed usage, safety,
performance, suggested idioms and many other topics are discussed.
This is a fairly lengthy document with more than 140 pages in the main
body and with 20 pages of appendices.  This may seem like a lot of
material to read through but consider that the 1500+ pages of
mainstream literature on modern C++ usage in just the references
{}\cite{stroustrup97, C++CodingStandards05, C++Gotchas03,
EffectiveC++ThirdEdition} still leaves a language that makes it too
easy to write programs with undefined behavior (i.e.\ segfault) and
memory leaks.

While this is a long document, there is a much shorter path given
below that gives the basics for the anxious reader that does not need
all the background material or the information on the many interesting
side topic discussed.

{}\noindent\textbf{Abbreviated table of contents:}

\begin{itemize}

{}\item Section~\ref{sec:intro} ``\nameref{sec:intro}''

{}\item Section~\ref{sec:nonpersisting-persisting-associations}
``\nameref{sec:nonpersisting-persisting-associations}''

{}\item Section~\ref{sec:overview_of_basic_approach}
``\nameref{sec:overview_of_basic_approach}''

{}\item Section~\ref{sec:mem-mng-classes-single-objs}
``{}\nameref{sec:mem-mng-classes-single-objs}'':\\[2ex]

{}\item Section~\ref{sec:array-classes}
``{}\nameref{sec:array-classes}''

{}\item Section~\ref{sec:idioms} ``{}\nameref{sec:idioms}''

{}\item Section~\ref{sec:roles-and-responsibilities}
``\nameref{sec:roles-and-responsibilities}''

{}\item Section~\ref{sec:comparison_with_other_libs}
``{}\nameref{sec:comparison_with_other_libs}''

{}\item Appendix~\ref{apdx:summary_of_idioms}
``{}\nameref{apdx:summary_of_idioms}''

{}\item Appendix~\ref{apdx:commandments}
``{}\nameref{apdx:commandments}''

\end{itemize}

The material shown above should be enough to a) give a basic idea of
the motivation for the Techos memory management classes, b) describe
the basic foundations for the classes, c) present the names,
identities, and basic usage for each of the classes, d) describe the
core idioms for the use of the classes, and e) mention how these
classes compare with other classes in the Boost and the standard C++
libraries.  This is the most basic material that should answer the
most basic questions that most developers will have.  The material in
Appendix~\ref{apdx:summary_of_idioms} and
Appendix~\ref{apdx:commandments} should be used as a (relatively)
short reference guide for the use of these classes.  This material
together with some existing code examples (e.g\ in Trilinos) should
give an experienced C++ developer enough to get started using these
classes in a productive way.  Finally, the reader should go through
the full table of contents at least once to get an idea of the variety
of topics covered and where to look when more information is needed
(and most developers will need to know most of this extra information
at some point).

The rest of the material covered in this document either provides more
background that might be needed to persuade some readers or expands on
a number of topics that almost every developer will need to consider
at some point while using these classes including a) how to deal with
type conversion problems, b) how the basic reference-counting
machinery works, what types of debug-mode runtime checking is
performed and how to debug problems when exceptions are thrown, c)
what optimized performance should look like and how to better optimize
code, d) what related idioms are useful or needed to fully exploit
these classes, e) guidance on how to refactor existing software, and
f) other related topics like a discussion of essential and accidental
complexity.

Hopefully this document will be educational and help open the one's
mind to what is possible to achieve in terms of safety and performance
in modern C++ programs.

The classes and idioms described in this document have been
encorporated into the coding guidelines document described in
{}\cite{ThyraCodingGuidelinesSAND}.


% ---------------------------------------------------------------------- %
% An optional glossary. We don't want it to be numbered
%\clearpage
%\subsection*{Nomenclature}
%\addcontentsline{toc}{section}{Nomenclature}
%\begin{itemize}
%\item[alohomora]
%spell to open locked doors and containers
%\end{itemize}

% ---------------------------------------------------------------------- %
% This is where the body of the report begins; usually with an Introduction
%

\SANDmain % Start the main part of the report

\pagenumbering{arabic}

%
\section{Introduction}
\label{sec:intro}
%

% General ToDos:
% * Remove all references to 'you' and replace with 'one' or more
%   generic.
% * Replace all references to 'we' and 'I' and make more generic.
% * Replace 'our' with more generic wording ... In Progress ...
% * Look for 'where' when it should be 'were'.

A critical problem in computational science and engineering (CS\&E)
software as well as in other types of software developed in C++ is in
the effective and safe management of memory and data.  CS\&E software
often has the goal of high performance where arbitrary data copy leads
to undue overhead and can actually complicate the software in many
cases.  It is common for CS\&E software to share and pass around large
blocks of memory in order to do work efficiently (however, common
approaches such as described in
{}\cite{DataSharinginScientificSimulations} lead to many of the
problems that exist in CS\&E programs).  At the most basic level,
large arrays of integral and floating point data are managed along
with more complex general objects and arrays of objects.  In C++, the
only universally accepted way to deal with memory for single objects
and arrays of objects is to use raw C++ pointers.  However, raw C++
pointer facilities for the manipulation and sharing of basic memory
are inherently unsafe and error prone.  The problem is further
exacerbated when larger programs composed out of separately developed
and maintained components are integrated together.  Assumptions about
the origin, ownership, and process for reclaiming memory and other
resources remain the most basic problems with lower-level C++
programming techniques and are unfortunately still ubiquitous in the
C++ community and even in the current C++ best-practices literature
{}\cite{C++CodingStandards05, EffectiveC++ThirdEdition}.  The general
C++ and CS\&E communitie's inability to effectively address the basic
problem of the usage of memory in large-scale modular C++ codes
affects every aspect of software quality, productivity, reusabliltiy,
and undermines the most basic software verification foundation for
these codes.  The challenges of writing software that uses raw memory
management results in components that are overly rigid in how they can
be used and reused which fundamentally detracts from the impact that
such software could otherwise have and makes it more difficult develop
and maintain.  The problems created by the use of raw memory
management can single-handily derail the vision of a large
interconnected network of reusable CS\&E software components developed
and used by many different CS\&E organizations
{}\cite{HPCNeedsAToolsStrategy05}.  Therefore, the issue of memory
management has as much or more impact on the macroscopic properties of
CS\&E software components as it does on low-level internal software
development.

C++ is a large and complex language that very few people really know
how to use in a confident and successful way.  Arguably the most
serious problems in C++ are related to dynamic memory management
(which must be used with any moderately complex object-oriented
program) and raw access to memory (e.g.\ array and pointer usage
errors).  The built-in C++ support for dealing with dynamic memory
allocation with {}\ttt{new} and {}\ttt{delete} is fundamentally
incompatible with the built-in exception handling mechanism using
{}\ttt{try}, {}\ttt{throw}, and {}\ttt{catch}.  One cannot effectively
build large-scale integrated software using just these low-level
language features at the application programming level.  Software
developed this way yields undefined behavior (e.g.\ segfaults) and
leaks memory unpredictably and is extremely difficult to integrate
with other code.  The only successful way to use C++ to create complex
robust software is to develop and rigorously adopt a set of
programming idioms for safely dealing with memory.  By developing the
right support software and associated idioms, we make C++ programs
safer, better defined, faster to develop, and more efficient when run.
The development of {}\ttt{std::vector} and {}\ttt{std::shared\_ptr}
are steps in the right direction by the C++ standards have not gone
far enough (as will be explained below).

The reason that C++ is in this state of affairs is due to how C++ came
into being and how it evolved over many years {}\cite{stroustrup94,
stroustrup07}.  C++ was first developed in the early 1980s as an
extension to the popular C programming language and was first called
``C with Classes''.  At the time, high efficiency, very low runtime
overhead, and strong compatibility with C were critical requirements
to the success of the new language.  Without this, the original
creator of C++, Bjarne Stroustrup, concluded that C++ would be
``stillborn'' {}\cite{stroustrup97}.  The first C++ compilers were
little more than preprocessors putting out C code on the back-end
which was then compiled into executable binary code.

As the years went on, however, object-oriented programming was
refined, computers become faster with more memory, and it was realized
that more runtime support was required to enable more advanced usages
of C++.  As new features were added to C++ to support new programming
idioms, a strong need for backward compatibility constrained the
design of the language, sometimes making different language features
incompatible when used together in raw form.  The most unfortunate
example of this, which was already mentioned, is the fundamental
incompatibility of built-in dynamic memory management (i.e.\ using
{}\ttt{new}/{}\ttt{delete}) and built-in exception handling (i.e.\
using {}\ttt{try}/{}\ttt{throw}/{}\ttt{catch}) that was added more
than a decade later {}\cite{stroustrup94}.

Because of the way that C++ ``evolved'' along with a strong need for
backward compatibility, we have a language that is a disaster when
used in raw form in undisciplined ways on complex large-scale
software.  Many programming teams have exploited this natural
capability of C++ to create travesties of software which in turn have
dumbfounded many a C++ programmer (and entire teams) and have resulted
in giving C++ a bad name in the general software engineering community
(see Section 6 ``DDD Matters Today'' in
{}\cite{DomainDrivenDesignQuickly} and ``The Case of the Construction
Blob'' in {}\cite[Chapter 9]{WorkingEffectivelyWithLegacyCode05} for a
few examples of C++ bashing).

More specifically, using low-level manual memory management (e.g.\
{}\ttt{new}/{}\ttt{delete}, raw pointers everywhere) at all
levels in C++ has resulted in several negative consequences in the
development of C++ (and C) software that other more modern languages
(e.g.\ Java and Python) have avoided:

\begin{itemize}

{}\item Programs that use raw memory management are more difficult to
write and debug because it is difficult to track down invalid memory
usage that results in undefined behavior (e.g.\ segfaults), double
deletes, and memory leaks.  (Also, memory checking tools like Valgrind
and Purify are too slow and do not catch enough of these types of
errors to adequately mitigate the problem.)

{}\item Programs that use raw memory management can have many
``hidden'' memory usage errors (i.e.\ undefined behavior) that can
linger in the code for months or years which damage the most basic
foundations of software quality and verification.  Many of these
programs are ``ticking time bombs'' just ready to go off, sometimes
with disastrous consequences for users and developers alike.

{}\item Dealing with raw memory management at all levels consumes large
amounts of developer focus which detracts from more general design
focus.  This results in software with lower quality designs compared
to software written in other modern languages developed using the same
amount of effort.

{}\item Developers maintaining C++ programs that use raw memory
management typically have a high degree of paranoia and fear about
modifying the software (and for good reason because modifying such
software is dangerous and error prone).  This results in the tendency
to not refactor software as requirements and domain knowledge change
{}\cite{DomainDrivenDesign} which therefore results in software that
dies the slow painful death of software entropy
{}\cite{MythicalManMonth95}.

{}\item Software that uses raw memory management at all levels
necessarily have designs that overly constrain how the software is
used and reused.  For example, in such programs factory objects
typically have to outlive the products they create and must also be
responsible for deleting the objects they create.  This results in
large numbers of ``static'' factory objects that make the software
hard to maintain and reuse in reasonable contexts.

\end{itemize}

The consequences of raw memory management described above are all too
common in C++ development organizations and software produced by such
organizations.  This is why the general software development community
is largely moving away from C++ and instead moving to use more modern
languages that do not require manual unchecked memory management
{}\cite{DomainDrivenDesignQuickly}.

However, C++ has some unique features that differentiate it from every
other language in wide use which include:

\begin{itemize}

{}\item Strong typing (leads to high-performance code)

{}\item High-performance native code

{}\item Support for creating very efficient concrete data types with
efficiency on par with built-in data types that do not require dynamic
memory management (i.e.\ true stack-based objects)

{}\item Support for operator overloading

{}\item Support for object-oriented programming

{}\item Support for generic programming (i.e.\ templates)

{}\item A powerful turing-complete compile-time programming mechanism
(i.e.\ template meta-programming)

\end{itemize}

No other programming language with wide availability has this powerful
set of features.  For instance, C++ can be used to create class
libraries for capabilities like automatic differentiation
{}\cite{ref:ad} for computing derivatives of functions that achieves a
level of generality and efficiency that has no rival in a software
library in any other programming language (e.g., see the
Trilinos\footnote{\ttt{http://trilinos.sandia.gov}} package
Sacado\footnote{\ttt{http://trilinos.sandia.gov/packages/sacado/}}
{}\cite{phippsEtAl2006}).  It is precisely the above feature set along
with wide availability of high quality compilers on every major
platform (including the cutting-edge massively parallel computers),
good interoperability with other languages (through C
interoperability), and strong support for next generation
architectures {}\cite{DesignIssuesForMultiCore08} that makes C++ so
attractive for writing computational science \& engineering software
in the first place.

It is also this unique feature set that is C++'s saving grace with
respect memory management problems.  In C++, one can actually develop
a set of new data types that in essence can be used to develop new
programming environments in C++.  This essentially allows one to
define a new programming language within C++ with a level of
efficiency and flexibility that does not exist in any other
programming language.  This is exactly what this paper advocates with
respect to basic memory management in C++; developing a new
higher-level programming language in C++ for abstracting and
encapsulating all raw memory usage as well as dynamic memory
management that is very compatible with the built-in C++ exception
handling mechanism.  The approach being described here is really just
the systematic and (arguably) elegant application to the approaches
advocated in ``Code Complete Second Edition'' {}\cite[Section 13.2:
Pointers]{CodeComplete2nd04} for instance.

This paper describes a set of low-level C++ classes and supporting
software in the Trilinos package
Teuchos\footnote{\ttt{http://trilinos.sandia.gov/packages/teuchos/}}
that are used to encapsulate all raw pointers and enable strong
debug-mode runtime checking while allowing for very high performance
in non-debug-mode optimized builds.  This ideas and approaches are
built on the the ideas and foundations of standard C++ classes like
{}\ttt{std::vector} and {}\ttt{std::shared\_ptr} but fill in all of
the gaps.

The Teuchos memory management classes and the idioms that they help to
define (which are described in this paper) do not remove the need for
programmers to learn and understand the intricate details of the C++
memory model and type system.  On the contrary, learning to
effectively use these memory management classes requires more effort
over just learning raw C++.  However, the payoff is that the programs
that result from the use of these classes and idioms will be more
likely to be correct on first writing, will be easier to debug when
there are defects, will be easier and safer to maintain, and will be
more self documenting (which helps all of the above).  In fact, the
self-documenting expressiveness of the resulting programs written
using these classes and idioms is unmatched in any other programming
language currently in popular use, including Java and Python.  This
statement will be backed up throughout this paper and then reiterated
in Section~\ref{sec:essentail-accidental-complexity}.

The remainder of this paper assumes that the reader has some basic
knowledge of C++ and is somewhat familiar with smart reference-counted
pointer classes like {}\ttt{boost::shared\_ptr} (which is the basis
for the new C++0x {}\ttt{std::shared\_ptr} class).  The Teuchos
equivalent for these smart pointer classes is {}\ttt{Teuchos::RCP}
which is abbreviated here as just {}\ttt{RCP} in sample code.  If the
reader is not familiar with the basics of smart reference-counted
pointer classes, then they should refer to
{}\cite{RefCountPtrBeginnersGuide} and {}\cite{C++CodingStandards05}.
If the reader is not familiar with fundamental C++ concepts like
implicit type conversions, templates, object lifetime models, raw
references and pointers and other basic topics, then some more basic
background will be needed.  However, specific references to basic C++
material in books like {}\cite{EffectiveC++ThirdEdition, stroustrup97,
C++CodingStandards05} are made throughout this document.  So if the
reader is a novice C++ programmer and is willing to look up the
mentioned references, then this paper can be a good guide to help
learn this basic C++ material as well.

A final warning: the material in this document is fairly detailed and
will take a significant investment in time and experience writing code
involving the Teuchos memory management classes using the idioms
described here before a developer will be proficient.  It takes years
just to master raw C++ so it should be no surprise that learning a new
set of idioms to fix a large number of the problems with raw C++ will
also take a significant amount of time and effort.  What is needed is
a culture change in the C++ programming community where this type of
approach and the idioms described here are taught at a very early
stage; much like the STL is now being taught in introductory C++
courses.  What we need is a revolution in C++ education but we have to
start somewhere and that is what this paper is all about, getting
started and on the road to a better generation of C++ programmers and
C++ software.  However, note that this document is not a tutorial but
instead is a complete reference guide to the Teuchos memory management
guide that covers almost every possible issue and reasonably related
topic.

The body of this document is organized as follows. The fundamental
problems with raw C++ pointers is described in
Section-\ref{sec:problems-with-raw-pointers}.  Common (suboptimal)
approaches for addressing memory management problems are discussed in
Section~\ref{sec:current-appraoches-to-mem-mng}.  Some important
prerequisite concepts like value-types versus references-types and
persisting versus non-persisting associations are defined in
Section~\ref{sec:important-prerequisites}.  With all this background
and context in place, the Teuchos memory management classes are
presented in Section~\ref{sec:teuchos-mem-mng-classes}.  The basic
outline of the approach in
Section~\ref{sec:overview_of_basic_approach} is perhaps the first
section one would jump to in order to get a quick idea what the
Teuchos memory management classes are all about.  Finally, taking a
step back, the concepts of essential and accidental complexity and a
philosophical discussion of the trade-offs between speed, safety and
generality related to memory management are discussed in
Section~\ref{sec:misc-topics}.  Concluding remarks are given in
Section~\ref{sec:conclusions}.


%
{}\section{Fundamental problems with raw C++ pointers}
\label{sec:problems-with-raw-pointers}
%

This section summarizes some of the fundamental problems with basic
C++ features related to raw pointers.  What is going to be argued is
that while many people will claim that C++ pointers are strongly
typed, it will be shown that raw pointers are actually very weakly
typed in many respects and how this weak typing is the cause of many
programming errors that result in incorrect programs and with
undefined behavior (e.g.\ segfaults).

In the following examples, the simple classes shown in
Listing~\ref{listing:Simple_A_B} are used in demonstration code:

\begin{listing}:\\
\label{listing:Simple_A_B}
{\small\begin{verbatim}
  class A {
    char dummy_;
    char *char_ptr_;
  public:
    A(...);
    void incrementA() { ++(*char_ptr_); }
  };

  class B : public A {
    int size_;
    int *int_ptr_;
  public:
    B(...);
    void incrementB() { ++(*int_ptr_); }
  };
\end{verbatim}}
\end{listing}

The concrete class hierarchy in Listing~\ref{listing:Simple_A_B} was
chosen to demonstrate some insidious and perhaps less well known flaws
in the C++ type system when dealing with raw C++ pointers.


%
{}\subsection{Problems using raw C++ pointers for handling single objects}
%

There are a number of problems with using raw C++ pointers to manage
single objects.  For example, given a class object of type {}\ttt{B}
in Listing~\ref{listing:Simple_A_B} consider a pointer declared as:

{\small\begin{verbatim}
  B some_b(...);
  B *b_ptr = &some_b;
\end{verbatim}}

Some of the legitimate things that one can do with this pointer are:

{\small\begin{verbatim}
  // Call member functions
  b_ptr->incrementA();
  b_ptr->incrementB();
  // Extract reference
  B &b_ref = *b_ptr;
  // Copy pointer
  B *b_ptr2 = b_ptr;
  // Implicit conversion to const
  const B *b_ptr3 = b_ptr;
  // Implicit conversion to base type
  A *a_ptr4 = b_ptr;
\end{verbatim}}

However, nothing good can {}\underline{ever} come of any of the
following operations when a pointer is only pointing to a single
object:

{\small\begin{verbatim}
  b_ptr++
  b_ptr--
  ++b_ptr
  --b_ptr
  b_ptr+i
  b_ptr-i
  b_ptr[i]
\end{verbatim}}

No C++ compiler I have ever worked with will even issue a warning when
array operations are invoked on a raw C++ pointer for which it is
clear is only pointing to a single object.

The problem here of course is that there is no way to tell the C++
compiler that a raw pointer is only pointing to a single object.  With
respect to differentiating single objects and arrays of objects, C++
pointers are untyped and the compiler provides no help whatsoever in
statically asserting correct usage.  This is strike one for the notion
that C++ pointers are strongly typed!


%
{}\subsection{Problems using raw C++ pointers for handling arrays of
objects}
\label{sec:problem-with-raw-array-pointers}
%

When considering the semantics of raw C++ pointers one realizes that
raw pointers are really designed primarily for dealing with contiguous
arrays of objects (save for one exception that is mentioned below).
This is because almost every operation that C++ defines for raw
pointers makes sense and is fairly well defined when raw C++ pointers
are pointing with contiguous arrays of objects.  Every valid C++
operation will not be reviewed for raw pointers to contiguous arrays
of objects (see {}\cite{stroustrup97} for a complete listing).
Instead, a few examples are shown where the C++ type system using raw
pointers falls flat on its face when dealing with arrays of memory.

One particularly troubling example where the C++ type system fails
when dealing with raw C++ pointers to contiguous arrays of memory is
shown in Listing~\ref{listing:BadArrayPointerConversion}.

\begin{listing}:\\
\label{listing:BadArrayPointerConversion}
{\small\begin{verbatim}

  void foo(const int n) {
      B *b_array = new B[n];
      A *a_array = b_array; // Compiles just fine :-(
      for (int i = 0; i < n; ++i) {
        a_array[i].incrementA(); // KABOMMMMM!
      }
      delete [] b_array;
  }

\end{verbatim}}
\end{listing}

There are a lot of beginning and even some more experienced C++
programmers that would think that the C++ code in
Listing~\ref{listing:BadArrayPointerConversion} is just fine.  The
resulting program has undefined behavior and may seem to run okay in
some cases but in the above case will almost certainly segfault right
away.  The above code fragment is wrong, wrong, wrong as described in
{}\cite[Gotcha 33]{C++Gotchas03} and {}\cite[Item
100]{C++CodingStandards05}.  Without going into great detail,
converting from a pointer for an array of type {}\ttt{B} to a pointer
of type of base type {}\ttt{A} is almost always asking for disaster
because the alignment of the base type {}\ttt{A} will be wrong
according to the full type {}\ttt{B} (again see {}\cite[Gotcha
33]{C++Gotchas03} all the gory details).  As a result, for the second
iteration {}\ttt{i=1}, the embedded pointer in
{}\ttt{a\_array[1].char\_ptr\_} is pointing to garbage because on most
32 bit machines with most compilers, the address in
{}\ttt{a\_array[1].char\_ptr\_} is actually the binary representation
of the integer {}\ttt{b\_array[0].size\_}.  Therefore, calling
{}\ttt{a\_array[1]->incrementA()} on most 32 bit machines is
equivalent to performing:

{\small\begin{verbatim}
  ++(*reinterpret_cast<char*>(b_array[0].size_)); // KABOMMMMM!
\end{verbatim}}

If this sort of thing comes as a surprise to C++ developers, then they
should probably fear using raw memory in C++ more than they currently
do and should seriously consider using the safer approach to
encapsulating raw memory usage that is being advocated in this paper.

So how did C++ come to allow such completely wrong and dangerous
operations like shown in
Listing~\ref{listing:BadArrayPointerConversion}?  It is because of the
untyped dual nature of raw C++ pointers in trying to handle both
single objects and contiguous arrays of objects with one data type
where the full set of operations are not appropriate for either.  The
ability to cast raw C++ pointers from derived types to base types only
ever generally makes sense when the pointer is pointing to a single
object and will not be interpreted as a pointer to a contiguous array
of objects.  Note that C does not have this problem since there is no
such thing as type derivation and the designers of C never even
envisioned that raw C pointers would be used for such a thing.
However, when the original designer of C++ adopted the C type system
along with raw pointers and tried to apply it to an object-oriented
language, he inadvertently opened up a number of serious language
gotchas that we are still living with to this day.  This is another
strike for the notion that C++ pointers are strongly typed!


%
{}\subsection{Problems with the incompatibility of
{}\ttt{new/delete} and {}\ttt{try/throw/catch}}
%

The use of raw pointers and raw calls to {}\ttt{new} and
{}\ttt{delete} is also fundamentally incompatible with the built-in
C++ exception handling mechanism using
{}\ttt{try}/{}\ttt{throw}/{}\ttt{catch}.  For example, the following
code will leak memory if the function {}\ttt{someFunc()} throws a C++
exception:

{\small\begin{verbatim}
  void foo()
  {
    A *a = new A(...);
    someFunc(); // Could throw an exception
    delete a; // Will never be called if someFunc() throws!
  }
\end{verbatim}}

According to current C++ best practices relating to memory management
and exception handling as described in {}\cite[Item
{}29]{EffectiveC++ThirdEdition} and {}\cite[Item
{}71]{C++CodingStandards05}, code like shown above that leaks memory
is totally unacceptable in production quality C++ programs.  This
fundamental incompatibility of the built-in C++ dynamic memory
management facilities using {}\ttt{new}/\ttt{delete} and the built-in
exception handling mechanism using
{}\ttt{try}/{}\ttt{throw}/\ttt{catch} was clear even to the committee
that created the official 1998 C++ standard.  However, again, because
of the need for backward compatibility they were powerless to fix the
problem at the language level.  Instead, the C++ standards committee
included the first standard C++ smart pointer class;
{}\ttt{auto\_ptr}.  The class {}\ttt{auto\_ptr} solves only the most
basic problem with raw C++ pointers and that is that it ensures that
memory will be reclaimed when exceptions are thrown.  For example, the
following refactored function will not leak any memory when
{}\ttt{someFunc()} throws:

{\small\begin{verbatim}
  void foo()
  {
    std::auto_ptr<A> a(new A(...));
    someFunc(); // Could throw an exception
    // NOTE: delete will get called on the A object no matter how this
    // function exists (i.e. normal exit or with a throw) since it is
    // called by the destructor of the stack object 'a' of type
    // std::auto_ptr<A>. 
  }
\end{verbatim}}

The introduction of {}\ttt{std::auto\_ptr} is perhaps the first
example of where a user-defined type was added to the standard C++
library in order to define an idiom meant to fix a fundamental C++
language flaw due to incompatible language features.  Note the term
``flaw'' is used and not ``deficiency''.  It is generally excepted in
most modern programming languages that the language proper will not
support every programming model or idiom that is of general interest
and instead (class) libraries are provided to fill in the gaps.  The
problem is that the language definition itself is flawed with respect
to the raw use of {}\texttt{new}/\texttt{delete} along with
{}\texttt{try}/\texttt{throw}/\texttt{catch} and is not just simply
missing some desirable feature.  One could argue that what C++ is
really missing is garbage collection (GC) but even that is not the
case because to add GC would be fundamentally incompatible with the
current user-controlled memory management facility using {}\ttt{new}
and {}\ttt{delete}.  There is a lot of C++ code out there that
requires that destructors for objects be called exactly when expected
such as when {}\ttt{delete} is called (and there are idioms such as
defined in Section~\ref{sec:generalized-view-design-pattern} that
depend on this behavior).  Any form of language-supported GC will
break some backward compatibility of C++ and therefore we may never
see a C++ standard with full GC.  Also, removing the ability to
precisely control when destructors are called and memory is reclaimed
would make C++ less attractive for many domains where such low-level
control is critical (e.g.\ embedded programming, systems programming,
scientific programming).

The Boost library and the up-coming C++0x standard add more types that
continue in this trend of providing new user-defined types and idioms
to address fundamental C++ language flaws and deficiencies.  However,
as described in meat of this paper, both the Boost and the C++0x
standard libraries fall short of providing a complete and
comprehensive solution to the problems with raw C++ pointers and raw
access to memory.

Note that the upcoming C++0x standard as it is currently defined (at
least the time of this writing) will do nothing to fix the majority of
these nonsensical raw C++ pointer gotchas because to do so would
destroy backward compatibility of millions of lines of existing C++
code.  Because of the need for backward compatibility, we cannot rely
on any future C++ standard to fix the basic problems with raw C++
pointers.  Instead, this document advocates using new C++ user-defined
types to create a new safer type-system in C++ and avoiding the direct
use of raw C++ pointers except where required to interact with
non-compliant code.


%
{}\section{Problems with common approaches for addressing memory
management in C++}
\label{sec:current-appraoches-to-mem-mng}
%

Because of some of the obvious problems with using raw C++ pointers to
access raw memory and using raw calls to {}\ttt{new} and
{}\ttt{delete} to perform dynamic memory management, various authors
have advocated a number of different approaches for addressing these
problems.  A few of these approaches will be described along with
arguments as to why they are far too sub-optimal.


%
{}\subsection{Problems with using {}\ttt{std::vector} for handling
all arrays}
%

A very common approach to try to get around using raw C++ pointers for
managing contiguous arrays of data is to use the container class
{}\ttt{std::vector} in {}\underline{every} use case where a raw C++
array or pointer to an array would be used.  Before describing use
cases where {}\ttt{std::vector} is being poorly used, first a review
is given for what {}\ttt{std::vector} is and what it is good for.  The
standard library class {}\ttt{std::vector} is a general-purpose
concrete contiguous data container class for storing and retrieving
value objects\footnote{See Section~\ref{sec:value-and-reference-types}
for a definition of ``Value Types''.}.  What makes using
{}\ttt{std::vector} attractive as compared to a simple class that a
developer would write for themselves is that:

\begin{itemize}

{}\item\ttt{std::vector} is a Standard Template Library (STL)
compliant data container which makes it easy to use with STL-like
generic algorithms.

{}\item\ttt{std::vector} contains functions for efficiently expanding
and shrinking the size of the array that can have platform/compiler
specific optimizations with much better performance than what a
developer would roll on their own.

{}\item\ttt{std::vector} is standardized so one can use it as a means
for interoperability with other software in appropriate situations.

\end{itemize}

These are pretty much the advantages of using {}\ttt{std::vector} over
other alternatives.  When used as a general purpose data container
where one will be changing the size of the array on the fly,
{}\ttt{std::vector} is convenient, general, and efficient (just what
components from a standard library should be).  However, in other use
cases, {}\ttt{std::vector} is far from convenient, general, or
efficient.  As one example, consider using {}\ttt{std::vector} to
replace raw C++ pointers for array arguments in {}\underline{all} C++
functions as some authors have suggested (e.g.\ see
{}\cite{Modernizing-the-C++-Interface-to-MPI}).  For example, consider
a VISITOR~\cite{ref:design_patterns_1995} interface that operates on
blocks of data (similar to the RTOp interface described
in~\cite{ref:rtop_toms}) along with a concrete subclass shown in
Listing~\ref{listing:addArrayIntoArray-raw}.

\begin{listing}:\\
\label{listing:addArrayIntoArray-raw}
{\small\begin{verbatim}
  template<class T>
  class BlockTransformerBase {
  public:
    virtual ~BlockTransformerBase();
    virtual void transform(const int n, const T a[], T b[]) const = 0;
  };

  template<class T>
  class AddIntoTransformer : public BlockTransformerBase<T> {
  public:
    virtual void transform(const int n, const T a[], T b[]) const
      {
        for (int i = 0; i < n; ++i)
          b[i] += a[i];
      }
  };
\end{verbatim}}
\end{listing}

The VISITOR interface shown in
Listing~\ref{listing:addArrayIntoArray-raw} allows clients to accept
any {}\texttt{BlockTransformerBase} object and allow it to
transparently implement any number of user-defined transformations.
Note that virtual funtions cannot be templated so it is not possible
for the {}\texttt{transform(...)} function to be templated on an
iterator type but must instead accept some fixed representation of the
arrays of data to be operated on.  The advantages of the
{}\texttt{transform(...)} function in
Listing~\ref{listing:addArrayIntoArray-raw} are that a) it is clean,
b) the arrays of data can be sub-views of large arrays, and c) it will
yield very fast code.  Of course the problem with the above function
{}\ttt{transform(...)} is that is uses raw C++ pointers.  How does the
function {}\ttt{transform(...)} know that {}\ttt{a} and {}\ttt{b} are
valid pointers and really point to valid arrays of data with at least
{}\ttt{n} elements.  It is impossible for the function
{}\ttt{transform(...)} to assert anything about the data and
completely relies on the caller of the function to validate the data.
Even in a debug build of the code, there is no way for the
implementation of the function {}\ttt{transform(...)} to validate that
the preconditions concerning arguments have been met.  This is not
good and does not allow for even the most basic approaches for
defensive programming.

Therefore, some C++ programmers look at this and then they change
functions like {}\ttt{transform(...)} in
Listing~\ref{listing:addArrayIntoArray-raw} to use {}\ttt{std::vector}
which is shown in Listing~\ref{listing:addArrayIntoArray-std-vector}.

\begin{listing}:\\
\label{listing:addArrayIntoArray-std-vector}
{\small\begin{verbatim}
  template<class T>
  class BlockTransformerBase {
  public:
    virtual ~BlockTransformerBase();
    virtual void transform(const std::vector<T> &a, std::vector<T> &b) const = 0;
  };

  template<class T>
  class AddIntoTransformer : public BlockTransformerBase<T> {
  public:
    virtual void transform(const std::vector<T> &a, std::vector<T> &b) const
      {
        DEBUG_MODE_ASSERT_EQUALITY( a.size(), b.size() );
        for (int i = 0; i < a.size(); ++i)
          b[i] += a[i];
      }
  };
\end{verbatim}}
\end{listing}

The advantages of the function in
Listing~\ref{listing:addArrayIntoArray-std-vector} are that a) the
size of each array is kept with the pointer to the array itself inside
of each {}\ttt{std::vector} object, b) The sizes of the arrays can be
asserted by the implementation of the function {}\ttt{transform(...)},
c) it is easy for callers who already use single {}\ttt{std::vector}
objects.

While this use of {}\ttt{std::vector} replaces raw C++ pointers as
basic array function arguments, it has several serious problems in
both usability and performance in some important use cases.  The
primary disadvantages of using {}\ttt{std::vector} as general array
arguments to functions is a) there is no flexibility in how the arrays
are allocated, and b) one cannot pass sub-views of larger arrays of
data.

To illustrate the problems with using {}\ttt{std::vector} for all
array arguments to functions, consider a situation where the
application wants to allocate big arrays of data and then operate on
pieces of the array based on different logic.  One motivation for
allocating big arrays of data is to avoid memory fragmentation and
improve data locality.  Now consider in
Listing~\ref{listing:someBlockAlgo-std-vector} what the client code
would have to look like when using the form of {}\ttt{transform(...)} 
in Listing~\ref{listing:addArrayIntoArray-std-vector} which takes in
{}\ttt{std::vector} objects.

{}\begin{listing}: Client code that has to create temporary
{}\ttt{std::vector} objects to call function that takes
{}\ttt{std::vector} arguments
\label{listing:someBlockAlgo-std-vector}
{\small\begin{verbatim}
  void someBlockAlgo( const BlockTransformerBase &transfomer,
    const int numBlocks, const std::vector<double> &big_a,
    std::vector<double> &big_b )
  {
    DEBUG_MODE_ASSERT_EQUALITY( big_a.size(), big_b.size() );
    const int totalLen = big_a.size();
    const int blockSize = totalLen/numBlocks; // Assume no remainder!
    
    const int blockOffset = 0;
    for (int block_k = 0; block_k < numBlocks; ++block_k, blockOffset += blockSize)
    {
      if (big_a[blockOffset] > 0.0) {
        // Create temporary std::vectors to do function call
        std::vector a(big_a.begin()+blockOffset,
          big_a.begin()+blockOffset+blockSize);
        std::vector b(big_a.begin()+blockOffset,
          big_b.begin()+blockOffset+blockSize);
        // Do the operation
        transfomer.transform(a, b);
        // Copy back into the output array
        std::copy(b.begin(), b.end(), big_b.begin() + blockOffset);
      }
    }
  }
\end{verbatim}}
\end{listing}

As it is clear to see, the above client code that uses the
{}\ttt{std::vector} version of {}\ttt{transform(...)} is
neither clean, nor efficient since temporary copies of all of the data
have to be created just to make the function call and then data has be
be copied back into the full array.

Now consider the client code in
Listing~\ref{listing:someBlockAlgo-std-vector-raw-ptr} which uses the
raw C++ pointer version of {}\ttt{transform(...)} in
Listing~\ref{listing:addArrayIntoArray-raw}.

{}\begin{listing}: Example driver code that uses the raw-pointer
version of {}\ttt{transform(...)}
\label{listing:someBlockAlgo-std-vector-raw-ptr}
{\small\begin{verbatim}
  void someBlockAlgo(const BlockTransformerBase &transformer,
    const int numBlocks, const std::vector<double> &big_a,
    std::vector<double> &big_b )
  {
    DEBUG_MODE_ASSERT_EQUALITY( big_a.size(), big_b.size() ); const int
    totalLen = big_a.size(); const int blockSize = totalLen/numBlocks;
    
    const int blockOffset = 0;
    for (int block_k = 0; block_k < numBlocks; ++block_k, blockOffset += blockSize)
    {
      if (big_a[blockOffset] > 0.0) {
        transformer.transform(blockSize, &big_a[blockOffset], &big_b[blockOffset]);
      }
    }
  }
\end{verbatim}}
\end{listing}

As one can clearly see, using the raw C++ pointer version of
{}\ttt{transform(...)} makes the client code much cleaning and much
more efficient.  However, of course, if the client makes any mistakes
with its arrays of memory, then the resulting program will yield
undefined behavior and (in the best case) will segfault, or will
silently produce the wrong result, or (in the worst case) actually
produce the right result on the current platform but will fail on
other platforms.

The Teuchos memory management array classes make algorithms involving
sub-views like shown above very clean, very efficient, and very safe
(see the same versions of this example code using these new Teuchos
classes in Section~\ref{sec:array-views}).

In summary, {}\ttt{std::vector} is {}\underline{not} an efficient
or convenient general-purpose replacement for raw C++ pointers as
function arguments in many important use cases.


%
{}\subsection{Problems with relying on standard memory checking
utilities}
\label{sec:problems-with-mem-checkers}
%

Some programmers simply use raw C++ pointers and think that standard
memory checking tools like
Valgrind\footnote{{}\ttt{http://valgrind.org}} and
Purify\footnote{\ttt{http://www.ibm.com/software/awdtools/purify}}
will catch all of their mistakes.  When I first started coding in C++
back in 1996, I was very aware of the problems with using raw pointers
in C++ after experiencing the segfaults and memory leaks that all C++
programmers experience.  At the time, I had experimented some with
writing my own utility classes that encapsulated raw C++ pointers and
I considered taking that further.  However, at that time, I
conjectured that going through the effort of encapsulating all raw C++
pointers might be a waste of time because it would not be long until
someone came up with a 100\% bullet-proof memory checking tool for C++
that would make my feeble programmer-controlled attempts to wrap raw
pointers obsolete.  After more than 10+ years of C++ programming
experience where I have written hundreds of thousands of lines of C++
code on a number of different platforms/compilers, I have come to
regret that decision.

Through painful experience and then through some more careful thought,
I have come to realize that memory checking tools like Valgrind and
Purify will never be able to provide an even sufficient (certainly not
100\%) means to validate memory usage in C++ programs.  With respect
to existing tool implementations, I have experienced cases where both
Valgrind and Purify have reported not even a single warning before the
program segfaulted (while running in the tool) with essentially no
feedback at all.  I will not go into detail about what techniques
memory tools like Valgrind and Purify use to verify memory usage other
than to say that they can do a lot by just taking control of
{}\ttt{malloc(...)} and {}\ttt{free(...)} and in inserting checks into
the execution of the program by controlling the manipulation of the
program stack.

One such case where Valgrind and Purify were completely unhelpful
occurred with an off-by-one error with {}\ttt{std::vector} using
Linux/gcc (before I learned the GCC had a checked STL implementation).
In the end, the way that I found the off-by-one error was by just
staring at the code over and over again until I happened to see the
problem.  However, what I discovered through two days of debugging was
that {}\ttt{std::vector} used its own allocator which allocated big
chunks of memory through {}\ttt{malloc(...)}.  It then proceeded to do
its own memory allocation scheme, which was very fast but was
invisible to the watchful eyes of Valgrind and Purify.  Any reads to
this block of memory looked fine to Valgrind and Purify because it was
all contained within the block returned from {}\ttt{malloc(...)}.
What the off-by-one error did was to write over a library managed part
of the memory block and that silent corruption would doom a later
attempt by {}\ttt{std::vector} to allocate memory.

There are other categories of use cases where external memory checking
tools like Valgrind and Purify will never be able to verify correct
memory usage.  One example is semantic off-by-one errors committed in
larger blocks of data.  To demonstrate this type of error, consider
the example code in the function {}\ttt{someBlockAlgo(...)} in
Listing~\ref{listing:someBlockAlgo-std-vector-raw-ptr} which uses the
raw C++ pointer version of the function {}\ttt{transform(...)} in
Listing~\ref{listing:addArrayIntoArray-raw}.  Now consider what
happens when a developer introduces an off-by-one error such as shown
in {}\ttt{transform(...)} in
Listing~\ref{listing:addArrayIntoArray_rawError}.

\begin{listing}:\\
\label{listing:addArrayIntoArray_rawError}
{\small\begin{verbatim}
  template<class T>
  void AddIntoTransformer<T>::transform( const int n, const T a[], T b[] )
  {
    for (int i = 0; i <= n; ++i)
      b[i] += a[i];
  }
\end{verbatim}}
\end{listing}

In case it is not obvious, the off-by-one error shown in
Listing~\ref{listing:addArrayIntoArray_rawError} is the replacement of
the loop termination statement {}\ttt{i < n} with {}\ttt{i <= n} which
is a very common C++ programming error.

Now let's consider the implications that the off-by-one error shown in
Listing~\ref{listing:addArrayIntoArray_rawError} will have on the data
in {}\ttt{big\_b} as driven by the code in
Listing~\ref{listing:someBlockAlgo-std-vector-raw-ptr}.  If the last
block {}\ttt{block\_k=numBlocks-1} of data is processed, then there is
a reasonable chance a memory checking tool like Valgrind would catch
the off-by-one error being committed at the very end of the array
{}\ttt{big\_b}.  However, as described above, Valgrind may not catch
even this type of error.  Also, note that turning on bounds checking
with {}\ttt{std::vector} (i.e.\ by enabling {}\ttt{\_GLIB\_CXX\_DEBUG}
with gcc) will not catch this error either because of the way the raw
pointers are extracted in and and passed in the function call:

{\small\begin{verbatim}
  transformer.transform(blockSize, &big_a[blockOffset], &big_b[blockOffset]);
\end{verbatim}}

Now consider a defect caused by this off-by-one error for which no
automated memory checking tool that will ever be devised will ever be
able to catch.  This type of defect will occur, for example, when for
the last block {}\ttt{block\_k=numBlocks-1} we have
{}\ttt{big\_a[(numBlocks-2)*blockSize] > 0.0} and
{}\ttt{big\_a[(numBlocks-1)*blockSize] <= 0.0}.  In this case, only
the next-to-last block of data will be processed by the defective
{}\ttt{transform(...)} function.  This will not result in a classic
off-by-one error that a memory checking tool would catch because it
would not touch memory outside of what is stored in {}\ttt{big\_b}.
However, this off-by-one error committed in
Listing~\ref{listing:addArrayIntoArray_rawError} would result in the
array entry {}\ttt{big\_b[(numBlocks-2)*blockSize+blockSize]} being
erroneously modified.  This is a defect that might only slightly
damage the final result of the program for the typical use case and
might therefore go unnoticed for years.  However, when the program was
really being used for something important years later for a
non-typical use case, this small off-by-one error could result in
reporting incorrect results with perhaps disastrous consequences.

The point that is trying to be made in the above example is that
automated memory checking tools like Valgrind and Purify will never be
able to check the {}\textit{semantic} correctness of the usage of
memory.  The semantic off-by-one defect described above is 100\%
correct from a strict memory usage point of view (i.e.\ only allocated
memory can be written to and only allocated and initialized memory can
be read from) but is 100\% wrong from a semantic point of view (i.e.\
the function {}\ttt{transform(...)} can only operate on the elements
of data from {}\ttt{0} to {}\ttt{n-1}).  The array memory management
classes in Teuchos described in this document help to verify that
memory is used in a semantically correct way and throws exceptions for
these types of errors in a debug-mode build.

% ToDo: Give a summary of the bad appraoches to handling memory and
% memory checking tools.


%
{}\section{Important prerequisites}
\label{sec:important-prerequisites}
%

Before finally discussing the Teuchos memory management classes, a set
of prerequisite concepts are presented that are needed in order to
understand the holistic memory management approach.


%
{}\subsection{Value types versus reference types}
\label{sec:value-and-reference-types}
%

Because of the flexibility of C++, many C++ programmers can and do
implement a wide variety of types yielding objects with different
types of usage semantics.  A quick summary of common ``accepted''
class types in C++ is given in Item 33 ``Be clear what kind of class
you're writing'' in {}\cite{C++CodingStandards05}.  There is little
point here in trying to classify all of the crazy ways that people
have used to code objects in C++ that stray from these ``accepted''
class types.  Instead, the recommendation here is to classify the
majority of classes as either {}\textit{value types} or
{}\textit{reference types}.  Value types and reference types are said
to use {}\textit{value semantics} and {}\textit{reference semantics},
respectively, and that is sometimes how these data-types are described
in various C++ literature.

{}\textit{Value types} in general:

\begin{itemize}

{}\item have public destructors, default constructors, copy
constructors, and assignment operators (all implementing deep copy
semantics),

{}\item have an identity that is determined by their value not their
address,

{}\item are usually allocated on the stack or as direct data members
in other class objects,

{}\item are usually {}\underline{not} allocated on the heap (but can
be for most value-type classes), and

{}\item do not have any virtual functions and are not to be used as
base classes (see Item 35 in {}\cite{C++CodingStandards05}).

\end{itemize}

If {}\ttt{S} denotes a typical value type, the class definition of
{}\ttt{S} includes:

{\small\begin{verbatim}
  class S {
  pubic:
    ~S();
    S();
    S(const S&);
    S& operator=(const S&);
    ...
  };
\end{verbatim}}

All of the built-in intrinsic C++ data-types like {}\ttt{char},
{}\ttt{int}, and {}\ttt{double} are value types.  Likewise, class
types like {}\ttt{std::complex} and {}\ttt{std::vector} are also value
types.  Value types have also been called by other names in the C++
literature.  Stroustrup refers to value types as ``true local
variables'' in {}\cite{stroustrup94}.  The term Abstract Data Type
(ADT) in older C++ literature such as {}\cite{AdvancedC++92} usually
maps to the concept of a value type, but usually carries greater
significance in implying that operator overloading is used to make an
ADT look more like a built-in C++ type (such as is the case for
{}\ttt{std::complex}).

Alternatively, {}\textit{reference types} in general:

\begin{itemize}

{}\item do not have a public copy constructor or assignment operator,

{}\item are manipulated through a (smart) pointer or reference,

{}\item have an identity that is primarily determined by their address
and not their value,

{}\item are allocated on the heap,

{}\item typically are not permitted to be or cannot be allocated on
the stack,

{}\item are copied through an abstract clone function (if copying is
allowed at all),

{}\item have one or more virtual functions, and

{}\item are usually designed to be used as base classes or are derived
from base classes.

\end{itemize}

Reference types (employing reference semantics) are typically used for
base classes in C++.  Examples of base classes in the C++ standard
library include {}\ttt{std::ios\_base} and
{}\ttt{std::basic\_streambuf}.  Reference types in the form of
abstract base classes form the foundation for object-oriented
programming in C++.

If {}\ttt{A} denotes a typical reference type class, the class
definition of {}\ttt{A} generally includes:

{\small\begin{verbatim}
  class A {
  pubic:
    virtual ~A();
    virtual A* clone() const = 0;  // NOTE: Should use RCP (see later)
    virtual void someFunc() = 0;
    ...
  protected: // or private
    A(const A&);
    A& operator=(const A&);
    ...
  };
\end{verbatim}}

Note that one can almost always choose to manipulate a value type 
using reference semantics.  For example, it is very common to choose
to dynamically allocate large value objects like {}\ttt{std::vector}
and then pass around (smart) pointers and references to the object to
avoid unnecessary and expensive copying and to facilitate the sharing
of state.

While the ideas of value types and reference types and value semantics
and reference semantics are long established in the C++ literature
(even if the terminology is not very uniform), many C++ programmers
either seem to not know about these idioms or choose not to follow
them for some reason.  By forcing the majority of classes into either
using {}\textit{value semantics} or {}\textit{reference semantics} one
eliminates meaningless variability in C++ programs and frees one's
self to think about more important things (see the discussion of using
standards to actually improve creativity in
{}\cite{CodeComplete2nd04}).

{}\textbf{Side Note:} The somewhat rigid classification of C++ types
into value types and reference types is similar in motivation and in
many other respects to Eric Evans' differentiation of all domain types
into {}\textit{Value Objects} and {}\textit{Entities} in Domain Driven
Design (DDD) {}\cite{DomainDrivenDesign}.  While there are
similarities between DDD's Value Objects and Entities and C++'s value
types and reference types, respectively, there is not a one-to-one
mapping.  In DDD, the distinction between a Value Object and an Entity
has more to do with the nature of the object in relation to the domain
model and is not related to how memory is manged.  Evans assumes that
one is using a language like Java where all objects use reference
semantics.


%
{}\subsection{Non-persisting versus persisting and semi-persisting
associations}
\label{sec:nonpersisting-persisting-associations}
%

Another important prerequisite for understanding the Teuchos memory
management classes is the distinction between {}\textit{non-persisting
associations} and {}\textit{persisting associations}.  Working
definitions for these are:

\begin{itemize}

{}\item\textit{Non-Persisting associations} are associations between
two or more objects that exist only within a single function call for
formal function arguments, or a single statement for function return
objects, where no memory of any of the objects is retained as a side
effect after the function returns or the statement ends.

{}\item\textit{Persisting associations} are associations that exist
between two or more objects that extend past a single function call
for formal function arguments, or a single statement for function
return objects.

\end{itemize}

To help define these two different types of associations, consider the
class and function definitions in
Listing~\ref{listing:NonPersistingPersistingAssociationsRawPointers}
and shown in Figure~\ref{fig:UML_A_B_C}.


{}\begin{listing}: Classes using raw pointers with both non-persisting
and persisting associations
\label{listing:NonPersistingPersistingAssociationsRawPointers}
{\small\begin{verbatim}
  class A {
  public:
    void fooA() const;
  };

  class B {
  public:
    void fooB1(const A &a) { a.fooA(); }
    void fooB2() const { ... }
  };

  class C {
    B* b_;    
  public:
    C() : b_(0) {}
    void fooC1(B &b, const A &a)
      { b_ = &b; b_->fooB1(A); }
    void fooC2() const
      { b_->fooB2(); }
  };

  void someFunc(C &c, B &b, const A &a)
  {
    c.fooC1(b, a);
    c.fooC2();
  }
\end{verbatim}}
\end{listing}


The function {}\ttt{B::fooB1(...)} in
Listing~\ref{listing:NonPersistingPersistingAssociationsRawPointers}
involves a non-persisting association with respect to the {}\ttt{A}
and {}\ttt{B} objects since no memory of the object {}\ttt{a} remains
after the function {}\ttt{B::fooB1(...)} exists.  Non-persisting
associations represent typical input/output-only arguments to a
function.

The function {}\ttt{C::fooC1(...)} in
Listing~\ref{listing:NonPersistingPersistingAssociationsRawPointers}
creates a persisting association between a {}\ttt{C} object and a
{}\ttt{B} object since the memory of the {}\ttt{B} object is retained
in the {}\ttt{C} object that persists after the function
{}\ttt{C::fooC1(...)} exits.  This memory of the {}\ttt{B} object
stored in the {}\ttt{C::b\_} pointer data member is then used to
implement the function {}\ttt{C::fooC2()}.  Note that the function
{}\ttt{C::fooC1(...)} also involves a non-persisting association with
the {}\ttt{A} object {}\ttt{a} since it is only used to call
{}\ttt{B::fooB1(...)} and no memory of {}\ttt{a} lingers after
{}\ttt{C::fooC1(...)} exists.

Another interesting case is the nonmember function
{}\ttt{someFunc(...)} also shown in
Listing~\ref{listing:NonPersistingPersistingAssociationsRawPointers}.
While {}\ttt{someFunc(...)} is a free function, it actually involves
the creation of a persisting association between the {}\ttt{C} and
{}\ttt{B} objects as a side effect because it calls the
{}\ttt{C::fooC1(...)} function.

In the idioms advocated in this paper, smart reference counted
pointers are used for all persisting associations and never for
non-persisting associations.  Using the basic Teuchos {}\ttt{RCP}
class, the raw pointer code in
Listing~\ref{listing:NonPersistingPersistingAssociationsRawPointers}
would be refactored into the code shown in
Listing~\ref{listing:NonPersistingPersistingAssociationsRCP}.


{}\begin{listing}: Refactored classes to use {}\ttt{RCP} for
persisting associations
\label{listing:NonPersistingPersistingAssociationsRCP}
{\small\begin{verbatim}
  class A {
  public:
    void fooA() const;
  };

  class B {
  public:
    void fooB1(const A &a) { a.fooA(); }
    void fooB2() const { ... }
  };

  class C {
    RCP<B> b_;
  public:
    void fooC1(const RCP<B> &b, const A &a)
      { b_ = b; b_->fooB1(A); }
    void fooC2() const
      { b_->fooB2(); }
  };

  void someFunc(C &c, const RCP<B> &b, const A &a)
  {
    c.fooC1(b, a);
    c.fooC2();
  }
\end{verbatim}}
\end{listing}


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=0.65]{UML_A_B_C}
%}
\end{center}
\caption[UML Class Diagram showing non-persisting and persisting associations]{
\label{fig:UML_A_B_C}
UML Class Diagram showing non-persisting and persisting associations
for classes in
Listing~\ref{listing:NonPersistingPersistingAssociationsRawPointers}
and Listing~\ref{listing:NonPersistingPersistingAssociationsRCP}.}
\end{figure}
\esinglespace}


Note that the classes {}\ttt{A} and {}\ttt{B} remain unchanged because
they do not involve any persisting associations.  It is only the class
{}\ttt{C} that needed to be refactored to handle the persisting
association with {}\ttt{B}.  The non-member function
{}\texttt{someFunc(...)} is also be modified since the creation of a
persisting association is involved.

Most programming languages do not provide any means to differentiate
between non-persisting associations and persisting associations (see
Section~\ref{sec:essentail-accidental-complexity} for an expanded
discussion).  However, note that the Unified Modeling Language (UML
{}\cite{UMLDistilledThirdEdition04}) does differentiate between them
in that persisting relationships are shown with a solid line while
non-persisting relationships are shown with a dotted line as depicted
for these example classes in Figure~\ref{fig:UML_A_B_C}.

Another situation where the concepts of persisting and non-persisting
associations comes up relates to how objects are returned by C++
functions as return values.  A persisting relationship is created
through a function return object if that object is remembered past a
single statement.  For example, consider the code fragment in
Listing~\ref{listing:bad-perist-example}.


{}\begin{listing}: Example of a dangerous type of persisting
association that can result in undefined behavior (e.g.\ segfault)
\label{listing:bad-perist-example}
{\small\begin{verbatim}
  std::vector<int> v(n);
  ...
  int &ele = v[0];  // Creates a persisting return object relationship
  ...
  ele = 5;          // Changes v[0] much later!
\end{verbatim}}
\end{listing}


The code fragment in Listing~\ref{listing:bad-perist-example} shows a
presenting relationship between the client code that is initializing
the local reference {}\ttt{ele} and the {}\ttt{std::vector} container
object {}\ttt{v}.  This is very fragile and dangerous code because if
{}\ttt{v} is re-sized, grown or have some other type of change, then
the reference pointed to by {}\ttt{ele} can become invalid.  For
example, the following code fragment will likely result in a runtime
memory usage error with undefined behavior and (if one is lucky) will
segfault:

\begin{listing}:\\
{\small\begin{verbatim}
  std::vector<int> v(n);
  int &ele = v[0];
  v.resize(10*n);
  ele = 5;  // ele is likely to be invalid here!
\end{verbatim}}
\end{listing}

If one is unlucky, the statement {}\ttt{ele = 5} will work just fine on one
platform with one implementation of the {}\ttt{std::vector} but will break on
another platform when run with a different data set.  Note that tools like
Valgrind and Purify may not flag the problem due to the way that many
implementations of {}\ttt{std::vector} deal with memory.

Basically the problem here is that the
{}\ttt{std::vector::operator[](size\_type)} function returns a raw C++
reference that should never be remembered past a single statement.
The safe way to change an element is:

\begin{listing}:\\
{\small\begin{verbatim}
  std::vector<int> v(n);
  v[0] = 5; // Non-persisting relationship!
  v.resize(10*n);
\end{verbatim}}
\end{listing}

Therefore, functions like {}\ttt{std::vector::operator[](size\_type)}
which return raw C++ references should only be used for non-persisting
associations as shown above.

Before leaving the topic of persisting and non-persisting associations, one
has to recognize that there exists a third category of associations that lie
in between strict persisting and non-persisting associations.  This gray area
will be referred to here as semi-persisting associations defined as:

\begin{itemize}

{}\item\textit{Semi-persisting associations} are associations that (like
persisting associations) exist between two or more objects that extend past a
single function call for formal function arguments, or a single statement for
function return objects except where the use of the objects and the lifetime
of the association have more rigid constraints requiring greater care in use.

\end{itemize}

An example of a semi-persisting association is the use of an iterator
to access an STL container as shown in
Listing~\ref{listing:SemiPersistingIterators}:


\begin{listing}:\\
\label{listing:SemiPersistingIterators}
{\small\begin{verbatim}

  void someFunc(std::vector<int> &v)
  {
    typedef std::vector<int>::iterator itr_t;
    for (itr_t itr = v.begin(); itr != v.end(); ++itr) {
      *itr = 5;
    }
  }
\end{verbatim}}
\end{listing}


As shown in Listing~\ref{listing:SemiPersistingIterators}, the
iterator object {}\ttt{itr} is used well past (perhaps thousands of
loop iterations) where it was created by the statement {}\ttt{itr\_t
itr = v.begin()}.  There are, however, significant restrictions on how
such iterators can be used: a) the iterator cannot be accessed after
the originating parent object has been destroyed, and b) the iterator
cannot be accessed after the structure of the originating parent has
changed (e.g.\ {}\ttt{v.resize(...)} was called).  For the sake of
performance, one has to allow for the use of semi-persisting
associations such as this where the optimized build of the code lacks
the machinery to detect invalid usage.  However, note that in the case
of the STL containers that in a debug-mode checked STL build
(supported by GCC and the Microsoft compiles for instance), these
types of dangling iterator references will typically be safely
detected.  This type of debug-mode runtime checking is the saving
grace for the use of iterators and other types of semi-persisting
associations which makes their use acceptable.  If iterators to
{}\ttt{std::vector} where simply hard-coded as raw pointers, this type
of debug-mode runtime checking would not be possible.

Semi-persisting associations also play a role in the use of the
Teuchos memory management classes in situations where performance is
critical (see Section~\ref{sec:perf-tuning-strategies} and
Commandments~\ref{cmnd:ptr-semi-persisting} and
{}\ref{cmnd:arrayview-semi-persisting} in
Appendix~\ref{apdx:commandments}).


%
{}\section{Teuchos classes for safer memory management and usage}
\label{sec:teuchos-mem-mng-classes}
%

The primary purpose for the Teuchos memory management classes is to
encapsulate all raw C++ pointers in all high-level code and eliminate
undefined behavior in C++ programs without sacrificing portability,
control or efficiency.  These classes are efficient and general and,
in a debug-mode build of the code, will catch and gracefully report
99\% or so of the programming errors typically made with the
ubiquitous high-level use of raw C++ pointers.


%
{}\subsection{Overview of basic approach employed by Teuchos
memory management classes}
\label{sec:overview_of_basic_approach}
%

The basic approach being advocated here and implemented in the Teuchos
memory management classes is to:

\begin{itemize}

{}\item Encapsulate all raw C++ pointers in high-level code using
specially designed memory management classes, capture raw C++ pointers
as soon as possible, and encapsulate raw calls to {}\ttt{new} in
library and application code.

{}\item Provide a complete set of cooperating types that work together
to safely and conveniently implement all hand-offs of encapsulated raw
C++ pointers using carefully scrutinized conversion code provided with
the classes.  Also, never define implicit conversions from these safe
types to raw C++ pointers (or the safety of the entire type system
falls apart).

{}\item Differentiate memory management classes for handling single
objects from those for handling contiguous arrays of objects.

{}\item Differentiate memory management classes according to
persisting and non-persisting (and semi-persisting) associations.

  \begin{itemize}

  {}\item Use reference counting for memory management classes
  designed to handle persisting associations.

  {}\item Do not impose the overhead of reference counting for memory
  management classes designed to handle non-persisting associations.

  {}\item Do not impose the overhead of reference counting for memory
  management classes designed to handle semi-persisting associations
  (but provide the machinery for strong debug-mode runtime checking).

  \end{itemize}

{}\item Provide encapsulations for all uses of raw C++ pointers for
arrays of contiguous objects including dynamically sized arrays,
statically sized arrays, and stack-based arrays.

{}\item Provide a default {}\textit{optimized mode} where maximum
performance and minimal overhead are the goals where raw C++ pointer
performance is achieved for all reasonable use cases.

{}\item Provide an optional {}\textit{debug mode} whose goal is to
provide maximum runtime checking with reasonably low overhead in order
to catch all sorts of common errors like:

  \begin{itemize}

  {}\item Dereferencing null pointers
  (Section~\ref{sec:null-dereferences-range-checking})

  {}\item Array access errors like off-by-one and other errors
  (Section~\ref{sec:null-dereferences-range-checking})

  {}\item Incorrect iterator usage
  (Section~\ref{sec:null-dereferences-range-checking})

  {}\item Circular dependencies
  (Section~\ref{sec:detection-circular-references})

  {}\item Dereferencing dangling pointers (references)
  (Section~\ref{sec:detection-dangling-references})

  {}\item Multiple owning reference-counting node object
  (Section~\ref{sec:detection-dual-owning-rcps})

  \end{itemize}

{}\item Structure debug-mode checking such that it does not alter the
observable behavior of correct programs in any way.  However, when
debug-mode checking is enabled, the software should never yield
undefined behavior (e.g.\ segfault).

\end{itemize}


\begin{table}
\begin{center}
\input{BasicTeuchosSmartPointerClasses}
\end{center}
\caption{\label{tbl:BasicSingleArrayTypes}
Basic Teuchos memory management utility classes for encapsulating raw
pointers.}
\end{table}


\begin{table}
\begin{center}
\input{OperationsSummaryTable}
\end{center}
\caption{\label{tbl:TypesSummary}
Summary of capabilities of the basic Teuchos memory management
classes.}
\end{table}

The basic templated Teuchos memory management classes for
encapsulating raw C++ pointers for single objects and arrays are
{}\ttt{Ptr}, {}\ttt{RCP}, {}\ttt{ArrayView}, and {}\ttt{ArrayRCP}
shown in Table~\ref{tbl:BasicSingleArrayTypes}.  A summary of the
capabilities of these classes is shown in
Table~\ref{tbl:TypesSummary}.  What one can see from this table is
that raw pointer-like functionality is partitioned across these
various sets of classes in logical and safe ways.  For example,
array-related operations are not defined on the single-object classes
{}\ttt{Ptr} and {}\ttt{RCP} but implicit conversion from derived types
to base types is allowed.  Alternatively, the array classes
{}\ttt{ArrayView}, and {}\ttt{ArrayRCP} do {}\underline{not} support
the dangerous and ill-conceived ability to implicitly convert arrays
of derived types to arrays of base types that is discussed in
Section~\ref{sec:problem-with-raw-array-pointers}.  Note that the
class {}\ttt{ArrayView} does not support all of the raw pointer
iterator-like operations that {}\ttt{ArrayRCP} supports like the
dereference operator {}\ttt{operator*()} or the pointer offset
functions that change the pointer.  The reason that {}\ttt{ArrayRCP}
does support these iterator-like operations is so that it can be used
as a general purpose iterator implementation while {}\ttt{ArrayView}
objects do not need to be used in this way.  Note that all of the
array classes defined in Teuchos all support a basic iterator
interface with the {}\ttt{[const]\_iterator} member typedefs and the
functions {}\ttt{begin()} and {}\ttt{end()}.  In optimized mode, these
iterators are simply raw C++ pointers yielding maximum performance.
However, in debug mode, the iterators are implemented as
{}\ttt{ArrayRCP} objects resulting in fully checked iterators.

\begin{table}
\begin{center}
\input{ArrayContainersTable}
\end{center}
\caption{\label{tbl:ExtendedArrayTypes}
Teuchos array container classes.}
\end{table}

In addition to the four basic memory management classes shown in
Table~\ref{tbl:BasicSingleArrayTypes} (which provide the most
fundamental encapsulations for all raw C++ pointers in all high-level
code) Teuchos also contains a few other array container classes for a
few more specific use cases shown in
Table~\ref{tbl:ExtendedArrayTypes}.  The array container classes
{}\ttt{Array} and {}\ttt{Tuple} pretty much cover the majority of use
cases in C++ where raw C++ pointer arrays are used for containers.
The class {}\ttt{Array} is a direct replacement for
{}\ttt{std::vector} and actually wraps it internally.

Note that all of these classes are templated on value types and are
themselves value-types (see
Section~\ref{sec:value-and-reference-types}).  This means that one can
embed these types in each other in any arbitrary order to create any
type of data structure that one would like.  For example, one could
have {}\ttt{Array<RCP<ArrayRCP<ArrayView<Tuple<Ptr<T>,5> > > > > >}.
By understanding what each of these types provide and what each type
means (in terms of the idioms defined in Section~\ref{sec:idioms}),
one can achieve almost anything in a way that is self documenting.

These classes all work together to provide a high level of debug-mode
runtime checking to catch the majority of common programming errors
and report these errors gracefully with informative error messages.  A
debug-mode build of the code is facilitated by defining the
preprocessor macro {}\ttt{TEUCHOS\_DEBUG} (through the CMake
configuration variable {}\ttt{Teuchos\_ENABLE\_DEBUG=ON}).  When
{}\ttt{TEUCHOS\_DEBUG} is not defined, the Teuchos memory management
classes are configured to impart minimal overhead and yield fast
performance.  When {}\ttt{TEUCHOS\_DEBUG} is defined, these classes
are configured to perform maximal debug runtime checking.  These
classes are also carefully designed so that if a program is
implemented correctly using these classes and executes correctly in
optimized mode, then the program compiled with the debug checking
turned on will execute in exactly the same way.  However, if any
undefined, dangerous, or just plain wrong behavior is being used, then
these memory management classes will throw exceptions and the
exception objects will have very good error messages embedded in them
making it easier to debug and fix the problems.

What is important to understand is that all of these memory management
classes must be developed together with knowledge of each other's
internal implementations in order to provide solid debug-mode runtime
checking.  For example, in general, one cannot mix together different
memory management classes like {}\ttt{boost::shared\_ptr} (i.e.\
{}\ttt{std::shared\_ptr} in C++0x) and {}\ttt{std::vector} with the
Teuchos memory management classes at the user level and provide the
same high level of runtime checking that is supported by the complete
system of Teuchos memory management classes.  More details about why
this is so are given in Section~\ref{sec:debug-mode-runtime-checking}
in the context of debug-mode runtime checking for and reporting of
dangling references.

As with the development of any set of C++ classes, a set of
accompanying idioms must also be developed for maximizing their
effective use.  The idioms described in this paper involving the
Teuchos memory management classes result in code with maximum
compile-time checking, maximum debug-mode runtime checking, near
optimal perforamnce, and maximally self-documenting.


%
{}\subsection{The proper role of raw C++ pointers}
\label{sec:role-of-raw-pointers}
%

The main thesis of this paper is that the use of all raw C++ pointers
should be fully encapsulated in all high-level C++ code and instead a
system of safe specially designed types tailored to specific use cases
should be used instead.  Does that mean that raw C++ pointers should
never be used in any C++ code?  The answer of course is
{}\underline{no}, since raw C++ pointers will always have to be used
in some special situations (but perhaps not directly used as described
below).

Given the full use of the Teuchos memory management classes, here are
the valid situations where it is appropriate (or required) to use raw
C++ pointers in fully compliant C++ programs:

\begin{itemize}

{}\item{}\textit{Use raw C++ pointers (indirectly) for extremely
well-encapsulated, low-level, high-performance algorithms}

In order to achieve high performance in computationally intensive
code, one will always have to use raw C++ pointers (at least
indirectly) in a non-debug optimized build.  This includes using raw
C++ pointers to build specialized data structures and similar
purposes.  In this context, one can think of raw C++ pointers as a
fairly compact and efficient way to communicate with the compiler
about how one wants to manage memory at the hardware level.  The
ability to do this type of fine-grained manipulation of memory has
always been one of the strengths of C and C++ in systems-level
programming.  Therefore, one can think of using raw pointers in C++ as
a kind of portable assembly language that one always has at one's
disposal on every platform and with every compiler.  However, instead
of using raw pointers, one can always use the types {}\ttt{Ptr},
{}\ttt{ArrayView} or {}\ttt{ArrayType::iterator} (where
{}\ttt{ArrayType} is {}\ttt{Array}, {}\ttt{ArrayRCP}, or
{}\ttt{ArrayView}) to yield raw pointer performance in a non-debug
optimized build but still maintain strong debug-mode runtime checking.
This approach is discuss in more detail in
Section~\ref{sec:perf-tuning-strategies}.

{}\item{}\textit{Use raw C++ pointers to communicate with legacy C++
code and with other languages through C bindings}

The only remaining valid reason to use raw C++ pointers is to reuse
and communicate with legacy C++ code and to call functions in other
languages through the now-universal approach of using C bindings.
However, one must endeavor to minimize the amount of C++ code that has
naked raw C++ pointers and one should only expose a raw C++ pointer at
the last possible moment (such as in the call to the external
functions themselves).  Again, one must carefully encapsulate access
to non-compliant code that requires the exposure of raw C++ pointers.

\end{itemize}

One point is worth nothing here which is that in this new modern C++
software one must never use raw C++ pointers in the basic interfaces
between the various modules as that is where a majority of mistakes in
the use of memory will be made.  This goes somewhat contrary to the
advice in Item 63 ``Use sufficiently portable types in a module's
interface'' in {}\cite{C++CodingStandards05}.  If this new modern safe
C++ software must be called by non-compliant software that uses raw
C++ pointers, then one can provide specialized C-like interfaces for
those clients that use raw C++ pointers for communication.  Of course,
once one does this, one will have to rely on clients to pass in memory
correctly and keep it valid as long as local modules need it.

%
{}\subsection{Common aspects of all Teuchos memory management classes}
\label{sec:common-aspects}
%

Table~\ref{tbl:common-type-members} gives the member and non-member
functions common all the Teuchos memory management classes {}\ttt{Ptr},
{}\ttt{RCP}, {}\ttt{Array}, {}\ttt{ArrayView}, {}\ttt{ArrayRCP}, and
{}\ttt{Tuple}.  The comparison operators allows all of these types to be used
as keys in associative containers like {}\ttt{std::map}.  The member function
{}\ttt{getRawPtr()} is actually an incredibly useful function that will return
a null pointer (i.e.\ 0) when the underlying smart pointer is null (such as
with {}\ttt{Ptr}, {}\ttt{RCP}, {}\ttt{ArrayRCP}, and {}\ttt{ArrayView}) or
when the container has size zero (such as with {}\ttt{Array}).

\begin{table}
{\small\begin{center}
\begin{tabular}{|l|}
\hline
{}\textbf{Common member functions} \\
\hline
{}\ttt{T* getRawPtr() [const]} \\
\hline
{}\textbf{Common nonmember functions} \\
\hline
{}\ttt{void swap(Type<T>\&, Type<T>\&)} \\
{}\ttt{bool is\_null(const Type<T>\&)} \\
{}\ttt{bool nonnull(const Type<T>\&)} \\
{}\ttt{bool operator==(const Type<T>\&, ENull)} \\
{}\ttt{bool operator!=(const Type<T>\&, ENull)} \\
{}\ttt{bool operator==(const Type<T>\&, const Type<T>\&)} \\
{}\ttt{bool operator!=(const Type<T>\&, const Type<T>\&)} \\
{}\ttt{bool operator<(const Type<T>\&, const Type<T>\&)} \\
{}\ttt{bool operator<=(const Type<T>\&, const Type<T>\&)} \\
{}\ttt{bool operator>(const Type<T>\&, const Type<T>\&)} \\
{}\ttt{bool operator>=(const Type<T>\&, const Type<T>\&)} \\
\hline
\end{tabular}
\caption[Common members and non-members for all types]{
\label{tbl:common-type-members}
Common members and non-members for {}\ttt{Type} = {}\ttt{Ptr},
{}\ttt{RCP}, {}\ttt{Array} {}\ttt{ArrayRCP}, {}\ttt{ArrayView}, and
{}\ttt{Tuple}.}
\end{center}}
\end{table}

% ToDo: Implement all of the ``Common nonmember functions'' in all
% Teuchos memory management classes.


%
{}\subsection{Memory management classes replacing raw pointers for
single objects}
\label{sec:mem-mng-classes-single-objs}
%

The templated classes {}\ttt{Ptr} and {}\ttt{RCP} described in the
next two sections are used to encapsulate raw C++ pointers to single
objects.  Again, {}\ttt{Ptr} is used for non-persisting (and
semi-persisting) associations and {}\ttt{RCP} is used for persisting
associations.  Below, and in all of the code listings, it is assumed
that the code is enclosed in the {}\ttt{Teuchos} namespace or there
are appropriate {}\ttt{using Teuchos::XXX} declarations (as is safe
and appropriate) for the various names in place.

%
{}\subsubsection{\ttt{Teuchos::Ptr<T>}}
\label{sec:Ptr}
%

The templated class {}\ttt{Ptr} is the simplest of all the Teuchos
memory management classes.  In optimized mode it is just the thinnest
of wrappers around a raw C++ pointer.  Listing~\ref{listing:Ptr}
shows what the implementation of {}\ttt{Ptr} looks like in
optimized mode:

\begin{listing}: Teuchos::Ptr class\\
\label{listing:Ptr}
{\small\begin{verbatim}
  template<class T>
  class Ptr {
  public:
    Ptr( ENull null_in = null ) : ptr_(0) {}
    explicit Ptr( T *ptr ) : ptr_(ptr) {}
    Ptr(const Ptr<T>& ptr) : ptr_(ptr.ptr_) {}
    template<class T2> Ptr(const Ptr<T2>& ptr) : ptr_(ptr.ptr_) {}
    Ptr<T>& operator=(const Ptr<T>& ptr) { ptr_=ptr.ptr_; return *this; }
    T* operator->() const { return ptr_; }
    T& operator*() const { return *ptr_; }
    T* getRawPtr() const { return ptr_; }
    T* get() const { return ptr_; } // For compatibility with shared_ptr
    const Ptr<T>& assert_not_null() const;
  private:
    T *ptr_;
  };
\end{verbatim}}
\end{listing}

In optimized mode, the only overhead imparted by {}\ttt{Ptr} is the
default initialization to null (0).  All other functions are just
inline accessors to the underlying raw C++ pointer member
{}\ttt{ptr\_}.  Therefore, the performance when using this type is the
same as when using a raw C++ pointer.

However, in debug mode (enabled when {}\ttt{TEUCHOS\_DEBUG} is
defined), the {}\ttt{Ptr} class becomes more complex and performs a
number of runtime checks like for null dereferences and dangling
references (see Section~\ref{sec:detection-dangling-references}).

One note about the default null constructor shown in
Listing~\ref{listing:Ptr} which is:

{\small\begin{verbatim}
  template<class T>
  Ptr<T>::Ptr( ENull null_in = null ) : ptr_(0) {}
\end{verbatim}}

{}\noindent{}is that the type {}\ttt{ENull} is the simple enum in
the {}\ttt{Teuchos} namespace:

{\small\begin{verbatim}
  enum ENull { null };
\end{verbatim}}

This simple enum allows for the safe implicit conversion from the enum
value {}\ttt{null} to any {}\ttt{Ptr<T>} object.  For example, one can
write code like:

{\small\begin{verbatim}
  Ptr<A> a_ptr = null;
\end{verbatim}}

This implicit conversion from {}\ttt{null} is shared by the other
Teuchos memory management smart-pointer classes {}\ttt{RCP<T>},
{}\ttt{ArrayView<T>}, and {}\ttt{ArrayRCP<T>}.  This allows calling
functions that accept one of these objects and by just passing in
{}\ttt{null} when appropriate and the implicit conversion will be done
automatically if possible (see Section~\ref{sec:conversion-problems}).

The main purpose for the existence of the {}\ttt{Ptr} class is to
replace raw C++ pointers in function calls for typical input,
input/output, and output arguments where no persisting relationship is
present.  (the class {}\ttt{Ptr} should also be used for
semi-persisting associations where single objects are involved.)  For
example, consider the function that modifies a type {}\ttt{A}
object shown in Listing~\ref{listing:modifyA-rawPtr}.

{}\begin{listing}: Simple function using unsafe raw pointer
\label{listing:modifyA-rawPtr}
{\small\begin{verbatim}
  void modifyA( A *a )
  {
    assert(a);
    a->increment();
  }
\end{verbatim}}
\end{listing}

Using {}\ttt{Ptr}, the function {}\ttt{modifyA(...)} in
Listing~\ref{listing:modifyA-rawPtr} would be changed to the form
shown in Listing~\ref{listing:modifyA-Ptr}.

{}\begin{listing}: Simple function refactored to use safe {}\ttt{Ptr} wrapped
pointer
\label{listing:modifyA-Ptr}
{\small\begin{verbatim}
  void modifyA( const Ptr<A> &a )
  {
    a->increment();
  }
\end{verbatim}}
\end{listing}

In this context, the primary advantage of the form shown in
Listing~\ref{listing:modifyA-Ptr} as apposed to
Listing~\ref{listing:modifyA-rawPtr} is that in debug mode, a check
for a null pointer or a dangling reference would be performed
automatically.  If a null dereference occurred, then an exception
would be thrown with a very good error message.  I have seen platforms
where a null dereference did not automatically result in a graceful
assert, stopping the program.  I have seen cases where somehow memory
was corrupted and the program continued!  A good philosophy is to make
as few assumptions as possible about undefined behavior of the
compiler and platform because I have found that ``typical and
obvious'' behavior for undefined behavior is not universal.  Many have
learned the hard way that one will pay a price for such assumptions in
lost time debugging obscure things like a null pointer dereference
that should have stopped the program but did not.  Don't take chances
with undefined behavior in the code, take control!

When all of the high-level code has been converted over to use these
memory management classes and there are no more raw C++ pointers, then
client code should never have to construct a {}\ttt{Ptr} object using
a raw C++ pointer.  However, as code is being transitioned over and
when such code is called by non-compliant code, construction from a
raw pointer is needed.  The recommended way to convert from a raw C++
pointer to {}\ttt{Ptr} is to use the following templated non-member
function:

\begin{listing}: Teuchos::ptr(...)\\
\label{listing:ptr}
{\small\begin{verbatim}
  template<class T>  Ptr<T> ptr(T *p);
\end{verbatim}}
\end{listing}

Using this non-member constructor function, client code would then be
written as shown in Listing~\ref{listing:using-ptr}.

\begin{listing}:\\
\label{listing:using-ptr}
{\small\begin{verbatim}
  void foo( A* a )
  {
    using Teuchos::ptr;
    modifyA(ptr(a));
  }
\end{verbatim}}
\end{listing}

A more typical use case for the construction of a {}\ttt{Ptr} object
is from a raw C++ object or reference.  This type of construction
should always be performed using one of the non-member constructor
functions shown in
Listing~\ref{listing:ptr-from-ref-nonmember-constructors}.

\begin{listing}: Safe nonmember constructors for Teuchos::Ptr\\
\label{listing:ptr-from-ref-nonmember-constructors}
{\small\begin{verbatim}
  template<typename T> Ptr<T>        ptrFromRef( T& arg );
  template<typename T> Ptr<T>        inOutArg( T& arg );
  template<typename T> Ptr<T>        outArg( T& arg );
  template<typename T> Ptr<T>        optInArg( T& arg );
  template<typename T> Ptr<const T>  constOptInArg( T& arg );
\end{verbatim}}
\end{listing}

The different forms of non-member constructor functions shown in
Listing~\ref{listing:ptr-from-ref-nonmember-constructors} are to allow
for self-documenting code for calls to functions that accept
{}\ttt{Ptr}-wrapped objects.  A complete and comprehensive set of
idioms for using {}\ttt{Ptr} along with the other Teuchos memory
management types is given in Section~\ref{sec:idioms}.


%
{}\subsubsection{\ttt{Teuchos::RCP<T>}}
\label{sec:RCP}
%

The class {}\ttt{RCP}, the real workhorse of the Teuchos memory
management classes, is used to manage single objects in persisting
associations.  {}\ttt{RCP} is very similar to other high-quality
reference-counted smart pointer classes like
{}\ttt{boost::shared\_ptr} and of course the upcoming standard C++0x
class {}\ttt{std::shared\_ptr}.  However, {}\ttt{RCP} has some key
features that differentiate it from these other better known smart
pointer classes.  In particular, {}\ttt{RCP} has built in support for
the detection of circular references
(Section~\ref{sec:circular-references-weak-pointers}), has built in
support for resolving circular references with built-in weak pointers
(Section~\ref{sec:basic-reference-counting-machinery}), and other
strong debug runtime checking such as detecting multiple non-related
{}\ttt{RCP} objects owning the same reference-counted objects
(Section~\ref{sec:detection-dual-owning-rcps}) and other types of
checks.

Because the class {}\ttt{RCP} is described in
{}\cite{RefCountPtrBeginnersGuide} and is so similar in use to
{}\ttt{boost::shared\_ptr} (described some in
{}\cite{EffectiveC++ThirdEdition}), this class will not be described
in too much detail here.  However, a fairly complete definition of the
class {}\ttt{RCP} is shown in Listing~\ref{listing:RCP} (the full
listing can be found in the Doxygen documentation).

\begin{listing}: Class and helper function listing for {}\ttt{RCP} \\
\label{listing:RCP}
{\small\begin{verbatim}
  template<class T>
  class RCP {
  public:

    // General functions
    RCP(ENull null_arg = null);
    explicit RCP(T* p, bool has_ownership = false);
    template<class Dealloc_T> RCP(T* p, Dealloc_T dealloc, bool has_ownership);
    RCP(const RCP<T>& r_ptr);
    template<class T2> RCP(const RCP<T2>& r_ptr);
    ~RCP();
    RCP<T>& operator=(const RCP<T>& r_ptr);
    bool is_null() const;
    T* operator->() const;
    T& operator*() const;
    T* getRawPtr() const;
    Ptr<T> ptr() const;
  
    // Other shared_ptr compariblity functions
    ...
  
    // Reference counting member functions
    ...
  
  private:
    T *ptr_;
    RCPNodeHandle node_;
    ...
  };

  // General non-member constructor functions
  template<class T> RCP<T> rcp(T* p, bool owns_mem = true);
  template<class T> RCP<T> rcpFromRef(T& r);
  template<class T> RCP<T> rcpFromUndefRef(T& r);

  // Deallocation policy functions
  ...

  // Embedded objects functions
  ...

  // Extra data functions
  ...
 
  // Conversion functions
  ...

  // Other common non-member functions
  ...

\end{verbatim}}
\end{listing}

Again, basic usage of the {}\ttt{RCP} class is described in
{}\cite{RefCountPtrBeginnersGuide} and the functions for decallocation
policies, embedded objects, extra data, conversion functions and other
functions are discussed in other sections in a more general setting.
The basic idioms for smart pointers and reference counting are fairly
well known, are well documented in the literature, and there is a good
overview in {}\cite{RefCountPtrBeginnersGuide} so basic information
will not be replicated here.  However, some of the more advanced
functionality for {}\ttt{RCP} that is not described in
{}\cite{RefCountPtrBeginnersGuide} or an any of the existing C++
literature is described in later sections of this document.


%
{}\subsubsection{Raw C++ references}
\label{sec:raw-C++-references}
%

Why is there a subsection on raw C++ references under the a section
describing Teuchos Memory Management classes for single objects?  The
reason is that raw C++ references to single objects are used in the
idioms described in this paper for non-persisting associations for
single objects and this was a reasonable place to discuss issues with
raw C++ references.

While this paper argues that raw C++ pointers have no place in
application-level code because they are fundamentally unsafe, are C++
references also not inherently unsafe as well?  After all, under the
covers raw C++ references really are just raw C++ pointers in
disguise.  While this is true, in practice raw C++ references are
significantly safer than raw C++ pointers, especially if the idioms
outlined in this paper are carefully followed.  In addition, the use
of raw C++ references is exploited (as explained in
Section~\ref{sec:raw-C++-references}) in defining idioms that increase
the self-documenting nature of C++ code and play a role in defining
non-persisting associations related to function formal arguments and
return objects.  All in all, the increased expressiveness in using raw
C++ references is worth the increased risk of misuse (this is still
going to be C++ after all).

Basically, a raw C++ reference is relatively safe as long as a) it is
always initialized to point to a valid object, and b) it is only used
for non-persisting relationships (e.g.\ as const input arguments in
C++ functions).  If a raw C++ reference is initialized directly from
an object or from dereferencing a smart pointer, then it is guaranteed
that the object will be valid when the reference is first created (at
least in a debug build where dereferencing null smart pointers
throws).  While raw C++ references are fairly safe when used with the
idioms described in this paper, there are no 100\% guarantees.  There
are typically no guarantees that the object pointed to by a raw
reference will stay valid (because dangling references cannot be
detected as described in
Section~\ref{sec:limitations-debug-mode-checking}).  This can happen
when one breaks one or more of the idioms or guidelines defined in
this paper (which will happen because programmers make mistakes).

Note that raw C++ references should never be used for representing
semi-persisting associations because it is impossible to catch invalid
usage like dangling references.  Instead, when a semi-persisting
association is involved, always use {}\ttt{Ptr} instead of a raw C++
reference (even if the object being represented is not allowed to be
null).  Semi-persisting associations are described in more detail in
Section~\ref{sec:nonpersisting-persisting-associations} and
Section~\ref{sec:perf-tuning-strategies}.


%
{}\subsection{Memory management classes replacing raw pointers for
arrays of objects}
\label{sec:array-classes}
%

The Teuchos memory management module actually defines four different
C++ classes for dealing with contiguous arrays of objects:
{}\ttt{ArrayView}, {}\ttt{ArrayRCP}, {}\ttt{Array}, and {}\ttt{Tuple}.
As stated in Section~\ref{sec:overview_of_basic_approach} each of
these classes is needed in order to address different important use
cases for dealing with contiguous arrays of objects.  The conventions
outlined in the paper never have high-level code exposing a raw C++
pointer to an array or directly using built-in (statically sized) C++
arrays.

In addition to the common members shown in
Table~\ref{tbl:common-type-members}, all of the Teuchos array classes
provide a common subset of the interface of {}\ttt{std::vector} which
includes the typedefs and member functions shown in
Table~\ref{tbl:common-array-type-members}.

\begin{table}
{\small\begin{center}
\begin{tabular}{|l|}
\hline
{}\textbf{std::vector compatible member typedefs} \\
\hline
{}\ttt{value\_type} \\
{}\ttt{size\_type} \\
{}\ttt{difference\_type} \\
{}\ttt{pointer} \\
{}\ttt{const\_pointer} \\
{}\ttt{reference} \\
{}\ttt{const\_reference} \\
{}\ttt{iterator} \\
{}\ttt{const\_iterator} \\
{}\ttt{element\_type} \\
\hline
{}\textbf{std::vector compatible member functions} \\
\hline
{}\ttt{size\_type size()} \\
{}\ttt{[const\_]reference operator{}(size\_type) [const]} \\
{}\ttt{[const\_]reference front() const} \\
{}\ttt{[const\_]reference back() const} \\
{}\ttt{[const\_]iterator begin() [const]} \\
{}\ttt{[const\_]iterator end() [const]} \\
\hline
{}\textbf{ArrayView returning member functions} \\
\hline
{}\ttt{ArrayView<[const] T> view(size\_type offset, size\_type size) [const]} \\
{}\ttt{ArrayView<[const] T> operator[]()(size\_type offset, size\_type size) [const]} \\
{}\ttt{ArrayView<[const] T> operator()() [const]} \\
\hline
{}\textbf{Additional common member functions} \\
\hline
{}\ttt{[const\_]pointer getRawPtr() [const]} \\
{}\ttt{std::string toString() const} \\
\hline
\end{tabular}
\caption[Additional non-members for array types]{
\label{tbl:common-array-type-members}
Additional common members and non-members for {}\ttt{ArrayView},
{}\ttt{ArrayRCP}, {}\ttt{Array}, and {}\ttt{Tuple} .}
\end{center}}
\end{table}

A few things to note about the common array interface components shown in
Table~\ref{tbl:common-array-type-members} include:

\begin{itemize}

{}\item All of the Teuchos array classes are drop-in replacements for
any code that uses {}\ttt{std::vector} that does not grow or shrink
the container by supporting the necessary typedefs, query functions,
element access, and iterator access.  This helps in migrating current
code that uses {}\ttt{std::vector} but should be using {}\ttt{Array},
{}\ttt{ArrayView}, {}\ttt{ArrayRCP} or {}\ttt{Tuple}.

{}\item All of the array classes support returning \ttt{ArrayView}
subviews of contiguous ranges of elements.

{}\item All of the array classes support a handy {}\ttt{getRawPtr()}
function that allows a client to get the base pointer address to the
array or null.  The standard {}\ttt{std::vector} class supports no
such function which is very painful for users since it makes it hard
to get a null pointer then the container can legitimately be unsized
in some use cases.

\end{itemize}

The exact functions shown in Table~\ref{tbl:common-array-type-members}
for {}\ttt{ArrayView} and {}\ttt{ArrayRCP} are a little different than
for {}\ttt{Array} due to the different nature of these view classes as
apposed to the container class {}\ttt{Array}.  As described in
Section~\ref{sec:teuchos-const-nonconst-pointer-objects}, the classes
{}\ttt{ArrayView} and {}\ttt{ArrayRCP} can encapsulate both non-const
and const types {}\ttt{T} as their template argument while
{}\ttt{Array} can only accept a non-const type {}\ttt{T}.  Therefore,
the {}\ttt{std::vector} compatible functions in {}\ttt{ArrayView} and
{}\ttt{ArrayRCP} are all {}\ttt{const} functions since they don't
change what data these objects point to, but only change the data
itself.

One other aspect to note about the Teuchos array classes is that they deviate
from the standard C++ library convention of using an unsigned integer for
{}\ttt{size\_type}.  Instead, they use a signed integer for {}\ttt{size\_type}
typedefed to the signed type {}\ttt{Teuchos\_Ordinal} which is guaranteed to
be 32 bit on a 32 bit machine and 64 bit on a 64 bit
machine\footnote{{}\ttt{Teuchos\_Ordinal} is typedefed by default to the
standard C library type {}\ttt{ptrdiff\_t} which is always signed and is 32
bit on a 32 bit machine and 64 bit on a 64 bit machine.}.  The reasoning for
breaking from the {}\ttt{std::vector} standard for {}\ttt{size\_type} is
described in Appendix~\ref{sec:unsigned_size_type}.


%
{}\subsubsection{\ttt{Teuchos::ArrayView<T>}}
\label{sec:ArrayView}
%

The class {}\ttt{ArrayView}, the simplest of the Teuchos array memory
management classes, is designed to encapsulate raw pointers in
non-persisting associations primarily for formal function array
arguments.  ({}\ttt{ArrayView} is to be used for semi-persisting
associations as well.)  In an optimized build, an {}\ttt{ArrayView}
object simply holds a raw base array pointer and an integer size.  In
an optimized build, {}\ttt{ArrayView} looks like
Listing~\ref{listing:ArrayView}.

{}\begin{listing}: {}\ttt{Teuchos::ArrayView} declaration (See
Table~\ref{tbl:common-array-type-members} for common array members.)
\label{listing:ArrayView}
{\small\begin{verbatim}

  template<class T>
  class ArrayView {
  public:

    // Constructors/Assignment/Destructors
    ArrayView( ENull null_arg = null );
    ArrayView( T* p, size_type size );
    ArrayView(const ArrayView<T>& array);
    ArrayView(std::vector<typename ConstTypeTraits<T>::NonConstType>& vec);
    ArrayView(const std::vector<typename ConstTypeTraits<T>::NonConstType>& vec);
    ArrayView<T>& operator=(const ArrayView<T>& array);
    ~ArrayView();

    // Implicit conversion to const
    operator ArrayView<const T>() const;

    // Deep copy  
    void assign(const ArrayView<const T>& array) const;

    // Common array class members and other functions
    ...

  private:
    T *ptr_;     // Optimized implementation
    size_type size_;

  };

  // Non-member helpers

  template<class T>
  ArrayView<T> arrayView( T* p, typename ArrayView<T>::size_type size );

  template<class T>
  ArrayView<T> arrayViewFromVector( std::vector<T>& vec );

  template<class T>
  ArrayView<const T> arrayViewFromVector( const std::vector<T>& vec );

  template<class T>
  std::vector<T> createVector( const ArrayView<T> &av );

  template<class T>
  std::vector<T> createVector( const ArrayView<const T> &av );

  // Other common non-member helpers
  ...

  // Explicit conversion functions
  ...

\end{verbatim}}
\end{listing}

% ToDo: In the code, match up the above set of declarations with the
% class ArrayView itself.  Also, test all the typedefs to make sure they
% work correctly.

A few specific things to note about {}\ttt{ArrayView} shown in
Listing~\ref{listing:ArrayView} in addition to the comments in
Section~\ref{sec:array-classes} and other sections include:

\begin{itemize}

{}\item{}{}\ttt{ArrayView} is extremely lightweight in an optimized build,
carrying only a pointer and an integer size.  This allows one to replace the
typical pointer and separate size argument with a single aggregate
light-weight object.  Therefore, it yields very efficient code.

{}\item{}\ttt{ArrayView} in optimized mode has all trivial inlined
functions that work with the raw pointer so it is as efficient as raw
pointer code (Section~\ref{sec:array-overhead}).

{}\item{}{}\ttt{ArrayView} is a drop in replacement for any code that uses
{}\ttt{std::vector} that does not grow or shrink the container by supporting
the necessary typedefs, query functions, and iterator access.  This helps in
migrating current code that uses {}\ttt{std::vector} but should be using
{}\ttt{ArrayView}.

{}\item{}{}\ttt{ArrayView} implicitly converts from an {}\ttt{std::vector} so
functions called by existing client code that uses {}\ttt{std::vector} can be
safely and transparently refactored to use {}\ttt{ArrayView} instead of
{}\ttt{std::vector} (subject to the limitations for implicit conversions
described in Section~\ref{sec:conversion-problems}).

{}\item{}\ttt{ArrayView} directly supports the creation of subviews of
contiguous ranges of elements.

\end{itemize}

What makes {}\ttt{ArrayView} non-trivial and special, however, is that
in a debug build, the implementation takes on a variety of runtime
checking to catch all sorts of errors such as dangling iterators,
dangling sub-views (Section~\ref{sec:detection-dangling-references}),
range checking (Section~\ref{sec:null-dereferences-range-checking}),
and other types of runtime checking.

It should be noted that one should almost never create an {}\ttt{ArrayView}
object directly from a raw pointer but instead create them as views of
{}\ttt{Array}, {}\ttt{ArrayRCP}, {}\ttt{Tuple} and other {}\ttt{ArrayView}
objects.  If client code is routinely creating {}\ttt{ArrayView} objects from
raw pointers, then the code is not safe and one needs to study the core idioms
described in Section~\ref{sec:idioms}.

The class {}\ttt{ArrayView} has no equivalent in boost or the current
C++ or proposed C++0x standard.  This is a critical class needed to
allow for flexibility, high-performance, safety, and maximaly
self-documenting code.  One cannot develop an effective type system
without an integrated type like {}\ttt{ArrayView}.


%
{}\subsubsection{\ttt{Teuchos::ArrayRCP<T>}}
\label{sec:ArrayRCP}
%

The class {}\ttt{ArrayRCP} is the counterpart to {}\ttt{ArrayView} for general
flexible array views except it is used for persisting relationships where
reference-counting machinery is required.  An {}\ttt{ArrayRCP} object can
provide a contiguous view into any array of data allocated in anyway possible
and can allow the user to define what is done to release memory in anyway they
would like.

The class declaration for {}\ttt{Teuchos::ArrayRCP} is shown in
Listing~\ref{listing:ArrayRCP}.

\begin{listing}: {}\ttt{Teuchos::ArrayRCP} declaration (optimized build)\\
\label{listing:ArrayRCP}
{\small\begin{verbatim}
  template<class T>
  class ArrayRCP {
  public:
  
    // Constructors/initializers
    ArrayRCP(ENull null_arg=null);
    ArrayRCP(T* p, size_type lowerOffset, size_type upperOffset,
      bool has_ownership);
    template<class Dealloc_T>
      ArrayRCP( T* p, size_type lowerOffset, size_type upperOffset,
        Dealloc_T dealloc, bool has_ownership);
    explicit ArrayRCP(size_type lowerOffset, const T& val = T());
    ArrayRCP(const ArrayRCP<T>& r_ptr);
    ~ArrayRCP();
    ArrayRCP<T>& operator=(const ArrayRCP<T>& r_ptr);

    // Object/Pointer Access Functions 
    T* operator->() const;
    T& operator*() const;
    ArrayRCP<T>& operator++();
    ArrayRCP<T> operator++(int);
    ArrayRCP<T>& operator--();
    ArrayRCP<T> operator--(int);
    ArrayRCP<T>& operator+=(size_type offset);
    ArrayRCP<T>& operator-=(size_type offset);
    ArrayRCP<T> operator+(size_type offset) const;
    ArrayRCP<T> operator-(size_type offset) const;
  
    // ArrayRCP Views
    ArrayRCP<const T> getConst() const;
    ArrayRCP<T> persistingView(size_type lowerOffset, size_type size) const;
  
    // Implicit conversions
    operator ArrayRCP<const T>() const;

    // Explicit ArrayView
    ArrayView<T> operator()() const;
  
    // Size and extent query functions 
    size_type lowerOffset() const;
    size_type upperOffset() const;
    size_type size() const;
  
    // std::vector like and other misc functions
    void assign(size_type n, const T &val);
    template<class Iter>
      void assign(Iter first, Iter last);
    void deepCopy(const ArrayView<const T>& av);
    void resize(const size_type n, const T &val = T());
    void clear();

    // Common array class members (see above)
    ...
  
    // Reference counting (same as for RCP)
    ...
  
  private:
    T *ptr_; // NULL if this pointer is null
    RCPNodeHandle node_; // NULL if this pointer is null
    size_type lowerOffset_; // 0 if this pointer is null
    size_type upperOffset_; // -1 if this pointer is null
  };
  
  // Nonmember constructors
  
  template<class T>
  ArrayRCP<T> arcp(T* p, typename ArrayRCP<T>::size_type lowerOffset,
    typename ArrayRCP<T>::size_type size, bool owns_mem = true);
  
  template<class T, class Dealloc_T>
  ArrayRCP<T> arcp(T* p, typename ArrayRCP<T>::size_type lowerOffset,
    typename ArrayRCP<T>::size_type size, Dealloc_T dealloc, bool owns_mem);
  
  template<class T>
  ArrayRCP<T> arcp( typename ArrayRCP<T>::size_type size );
  
  template<class T>
  ArrayRCP<T> arcpClone( const ArrayView<const T> &v );
  
  template<class T>
  ArrayRCP<T> arcp(const RCP<std::vector<T> > &v);
  
  template<class T>
  ArrayRCP<const T> arcp(const RCP<const std::vector<T> > &v);
  
  template<class T>
  ArrayRCP<T> arcpFromArrayView(const ArrayView<T> &av);
  
  template<class T>
  RCP<std::vector<T> > get_std_vector(const ArrayRCP<T> &ptr);
  
  template<class T>
  RCP<const std::vector<T> > get_std_vector(const ArrayRCP<const T> &ptr);

  // Customized deallocators
  ...

  // Embedded object functions
  ...

  // Extra data functions
  ...

  // Conversion functions
  ...

  // Common non-member functions
  ...

  // Other nonmember functions
  
  template<class T>
  typename ArrayRCP<T>::difference_type
  operator-(const ArrayRCP<T> &p1, const ArrayRCP<T> &p2);
  
  template<class T>
  std::ostream& operator<<( std::ostream& out, const ArrayRCP<T>& p );
\end{verbatim}}
\end{listing}

Some of the main features of the {}\ttt{ArrayRCP} class are:

{}\ttt{ArrayRCP} allows the user to allocate the contiguous array of data in
anyway they would like and can define how that array is deallocated anyway
they would like.

{}\ttt{ArrayRCP} returns persisting subviews of data through the
member function {}\ttt{persistingView(...)}.  This means that the
underlying array of data will not be deleted until all the persisting
subviews are destroyed.

{}\ttt{ArrayRCP} is a full replacement for a general raw pointer and can be
used as a general iterator that always remembers the allowed upper and lower
bounds.  It supports all the appropriate pointer array-like operations
including {}\ttt{ptr+i}, {}\ttt{i+ptr}, {}\ttt{ptr-i}, {}\ttt{ptr+=i},
{}\ttt{ptr-=i}, , {}\ttt{ptr++}, {}\ttt{ptr--}, {}\ttt{*ptr},
{}\ttt{ptr->member()}, and of course {}\ttt{ptr[i]}.  This is what allows
{}\ttt{ArrayRCP} to be used as a checked iterator implementation in a
debug-mode build.

{}\ttt{ArrayRCP} can be used safely as a contiguous array by using it through
its {}\ttt{const} interface which disables all of the pointer-like functions
that change the frame of reference (e.g. {}\ttt{ptr+=i}, {}\ttt{ptr-=i}, ,
{}\ttt{ptr++}, and {}\ttt{ptr--} are disabled in the {}\ttt{const} interface).

{}\ttt{ArrayRCP} can be used in place of {}\ttt{std::vector} (and
therefore {}\ttt{Array}) that only needs to size or resize the array
in baulk and does not need to flexibly grow or shrink the array.  It
does this by supporting functions like {}\ttt{assign(...)},
{}\ttt{resize(...)}, and {}\ttt{clear()}.  Because of the reference
counting machinery that is always part of {}\ttt{ArrayRCP} and support
for all raw C++ pointer functionality (e.g., {}\ttt{ptr++}), one may
not want to use {}\ttt{ArrayRCP} instead of {}\ttt{Array} in many
types of code.  However, if the overhead is not going to be
significant, then going with {}\ttt{ArrayRCP} instead of {}\ttt{Array}
can be a good choice because it is much more flexible in how memory is
allocated and has built-in support for shared ownership (again, which
may not be needed).  The class {}\ttt{ArrayRCP} does not attempt to
replace {}\ttt{Array} but can be a better choice in many cases where
an {}\ttt{Array} may otherwise be used.

{}\ttt{ArrayRCP} supports explicit shallow conversion to
{}\ttt{ArrayView}.  Requiring an explicit conversion from
{}\ttt{ArrayRCP} to {}\ttt{ArrayView} in consistent with the required
explicit conversion from {}\ttt{RCP} to {}\ttt{Ptr}.  As explained in
Section~\ref{sec:idioms-for-passing-arguments}, requiring this type of
explicit conversion is meant to increase the type safety and
self-documenting nature of all code (including the calling code as
well).  Note that the {}\ttt{ArrayRCP::operator()()} function is a
very short-hand way to perform conversion to {}\ttt{ArrayView}.

{}\ttt{ArrayRCP} supports owning conversions from {}\ttt{RCP}-wrapped
{}\ttt{Array} and {}\ttt{std::vector} objects.  This allows for better
interoperability between code and uses solid reference-counting
ownership semantics.

Some of the other features of the {}\ttt{ArrayRCP} class that are
common with the other classes are discussed in
Section~\ref{sec:conversions},
Section~\ref{sec:reference-counting-machinary}, and
Section~\ref{sec:debug-mode-runtime-checking}.


%
{}\subsubsection{\ttt{Teuchos::Array<T>}}
\label{sec:Array}
%

The class {}\ttt{Array} is a complete drop-in replacement for
{}\ttt{std::vector} that is integrated with the {}\ttt{ArrayView}
class for debug-mode runtime checking.  In an optimized build,
{}\ttt{Array} is nothing but an inline wrapper around a fully
encapsulated {}\ttt{std::vector} object.  This means that in an
optimized build, {}\ttt{Array} takes advantage of all of the
platform-specific optimizations contained in the native
{}\ttt{std::vector} implementation and imparts no extra space/time
overhead (see the timing results in Section~\ref{sec:array-overhead}
for evidence of this claim).  However, in a debug build, a full set of
platform-independent runtime checking is performed that is as strong
or stronger than any checked STL implementation (see {}\cite[Item
{}83]{C++CodingStandards05}) and in addition includes dangling
reference detection of {}\ttt{ArrayView} views or direct conversions
to {}\ttt{ArrayRCP} objects (see
Section~\ref{sec:detection-dangling-references}).  {}\ttt{Array} also
supports better runtime debug output with better exception error
messages.

The class declaration for the {}\ttt{Array} class is shown in
Listing~\ref{listing:Array}.

\begin{listing}: {}\ttt{Teuchos::Array} declaration (optimized build) \\
\label{listing:Array}
{\small\begin{verbatim}
  template<typename T>
  class Array {
  public:
  
    // Constructors/initializers
    Array();
    explicit Array(size_type n, const value_type& value = value_type());
    Array(const Array<T>& x);
    template<ypename InputIterator> Array(InputIterator first, InputIterator last);
    Array(const ArrayView<const T>& a);
    template<int N> Array(const Tuple<T,N>& t);
    ~Array();
    Array& operator=(const Array<T>& a);
  
    // Other std::vector functions
    void assign(size_type n, const value_type& val);
    template<typename InputIterator> void assign(InputIterator first,
      InputIterator last);
    iterator begin();
    iterator end();
    const_iterator begin() const;
    const_iterator end() const;
    reverse_iterator rbegin();
    reverse_iterator rend();
    const_reverse_iterator rbegin() const;
    const_reverse_iterator rend() const;
    size_type size() const;
    size_type max_size() const;
    void resize(size_type new_size, const value_type& x = value_type());
    size_type capacity() const;
    bool empty() const;
    void reserve(size_type n);
    reference operator[](size_type i);
    const_reference operator[](size_type i) const;
    reference at(size_type i);
    const_reference at(size_type i) const;
    reference front();
    const_reference front() const;
    reference back();
    const_reference back() const;
    void push_back(const value_type& x);
    void pop_back();
    iterator insert(iterator position, const value_type& x);
    void insert(iterator position, size_type n, const value_type& x);
    template<typename InputIterator> void insert(iterator position,
      InputIterator first, InputIterator last);
    iterator erase(iterator position);
    iterator erase(iterator first, iterator last);
    void swap(Array& x);
    void clear();
  
    // Conversions to and from std::vector
    Array( const std::vector<T> &v );
    std::vector<T> toVector() const;
    Array& operator=( const std::vector<T> &v );

    // Implicit conversion to ArrayView
    operator ArrayView<T>();
    operator ArrayView<const T>() const;
  
    // Common array class members (see above)
    ...
  
  private:
    std::vector<T> vec_; // Optimized implementation
  };
  
  
  // Non-member helper functions
  template<class T> ArrayRCP<T> arcp( const RCP<Array<T> > &v );
  template<class T> ArrayRCP<const T> arcp( const RCP<const Array<T> > &v );
  template<class T> ArrayRCP<T> arcpFromArray( Array<T> &a );
  template<class T> ArrayRCP<const T> arcpFromArray( const Array<T> &a );
  template<typename T> std::ostream& operator<<(std::ostream& os,
    const Array<T>& array);
  template<typename T> std::vector<T> createVector( const Array<T> &a );
  std::string toString(const Array<T>& array);
  template<typename T> Array<T> fromStringToArray(const std::string& arrayStr);

  // Other common nonmember functions
  ...
\end{verbatim}}
\end{listing}

The usage of the {}\ttt{Array} class is identical to the usage of
{}\ttt{std::vector} except that it naively supports the creation of
{}\ttt{AraryView} objects that can detect and report dangling
references or attempts to resize the container when one or more
{}\ttt{ArrayView} objects are active.  The unit tests for
{}\ttt{Array} provide a complete catalog of all the debug-mode runtime
checking that {}\ttt{Array} performs.  A more general discussion of
debug-mode runtime checking can be found in
Section~\ref{sec:debug-mode-runtime-checking}.


%
{}\subsubsection{\ttt{Teuchos::Tuple<T,N>}}
%

The last array class discussed here is the {}\ttt{Tuple} class which
represents a compile-time sized array that implicitly converts into an
{}\ttt{ArrayView} object.  The class listing for {}\ttt{Tuple} is
shown in Listing~\ref{listing:Tuple}.

\begin{listing}: {}\ttt{Teuchos::Tuple} declaration (optimized build) \\
\label{listing:Tuple}
{\small\begin{verbatim}
  template<typename T, int N>
  class Tuple {
  public:
    
    // Constructors/initializers
    inline Tuple();
    Tuple( const Tuple<T,N> &t );
  
    // Implicit conversion to ArrayView
    operator ArrayView<T>();
    operator ArrayView<const T>() const;
    
    // Common array class members (see above)
    ...
  
  private:
    T array_[N]; // Optimized implementation
  };
  
  // Non-member constructors
  
  template<typename T>
  Tuple<T,1> tuple(const T& a);
  
  template<typename T>
  Tuple<T,2> tuple(const T& a, const T& b);
  
  template<typename T>
  Tuple<T,3> tuple(const T& a, const T& b, const T& c);
  
  ...
  
  template<typename T>
  Tuple<T,15> tuple(const T& a, const T& b, const T& c, const T& d, const T& e,
    const T& f, const T& g, const T& h, const T& i, const T& j, const T& k,
    const T& l, const T& m, const T& n, const T& o);
\end{verbatim}}
\end{listing}

The class {}\ttt{Tuple} is very small and efficient in an optimized
build.  All the functions are inlined and all data is allocated on the
stack (or statically) and does not use the free store.  In an debug
build, however, {}\ttt{Tuple} takes on all the debug checking of all
the other Teuchos array classes including the detection of dangling
{}\ttt{ArrayView} views and dangling iterators.

One of the most useful features of {}\ttt{Tuple} is that a number of
overloaded non-member constructor functions with name
{}\ttt{tuple(...)} are provided (show above) to make it easy to pass
in arrays to functions that accept them as {}\ttt{ArrayView}
arguments.  Overloads of {}\ttt{tuple(...)} are currently provided
from one up through 15 arguments.  For an example for using
{}\ttt{tuple(...)} to call a function call, consider the function to
be called:

{\small\begin{verbatim}
  void doSomething(const ArrayView<const int>&);
\end{verbatim}}

To call the function with three int arguments, one would use:

{\small\begin{verbatim}
  doSomething(tuple<int>(1, 2, 3)); // Implicitly converts to ArrayView<int>
\end{verbatim}}

Note that in an optimized build for the above function call that all
data would be allocated on the stack and would not involve the free
store.  This results in very efficient code which is important when
this is being used in an inner loop.


%
{}\subsubsection{Array views}
\label{sec:array-views}
%

One of the most powerful features of the Teuchos memory management
array types is that they allow for the creation of arbitrary
contiguous subviews of data that have the strongest debug-mode runtime
checking possible.  All of the array classes {}\ttt{ArrayView},
{}\ttt{ArrayRCP}, {}\ttt{Array}, and {}\ttt{Tuple} provide contiguous
views as {}\ttt{ArrayView} objects.  The functions that provide
{}\ttt{ArrayView} views are shown in
Table~\ref{tbl:common-array-type-members}.  The {}\ttt{ArrayRCP} class
can also provide persisting contiguous subviews as new
{}\ttt{ArrayRCP} objects using the function
{}\ttt{ArrayRCP::persistingView(...)}.  Persisting views will remain
even if the parent {}\ttt{ArrayRCP} objects have been released.

As soon as a contiguous array of data is correctly captured in
{}\ttt{Array} or an owning {}\ttt{ArrayRCP} object, all children
{}\ttt{ArrayView} objects will be protected in that if the parent
array gets deleted, a debug-mode runtime check will detect and report
a dangling reference if a client tries to access the data after the
parent has gone away (see
Section~\ref{sec:detection-dangling-references} for details).

To demonstrate the elegance and superior error checking of
{}\ttt{ArrayView} subviews, consider a refactored version of code in
Listing~\ref{listing:addArrayIntoArray-std-vector} and
Listing~\ref{listing:someBlockAlgo-std-vector} that tried to use
{}\ttt{std::vector} but resulted in verbose clumsy code that was
really no more correct or safe than the raw C++ pointer version.  This
refactored version to use {}\ttt{ArrayView} is shown in
Listing~\ref{listing:addArrayIntoArray-ArrayView} and
Listing~\ref{listing:someBlockAlgo-ArrayView}.


{}\begin{listing}: Refactored version of
Listing~\ref{listing:addArrayIntoArray-std-vector} to use
{}\ttt{ArrayView}
\\
\label{listing:addArrayIntoArray-ArrayView}
{\small\begin{verbatim}
  template<class T>
  class BlockTransformerBase {
  public:
    virtual ~BlockTransformerBase();
    virtual void transform(const ArrayView<const T> &a, const ArrayView<T> &b) const = 0;
  };

  template<class T>
  class AddIntoTransformer : public BlockTransformerBase<T> {
  public:
    virtual void transform(const ArrayView<const T> &a, const ArrayView<T> &b) const
      {
        DEBUG_MODE_ASSERT_EQUALITY( a.size(), b.size() );
        for (int i = 0; i < a.size(); ++i)
          b[i] += a[i];
      }
  };
\end{verbatim}}
\end{listing}


{}\begin{listing}: Refactored version of
Listing~\ref{listing:someBlockAlgo-std-vector} to use
{}\ttt{ArrayView} \\
\label{listing:someBlockAlgo-ArrayView}
{\small\begin{verbatim}
  void someBlockAlgo( const BlockTransformerBase &transfomer,
    const int numBlocks, const ArrayView<const double> &big_a,
    const ArrayView<double> &big_b )
  {
    DEBUG_MODE_ASSERT_EQUALITY( big_a.size(), big_b.size() );
    const int totalLen = big_a.size();
    const int blockSize = totalLen/numBlocks; // Assume no remainder!
    
    const int blockOffset = 0;
    for (int block_k = 0; block_k < numBlocks; ++block_k, blockOffset += blockSize)
    {
      if (big_a[blockOffset] > 0.0) {
        transformer.transform(big_a(blockOffset, blockSize),
          big_b(blockOffset, blockSize));
      }
    }
  }
\end{verbatim}}
\end{listing}


The advantages of the refactored code in
Listing~\ref{listing:addArrayIntoArray-ArrayView} and
Listing~\ref{listing:someBlockAlgo-ArrayView} are that they are nearly
as compact as the raw pointer versions in
Listing~\ref{listing:addArrayIntoArray-raw} and
Listing~\ref{listing:someBlockAlgo-std-vector-raw-ptr} but in addition
also have full debug-mode runtime error checking.  To see the improved
safety, let's consider the case where the {}\ttt{transform(...)}
function is incorrectly implemented with an off-by-one error as shown
in Listing~\ref{listing:addArrayIntoArray-ArrayViewError}.

{}\begin{listing}: Refactored version of off-by-one error in
Listing~\ref{listing:addArrayIntoArray_rawError} to use
{}\ttt{ArrayView} \\
\label{listing:addArrayIntoArray-ArrayViewError}
{\small\begin{verbatim}
  template<class T>
  void AddIntoTransformer<T>::transform(const ArrayView<const T> &a, const ArrayView<T> &b)
  {
    DEBUG_MODE_ASSERT_EQUALITY( a.size(), b.size() );
    for (int i = 0; i <= a.size(); ++i)
      b[i] += a[i]; // Throws when i == a.size()
  }
\end{verbatim}}
\end{listing}

If the erroneous {}\ttt{transform(...)} function in
Listing~\ref{listing:addArrayIntoArray-ArrayViewError} were called
from Listing~\ref{listing:someBlockAlgo-ArrayView} then in debug-mode,
a runtime exception would immediately be raised when the
{}\ttt{transform(...)} function tried to access one past the last
element.  As mentioned in
Section~\ref{sec:problems-with-mem-checkers}, memory checking tools
like Valgrind or Purify will never be able to catch semantic usage
errors like this but it is trivial to catch these mistakes when using
the Teuchos memory management classes.

As mentioned in Section~\ref{sec:conversions}, subviews can also
be used along with the reinterpret cast functions to create very
efficient memory management schemes for POD (plain old data) where
large untyped {}\ttt{char} arrays are created and then subviews are
broken off and reinterpret cast to specific data types.  Examples of
this can be found in the unit testing code.


%
{}\subsection{Const versus non-const pointers and objects}
\label{sec:teuchos-const-nonconst-pointer-objects}
%

The core smart-pointer pointer classes {}\ttt{Ptr}, {}\ttt{RCP},
{}\ttt{ArrayView} and {}\ttt{ArrayRCP} allow for the inner object (or
array of objects) to be const or non-const and for the outer pointer
object to be const or non-const, just like with regular C++ pointers.
To draw the analogy with raw pointers, consider the equivalent
declarations of a raw pointer and the pointer encapsulation class in
Table~\ref{tbl:teuchos-const-nonconst-pointer-objects}.

\begin{table}
%
%\fbox{
\begin{center}
%
%\begin{minipage}{{}\textwidth}
%
\input{RawPointerSmartPointerEquivalencies}
%
%\end{minipage}
%
\end{center}
%} % end fbox
{}\caption[Equivalences between raw pointer and smart pointer types
for const protection]{
\label{tbl:teuchos-const-nonconst-pointer-objects}
Equivalences between raw pointer and smart pointer types for const
protection.  Here, {}\ttt{RCP} is a stand-in for all four types
{}\ttt{Ptr}, {}\ttt{RCP}, {}\ttt{ArrayView} and {}\ttt{ArrayRCP}.}
%
\end{table}

The majority of problems that beginners have with the Teuchos memory
management classes is related to the inability to make the basic
equivalencies between raw pointers and smart pointers shown in
Table~\ref{tbl:teuchos-const-nonconst-pointer-objects} (see
Section~\ref{sec:conversion-problems} for specific examples).  It is
critical that the programmer recognize this equivalence with raw
pointers because it impacts many things especially implicit type
conversions to satisfy function calls (again, see
Section~\ref{sec:conversions}).


%
{}\subsection{Conversions}
\label{sec:conversions}
%

Type conversions exist both for a single smart pointer type for the
embedded type argument (e.g.\ {}\ttt{RCP<Derived>} implicitly converts
to {}\ttt{RCP<const Derived>}, {}\ttt{RCP<Base>}, and {}\ttt{RCP<const
Base>}) and also between different smart pointer types (e.g.\
{}\ttt{Array} implicitly converts to {}\ttt{ArrayView}).  There are
implicit conversions and explicit conversions.  These two types of
conversions are depicted in Figures~\ref{fig:TeuchosPtrConversions}
and~\ref{fig:TeuchosArrayConversions} and shown in more detail in
more detail in Table~\ref{tbl:ConversionsTableSingleObjs} and
Table~\ref{tbl:ConversionsTableArrays}.  (Note: All of the conversions
shown in Table~\ref{tbl:ConversionsTableSingleObjs} and
Table~\ref{tbl:ConversionsTableArrays} are not shown in
Figure~\ref{fig:TeuchosPtrConversions} and
Figure~\ref{fig:TeuchosArrayConversions} for the sake of not making
the figures to complex.)  These conversions are described in the
following two sections.


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.65]{TeuchosPtrConversions}
%}
\end{center}
\caption{
\label{fig:TeuchosPtrConversions}
Conversions between different single-object memory management types.}
\end{figure}
\esinglespace}


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.65]{TeuchosArrayConversions}
%}
\end{center}
\caption{
\label{fig:TeuchosArrayConversions}
Conversions between array memory management types.  }
\end{figure}
\esinglespace}


%
{}\subsubsection{Implicit and explicit raw-pointer-like conversions}
\label{sec:raw-pointer-like-type-conversions}
%

The core Teuchos memory management smart pointer types {}\ttt{Ptr},
{}\ttt{RCP}, {}\ttt{ArrayView} and {}\ttt{ArrayRCP} support all of the
reasonable implicit and explicit type conversions that are defined by
raw C++ pointers.  C++ defines implicit conversions for raw pointers
from non-const to const and from derived to base types.
Table~\ref{tbl:implicit_explicit_conversions} shows what implicit and
explicit conversions are supported for the four core memory management
smart pointer types.


\begin{table}
\begin{center}
\input{BasicSupportedImplicitExplictConversions}
\end{center}
\caption{\label{tbl:implicit_explicit_conversions}
Basic implicit and explicit conversions by smart-pointer types.}
\end{table}


As seen in Table~\ref{tbl:implicit_explicit_conversions}, the smart
pointer types for single objects {}\ttt{Ptr} and {}\ttt{RCP} do not
support the same implicit and explicit conversions that are supported
for the array smart pointer types {}\ttt{ArrayView} and
{}\ttt{ArrayRCP}.  As explained in
Section~\ref{sec:problem-with-raw-array-pointers}, it almost always
incorrect and dangerous to allow implicit conversions from derived to
base type for pointers that point into contiguous arrays of objects.
Therefore, the types {}\ttt{ArrayView} and {}\ttt{ArrayRCP} do not
support implicit conversions from derived to base types.  Due to
similar logic, it almost never makes any sense to perform a static
cast or a dynamic cast on a pointer to an array of contiguous objects
so the types {}\ttt{ArrayView} and {}\ttt{ArrayRCP} do not support
static and dynamic casts.

In well formed programs, there is a justification to perform
reinterpret casts for contiguous arrays of POD (plain old data)
types. It is perfectly reasonable to allocate a large array of
{}\ttt{char} (untyped) data and then create subviews and reinterpret
cast to separate arrays of {}\ttt{double} and {}\ttt{int} data, for
instance.  However, in a well formed program in high-level code there
is not a single valid reason to perform a reinterpret cast for single
objects and therefore reinterpret cast is not supported for the types
{}\ttt{Ptr} and {}\ttt{RCP}.

The allowed implicit conversions for {}\ttt{Ptr} and {}\ttt{RCP} are
implemented through templated copy constructors (see
Section~\ref{sec:Ptr} and Section~\ref{sec:RCP}).  However, the only
allowed implicit conversion for {}\ttt{<T*>} to {}\ttt{<const T*>} for
{}\ttt{ArrayView} and {}\ttt{ArrayRCP} are instead supported through
conversion member functions (see Section~\ref{sec:ArrayView} and
Section~\ref{sec:ArrayRCP}).  The supported explicit conversion
operators for these four types are shown in the
Listings~\ref{listing:Ptr-conversions},
{}\ref{listing:RCP-conversions},
{}\ref{listing:ArrayView-conversions}, and
{}\ref{listing:ArrayRCP-conversions}.


{}\begin{listing}: Conversion functions for {}\ttt{Ptr}
\label{listing:Ptr-conversions}
{\small\begin{verbatim}
  template<class T2, class T1> Ptr<T2> ptr_implicit_cast(const Ptr<T1>& p1);
  template<class T2, class T1> Ptr<T2> ptr_static_cast(const Ptr<T1>& p1);
  template<class T2, class T1> Ptr<T2> ptr_const_cast(const Ptr<T1>& p1);
  template<class T2, class T1> Ptr<T2> ptr_dynamic_cast(const Ptr<T1>& p1,
    bool throw_on_fail = false);
\end{verbatim}}
\end{listing}


\begin{listing}: Conversion functions for RCP\\
\label{listing:RCP-conversions}
{\small\begin{verbatim}
  template<class T2, class T1> RCP<T2> rcp_implicit_cast(const RCP<T1>& p1);
  template<class T2, class T1> RCP<T2> rcp_static_cast(const RCP<T1>& p1);
  template<class T2, class T1> RCP<T2> rcp_const_cast(const RCP<T1>& p1);
  template<class T2, class T1> RCP<T2> rcp_dynamic_cast(const RCP<T1>& p1,
    bool throw_on_fail = false);
\end{verbatim}}
\end{listing}


\begin{listing}: Conversion functions for ArrayView\\
\label{listing:ArrayView-conversions}
{\small\begin{verbatim}
  template<class T2, class T1> ArrayView<T2> av_const_cast(const ArrayView<T1>& p1);
  template<class T2, class T1> ArrayView<T2> av_reinterpret_cast(const ArrayView<T1>& p1);
\end{verbatim}}
\end{listing}


\begin{listing}: Conversion functions for ArrayRCP\\
\label{listing:ArrayRCP-conversions}
{\small\begin{verbatim}
  template<class T2, class T1> ArrayRCP<T2> arcp_const_cast(const ArrayRCP<T1>& p1);
  template<class T2, class T1> ArrayRCP<T2> arcp_reinterpret_cast(const ArrayRCP<T1>& p1);
  template<class T2, class T1> ArrayRCP<T2> arcp_reinterpret_cast_nonpod(
    const ArrayRCP<T1>& p1, const T2& val = T2());
\end{verbatim}}
\end{listing}


These conversion functions are used very similarly as for the built-in
conversion operations in that only the output type needs to be
explicitly specified.  For example,
Listing~\ref{listing:conversions-examples} shows some example
conversions involving {}\ttt{RCP} (but the conversion function usage
for the other types are identical).  One function worth noting in
Listing~\ref{listing:ArrayRCP-conversions} is
{}\ttt{arcp\_reinterpret\_cast\_nonpod(...)} which performs a
reinterpret cast from a POD (plain old data) datatype (e.g.\
{}\ttt{char}) to a non-POD datatype (e.g. {}\ttt{std::vector<int>}).
This function calls (copy) constructors on the array elements and
defines a specialized deallocation policy to call destructors on the
elements when the last {}\ttt{ArrayRCP<T2>} object is released.


{}\begin{listing}: Example usage of the explicit conversion functions
\label{listing:conversions-examples}
{\small\begin{verbatim}
  RCP<const Base> = cbase(new Derived);
  RCP<Base> base = rcp_const_cast<Base>(cbase);
  RCP<const Derived> cderived = rcp_dynamic_cast<const Derived>(cbase, true);
  RCP<const Derived> cderived2 = rcp_static_cast<const Derived>(cbase);
  // NOTE: Static casting of Base to Derived is not safe when
  // using virtual base classes or multiple inheritance.  Only dynamic
  // casting is always safe with polymophpic types.
\end{verbatim}}
\end{listing}


Note that the dynamic cast conversion functions
{}\ttt{ptr\_dynamic\_cast()} and {}\ttt{rcp\_dynamic\_cast()} both
take an option extra argument {}\ttt{throw\_on\_fail} that if set to
{}\ttt{true} will result in an exception being thrown on a dynamic
cast failure which is embedded with a very helpful error message
(accessed through the {}\ttt{std::exception::what()} function).


%
{}\subsubsection{Conversions between different memory management types}
\label{sec:teuchos-type-conversions}
%

It is critical that all conversions between the various Teuchos memory
management classes be performed using conversion code provided by the
memory management classes or by associated helper functions in the
Teuchos library.  Client code should never convert between memory
management types by exposing a raw C++ pointer.  As soon as a raw C++
pointer is exposed, nearly all of the debug-mode runtime checking will
be disabled.  If a raw C++ pointer is exposed in order to perform a
needed valid conversion, then either the programmer overlooked an
already provided conversion function or the function needs to be added
to Teuchos (please contact the developers of Teuchos at
{}\ttt{teuchos-users@software.sandia.gov}).

Figures~\ref{fig:TeuchosPtrConversions}
and~\ref{fig:TeuchosArrayConversions} show many of the types of
conversions that are supported between the different memory management
types.  Specific conversions are shown in more detail in
Tables~\ref{tbl:ConversionsTableSingleObjs} and
{}\ref{tbl:ConversionsTableArrays}.  (Note: All of the conversions
shown in Tables~\ref{tbl:ConversionsTableSingleObjs} and
{}\ref{tbl:ConversionsTableArrays} are not shown in
Figures~\ref{fig:TeuchosPtrConversions} and
{}\ref{fig:TeuchosArrayConversions} for the sake of not making the
figures to complex.)  For single objects, the conversions between
different {}\ttt{RCP} and {}\ttt{Ptr} objects of various kinds shown
in Figure~\ref{fig:TeuchosPtrConversions} and
Table~\ref{tbl:ConversionsTableSingleObjs} include both implicit and
explicit conversions (but do not show the explicit conversion
functions already shown in Listings~\ref{listing:Ptr-conversions} and
{}\ref{listing:RCP-conversions}).  Conversions between different array
types shown in Figure~\ref{fig:TeuchosArrayConversions} and
Table~\ref{tbl:ConversionsTableArrays} include both implicit and
explicit conversions and view and copy conversions yielding various
types of conversions (but do not show the explicit conversion
functions already shown in
Listings~\ref{listing:ArrayView-conversions} and
{}\ref{listing:ArrayRCP-conversions}).


\begin{table}
\begin{center}
\input{ConversionsTableSingleObjs}
\caption{\label{tbl:ConversionsTableSingleObjs}
Summary of basic conversions supported involving single objects.}
\end{center}
\end{table}


\begin{table}
\begin{center}
\input{ConversionsTableArrays}
\caption{\label{tbl:ConversionsTableArrays}
Summary of basic conversions supported for contiguous arrays.}
\end{center}
\end{table}


The conversions shown in Tables~\ref{tbl:ConversionsTableSingleObjs}
and {}\ref{tbl:ConversionsTableArrays} (and also in Listings
{}\ref{listing:Ptr-conversions}, {}\ref{listing:RCP-conversions},
{}\ref{listing:ArrayView-conversions}, and
{}\ref{listing:ArrayRCP-conversions}) are the most basic conversions
supported by the Teuchos memory management types but are not the only
supported conversions.  The see the full set of type conversions
supported, consult the Doxygen generated
documentation\footnote{\ttt{http://trilinos.sandia.gov/packages/teuchos}}.
Note that full debug-mode runtime checking is fully enabled for every
conversion between Teuchos memory management types, including full
dangling-reference detection and reporting when creating
non-reference-counting types {}\ttt{Ptr} and {}\ttt{ArrayView}.  In
general, dangling references cannot be detected when converting from
raw C++ pointers {}\ttt{T*} and raw C++ references {}\ttt{T\&} or for
shallow views involving {}\ttt{std::vector}.  However, there are a few
special cases where non-owning {}\ttt{Ptr}, {}\ttt{RCP}, and
{}\ttt{ArrayView}, {}\ttt{ArrayRCP} objects created from raw C++
pointers (or references) will be able to detect dangling references
through the sophisticated debug-mode node tracing system (see
Sections~\ref{sec:detection-dangling-references} and
{}\ref{sec:limitations-debug-mode-checking} for details).


%
{}\subsubsection{Implicit type conversion problems and shortcomings}
\label{sec:conversion-problems}
%

Implicit conversions between different Teuchos memory management
types, especially in templated application code, is one of the most
confusing aspects of using these classes.  As shown in
Figures~\ref{fig:TeuchosPtrConversions} and
{}\ref{fig:TeuchosArrayConversions}, many different implicit
conversions are defined.  An implicit conversion will only be
performed by the C++ compiler to satisfy the formal arguments for a
function call when several conditions are satisfied: a) when it is
needed to call a function where no other better functions provide a
better match, b) when only a single implicit conversion for each
argument is sufficient, and c) when calling a non-template function
(or a template function where all of the template arguments are
explicitly specified).  Also, the C++ compiler will not be able to do
implicit conversions to satisfy a function call when ambiguous
function calls exists.  Explaining the behavior of these implicit
conversions in C++ gets down to the low-level details of the C++ type
system that many C++ programmers take for granted or don't understand
all that well in the first place.

Almost all of the problems that programmers have with implicit
conversions occur when trying to call functions where implicit
conversions are required to satisfy the signature of the function.
Some of these problems occur when developers fail to understand the
C++ type system.  Other problems are due to a fundamental handicap
that smart pointer types have with respect to raw C++ pointers.

Implicit conversions of the Teuchos memory management classes (or any
other C++ classes in any other library) needed to call a given
function fail for one of the following reasons:

\begin{enumerate}

{}\item{}Implicit conversions to functions fail because the memory
management types are not passed by const reference (or by value) and
are mistakenly (or on purpose) passed by non-const reference. (This is
a programming error.)

{}\item{}Implicit conversions fail because templated functions cannot
perform implicit conversions in order to satisfy a call. (This is a
language usability annoyance associated with templates but also
represents a fundamental shortcoming of smart pointers compared to raw
C++ pointers.)

{}\item{}Implicit conversions fail due to ambiguous overloaded calls
to overloaded functions that would otherwise work just fine when raw
C++ pointers are involved. (This is a fundamental shortcoming of smart
pointers or any other class as compared to raw C++ pointers.)

\end{enumerate}

Each of these types of problems are examined one at a time in the
following three subsections.


%
{}\subsubsection*{Implicit conversions failing due to passing by
non-const reference}
%


First, consider implicit conversion problems caused by erroneously
passing Teuchos memory management objects by non-const references
instead of by const reference.  Consider the user-written function in
Listing~\ref{listing:someUserFunction-pass-by-non-const-ref} that
mistakenly passes an {}\ttt{RCP} by non-const reference.


{}\begin{listing}: User function with a bad pass by non-const
reference problem
\label{listing:someUserFunction-pass-by-non-const-ref}
{\small\begin{verbatim}
  class Base { ... };
  class Derived : public Base { ... };

  void someUserFunction(RCP<const Base> &base); // Should be 'const RCP<>&'

  void someOtherUserFunction()
  {
     RCP<Derived> derived(new Derived);
     someUserFunction(derived);  // Compile error, no implicit conversion!
     RCP<const Derived> cderived = derived;
     someUserFunction(cderived); // Compile error, no implicit conversion!
     RCP<Base> base = derived;
     someUserFunction(base);     // Complile error, no implicit conversion!
     RCP<const Base> cbase = base;
     someUserFunction(cbase);    // Compliles fine, exact match!
  }
\end{verbatim}}
\end{listing}


When user code tries to call {}\ttt{someUserFunction(...)} as shown in
Listing~\ref{listing:someUserFunction-pass-by-non-const-ref}, the C++
compiler refuses to perform the implicit type conversions because the
compiler will never perform an implicit type conversion for an
argument passed by non-const reference.  This type of error is made at
least once by most developers when they first start using the Teuchos
memory management classes and they can't understand why the code does
not compile.  To understand why the implicit conversions in
Listing~\ref{listing:someUserFunction-pass-by-non-const-ref} are not
occurring, one must understand the C++ type system in how it handles
basic type conversions.  The C++ standard specifies that implicit type
conversions to facilitate the call of a C++ function will only occur
for arguments passed by value or by {}\textit{const} reference.  For
example, a C++ compiler will convert an {}\ttt{int} into a
{}\ttt{double} to call a function taking a {}\ttt{double} argument but
only if the double is passed by value (i.e.\ {}\ttt{double x}) or by
const reference (i.e.\ {}\ttt{const double\& x}).  The same holds true
for C++ pointer types.  Note that every pointer type (e.g.\
{}\ttt{int*}, {}\ttt{SomeType*}) is a new C++ value data type that is
automatically defined by the compiler for every defined type.  The C++
compiler also automatically defines implicit conversions between
pointer types for {}\ttt{T*} to {}\ttt{const T*} and for
{}\ttt{Derived*} to {}\ttt{Base*} (or combinations of both with
{}\ttt{Derived*} to {}\ttt{const Base*}).  While C++ pointer data
types have a special place in the C++ language, they behave exactly
like every other data type in C++ with respect to non-const references
and implicit conversions.  That is, if a pointer object is passed by
non-const reference instead of by value, the compiler will refuse the
perform the implicit conversion.  For example, the equivalent code to
Listing~\ref{listing:someUserFunction-pass-by-non-const-ref} replacing
{}\ttt{RCP} with raw pointers shown in
Listing~\ref{listing:someUserFunction-pass-by-non-const-ref-raw-ptr}
will also result in code that will not compile.


{}\begin{listing}: User function with a bad pass by non-const
reference problem using raw pointers
\label{listing:someUserFunction-pass-by-non-const-ref-raw-ptr}
{\small\begin{verbatim}
  typedef const Base* ptr_const_Base; // Equivalent to RCP<const Base>

  void someUserFunction(ptr_const_Base &base); // Bad pass by non-const ref!

  void someOtherUserFunction()
  {
     Derived *derived = new Derived;
     someUserFunction(derived);   // Compile error, no implicit conversion!
     const Derived *cderived = derived;
     someUserFunction(cderived); // Compile error, no implicit conversion!
     Base *base = derived;
     someUserFunction(base);     // Complile error, no implicit conversion!
     const Base *cbase = base;
     someUserFunction(cbase);    // Compliles fine, exact match!
     delete derived;
  }
\end{verbatim}}
\end{listing}


The way to fix this problem is to pass the Teuchos memory management
types (or any other type one wants the compiler to perform an implicit
conversion on) by const reference.  For example, fixing the code in
Listing~\ref{listing:someUserFunction-pass-by-non-const-ref} to pass
by const reference shown in Listing~\ref{listing:someUserFunction-pass-by-const-ref} results in code
that compiles just fine with the C++ compiler performing all of the
expected implicit conversions.


{}\begin{listing}: User function with corrected pass by const
reference
\label{listing:someUserFunction-pass-by-const-ref}
{\small\begin{verbatim}
  void someUserFunction(const RCP<const Base> &base); // Now correct!

  void someOtherUserFunction()
  {
     RCP<Derived> derived(new Derived);
     someUserFunction(derived);  // Compiles fine, Derived* -> const Base*
     RCP<const Derived> cderived = derived;
     someUserFunction(cderived); // Compiles fine, const Derived* -> const Base*
     RCP<Base> base = derived;
     someUserFunction(base);     // Compiles fine, Base* -> const Base*
     RCP<const Base> cbase = base;
     someUserFunction(cbase);    // Compliles fine, exact match!
  }
\end{verbatim}}
\end{listing}


%
{}\subsubsection*{Implicit conversions failing due to templated function}
%

Another situation where implicit conversions will fail to be performed
to satisfy a function call are when the function being called is a
template function.  The C++98 standard does not allow the implicit
conversion of input arguments in order to call a template function
{}\cite[Item 45]{EffectiveC++ThirdEdition}.  For example, consider the
code in Listing~\ref{listing:implicit-conv-fail-template-func} that
fails to compile:


{}\begin{listing}: Situation where implicit conversion fails due to a
template function.
\label{listing:implicit-conv-fail-template-func}
{\small\begin{verbatim}
  template<class T> class Base { ... };
  template<class T> class Derived : public Base<T> { ... };

  template<class T>
  void someTemplateUserFunction(const RCP<const Base<T> > &base);

  template<class T>
  void someOtherTemplateUserFunction()
  {
     RCP<Derived<T> > derived(new Derived<T>);
     someTemplateUserFunction(derived);   // No implicit conv, no compmile!
     RCP<const Derived<T> > cderived = derived;
     someTemplateUserFunction(cderived);  // No implicit conv, no compmile!
     RCP<Base<T> > base = derived;
     someTemplateUserFunction(base);      // No implicit conv, no compmile!
     RCP<const Base<T> > cbase = base;
     someTemplateUserFunction(cbase);     // Exact match, compiles!
  }
\end{verbatim}}
\end{listing}


What is frustrating and yet interesting about this situation is that
if the {}\ttt{RCP}s are replaced with raw pointers, as shown in
Listing~\ref{listing:implicit-conv-pass-raw--template-func}, the C++
compiler will perform the implicit type conversions just fine.


{}\begin{listing}: Example where implicit conversion to call a
template function works fine when using raw C++ pointers.
\label{listing:implicit-conv-pass-raw--template-func}
{\small\begin{verbatim}
  template<class T>
  void someTemplateUserFunction(const Base<T> *base);
  
  template<class T>
  void someOtherTemplateUserFunction()
  {
    Derived<T> *derived = new Derived<T>;
    someTemplateUserFunction(derived);  // Okay, Derived<T>* -> const Base<T>*
    const Derived<T> *cderived = derived;
    someTemplateUserFunction(cderived); // Okay, const Derived<T>* -> const Base<T>*
    Base<T> *base = derived;
    someTemplateUserFunction(base);     // Okay, Base<T>* -> const Base<T>*
    const Base<T> *cbase = base;
    someTemplateUserFunction(cbase);    // Okay, exact match!
    delete derived;
  }
\end{verbatim}}
\end{listing}


Comparing the templated code in Listing~\ref{listing:implicit-conv-fail-template-func} and Listing~\ref{listing:implicit-conv-pass-raw--template-func} it is clear that
C++ assigns special privileges and abilities to the conversion of raw
C++ pointer data types that are not afforded to any other data type.
This is the first example of where smart pointer classes in C++ are
put at a fundamental disadvantage with respect to raw C++ pointers.
This is an unfortunate situation but the problem can be dealt with by
either forcing the conversion of the input arguments or by explicitly
specifying the template arguments as shown, for example, in Listing~\ref{listing:implicit-conv-pass-explicit-template-func}.


{}\begin{listing}: Example of methods for addressing implicit
conversions to allow the call of templated functions
\label{listing:implicit-conv-pass-explicit-template-func}
{\small\begin{verbatim}
  template<class T>
  void someTemplateUserFunction(const RCP<const Base<T> > &base);

  template<class T>
  void someOtherUserTemplateFunction()
  {
     RCP<Derived<T> > derived(new Derived<T>);
     // Force the conversion Derived<T>* -> const Base<T>*
     someTemplateUserFunction(RCP<const Base<T> >(derived));
     // or, specify template argument allowing implicit conversion
     // Derived<T>* -> const Base<T>*
     someTemplateUserFunction<T>(derived);
     ...
  }
\end{verbatim}}
\end{listing}


As shown in
Listing~\ref{listing:implicit-conv-pass-explicit-template-func},
typically the least verbose way to call a template function that
requires a conversion of input arguments is to just explicitly specify
the template argument(s) which turns the template function into a
regular function in the eyes of the C++ compiler and then implicit
conversions will be allowed to satisfy the function
call\footnote{Enabling emplicit conversions of input arguments for
template functions with explicitly defined template arguments does not
work on always work on even recent versions of the Sun C++ compiler.}.


%
{}\subsubsection*{Implicit conversions failing due to ambiguous
overloaded function calls}
%

The last situation to discuss where implicit conversions will fail to
be performed for the Teuchos memory management types occurs when
calling overloaded functions that require a conversion of the internal
pointer type that would otherwise work just fine for raw C++ pointers.
Consider the example code in
Listing~\ref{listing:overloaded-func-implicit-conv-problem} showing
the use of overloaded functions that differ in the const type of the
object.


{}\begin{listing}: Example of ambiguous calls to overloaded functions
\label{listing:overloaded-func-implicit-conv-problem}
{\small\begin{verbatim}
  class Base { ... };
  class Derived : public Base { ... };

  void someUserFunction(const RCP<Base> &base);         // Overload #1
  void someUserFunction(const RCP<const Base> &base);   // Overload #2

  void someOtherUserFunction()
  {
     RCP<Derived> derived(new Derived);
     someUserFunction(derived);  // Compile error, ambiguous call
     RCP<const Derived> cderived = derived;
     someUserFunction(cderived); // Compile error, ambiguous call
     RCP<Base> base = derived;
     someUserFunction(base);     // Okay, exact match for Overload #1
     RCP<const Base> cbase = base;
     someUserFunction(cbase);    // Okay, exact match for Overload #2
  }
\end{verbatim}}
\end{listing}


The reason that the first two function calls in
Listing~\ref{listing:overloaded-func-implicit-conv-problem} with
{}\ttt{RCP<Derived>} and {}\ttt{RCP<const Derived>} result in
ambiguous function call compile errors is that the C++ compiler is not
smart enough to know that a conversion from {}\ttt{RCP<Derived>} to
{}\ttt{RCP<Base>} is better than a conversion from
{}\ttt{RCP<Derived>} to {}\ttt{RCP<const Base>} which would allow the
first function call to result in a call to Overload \#1, for instance.
However, if raw C++ pointers are used in same code, as shown in
Listing~\ref{listing:overloaded-func-implicit-conv-raw-pass}, the
compiler will make the right implicit conversions and call the right
overloaded functions just fine.


{}\begin{listing}: Example of implicit conversions for overloaded
functions that work just fine for raw pointers
\label{listing:overloaded-func-implicit-conv-raw-pass}
{\small\begin{verbatim}
  void someUserFunction(Base *base);         // Overload #1
  void someUserFunction(const Base *base);   // Overload #2

  void someOtherUserFunction()
  {
     Derived *derived = new Derived;
     someUserFunction(derived);  // Calls Overload #1: Derived* -> Base*
     const Derived *cderived = derived;
     someUserFunction(cderived); // Calls Overload #2: const Derived* -> const Base*
     Base *base = derived;
     someUserFunction(base);     // Okay, exact match for Overload #1
     const Base *cbase = base;
     someUserFunction(cbase);    // Okay, exact match for Overload #2
     delete derived;
  }
\end{verbatim}}
\end{listing}


Again, similar to the templated function example given above,
comparing Listing~\ref{listing:overloaded-func-implicit-conv-problem}
and Listing~\ref{listing:overloaded-func-implicit-conv-raw-pass}, it
is clear that the conversions of raw C++ pointer types to call
overloaded functions are given special privileges and abilities that
are not afforded to any other data type in C++.  The C++ compiler will
resolve overloaded functions for the conversion of C++ pointer types
based on the least required conversions (e.g.\ {}\ttt{Derived*} to
{}\ttt{Base*} is better than {}\ttt{Derived*} to {}\ttt{const Base*}).
This is wonderful behavior for raw C++ pointers (or perhaps confusing
depending on how one looks at it) but such special abilities are not
afforded to smart pointer types like {}\ttt{Ptr} or {}\ttt{RCP} (or
any other smart pointer type including
{}\ttt{boost::shared\_ptr})\footnote{Fixing the problem of implicit
conversions for template and overloaded functions to put smart
pointers at the same level as raw pointers would require a C++
language extension.}.

Problems in calling overloaded functions like this can be resolved but
only through explicitly converting the input arguments as shown in
Listing~\ref{listing:overloaded-func-implicit-conv-explicit-pass}.


{}\begin{listing}: Example of resolving ambiguous calls to overloaded
functions through explicit argument conversions
\label{listing:overloaded-func-implicit-conv-explicit-pass}
{\small\begin{verbatim}
  void someUserFunction(const RCP<Base> &base);         // Overload #1
  void someUserFunction(const RCP<const Base> &base);   // Overload #2

  void someOtherUserFunction()
  {
     RCP<Derived> derived(new Derived);
     someUserFunction(RCP<Base>(derived));        // Calls Overload #1
     someUserFunction(RCP<const Base>(derived));  // Calls Overload #2
     ...
  }
\end{verbatim}}
\end{listing}


Having to explicitly convert input arguments to satisfy overloaded
function calls gets annoying very quickly for any reasonable-minded
programmer.  A much better way to deal with the problem of overload
functions and smart pointer types is to not use overloaded functions
in the first place as demonstrated in
Listing~\ref{listing:overloaded-func-implicit-conv-nonoverload}.


{}\begin{listing}: Example of resolving ambiguous calls to overloaded
functions by not using overloaded functions in the first place
\label{listing:overloaded-func-implicit-conv-nonoverload}
{\small\begin{verbatim}
  void someNonconstUserFunction(const RCP<Base> &base);
  void someUserFunction(const RCP<const Base> &base);

  void someOtherUserFunction()
  {
     RCP<Derived> derived(new Derived);
     // Compiles fine, implicit conv: Derived* -> Base*
     someNonconstUserFunction(derived);
     // Compiles fine, implicit conv: Derived* -> const Base*
     someUserFunction(derived);
     ...
  }
\end{verbatim}}
\end{listing}


Avoiding problems with ambiguous function calls to overloaded
functions by avoiding overloaded functions (as demonstrated in
Listing~\ref{listing:overloaded-func-implicit-conv-nonoverload}) may
seem like a bit of cop-out but in general function overloading tends
to be abused in C++ anyway.  In many cases, code can be much more
clear by using different function names in cases where most developers
would just use overloaded functions (perhaps because they cannot think
of better non-overloaded names).


%
{}\subsection{Core idioms for the use of the Teuchos memory management
classes}
\label{sec:idioms}
%

Well designed C++ class libraries are created together with a set of
idioms for their use and this is especially true for the Teuchos
Memory Management classes.  This paper describes idioms related to the
creation of single dynamically allocated objects, for defining and
using local variables and data members, for passing objects and arrays
of objects to and from functions, and for returning objects and arrays
of objects as return values from functions.  It is critical that these
idioms be used consistently in order to yield the safest, highest
quality, clearest, most self-documenting code.


%
{}\subsubsection{The non-member constructor function idiom}
\label{sec:nonmember-constructor-idiom}
%

The mainstream C++ literature espousing the use of smart
reference-counted pointers like {}\ttt{boost::shared\_ptr} seems to
lack a solution for an effective, safe, and clean way to create new
dynamically allocated objects.  To demonstrate the issues involved,
consider the C++ class {}\ttt{Blaget} shown in
Listing~\ref{listing:BlagetClass}:

\begin{listing}: A class taking multiple dynamically allocatable objects \\
\label{listing:BlagetClass}
{\small\begin{verbatim}
  class Blaget {
  public:
    Blaget(const RCP<Widget> &widgetA, const RCP<Widget> const widgetB);
      widgetA_(widget), widgetB_(widget) {}
    ...
  private:
    RCP<Widget> widgetA_;
    RCP<Widget> widgetB_;
  };
\end{verbatim}}
\end{listing}

Now consider how one might go about constructing a {}\ttt{Blaget}
object on the stack given newly dynamically allocated {}\ttt{Widget}
objects.  A compact, clean, and seemingly safe way to do so is shown
in Listing~\ref{listing:BlagetConstruct1}.

\begin{listing}: A leaky way to construct \\
\label{listing:BlagetConstruct1}
{\small\begin{verbatim}
  Blaget blaget( rcp(new Widget()), rcp(new Widget()) );
\end{verbatim}}
\end{listing}

The problem with the code in Listing~\ref{listing:BlagetConstruct1}
is that it might result in a memory leak if an exception is thrown by
one of the constructors for {}\ttt{Widget} (see {}\cite[Item
13]{C++CodingStandards05}).  The reason that a memory leak might occur
is that a C++ compiler is allowed to evaluate both {}\ttt{new
Widget()} calls before calling the {}\ttt{rcp()} functions.
If the second constructor {}\ttt{Widget()} throws an exception
after the first {}\ttt{Widget()} constructor has been invoked
but before the {}\ttt{RCP} object wrapping the first
{}\ttt{Widget} object is constructed, then the memory created by
the first {}\ttt{new Widget()} will never be reclaimed.

The current C++ literature (see {}\cite[Item
13]{C++CodingStandards05}) recommends rewriting constructor code like
shown in Listing~\ref{listing:BlagetConstruct1} using temporary local
variables as shown in Listing~\ref{listing:BlagetConstruct2}.

\begin{listing}: A sound but verbose way to construct \\
\label{listing:BlagetConstruct2}
{\small\begin{verbatim}
  RCP<Widget> widgetA(new Widget());
  RCP<Widget> widgetB(new Widget());
  Blaget blaget(widgetA, widgetB);
\end{verbatim}}
\end{listing}

While the code in Listing~\ref{listing:BlagetConstruct2} will avoid a
memory leak being created in case an exception is thrown, competent
Java and Python programs will rightfully be disgusted that they have
to create temporary variables just to call another constructor.  From
a software engineering perspective, it is undesirable to create
useless local variables like {}\ttt{widgetA} and {}\ttt{widgetB}
because they might be inadvertently copied and used for other
purposes, resulting in undesirable side-effects.

The way to solve the problems described above is to provide non-member
constructor functions for all dynamically allocatable reference-type
classes and then always call them to create {}\ttt{RCP}-wrapped
objects in client code.  In fact, to avoid mistakes when using
reference-type classes, one should disallow the creation of
reference-type objects except through a provided non-member
constructor.  A {}\textit{non-member constructor} compliant
{}\ttt{Widget} class declaration is shown in
Listing~\ref{listing:WidgetNonmemberConstructor}.

{}\begin{listing}: The non-member constructor idiom for reference-type
classes
\label{listing:WidgetNonmemberConstructor}
{\small\begin{verbatim}
  class Widget {
  public:
    static RCP<Widget> create() { return rcp(new Widget); }
    void display(std::ostream&);
  private: // or protected
    // Not for user's to call!
    Widget();
    Widget(const Widget&);
    Widget& operator=(const Widget&);
  };

  // Non-member constructor function
  inline RCP<Widget> createWidget() { return Widget::create(); }
\end{verbatim}}
\end{listing}

Using the non-member constructor function {}\ttt{createWidget()}, the
unsafe constructor call in Listing~\ref{listing:BlagetConstruct1}
can be written as shown in Listing~\ref{listing:BlagetConstruct3}.

{}\begin{listing}: Clean and bullet-proof way to construct dynamically
allocated objects using the ``non-member constructor function'' idiom
\label{listing:BlagetConstruct3}
{\small\begin{verbatim} Blaget blaget(createWidget(), createWidget());
\end{verbatim}}
\end{listing}

The code in Listing~\ref{listing:BlagetConstruct3} will never result
in a memory leak if an exception is thrown because each argument is
returned as a fully formed {}\ttt{RCP} object which will clean up
memory if any exception is thrown.

Note that the use of the {}\textit{non-member constructor idiom} not
only means that raw calls to {}\ttt{delete} are encapsulated in all
high-level C++ code (due to the use of {}\ttt{RCP}), but it also means
that raw calls to {}\ttt{new} should be largely encapsulated as well!

The non-member constructor idiom as shown in
Listing~\ref{listing:WidgetNonmemberConstructor} where a
reference-type object can only be dynamically allocated and returned
wrapped in an {}\ttt{RCP} object is recommended for all reference-type
objects.  The reason for this is that, as described in
Section~\ref{sec:reference-counting-machinary}, when an object is
dynamically allocated in managed in an {}\ttt{RCP} object, a number of
important debug-mode runtime checks can be performed which cannot be
when the object is first allocated on the stack or managed as a static
object.


%
{}\subsubsection{General idioms for handling arrays of objects}
\label{sec:general-array-idioms}
%

Before describing specific idioms for class data members, formal
function arguments, and function return types it is worth discussing
how arrays of objects are treated in a common way in all of these
idioms and why.  A common set of idioms that is used throughout is how
arrays of value-type objects and reference-types objects are handled.
When dealing with an array of value-type objects, typically a
contiguous array of objects will be allocated.  For example, to create
an array of value-type objects one would declare:

{\small\begin{verbatim}
  Array<S> valTypeArray;
\end{verbatim}}

In this case, the storage for the array holding the value-type objects
and the storage for the value-type objects themselves are one and the
same.  This is also true for persisting and non-persisting views of
array of value-type objects represented as {}\ttt{ArrayRCP<[const] S>}
and {}\ttt{ArrayView<[const] S>}, respectively.  It is common for
numerical programs to create very large arrays of value-type objects
of integers and floating point numbers.  Therefore, it is usually
important to share these arrays and pass them around instead of
creating copies.  Because if this, it is typical to see
{}\ttt{ArrayRCP<[const] S>} being used to share large value-type
arrays of objects.

On the other hand, one cannot generally allocate a contiguous array of
reference-type objects.  Instead, one has to allocate and use a
contiguous array of (smart) pointer objects that then point to
individually allocated reference-type objects.  For example, to store
an array of dynamically allocated reference-type objects, one would
declare:

{\small\begin{verbatim}
  Array<RCP<A> > refTypeArray;
\end{verbatim}}

Anyone familiar with object-oriented programming in C++ should already
knows this, but they might be accustomed to allocating and working
with arrays of raw pointers like {}\ttt{std::vector<T*>}.  This is a
really bad idea of course which is mentioned in Item 79 ``Store only
values and smart pointers in containers'' in
{}\cite{C++CodingStandards05}.  In this case, one can think of the
storage for the array of {}\ttt{RCP} value-type objects and the
storage for the reference-type objects of type {}\ttt{A} themselves to
be different sets of storage.  For example, one can change what
{}\ttt{A} object is pointed to in the {}\ttt{RCP<A>} object stored in
the contiguous array to without changing the {}\ttt{A} object itself
such as in Listing~\ref{listing:change-array-not-ref-type-objs}:


{}\begin{listing}: Code that changes memory in the contiguous array
but does not touch the memory in the reference-type objects themselves
\label{listing:change-array-not-ref-type-objs}
{\small\begin{verbatim}
  void foo(Array<RCP<A> > &refTypeArray, const RCP<A> &someA)
  {
    refTypeArray[0] = someA;
  }
\end{verbatim}}
\end{listing}


Note in Listing~\ref{listing:change-array-not-ref-type-objs} that
technically the memory stored in the array (of {}\ttt{RCP<A>} objects)
was changed but the memory stored in the reference-type objects being
pointed to where not changed at all.  Likewise, one can change an
{}\ttt{A} object itself without disturbing the array storage inside of
the {}\ttt{Array<RCP<A> >} object itself such as shown in
Listing~\ref{listing:change-ref-type-objs-not-array}:


{}\begin{listing}: Code that changes the memory associated with the
reference-type objects but does not change the memory of the
contiguous array at all
\label{listing:change-ref-type-objs-not-array}
{\small\begin{verbatim}
  void foo(const Array<RCP<A> > &refTypeArray)
  {
    refTypeArray[0]->someChange();
  }
\end{verbatim}}
\end{listing}


As opposed to arrays used to store value-type objects (e.g.\
{}\ttt{int}, {}\ttt{float}, {}\ttt{double},
{}\ttt{std::complex<double>}, etc.) which can be huge (with millions
of elements) one typically does not create large arrays of
reference-type objects.  (Note that creating large arrays of
reference-type objects would generally imply that the reference-type
objects are small and cheap and therefore creating a large array of
{}\ttt{RCP} objects could impart a large storage and runtime overhead
as described in Section~\ref{sec:reference-counting-overhead}.)
Since arrays of reference-type objects tend to be small in well
designed programs, one usually does not care to share the array
storage of {}\ttt{Ptr} or {}\ttt{RCP} objects itself, only the
reference-type objects they point to.  Because of this, one typically
will not see {}\ttt{ArrayRCP<[const] RCP<[const] A> >} objects being
passed around and stored.  Instead, one would typically just pass
{}\ttt{ArrayView<[const] RCP<[const] A> >} objects and then use this
array to create a new {}\ttt{Array<[const] RCP<[const] A> >} object to
copy the smart pointers.  In general, we use arrays of {}\ttt{RCP}
objects for representing persisting associations and arrays of
{}\ttt{Ptr} objects for representing non-persisting associations when
dealing with reference-type objects.


%
{}\subsubsection{Idioms for class object data members and local
variables}
%

In general, class object data members and local variables represent a
persisting relationship and therefore should have unique ownership or
use reference counting.  That means that the types {}\ttt{Ptr} and
{}\ttt{ArrayView} should almost never be used for class object data
members or local variables (especially not for data members).
However, local variables of type {}\ttt{Ptr} and {}\ttt{ArrayView}
will be created in a function when that are created off other
{}\ttt{Ptr} and {}\ttt{ArrayView} objects (passed through the formal
argument list).  The types {}\ttt{Ptr} and {}\ttt{ArrayView} will also
be used as local variables when semi-persisting associations are
involved (see Section~\ref{sec:perf-tuning-strategies} for an
example).


\begin{table}
%
%\fbox{
\begin{center}
%
%\begin{minipage}{{}\textwidth}
%
\input{ValueTypeDataMembersTable}
%
%\end{minipage}
%
\end{center}
%} % end fbox
\caption{\label{fig:data_member_value_type}
Idioms for class data member declarations for value-type objects.}
%
\end{table}


\begin{table}
%
%\fbox{
\begin{center}
%
%\begin{minipage}{{}\textwidth}
%
\input{ReferenceTypeDataMembersTable}
%
%\end{minipage}
%
\end{center}
%} % end fbox
\caption{\label{fig:data_member_reference_type}
Idioms for class data member declarations for reference-types
objects.}
%
\end{table}


Tables~\ref{fig:data_member_value_type} and
{}\ref{fig:data_member_reference_type} give some idioms for class
object data members.  Usages for local variables are similar.
Table~\ref{fig:data_member_value_type} shows a few use cases involving
value-type objects.  Table~\ref{fig:data_member_reference_type} shows
use cases involving reference-type objects.  Every possible use case
is not shown in these tables, only the most common ones.  There is
almost no end to the number of different types of data structures that
can be created by embedding these memory management types in each
other to address different needs.  When creating these composite data
structures one just needs to understand the implications for the
selections of the class types and for the use of const.

It is important to note that an {}\ttt{RCP<S>} data member for a
value-type object is not shown in
Table~\ref{fig:data_member_value_type}.  That is because once one
declares an {}\ttt{RCP} object pointing to a value-type object, at
that point one is treating the value-type object with reference
semantics so it would be considered to be a reference-type object
(which takes one to Table~\ref{fig:data_member_reference_type}).
Again, most value-type class objects can be treated as reference-types
in certain contexts (e.g.\ such as when dynamically allocating a large
{}\ttt{Array} object so it can be shared and avoid expensive deep copy
semantics).

Note that there are a few other important differences between the way
that value-type objects and reference-type objects are handled.  The
main difference, obviously, is that one can hold a value-type object
by value but not for a reference-type object.  One can see this in how
single objects are stored and how arrays of objects are declared in
Table~\ref{fig:data_member_reference_type}.


%
{}\subsubsection{Idioms for the specification of formal arguments for
C++ functions}
\label{sec:idioms-for-passing-arguments}
%

\begin{table}[p]
%
%\fbox{
\begin{center}
%
%\begin{minipage}{{}\textwidth}
%
\input{PassingValueObjectsTable}
%
%
%\end{minipage}
%
\end{center}
%} % end fbox
\caption{\label{fig:func_args_value_type}
Idioms for passing value-type objects to C++ functions.}
%
\end{table}


\begin{table}[p]
%
%\fbox{
\begin{center}
\input{PassingReferenceObjectsTable}
\end{center}
\caption{\label{fig:func_args_ref_type}
Idioms for passing reference-type objects to C++ functions.}
%} % end fbox
\end{table}


Described here are idioms for the specification of the formal
arguments for C++ functions that maximize compile-time and debug-mode
run-time checking, yield near optimal raw pointer performance for
non-debug-mode builds, and result in highly self-documenting code.  A
key component to this specification is that no raw C++ pointers are
used.  Raw pointers are the cause of almost all memory usage problems
in C++.  Raw C++ references, on the other hand, are safe to use as
long as the object reference they are being used to point to is valid
and no persisting association exists (see
Section~\ref{sec:raw-C++-references}).

Tables~\ref{fig:func_args_value_type} and
{}\ref{fig:func_args_ref_type} give conventions for passing single
objects and arrays of objects for value-type {}\index{Types!Value
Type} and reference-type {}\index{Types!reference type} objects,
respectively.  In this specification, the Teuchos classes {}\ttt{Ptr},
{}\ttt{RCP}, {}\ttt{ArrayRCP}, and {}\ttt{ArrayView} are used as a
means to pass objects of another type (shown as {}\ttt{S} and
{}\ttt{A} in Tables~\ref{fig:func_args_value_type} and
{}\ref{fig:func_args_ref_type}).  Conventions are shown for both
passing in objects and for passing out objects through the formal
arguments to C++ functions.  Note that value-type objects can always
be handled using reference semantics so all of the passing conventions
in Table~\ref{fig:func_args_ref_type} apply equally as well for
value-type objects as they do for reference-type objects.  However,
the conventions in Table~\ref{fig:func_args_value_type} only apply to
value-type objects that can be stored in contiguous arrays.

This specification addresses the five different properties that must
be considered when passing an object to a function as a formal
function argument (or passing back an object through a formal function
argument):

\begin{itemize}

{}\item Is it a single object or an array of objects?

{}\item Does the object or array of objects use value semantics or
reference semantics?

{}\item Is the object or array of objects changeable or non-changeable
(i.e.\ const)?

{}\item Is this establishing a persisting or non-persisting (or
semi-persisting) association?

{}\item Is the object or array of objects optional or required?

\end{itemize}

The first four of these properties are directly expressed in the C++
code in all cases shown in Tables~\ref{fig:func_args_value_type} and
{}\ref{fig:func_args_ref_type}.  The specification for whether an
argument or object is required or optional must be documented in the
function's interface specification (i.e.\ in a Doxygen documentation
{}\ttt{param} field).  It is declared here that, by default, an
argument passed through an {}\ttt{Ptr}, {}\ttt{RCP},
{}\ttt{ArrayView}, or {}\ttt{ArrayRCP} object will be assumed to be
required (i.e.\ non-null) unless otherwise stated.  The only exception
for this implicit assumption for non-null objects is {}\ttt{const
Ptr<const T>\&} for single, non-changeable, non-persisting, objects
where these always mean that the argument is optional.  If such an
argument is required, it is specified as {}\ttt{const T\&}.

An array of value objects is passed as contiguous storage through an
{}\ttt{ArrayView<S>} or {}\ttt{ArrayView<const S>} object.  An
array of reference objects, however, cannot be passed in contiguous
storage for the objects themselves and instead must be passed as
contiguous storage of (smart) pointers to the objects using
{}\ttt{ArrayView<const Ptr<const A> >} for non-persisting
associations or {}\ttt{ArrayView<const RCP<const A> >} for
persisting associations.  The {}\ttt{const} can be removed from the
either {}\ttt{Ptr}/{}\ttt{RCP} or {}\ttt{A} depending on what
is allowed to change or not change during the function call.

Note that in the case of {}\ttt{Ptr}, {}\ttt{RCP}, {}\ttt{ArrayView},
and {}\ttt{ArrayRCP} objects, that these can be treated as output
objects in their own right which is shown in
Tables~\ref{fig:func_args_value_type} and
{}\ref{fig:func_args_ref_type} for passing out persisting and
semi-persisting relationships to single objects and arrays of objects.
For example, passing an {}\ttt{RCP<T>} object into a function to be
set to point to a different {}\ttt{A} object would be specified in the
function prototype as {}\ttt{const Ptr<RCP<A> >\&} or {}\ttt{RCP<A>\&}
depending on preference (only the case {}\ttt{const Ptr<RCP<A> >\&} is
shown in the tables which is a better self-documenting form and
provides better debug-mode runtime checking since it can detect
dangling references).  Note that semi-persisting associations are
always passed out as {}\ttt{Ptr} and {}\ttt{ArrayView} objects.  These
types have essentially zero overhead in an optimized build but yet
have full runtime checking including detection and reporting of
dangling references in a debug-mode build (see
Section~\ref{sec:perf-tuning-strategies} for a discussion of the
motivation and usage of semi-persisting associations).  The types
{}\ttt{RCP} and {}\ttt{ArrayRCP} are always used to establish
persisting associations.


%
{}\subsubsection*{Variations in passing single changeable objects}
\label{sec:vars-passing-single-objs}
%

The only area of contention in this specification is how to handle
arguments for required single changeable objects.  The specification
described here allows either passing them through a smart pointer as
{}\ttt{const Ptr<T>\&} or as a raw non-const object reference as
{}\ttt{T\&}.  In Item 25 in {}\cite{C++CodingStandards05}, the authors
recommend passing a raw non-const object reference {}\ttt{T\&} for
changeable required objects, which seems very reasonable.  However,
other notable authors {}\cite[Section Section 5.5]{stroustrup97} and
{}\cite[Section 13.2]{CodeComplete2nd04} and the Google C++ coding
standard\footnote{\ttt{http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml}}
recommend passing a pointer instead, as it provides a visual clue that
the object is being modified in the function call.  Of course, the
idioms defined here do not allow raw pointers so one must pass a
{}\ttt{const Ptr<T>\&} object instead.  To consider the issues, for
example, looking at the function call in
Listing~\ref{listing:fun-call-raw-refs}, which (if any) argument(s)
are being modified?


{}\begin{listing}: Function call using all raw references where it is
impossible to determine what objects are modified in the call
\label{listing:fun-call-raw-refs}
{\small\begin{verbatim}
  someFunction(a, b, c, d);
\end{verbatim}}
\end{listing}


To tell for sure which objects are being modified in
Listing~\ref{listing:fun-call-raw-refs}, one would have to look at the
function prototype shown in Listing~\ref{listing:fun-decl-raw-refs} to
see that it is the {}\ttt{d} argument that is being modified in the
function call.


{}\begin{listing}: Function prototype where all objects are passed as
raw C++ references
\label{listing:fun-decl-raw-refs}
{\small\begin{verbatim}
  void someFunction(const A& a, const B& b, const C& c, D& d);
\end{verbatim}}
\end{listing}


Now consider the convention that all changeable arguments be passed in
through a pointer as {}\ttt{const Ptr<T>\&}, giving the new prototype
shown in Listing~\ref{listing:fun-decl-ptr-changed-objs}.


{}\begin{listing}: Function prototype where modified objects are
passed through {}\ttt{Ptr} leading to self-documenting client code
\label{listing:fun-decl-ptr-changed-objs}
{\small\begin{verbatim}
  void someFunction(const A& a, const B& b, const C& c,
    const Ptr<D>& d );
\end{verbatim}}
\end{listing}


Now the new function call in
Listing~\ref{listing:fun-call-ptr-changed-obj} is self-documenting
with regards to which object is modified in the function call by using
the {}\ttt{outArg(...)} templated non-member function (see
{}\ttt{outArg(...)} in
Listing~\ref{listing:ptr-from-ref-nonmember-constructors}).


{}\begin{listing}: Self-documenting function call that shows what
argument is modified in the function call
\label{listing:fun-call-ptr-changed-obj}
{\small\begin{verbatim}
  someFunction(a, b, c, outArg(d));
\end{verbatim}}
\end{listing}


Also, given that all {}\ttt{Ptr<T>} arguments are assumed to be
non-null by default, this specifies that passing an argument as
{}\ttt{const Ptr<T>\&} has all of the same meaning that passing an
argument by {}\ttt{T\&}.  Of course now one has given up a
compile-time check for a non-null argument for {}\ttt{T\&} with a
debug-mode runtime check that {}\ttt{const Ptr<T>\&} is non-null.
Theoretically, the compile-time check would appear to be far superior
but in reality the debug-mode runtime check is usually what happens
anyway since the raw object reference would typically be created from
a smart pointer in most cases (which can be null, resulting in a null
dereference runtime exception in a debug-mode build).  Therefore the
issue is not whether a compile-time check will catch passing a
null-object (because it can't) but instead the issue is how soon a
debug-mode runtime check will catch a dereference of a null smart
pointer.

% ToDo: Show example code comparing the issues discussed above.


%
{}\subsubsection*{Converting from non-persisting to persisting
references to satisfy the defined idioms}
%

There are legitimate instances where client code needs to convert a
non-persisting reference (i.e. {}\ttt{T\&}, {}\ttt{Ptr<T>}, or
{}\ttt{ArrayView<T>}) to a persisting reference (i.e.\ {}\ttt{RCP} or
{}\ttt{ArrayRCP}) in order to satisfy the idioms outlined in
Tables~\ref{fig:func_args_value_type} and
{}\ref{fig:func_args_ref_type}.  The most common case is when a
function is passed a raw reference or a {}\ttt{Ptr} to a C++ object
(for a non-persisting association) but the function's implementation
must create (and destroy) and object what has a persisting association
with the passed in object.  Consider the classes {}\ttt{A}, {}\ttt{B}
and {}\ttt{C} shown in
Listing~\ref{listing:NonPersistingPersistingAssociationsRCP} where
{}\ttt{C} maintains an {}\ttt{RCP} to {}\ttt{B}.  Now consider a
client function that needs an {}\ttt{A} and {}\ttt{B} object to
perform its function but also needs to create and destroy a {}\ttt{C}
object internally giving it the {}\ttt{B} object.  In order to be
consistent with the idioms defined here, the {}\ttt{B} object must be
passed as a raw C++ reference or through a {}\ttt{Ptr} object.
Listing~\ref{listing:convert-from-raw-ref-to-RCP} shows how to convert
from a raw C++ reference to a non-owning {}\ttt{RCP} object to satisfy
the idioms.


{}\begin{listing}: Converting from a raw C++ reference to an
{}\ttt{RCP} object to satisfy function argument passing idiom
\label{listing:convert-from-raw-ref-to-RCP}
{\small\begin{verbatim}
  void doSomeOperation(B &b, const A &a)
  {
     ...
     C c;
     const RCP<B> b_rcp = rcpFromRef(b);
     c.fooC1(b_rcp, a);
     c.fooC2();
     ...
     // The C object is destroyed here!
  }
\end{verbatim}}
\end{listing}


In Listing~\ref{listing:convert-from-raw-ref-to-RCP}, the standard
conversion function {}\ttt{rcpFromRef(...)} converts from a raw C++
reference to a non-owning {}\ttt{RCP} object.  Creating an {}\ttt{RCP}
like is perfectly safe and correct.  The lifetime of the created
{}\ttt{C} object is contained within the function
{}\ttt{doSomeOperation(...)} so the promise of not creating a
persisting association inherent in the functions prototype (i.e.\
passing the {}\ttt{B} object as a raw C++ reference) is being
correctly kept.  Note that if the created non-owning {}\ttt{RCP} is
accidentally used to create a persisting association then, in many
cases, the dangling reference will be caught by the built-in
debug-mode runtime checking (see
Section~\ref{sec:detection-dangling-references}).

A similar type of conversion is required when passing in an object
through a {}\ttt{Ptr} object.  For example, the function in
Listing~\ref{listing:convert-from-raw-ref-to-RCP} may instead pass in
a {}\ttt{Ptr<B>} object instead of a raw C++ reference {}\ttt{B\&} and
the refactored function is shown in
Listing~\ref{listing:convert-from-Ptr-to-RCP}.


{}\begin{listing}: Converting from a {}\ttt{Ptr} object to an
{}\ttt{RCP} object to satisfy function argument passing idiom
\label{listing:convert-from-Ptr-to-RCP}
{\small\begin{verbatim}
  void doSomeOperation(const Ptr<B> &b, const A &a)
  {
     ...
     C c;
     const RCP<B> b_rcp = rcpFromPtr(b);
     c.fooC1(b_rcp, a);
     c.fooC2();
     ...
     // The C object is destroyed here!
  }
\end{verbatim}}
\end{listing}


Again, if a persisting association is accidentally created by copying
the {}\ttt{RCP<B>} object created in
Listing~\ref{listing:convert-from-Ptr-to-RCP} then this can be
detected in a debug-mode build.  Note that the conversion from
{}\ttt{Ptr<B>} to {}\ttt{RCP<B>} shown in in
Listing~\ref{listing:convert-from-Ptr-to-RCP} actually generates much
more efficient code in a debug-mode build because dangling-reference
detection is implemented without having to perform a more expensive
node look-up as described in
Section~\ref{sec:detection-dangling-references}.


%
{}\subsubsection{Idioms for returning objects from C++ functions}
\label{sec:idioms-returning-objects}
%

Idioms for how objects are returned from C++ functions are also
important in order to achieve C++ code that is efficient, safe (with
both compile-time and debug-mode run-time checking), and is as
self-documenting as possible.  Tables~\ref{fig:func_return_value_type}
and {}\ref{fig:func_return_reference_type} give common specifications
for returning single objects and arrays of objects for both value-type
and reference-type objects for non-persisting, persisting, and
semi-persisting associations.  Five different types of properties that
must be defined and considered when returning an object (or array of
objects) from a function:

\begin{itemize}

{}\item Is it a single object or an array of objects?

{}\item Does the object or array of objects use value semantics or
reference semantics?

{}\item Is the object or array of objects changeable or non-changeable
(i.e.\ const)?

{}\item Is this establishing a persisting or non-persisting (or
semi-persisting) association?

{}\item Is the object or array of objects optional or required?

\end{itemize}


\begin{table}
%
%\fbox{
\begin{center}
%
%\begin{minipage}{{}\textwidth}
%
\input{ReturningValueObjectsTable}
%
%
%\end{minipage}
%
\end{center}
%} % end fbox
\caption{\label{fig:func_return_value_type}
Idioms for returning value-type objects from C++ functions.}
%
\end{table}


\begin{table}
%
%\fbox{
\begin{center}
%
%\begin{minipage}{{}\textwidth}
%
\input{ReturningReferenceObjectsTable}
%
%
%\end{minipage}
%
\end{center}
%} % end fbox
\caption{\label{fig:func_return_reference_type}
Idioms for returning reference-type objects from C++ functions.}
%
\end{table}


These five different properties are the same five described for formal
function arguments described in
Section~\ref{sec:idioms-for-passing-arguments}.  Again, the first four
of these properties are clearly defined in the C++ code itself.
However, again, it is not always possible to directly state in the C++
code declarations whether the object (or array of objects) is optional
or required.  Here, we state by default that all array arguments of
type {}\ttt{ArrayView} and {}\ttt{ArrayRCP} are assumed to be required
non-null arguments by default.  Otherwise, documentation must exist
stating that the arguments are optional.

The semantics of return objects is different than for formal function
arguments.  There are several differences that one can see from
looking at Tables~\ref{fig:func_args_value_type} and
{}\ref{fig:func_args_ref_type}, and
Tables~\ref{fig:func_return_value_type} and
{}\ref{fig:func_return_reference_type}.  The key difference between
formal functions arguments and return values relates to using constant
references for formal arguments versus returning objects by value as
return types.  While the memory management objects of type
{}\ttt{Ptr}, {}\ttt{RCP}, {}\ttt{ArrayView}, and {}\ttt{ArrayRCP} are
all passed by constant reference in
Tables~\ref{fig:func_args_value_type} and
{}\ref{fig:func_args_ref_type}, alternatively they are always returned
as objects (i.e.\ return by value) in
Tables~\ref{fig:func_return_value_type} and
{}\ref{fig:func_return_reference_type}.  The reason that these memory
management objects should always be returned by value is that this is
needed to correctly set up the reference counting machinery to
properly set up persisting relationships and to enable debug runtime
checking (e.g.\ to detect dangling references with semi-persisting
associations).

Note that it is critical that semi-persisting associations for single
objects must always be returned as {}\ttt{Ptr<T>} objects and never as
raw references {}\ttt{T\&} which is otherwise acceptable for
non-persisting associations.  The reason that {}\ttt{Ptr<T>} objects
must always be used for semi-persisting associations is that in a
debug-mode build, the runtime checking machinery will be able to
detect dangling references or changes in the parent object that would
otherwise invalidate the semi-persisting view that is impossible to
catch when using raw C++ references.

In the following section, an extended example is given highlighting
the need to return the Teuchos memory management smart pointer objects
by value.  If one already accepts the need for this, the example can
be skipped.

%
{}\subsubsection*{Extended example for the need to return smart pointers by value}
%

In order to understand the importance of returning memory management
objects by value instead of by reference, first consider
Listing~\ref{listing:unsafe_raw_C++_reference1} that looks to be
perfectly safe code.


{}\begin{listing}: A seemingly safe use of raw C++ references
\label{listing:unsafe_raw_C++_reference1}
{\small\begin{verbatim}
  void seeminglySafeFoo(Blob &blob, Flab &flab)
  {
    blob.doGoodStuff(flab);
  }
\end{verbatim}}
\end{listing}


The code in Listing~\ref{listing:unsafe_raw_C++_reference1} does not
itself look unsafe.  However, the reason that it unsafe comes from the
code that calls {}\ttt{seeminglySafeFoo(...)} and the code that
implements {}\ttt{Blob} shown in Listing~\ref{listing:unsafe_raw_C++_reference2}.


{}\begin{listing}: Code that makes seeminglySafeFoo(...) fail
\label{listing:unsafe_raw_C++_reference2}
{\small\begin{verbatim}
  class Blob
  {
    RCP<Flab> flab_;
  public:
    Blob() : flab_(createFlab()) {}
    const RCP<Flab>& getFlab() { return flab_; }
    void doGoodStuff(Flab &flab_in)
    {
      flab_ = createFlab(); // Using non-member constructor
      flab_in.conflab(*flab_);
    }
  };


  void badCallingFunction()
  {
    Blob blob;
    seeminglySafeFoo(blob, *blob.getFlab());
  }
\end{verbatim}}
\end{listing}


When the code in Listings~\ref{listing:unsafe_raw_C++_reference1} and
{}\ref{listing:unsafe_raw_C++_reference2} executes, it will most
likely cause a segfault when it runs, if one is lucky.  However, if
unlucky, the code will actually seem to be working correctly on the
machine where the code is initially tested it but will explode later
(perhaps years later) when run under different circumstances.  The
reason that the code in
Listings~\ref{listing:unsafe_raw_C++_reference1}
and~\ref{listing:unsafe_raw_C++_reference2} is faulty is because the
{}\ttt{Flab} object that is passed through the call
{}\ttt{seeminglySafeFoo(blob, *blob.getFlab())} to
{}\ttt{blob.doGoodStuff(flab)} is invalidated before it is used
because it gets destroyed and is replaced by a new object in the
expression {}\ttt{flab\_ = createFlab()}.  When this happens, the
object now represented as the raw C++ reference {}\ttt{flab\_in} is
deleted which causes the code in the expression
{}\ttt{flab\_in->conflab(*flab\_)} to be in error, and the behavior of
the program is undefined (and again will segfault if one is lucky).

How did it come to this situation?  What if the raw C++ references
were replaced with with RCP-wrapped objects?  Well, consider the
updated code in Listing~\ref{listing:unsafe_raw_C++_reference3}.

\begin{listing}: Still unsafe code  \\
\label{listing:unsafe_raw_C++_reference3}
{\small\begin{verbatim}
  class Blob
  {
    RCP<Flab> flab_;
  public:
    Blob() : flab_(createFlab()) {}
    const RCP<Flab>& getFlab() { return flab_; }
    void doGoodStuff(const RCP<Flab> &flab_in)
    {
      flab_ = createFlab(); // Using non-member constructor
      flab_in.conflab(*flab_);
    }
  };


  void seeminglySafeFoo(Blob &blob, const RCP<Flab> &flab)
  {
    blob.doGoodStuff(flab);
  }


  void badCallingFunction()
  {
    Blob blob;
    seeminglySafeFoo(blob, blob.getFlab());
  }
\end{verbatim}}
\end{listing}

Is the code in Listing~\ref{listing:unsafe_raw_C++_reference3}
correct?  The sad answer is no, it is not.  The {}\ttt{Flab} object
returned from {}\ttt{blob.getFlab()} will still get deleted before it
is used in the expression {}\ttt{flab\_->conflab(flab\_in)}.  What is
going on here?  The core of the problem is that the function
{}\ttt{Blob::getFlab()} is incorrectly implemented.  Functions must
always return {}\ttt{RCP} objects by value and never by reference as
shown in Tables~\ref{fig:func_return_value_type}
and~\ref{fig:func_return_reference_type}.  By returning a raw C++
reference to the {}\ttt{RCP<Flab>} object, a persisting association
with the client is never properly established and this is the root
cause of the whole problem.

Now consider the updated code in
Listing~\ref{listing:safe_raw_C++_reference3} that goes back to using
raw C++ references where appropriate but now returns the
{}\ttt{RCP<Flab>} object by value as it should.

\begin{listing}: Correctly returning RCP by value yielding safe code \\
\label{listing:safe_raw_C++_reference3}
{\small\begin{verbatim}
  class Blob
  {
    RCP<Flab> flab_;
  public:
    Blob() : flab_(createFlab()) {}
    RCP<Flab> getFlab() { return flab_; } // Returns by value now!
    void doGoodStuff(Flab &flab_in)
    {
      flab_ = createFlab(); // Using non-member constructor
      flab_in.conflab(*flab_);
    }
  };


  void seeminglySafeFoo(Blob &blob, Flab &flab)
  {
    blob.doGoodStuff(flab);
  }


  void goodCallingFunction()
  {
    Blob blob;
    seeminglySafeFoo(blob, *blob.getFlab());
  }
\end{verbatim}}
\end{listing}

Is the code represented in
Listing~\ref{listing:safe_raw_C++_reference3} now safe and correct?
Yes it is.  The reason that it is now safe and correct is that a
persisting relationship is now being correctly created by the function
call {}\ttt{blob.getFlab()} in that a new temporary {}\ttt{RCP<Flab>}
object is created (which increments the reference count).  From this
new temporary {}\ttt{RCP<Flab>} object, a raw C++ reference is then
returned from {}\ttt{*blob.getFlab()} and passed through.  In this
case, since the reference count on the existing {}\ttt{Flab} object is
now two instead of one, the expression {}\ttt{flab\_ = createFlab()}
will not delete the existing {}\ttt{Flab} object and the following
expression {}\ttt{flab\_in.conflab(*flab\_)} will have two valid
{}\ttt{Flab} objects.  After the function
{}\ttt{seeminglySafeFoo(blob, *blob.getFlab())} exits, the first
{}\ttt{Flab} object will finally be deleted (but that is just fine).


%
{}\subsubsection*{More examples of function return issues}
%

Another difference between formal function arguments and return values
is what persisting and non-persisting associations mean related to
function returns.  In the case of objects returned from C++ functions,
a persisting association is one where the object returned from a C++
function is remembered past the end of the statement where the C++
function returning the objects is called.  For example, consider the
code in Listing~\ref{listing:persisting-func-return-1}.


{}\begin{listing}: Example of a bad persisting association
implemented as a raw C++ reference (see the {}\ttt{Grob} class
defined in Listing~\ref{listing:bad-Glob-non-persisting})
\label{listing:persisting-func-return-1}
{\small\begin{verbatim}
  void foo(Glob& glob)
  {
    const Flab &flab = glob.getFlab();
    glob.doStuff();
    flab.doMoreStuff();
  }
\end{verbatim}}
\end{listing}


The code in Listing~\ref{listing:persisting-func-return-1} represents
a persisting association because because the {}\ttt{Flab} object
returned in the expression {}\ttt{const Flab
\&flab = glob.getFlab()} is remembered past the statement where it is
called and is used later in calling {}\ttt{flab.doMoreStuff()}.  This
type of code is all too common in C++ programs (including a lot of
code I have written over the last 10 years) but it is not safe because
it is not properly respecting the notion of persisting associations.
To see why the code in Listing~\ref{listing:persisting-func-return-1} is so bad, consider the
possible unfortunate implementation of the {}\ttt{Glob} class shown in
Listing~\ref{listing:bad-Glob-non-persisting}:


{}\begin{listing}: Bad implementation of the {}\ttt{Glob} class with
respect to persisting associations
\label{listing:bad-Glob-non-persisting}
{\small\begin{verbatim}
  class Glob {
    RCP<Flab> flab_;
  public:
    Glob() : flab_(createFlab()) {}
    const Flab& getFlab() const { return *flab_; }
    void doStuff()
      {
        flab_ = createFlab(); // Non-member constructor
        ...
      }
  };
\end{verbatim}}
\end{listing}


What happens of course is that the behavior of the code in
Listings~\ref{listing:persisting-func-return-1}
and~\ref{listing:bad-Glob-non-persisting} is undefined and will most
likely result in a segfault (if one is lucky).  The reason this is bad
code is that the {}\ttt{Flab} object reference that gets returned from
{}\ttt{glob.getFlab()} is not used until after the function
{}\ttt{Glob::doStuff()} gets called which will delete the {}\ttt{Flab}
object and replace it with another one.  This results in
{}\ttt{flab.doMoreStuff()} being called on a deleted object.  Again,
this will typically result in a segfault, but on some systems in some
cases the program might actually seem to run just fine, perhaps even
for years.  This of course is an error that a tool like Valgrind or
Purify would likely catch pretty easily which is why these tools are
very useful to have around.  So what rule was broken in
Listing~\ref{listing:persisting-func-return-1}?  Consider again the
definition of a persisting association related to a return value which
is:

\begin{itemize}

{}\item\textit{Persisting associations} are associations that exist
between two or more objects that extend past a single function call
for formal function arguments, or a single statement for function
return objects.

\end{itemize}

What this means is that any object that is returned as a raw C++
reference from a function must be used in the same statement from
where the returning function is called.  Therefore, the function in
Listing~\ref{listing:persisting-func-return-1} should be rewritten
as shown in Listing~\ref{listing:non-persisting-func-return-1}.


\begin{listing}:\\
\label{listing:non-persisting-func-return-1}
{\small\begin{verbatim}
  void foo(Glob& glob)
  {
    glob.getFlab().doMoreStuff();
    glob.doStuff();
  }
\end{verbatim}}
\end{listing}


Here, of course, one is assuming that the order of evaluation of the
functions is not important.

Note that functions returning raw C++ references are common and are
fairly safe to use as long as the returned object is used in the same
statement where the function is called.  For example, this is what is
commonly done when a non-const reference to an element from a
user-defined array class object is returned and set in the same
statements such as shown in
Listing~\ref{listing:non-persisting-array-return-1}.


\begin{listing}:\\
\label{listing:non-persisting-array-return-1}
{\small\begin{verbatim}
  void foo(std::vector<int>& a)
  {
    a[0] = 5; // Non-persisting function return association
    ...
  }
\end{verbatim}}
\end{listing}


What is typically not safe, of course, is when one tries to save a
reference to an object and then use it like in
Listing~\ref{listing:bad-persisting-array-return-1}.


\begin{listing}:\\
\label{listing:bad-persisting-array-return-1}
{\small\begin{verbatim}
  void foo(std::vector<int>& a)
  {
    int &a_0 = a[0]; // Incorrect persisting association
    a.resize(20);
    a_0 = 5;         // Will likely segfault if one is lucky!
    ...
  }
\end{verbatim}}
\end{listing}


The problem with the code in
Listing~\ref{listing:bad-persisting-array-return-1} is that the
{}\ttt{a.resize(20)} function might cause a new buffer to be allocated
and the existing buffer to be deleted.  This will of course make the
reference returned in {}\ttt{int \&a\_0 = a[0]} invalid when it is
later written to in {}\ttt{a\_0 = 5}.

The whole point of the example code
Listings~\ref{listing:non-persisting-array-return-1}
and~\ref{listing:bad-persisting-array-return-1} is to demonstrate the
working definition of persisting \& non-persisting associations as
they relate to objects returned from functions.  This argument
supports the idioms shown in Tables~\ref{fig:func_return_value_type}
and {}\ref{fig:func_return_reference_type}.


%
{}\subsection{Reference-counting machinery in-depth}
\label{sec:reference-counting-machinary}
%

In order to effectively use these memory management classes and to
debug problems when they occur, one must understand the basic
reference-counting approach being used.  Basic reference counting with
smart pointers is well established in the C++ literature
{}\cite{MoreEffectiveC++96} but a basic overview and specific details
about the approach used in the Teuchos memory management classes is
appropriate to describe here.  Of equal importance is to describe how
the reference-counting infrastructure can be used to address some
boundary cases that can help solve some fundamental problems with
reference counting.

The basic reference counting machinery being used by the classes is
first described.  Next, the issue of circular references and weak
pointers are discussed.


%
{}\subsubsection{Basic reference counting machinery}
\label{sec:basic-reference-counting-machinery}
%

{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.65]{TeuchosRCPDesign}
%}
\end{center}
\caption{
\label{fig:TeuchosRCPDesign}
Basic design of the Teuchos reference-counting machinery.  }
\end{figure}
\esinglespace}

The foundation for the reference-counting machinery used by all of the
reference-counting classes is shown in
Figure~\ref{fig:TeuchosRCPDesign} (UML class diagram).  The class
{}\ttt{RCPNode} is an abstract base class that contains two different
reference counts (a strong count and a weak count) and inline
functions for manipulating the counts as efficiently as possible.  The
templated concrete subclass {}\ttt{RCPNodeImpl} is what actually
stores the raw C++ pointer to the reference-counted object.  This
class is also templated on an deallocation policy object that
determines how the object is reclaimed.  {}\ttt{RCPNodeHandle} is a
simple handle class that automates the manipulation of the reference
counts by overloading the copy constructor and assignment operator
functions.  This avoids having to replicate reference counting
incrementing and decrementing in the user-level classes {}\ttt{RCP}
and {}\ttt{ArrayRCP} that contain it.  All of the functions on
{}\ttt{RCPNodeHandle} are inlined and the only data members are a
pointer to the underlying {}\ttt{RCPNode} object and a
{}\ttt{strength} attribute (with values {}\ttt{RCP\_STRONG} and
{}\ttt{RCP\_WEAK}).  The class {}\ttt{RCPNodeHandle} imparts zero
space and time overhead and removes all duplication in how the
reference count node object is handled.  In future UML diagrams, the
{}\ttt{RCPNodeHandle} class will be considered to be part of the
owning {}\ttt{RCP} or {}\ttt{ArrayRCP} classes to avoid clutter.  The
classes {}\ttt{RCPNode}, {}\ttt{RCPNodeImpl}, and
{}\ttt{RCPNodeHandle}, are used unchanged for both the {}\ttt{RCP} and
{}\ttt{ArrayRCP} classes (however, only the {}\ttt{RCP} class is shown
for simplicity).

The member functions for {}\ttt{RCP} and {}\ttt{ArrayRCP} related to
reference-counting are shown in Listing~\ref{listing:ref-count-mem-funcs}.


{}\begin{listing}: Reference counting member functions for {}\ttt{RCP}
and {}\ttt{ArrayRCP}
\label{listing:ref-count-mem-funcs}
{\small\begin{verbatim}
  template<class T>
  class [Array]RCP {
  public:
    ...
    // Reference counting member functions
    ERCPStrength strength() const;
    bool is_valid_ptr() const;
    int strong_count() const;
    int weak_count() const;
    int total_count() const;
    void set_has_ownership();
    bool has_ownership() const;
    Ptr<T> release();
    RCP<T> create_weak() const;
    RCP<T> create_strong() const;
    template<class T2> bool shares_resource(const RCP<T2>& r_ptr) const;
    const RCP<T>& assert_not_null() const;
    const RCP<T>& assert_valid_ptr() const;
    ...
  };
\end{verbatim}}
\end{listing}


Most of the functions in Listing~\ref{listing:ref-count-mem-funcs} are
never called by general clients except in desperate situations.
Notable exceptions are the member functions {}\ttt{create\_weak()}
(which is used to create a {}\ttt{WEAK} {}\ttt{RCP} object from a
{}\ttt{STRONG} object) and and {}\ttt{create\_strong()} (which is used
to create a {}\ttt{STRONG} {}\ttt{RCP} object from a {}\ttt{WEAK}
object).  The function {}\ttt{create\_weak()} is used to break a
circular reference as described in
Section~\ref{sec:circular-references-weak-pointers} while
{}\ttt{create\_strong()} is used in situations like the ``object
self-reference'' idiom described in Section~\ref{sec:self-references}.

Figure~\ref{fig:TeuchosRCPDesign} also shows that every
{}\ttt{RCPNode} object has an optional {}\ttt{std::map} object
that can be used to store and retrieve arbitrary extra data
(represented as the {}\ttt{any} data-type which can handle any
value-type object).  A raw pointer is stored to the
{}\ttt{extra\_data\_map} object that is initialized to null by
default.  Therefore, if no extra data is used, the only overhead for
this feature is an extra pointer member and its initialization to
null.  The motivation for and the usage of extra data is discussed in
Section~\ref{sec:extra-data}.

It is critical to understand that the foundation for sharing objects
using reference counting is that only one owning {}\ttt{RCPNode}
object can exist for any object that is shared.  Consider the code in
Listing~\ref{listing:rcp-example-4} that creates the
reference-counting objects shown in Figure~\ref{fig:RCPEx1}.  All of
these {}\ttt{RCP} objects share the same {}\ttt{RCPNode} object.


{}\begin{listing}: Example of setting up several {}\ttt{RCP} objects
pointing to the same reference-counted object shown in
Figure~\ref{fig:RCPEx1}.
\label{listing:rcp-example-4}
{\small\begin{verbatim}
  RCP<C> c(new C);
  RCP<B1> b1 = c;
  RCP<B2> b2 = c;
  RCP<A> a1 = c;
  RCP<A> a2 = a.create_weak();
\end{verbatim}}
\end{listing}


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.65]{RCPEx1}
%}
\end{center}
\caption{
\label{fig:RCPEx1}
Example of several {}\ttt{RCP} objects pointing to the same
{}\ttt{RCPNodeImpl} object.  }
\end{figure}
\esinglespace}


If the programmer follows the idioms described in
Section~\ref{sec:idioms} and outlined in
Appendix~\ref{apdx:summary_of_idioms} and
Appendix~\ref{apdx:commandments}, it will always be the case that only
one reference-counting node object will exist for a given
reference-counted object.  Exceptions to the one owning
{}\ttt{RCPNode} object per reference-counted object guideline are
allowed to facilitate some more advanced use cases (see
Section~\ref{sec:inverting-obj-ownership} for an example).  As
mentioned earlier, the {}\ttt{RCPNode} object stores both a strong and
a weak reference count.  The strong and weak reference counts are
equal to the number of strong and weak {}\ttt{RCP} objects pointing to
the single {}\ttt{RCP} node object.  When the strong count goes to
zero, the underlying reference-counted object is destroyed but the
{}\ttt{RCPNodeImpl} object is not destroyed until the strong and weak
counts both go to zero.  The motivation and the workings of strong
versus weak reference counts is discussed in
Section~\ref{sec:circular-references-weak-pointers}.

Finally, one of the key integrated debug-mode capabilities of the
Teuchos reference-counting machinery is the ability to trace the
{}\ttt{RCPNode} objects that are created and destroyed and put them in
a low-overhead object database.  The {}\ttt{RCPNodeTracer}
class/object is a global singleton object that stores all of the
{}\ttt{RCPNode} objects in active use.  An {}\ttt{std::multimap}
object is used to store raw pointers to the {}\ttt{RCPNode} objects
and the multi-map is keyed by the {}\ttt{void*} address of the
underlying reference-counted objects themselves.  Therefore, one can
query to see if any {}\ttt{RCPNode} object already exists for a given
object.  The cost of this query is $O(log(n))$ where $n$ is the number
of active {}\ttt{RCPNode} objects currently in use.  Therefore, the
cost of node tracing quite scalable with the number of {}\ttt{RCPNode}
objects in use.  The current implementation optionally relies on Boost
code which provides some trickery for determining at compile-time if a
type is polymorphic or not and thereby allowing the use
{}\ttt{dynamic\_cast<const void*>(p)} to determine the true base
address of any object (no matter if it uses virtual base classes and
multiple inheritance or not).  The ability to trace active
{}\ttt{RCPNode} objects and look them up based on an object's address
is critical for many debug-mode runtime checking capabilities
including: a) reporting objects involved in circular dependencies
after a program ends (see
Section~\ref{sec:detection-circular-references}), b) detection of
dangling references of non-owning {}\ttt{RCP} objects (see
Section~\ref{sec:detection-dangling-references}), and c) detection of
the creation of multiple owning {}\ttt{RCPNode} objects (see
Section~\ref{sec:detection-dual-owning-rcps}).

Note that node tracing is only an optional debug-mode feature and is
not required for the correct functioning of the reference-counting
machinery.  In fact, the observable behavior of correct programs is
exactly the same whether debug-mode node tracing is enabled or not.
For correct programs, the only observable consequence of having node
tracing enabled will be increased runtimes.


%
{}\subsubsection{Circular references and weak pointers}
\label{sec:circular-references-weak-pointers}
%

The fundamental weakness of low-overhead reference counting as
described in this paper and used in the Teuchos (and boost and any
other reference-counting) memory management classes is that there is
no bullet-proof way to address circular references that otherwise
result in memory leaks.  Because of possible circular references, only
system-level garbage-collection methods, such as implemented in
languages like Java and Python, can robustly clean up memory in every
case of circular reference.  As stated earlier, given backward
compatibility constraints, many existing C++ programs cannot be used
with any C++ implementation that might implement garbage collection,
not now or ever.  A key issue is that many programs require the
side-effects of the deletion of objects as specific points in the
program and changing the time of deletion of the object (and the call
of the destructor) would break the program.

To understand the problem with circular references, consider the code
in Listing~\ref{listing:CircularRCP_A_B} which sets up a simple
circular reference between two objects.


\begin{listing}: Setting up a simple circular reference between two objects \\
\label{listing:CircularRCP_A_B}
{\small\begin{verbatim}
  {
    RCP<A> a = createA();
    RCP<B> b = createB();
    a->set_B(b);
    b->set_A(a);
    RCP<ClientA> clientA = createClientA(a);
    RCP<ClientB> clientB = createClientB(b);
    ...
  }
  // The A and B objects will not be deleted when the above code block ends!
\end{verbatim}}
\end{listing}


The code fragment in Listing~\ref{listing:CircularRCP_A_B} sets up
the objects in Figure~\ref{fig:CircularRCP_A_B} showing the circular
reference.  Here object {}\ttt{a} contains an {}\ttt{RCP} pointing to
object {}\ttt{b}, and object {}\ttt{b} contains an {}\ttt{RCP}
pointing to object {}\ttt{a}.  In this situation, when {}\ttt{ClientA}
and {}\ttt{ClientB} destroy their {}\ttt{RCP} objects pointing to the
underlying {}\ttt{a} and {}\ttt{b} objects, the reference counts will
not go to zero because of the circular reference between {}\ttt{a} and
{}\ttt{b}.  This will result in a memory leak that a tool like
Valgrind or Purify should complain about.  If lots of objects with
circular references are constantly being created and destroyed
resulting in these types of memory leaks, then obviously one has a
problem and the system could run out of memory and bring the program
down.


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.65]{CircularRCP_A_B}
%}
\end{center}
\caption{
\label{fig:CircularRCP_A_B}
Simple circular reference between two objects.  }
\end{figure}
\esinglespace}


When debug-mode node tracing is enabled and circular references exist,
the reference-counting node tracing machinery will print out the
remaining {}\ttt{RCPNode} objects when it exists (see
Section~\ref{sec:detection-circular-references} for more details).

While there is no completely general and bullet-proof way to address
the circular reference problem, there is a fairly simple and cheap
approach supported by the Teuchos reference-counting machinery that
developers can use to effectively resolve circular references in most
cases.  The approach described here supported by the Teuchos
reference-counted classes is to exploit the concept of weak
reference-counted pointers.  As shown in
Figure~\ref{fig:TeuchosRCPDesign}, this is accomplished through a
{}\ttt{strength} attribute with values {}\ttt{STRONG} and
{}\ttt{WEAK}.  By default, all {}\ttt{RCP} objects are {}\ttt{STRONG}.
When an {}\ttt{RCP} is {}\ttt{STRONG}, then the underlying
{}\ttt{ConcreteT} object is guaranteed to stay around.  However, when
the {}\ttt{RCP} is {}\ttt{WEAK}, the underlying {}\ttt{ConcreteT} can
get deleted when strong count goes to zero (by the deletion of other
{}\ttt{STRONG} {}\ttt{RCP} objects).

{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.65]{CircularRCP_A_B_weak}
%}
\end{center}
\caption{
\label{fig:CircularRCP_A_B_weak}
Simple circular reference between two objects broken using a
{}\ttt{WEAK} {}\ttt{RCP}.  }
\end{figure}
\esinglespace}

So how can one deal with circular references like this?  The answer in
this case is to use a weak {}\ttt{RCP} to break the circular reference
as shown in Listing~\ref{listing:CircularRCP_A_B_weak}.


\begin{listing}: Breaking a simple circular reference using a weak
{}\ttt{RCP} \\
\label{listing:CircularRCP_A_B_weak}
{\small\begin{verbatim}
  {
    RCP<A> a = createA();
    RCP<B> b = createB();
    a->set_B(b);
    b->set_A(a.create_weak());
    RCP<ClientA> clientA = createClientA(a);
    RCP<ClientB> clientB = createClientB(b);
    ...
    if (deleteClientAFirst)
      clientA = null;
    else
      clientB = null;
  }
  // Now all the objects will be deleted correctly no matter if
  // clientA or clientB goes away first.
\end{verbatim}}
\end{listing}


The object structure set up by the code in listing
Listing~\ref{listing:CircularRCP_A_B_weak} is depicted in
Figure~\ref{fig:CircularRCP_A_B_weak}.  With the weak pointer in
place, all of the objects will get destroyed when {}\ttt{ClientA} and
{}\ttt{ClientB} remove their {}\ttt{RCP} objects, no mater what order
they remove them.  The critical assumption is that the ``useful''
lifetime of {}\ttt{a} is a super-set of the ``useful'' lifetime of
{}\ttt{b}.  If {}\ttt{a} gets deleted before {}\ttt{b}, then {}\ttt{b}
had better not try to access {}\ttt{a} anymore!  However, the goal is
that whoever gets deleted first (i.e.\ {}\ttt{clientA} or
{}\ttt{clientB}), then the objects {}\ttt{a} and {}\ttt{b} will also
be deleted gracefully and not result in memory leaks.


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.65]{CircularRCP_A_B_ClientA_1}
%}
\\[2ex] a) {}\ttt{ClientA} goes away first \\[3ex]
%\fbox{
\includegraphics*[angle=270,scale=0.65]{CircularRCP_A_B_ClientA_2}
%}
\\[2ex] b) {}\ttt{ClientB} goes away second \\[3ex]
\end{center}
\caption{
\label{fig:CircularRCP_A_B_ClientA}
Weak pointer scenario where {}\ttt{ClientA} is deleted first  }
\end{figure}
\esinglespace}


In the next section, detailed scenarios are given for the deletion of
the objects shown in Figure~\ref{fig:CircularRCP_A_B_weak}.  This
information is important if one wants to understand exactly how the
weak pointers can allow the objects to be deleted correctly while
still catching mistakes gracefully and avoiding undefined behavior.
However, this information is not critical to understand for basic
usage of the classes.


%
{}\subsubsection*{Detailed scenarios for weak pointers and cicular
references}
%

Consider the scenario where the {}\ttt{clientA} object goes away first
(i.e.\ {}\ttt{deleteClientAFirst=true}) depicted in
Figure~\ref{fig:CircularRCP_A_B_ClientA} (UML communication diagram).
This scenario is shown in two phases in two separate UML communication
diagrams in Figure~\ref{fig:CircularRCP_A_B_ClientA} with the
following steps:

\begin{description}

{}\item[a)] {}\ttt{ClientA} goes away first

  \begin{description}

  {}\item[a.1)] As {}\ttt{rcpA2} goes away, it deincrements
  {}\ttt{nodeA::strongCount} from 1 to 0.

  {}\item[a.2)] Since {}\ttt{nodeA::weakCount > 0}, then
  {}\ttt{nodeA} is not deleted but since
  {}\ttt{nodeA::strongCount==0} the object {}\ttt{a} gets
  deleted.

  {}\item[a.3)] As {}\ttt{a} is deleted, it deletes its
  {}\ttt{RCP} object {}\ttt{rcpB1}.

  {}\item[a.4)] Since {}\ttt{rcpB1} is a strong pointer, it
  deincrements {}\ttt{nodeB::strongCount} from 2 to 1.  Therefore,
  neither {}\ttt{nodeB} or {}\ttt{b} gets deleted at this point.
  NOTE: At this point, the object {}\ttt{a} has been deleted and
  {}\ttt{nodeA}'s internal pointer has been set to {}\ttt{NULL}.  If
  the {}\ttt{b} object tries to access {}\ttt{a} after this, it will
  result in an exception being thrown in a debug build.  In a
  non-debug build, any access of {}\ttt{a} from {}\ttt{b} will result
  in undefined behavior (e.g.\ segfault).

  \end{description}

{}\item[b)] {}\ttt{ClientB} goes away second

  \begin{description}

  {}\item[b.1)] As {}\ttt{clientB} goes away, it takes {}\ttt{rcpB2}
  with it.  Since {}\ttt{rcpB2} is a strong pointer, it deincrements
  {}\ttt{nodeB::strongCount} from 1 to 0.  Since
  {}\ttt{nodeB::strongCount} and {}\ttt{nodeB::weakCount} are both 0
  this results in {}\ttt{nodeB} being deleted.

  {}\item[b.2)] As {}\ttt{nodeB} is being deleted, it deletes the
  {}\ttt{b} object.

  {}\item[b.3)] As {}\ttt{b} is being deleted, it deletes its
  {}\ttt{RCP} object {}\ttt{rcpA1}.

  {}\item[b.4)] With {}\ttt{rcpA1} being deleted it reduces
  {}\ttt{nodeA::weakCount} from 1 to 0.  Since
  {}\ttt{nodeA::strongCount} and {}\ttt{nodeA::weakCount} are
  both 0, this results in {}\ttt{nodeA} being deleted.  Since the
  object {}\ttt{a} is already deleted, nothing more happens.

  \end{description}

\end{description}


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.65]{CircularRCP_A_B_ClientB_1}
%}
\\[2ex] a) {}\ttt{ClientB} goes away first \\[3ex]
%\fbox{
\includegraphics*[angle=270,scale=0.65]{CircularRCP_A_B_ClientB_2}
%}
\\[2ex] b) {}\ttt{ClientA} goes away second \\[3ex]
\end{center}
\caption{
\label{fig:CircularRCP_A_B_ClientB}
Weak pointer scenario where {}\ttt{ClientB} is deleted first  }
\end{figure}
\esinglespace}


Now consider the scenario where the {}\ttt{clientB} object goes away
first (i.e.\ {}\ttt{deleteClientAFirst=false}) depicted in
Figure~\ref{fig:CircularRCP_A_B_ClientB} which involves the following
steps:

\begin{description}

{}\item[a)] {}\ttt{ClientB} goes away first

  \begin{description}

  {}\item[a.1)] The {}\ttt{clientB} object goes away first and takes
  its {}\ttt{RCP} object {}\ttt{rcpB2} with it.  This reduces
  {}\ttt{nodeB::strongCount} from 2 to 1.  No other objects are
  deleted yet.

  \end{description}

{}\item[b)] {}\ttt{ClientA} goes away second

  \begin{description}

  {}\item[b.1)] When {}\ttt{rcpA2} goes away, it deincrements
  {}\ttt{nodeA::strongCount} from 1 to 0.  At this point, since
  {}\ttt{nodeA::weakCount > 0}, the node is not deleted but the
  referenced object {}\ttt{a} is deleted.

  {}\item[b.2)] The object {}\ttt{a} is deleted.

  {}\item[b.3)] As {}\ttt{a} is deleted, it deletes its
  {}\ttt{RCP} object {}\ttt{rcpB1}.

  {}\item[b.4)] As {}\ttt{rcpB1} is deleted, it deincrements
  {}\ttt{nodeB::strongCount} from 1 to 0. Since
  {}\ttt{nodeB::weakCount==0}, then {}\ttt{nodeB} is deleted.

  {}\item[b.5)] As {}\ttt{nodeB} is deleted, it deletes the
  {}\ttt{b} object.

  {}\item[b.6)] As {}\ttt{b} is deleted, it deletes its {}\ttt{RCP}
  object {}\ttt{rcpA1}.  What is critical here is that {}\ttt{b} must
  not try to access {}\ttt{a} which is already in the process of being
  deleted.  If {}\ttt{b} were to try to access {}\ttt{a} as it is
  being deleted, in debug mode an exception would be thrown.  In
  non-debug mode, this would result in undefined behavior (e.g.\
  segfault).  It is rare, however, that one object tries to access
  another as they are deleted.

  {}\item[b.7)] When {}\ttt{rcpA1} is removed, it deincrements
  {}\ttt{nodeA::weakCount} from 1 to 0.  Since
  {}\ttt{nodeA::strongCount} is already 0, this results in
  {}\ttt{nodeA} being deleted.  Since {}\ttt{a} is already in
  the process of being deleted, nothing extra happens here.

  \end{description}

\end{description}

What is especially interesting about the second scenario is how
deleting the {}\ttt{a} object in
Figure~\ref{fig:CircularRCP_A_B_ClientB}.b triggers a chain reaction
that causes the {}\ttt{b} object to be deleted which recursively
causes the {}\ttt{nodeA} object to be deleted, all in the call stack
where the {}\ttt{a} object is being deleted.  To accomplish this
correctly, the {}\ttt{RCPNodeImpl::deleteObj()} function has some
special logic to avoid a double delete call being performed on the
reference-counted object.


%
{}\subsubsection*{Comparison to weak pointers in Boost}
%

With respect the weak pointers, the Teuchos class {}\ttt{RCP} differs
substantially from the Boost and therefore the C++0x standard
reference-counting classes.  With the class {}\ttt{RCP}, the
attribution of strong or weak is made at runtime.  This allows an
external client to decide at runtime to make {}\ttt{a}'s reference to
{}\ttt{b} weak or {}\ttt{b}'s reference to {}\ttt{a} weak depending on
the given circumstance.  With the Boost and C++0x {}\ttt{shared\_ptr}
class, one has to use a separate class {}\ttt{weak\_ptr} to represent
a weak pointer.  The problem with the Boost approach then is that one
has to decide at compile time if a particular reference is going to be
weak or strong.  While there are some cases where one can always
assume the reference needs be weak (like in the self-reference case
described in Section~\ref{sec:self-references}), there are more
complex cases where one cannot decide this so easily at compile time.
For example, if one were to use the {}\ttt{shared\_ptr} and
{}\ttt{weak\_ptr} classes, one would have to decide at compile time to
make {}\ttt{a}'s reference or {}\ttt{b}'s reference weak.  The
decision one makes make might work for one set of use cases that one
currently knows about, but for more complex use cases not discovered
yet, one may need to switch it.  In fact, in the same compiled program
there may be some use cases where {}\ttt{a} will be deleted before
{}\ttt{b} and other use cases where {}\ttt{b} will be deleted before
{}\ttt{a}.  With the classes {}\ttt{shared\_ptr} and
{}\ttt{weak\_ptr}, this is impossible to handle (at least not without
storing both smart pointer types in each class {}\ttt{A} and {}\ttt{B}
object and then using one or the other which is not very elegant or
efficient).  The only argument for the compile-time approach used by
Boost and C++0x is improved performance in both speed and memory
overhead but the results in
Section~\ref{sec:reference-counting-overhead} show that this extra
overhead is fairly minimal.  Overall, the overhead induced by the
flexible runtime approach to weak pointers of the {}\ttt{RCP} class
(and therefore also the {}\ttt{ArrayRCP} class) is well worth this
small extra overhead.  Typically, the classes {}\ttt{RCP} and
{}\ttt{ArrayRCP} are used to manage objects (or blocks of array data
for {}\ttt{ArrayRCP}) much larger than what is contained in the
infrastructure for the reference-counting objects so the additional
memory overhead is usually insignificant as well.


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=0.65]{CircularChain}
%}
\end{center}
\caption{
\label{fig:CircularChain}
Example of a circular chain involving many objects and many classes.}
\end{figure}
\esinglespace}


%
{}\subsubsection*{Summary of circular references and weak pointers}
%

While this section has focused on a simple example involving a
circular reference between two classes and two objects, in reality
circular references typically involve many different objects and
classes which may be in very distant parts of the code base which make
them very difficult to find by just examining the static code or
running the code in a debugger.  For example,
Figure~\ref{fig:CircularChain} (UML object diagram) depicts a circular
reference involving eight objects.  When the external
{}\ttt{someClient} object removes its {}\ttt{RCP<H>} object, the chain
of objects from {}\ttt{a} to {}\ttt{h} will not be deleted which
results in a memory leak.  These types of chains of circular
references can be very difficult to track down and that is where the
debug-mode runtime node tracing described in more detail in
Section~\ref{sec:detection-circular-references} comes in most handy.

Section~\ref{sec:detection-dangling-references} describes how weak
pointers are used in runtime debug checking for dangling
(non-persisting) references.  Section~\ref{sec:self-references}
describes how weak pointers are used in dealing with object
self-references.

In summary, the Teuchos reference-counting machinery dynamically
addresses both strong and weak references and is a very powerful tool
but to use it effectively, one needs to understand the basic semantics
for its use.  The good news is that likely 90\% of more casual
developers who use the classes {}\ttt{RCP} and {}\ttt{ArrayRCP} will
never need to know the difference between a strong and weak reference
and will by default just use strong references.  Weak references will
get used under the hood for some debug-mode runtime checking but they
are totally transparent to client code and the programmer.  It is only
in cases of circular references and with some more advanced idioms and
design patterns (see Section~\ref{sec:self-references} and
Section~\ref{sec:generalized-view-design-pattern} for examples) do
typical programmers need to know anything about weak pointers.


%
{}\subsubsection{Customized deallocators}
\label{sec:deallocators}
%

The most common use of {}\ttt{RCP} is to manage the lifetime of
objects allocated using operator {}\ttt{new} and deallocated using
operator {}\ttt{delete} (or {}\ttt{new []} and {}\ttt{delete []} for
{}\ttt{ArrayRCP}).  For these use cases, the built-in behavior in
{}\ttt{RCP} does exactly the right thing for this average case.
However, there are situations when one cannot simply call
{}\ttt{delete} to deallocate an object.

Some examples of situations where something other than calling
{}\ttt{delete} needs to be performed include when:

\begin{enumerate}

{}\item\textit{Reference counts for objects are managed by requiring
clients to explicitly call increment and decrement functions}: This
situation occurs when using CORBA {}\cite{ref:corba} and COM
{}\cite{ref:com} for instance.  Such an approach is also presented in
{}\cite[Item 29]{MoreEffectiveC++96} in the subsection ``A
Reference-Counting Base Class''.  In these protocols, deallocation
occurs automatically behind the scenes when this other reference count
goes to zero and does not occur through an explicit call to operator
{}\ttt{delete} as with the default behavior for {}\ttt{RCP}.

{}\item\textit{Objects are managed by certain types of object
databases}: In some object databases, an object that is grabbed from
the database must be explicitly returned to the database in order to
allow proper object deletion to take place later.

{}\item\textit{A different reference-counted pointer class is used to
initially get access to the managed object}: For example, suppose some
piece of peer software works with {}\ttt{boost::shared\_ptr} (see
{}\cite{ref:boost}) referenced-counted objects while the resident
software works with {}\ttt{RCP} objects.  It then becomes critical no
object is deleted until all the clients using either of these smart
pointer types remove their references to this underlying object (i.e.\
by destroying their smart pointer objects or setting them to null).

{}\item\textit{A C struct object is allocated and deallocated through
explicit C function calls}: Here, a C library function must be called
to deallocate the object (examples of this exist in unit test and
library code).

\end{enumerate}

There are many other additional situations where one cannot simply
assume that calling operator {}\ttt{delete} is used to release an
object.  The bottom line is that in order to be general, one must
allow arbitrary policies to be used to deallocate an object after
clients are finished using the object.

Perhaps the key differentiating property between a flexible high
quality reference-counted pointer implementation and a poor
implementation is the capability to allow the user to define an
arbitrary deallocator policy that defines exactly what it means to
release a reference-counted object (or array of objects).  The
reference-counted Teuchos classes {}\ttt{RCP} and
{}\ttt{ArrayRCP}, as well as {}\ttt{boost::shared\_ptr} all
allow the client to specify a user-defined deallocation policy object
when the first reference-counted object is constructed.

The code associated with customized deallocation policies for
{}\ttt{RCP} (which are also identical for {}\ttt{ArrayRCP}) are shown
in Listing~\ref{listing:RCP-dealloc}.

\begin{listing}: Declarations for customized deallocation policies
for {}\ttt{RCP} \\
\label{listing:RCP-dealloc}
{\small\begin{verbatim}
  // Default decallocation policy for RCP
  template<class T>
  class DeallocDelete
  {
  public:
    typedef T ptr_t;
    void free( T* ptr ) { if(ptr) delete ptr; }
  };

  // Other provided deallocation policy classes
  template<class T> class DeallocNull { ... };
  template<class T> class DeallocArrayDelete { ... };
  template<class T> class DeallocFunctorDelete { ... };
  template<class T> class DeallocFunctorHandleDelete { ... };
  template<class T> class EmbeddedObjDealloc { ... };

  template<class T>
  class RCP {
  public:
    ...
    template<class Dealloc_T>
    RCP(T* p, Dealloc_T dealloc, bool has_ownership);
    ...
  };

  // Non-member constructors for deallocators and extraction functions
  
  template<class T, class Dealloc_T>
  RCP<T> rcp(T* p, Dealloc_T dealloc, bool owns_mem);
  
  template<class Dealloc_T, class T>
  const Dealloc_T& get_dealloc(const RCP<T>& p);
  
  template<class Dealloc_T, class T>
  Dealloc_T& get_nonconst_dealloc(const RCP<T>& p);
  
  template<class Dealloc_T, class T>
  Ptr<const Dealloc_T> get_optional_dealloc(const RCP<T>& p);
  
  template<class Dealloc_T, class T> 
  Ptr<Dealloc_T> get_optional_nonconst_dealloc(const RCP<T>& p);

\end{verbatim}}
\end{listing}

All deallocator objects must support the typedef member {}\ttt{ptr\_t}
and function member {}\ttt{free(...)}.  The concept of a template
policy interface (also called a function object
\cite[Section 18.4]{stroustrup97}) should hopefully be familiar to
semi-advanced users of the STL (part of the standard C++ library).

To demonstrate the use of a deallocator object, let us assume that the
code must wrap objects of type {}\ttt{A} managed by the object
database shown in Listing~\ref{listing:ObjectADB}.


{}\begin{listing}: Example of a simple object database
\label{listing:ObjectADB}
{\small\begin{verbatim}
  class ObjectADB {
    ...
    A& get(int id);
    void release(int id);
    ...
  };
\end{verbatim}}
\end{listing}


In the object database in Listing~\ref{listing:ObjectADB}, objects
are accessed and released using an integer ID.  How this ID is
specified and determined is not important here.  Let us suppose that
one wants to define an abstract factory that returns objects of type
{}\ttt{A} wrapped in {}\ttt{RCP<A>} objects using a database object of
type {}\ttt{ObjectADB} shown in Listing~\ref{listing:ObjectADB}.
For this abstract factory, objects of type {}\ttt{A} will be allocated
from a list of ids given to the factory.  The outline of this abstract
factory subclass is shown in Listing~\ref{listing:ObjectADBFactory}:


{}\begin{listing}: Factory subclass that allocates new objects using
an {}\ttt{ObjectADB} object
\label{listing:ObjectADBFactory}
{\small\begin{verbatim}
  class ObjectADBFactory : public AbstractFactory<A> {
    RCP<ObjectjADB> db_;
    Array<int> ids_;
  public:
    ObjectADBFactory(const RCP<ObjectADB>& db, const ArrayView<const int>& ids)
     : db_(db), ids_(ids) {}
    RCP<A> create();  // Overridden from AbstractFactory
  };
\end{verbatim}}
\end{listing}


The above abstract factory subclass {}\ttt{ObjectADBFactory} inherits
from a generic {}\ttt{AbstractFactory} base class that defines a pure
virtual method {}\ttt{create()}.  In order to implement the
{}\ttt{create()} function, a deallocator class must be defined and
used shown in Listing~\ref{listing:DeallocObjectADB}.


{}\begin{listing}: Custom deallocator class for releasing objects
managed by {}\ttt{ObjectADB}
\label{listing:DeallocObjectADB}
{\small\begin{verbatim}
  class DeallocObjectADB
  {
    RCP<ObjectjADB> db_;
    int id_;
  public:
    DeallocObjectADB(const RCP<ObjectjADB>& db, int id)
      : db_(db), id_(id) {}
    typedef A ptr_t;
    void free(A* ptr) { db_->release(id_); }
  };
\end{verbatim}}
\end{listing}


Now one can define the implementation of the {}\ttt{create()} function
override as shown in Listing~\ref{listing:ObjectADBFactory_create}.


{}\begin{listing}: Implementation of the factory create function
\label{listing:ObjectADBFactory_create}
{\small\begin{verbatim}
  RCP<A> ObjectADBFactory::create()
  {
    TEST_FOR_EXCEPTION(ids_.size()==0, std::runtime_error, "No ids are left!");
    const int id = ids_.pop();
    return rcp(&db_->get(id), DeallocObjectADB(db_, id), true);
  }
\end{verbatim}}
\end{listing}


The program in Listing~\ref{listing:ObjectADBFactory-examplep-main}
shows the use of the factory subclass {}\ttt{ObjectADBFactory} defined
in Listings~\ref{listing:ObjectADB}, {}\ref{listing:ObjectADBFactory},
{}\ref{listing:DeallocObjectADB}, and
{}\ref{listing:ObjectADBFactory_create}.


{}\begin{listing}: Example driver program that transparently uses the
{}\ttt{ObjectADBFactory} class
\label{listing:ObjectADBFactory-examplep-main}
{\small\begin{verbatim}
  int main()
  {
    // Create the object database and populate it (and save the ids)
    RCP<ObjectADB> db;
    Array<int> ids;
    ...
    // Create the abstract factory object
    ObjectADBFactory  ftcy(db, ids());
    // Create some A objects and use them
    RCP<A> a_ptr1 = fcty.create();
    ...
    return 0;
  }
\end{verbatim}}
\end{listing}


In the example program in
Listing~\ref{listing:ObjectADBFactory-examplep-main}, all of the
objects of type {}\ttt{A} are created and removed seamlessly without
the client code that interacts with {}\ttt{RCP} and
{}\ttt{AbstractFactory} knowing anything about what is going on under
the hood.

Examples of other types of deallocators are given in the unit test
suite for the {}\ttt{RCP} class.


%
{}\subsubsection{Embedded objects}
\label{sec:embedded-objecs}
%

Support for customized template deallocator policy objects described
in Section~\ref{sec:deallocators} turns out to be a pretty flexible
feature.  The ability to embed any arbitrary object in the
{}\ttt{RCPNode} object gives one an efficient way to define a
different deallocation policy that is invoked by the destructor on the
object instead of requiring an explicit deallocation policy object.
In addition, one can also tack on any extra data desired and embed it
in the underlying {}\ttt{RCPNodeImpl} object.  The only restriction is
that one has to make the choice of what to embed in the
{}\ttt{RCPNode} object when the very first {}\ttt{RCP} object is
created (which in turn creates the concrete templated
{}\ttt{RCPNodeImpl} object).  If one wants the flexibility to embed
other data in the underlying {}\ttt{RCPNode} object after it has been
created then the ``extra data'' feature needs to used which is
described in Section~\ref{sec:extra-data}.  The advantage of embedding
objects in the deallocator in the {}\ttt{RCPNodeImpl} object is that
it can be quite a bit more efficient than using the ``extra data''
feature which requires more runtime-support and greater overhead.

The functions that are used to embed objects when creating {}\ttt{RCP}
objects and retrieve them again are shown in
Listing~\ref{listing:RCP-embedded-obj} (identical functions exist for
the {}\ttt{ArrayRCP} class).

\begin{listing}: Embedded object functions for RCP \\
\label{listing:RCP-embedded-obj}
{\small\begin{verbatim}
 
  template<class T, class Embedded>
  RCP<T> rcpWithEmbeddedObjPreDestroy(T* p, const Embedded &embedded,
    bool owns_mem=true);
  
  template<class T, class Embedded>
  RCP<T> rcpWithEmbeddedObjPostDestroy(T* p, const Embedded &embedded,
    bool owns_mem=true);
  
  template<class T, class Embedded>
  RCP<T> rcpWithEmbeddedObj(T* p, const Embedded &embedded, bool owns_mem=true);
  
  template<class TOrig, class Embedded, class T> 
  const Embedded& getEmbeddedObj(const RCP<T>& p);
  
  template<class TOrig, class Embedded, class T>
  Embedded& getNonconstEmbeddedObj(const RCP<T>& p);
  
  template<class TOrig, class Embedded, class T>
  Ptr<const Embedded> getOptionalEmbeddedObj( const RCP<T>& p );
  
  template<class TOrig, class Embedded, class T>
  Ptr<Embedded> getOptionalNonconstEmbeddedObj( const RCP<T>& p );
\end{verbatim}}
\end{listing}


The embedded object functions in
Listing~\ref{listing:RCP-embedded-obj} simply use the custom templated
deallocator class {}\ttt{EmbeddedObjDealloc} shown in
Listing~\ref{listing:RCP-EmbeddedObjDealloc} along with the public
deallocator functions in Listing~\ref{listing:RCP-dealloc}.


\begin{listing}: RCP Deallocator using an embedded object \\
\label{listing:RCP-EmbeddedObjDealloc}
{\small\begin{verbatim}
  template<class T, class Embedded, class Dealloc>
  class EmbeddedObjDealloc
  {
  public:
    typedef typename Dealloc::ptr_t ptr_t;
    EmbeddedObjDealloc(
      const Embedded &embedded, EPrePostDestruction prePostDestroy,
      Dealloc dealloc
      ) : embedded_(embedded), prePostDestroy_(prePostDestroy), dealloc_(dealloc)
      {}
    void setObj( const Embedded &embedded ) { embedded_ = embedded; }
    const Embedded& getObj() const { return embedded_; }
    Embedded& getNonconstObj() { return embedded_; }
    void free( T* ptr )
      {
        if (prePostDestroy_ == PRE_DESTROY)
          embedded_ = Embedded();
        dealloc_.free(ptr);
        if (prePostDestroy_ == POST_DESTROY)
          embedded_ = Embedded();
      }
  private:
    Embedded embedded_;
    EPrePostDestruction prePostDestroy_;
    Dealloc dealloc_;
    EmbeddedObjDealloc(); // Not defined and not to be called!
  };
\end{verbatim}}
\end{listing}


The customized deallocator class in
Listing~\ref{listing:RCP-EmbeddedObjDealloc} is then templated with
{}\ttt{DeallocDelete} (see Listing~\ref{listing:RCP-dealloc}) and set
by the non-member constructor functions in
Listing~\ref{listing:RCP-embedded-obj}.  The distinction between pre-
and post-destroy can be critical depending on how the embedded data is
used (many examples are given in this paper).  In most cases, the
order the embedded object is reset to the default value is not
important and therefore the client would just use
{}\ttt{rcpWithEmbeddedObj(...)} to set the embedded object (in which
case it uses post-destruction by default).

Typically, the embedded object will be some {}\ttt{RCP} such that when
the embedded object is assigned to the default state as in
{}\ttt{embedded\_ = Embedded()} then the destructor on that object
will be called (which is what happens when the strong count goes to
zero with {}\ttt{RCP}).  A simple example of embedding an {}\ttt{RCP}
that controls memory release is shown in
Listing~\ref{listsing:embedded-obj-simple-rcp-clone}:


{}\begin{listing}: A simple example of using embedded objects
\label{listsing:embedded-obj-simple-rcp-clone}
{\small\begin{verbatim}
  RCP<A> a_ptr1(new A);
  RCP<A> a_ptr2 = rcpWithEmbeddedObj(a_ptr1.getRawPtr(), a_rcp1, false);
\end{verbatim}}
\end{listing}


What the code in Listing~\ref{listsing:embedded-obj-simple-rcp-clone}
does it is creates a new now-owning {}\ttt{RCPNodeImpl} object with an
{}\ttt{RCP} object embedded in it.  This maintains the correct
ownership semantics by resets the reference count in the new
{}\ttt{RCPNodeImpl} object.  The use case shown in
Listing~\ref{listsing:embedded-obj-simple-rcp-clone} may look silly
and trivial but it is the foundation for several more advanced use
cases (see Section~\ref{sec:inverting-obj-ownership} for a related
example).  As a result of this code, the underlying {}\ttt{A} object
will not be deleted until the {}\ttt{RCPNodeImpl} object associated
with {}\ttt{a\_ptr2}, and all of the {}\ttt{RCP} objects created from
it, are destroyed.  Even the above simple use case can be useful if
one wants to be able to use the reference count on {}\ttt{RCP} objects
derived from {}\ttt{a\_ptr2} to determine usage of the object by other
clients.  There are concrete examples of this exact simple usage in
production code.

A more general usage of embedded objects to perform arbitrary actions
is demonstrated in the context of the ``generalized view'' design
pattern in Section~\ref{sec:generalized-view-design-pattern}.


%
{}\subsubsection{Extra data}
\label{sec:extra-data}
%

As mentioned in Section~\ref{sec:basic-reference-counting-machinery},
the Teuchos reference-counting machinery supports storing and
retrieving arbitrary objects as extra data stored on the
{}\ttt{RCPNode} object itself.  The functions supporting extra data
for the {}\ttt{RCP} class are shown in
Listing~\ref{listing:RCP-extra-data} (the functions for
{}\ttt{ArrayRCP} are identical).

\begin{listing}:  {}\ttt{RCP} extra data functions \\
\label{listing:RCP-extra-data}
{\small\begin{verbatim}
  template<class T1, class T2>
  void set_extra_data(const T1 &extra_data, const std::string& name,
    const Ptr<RCP<T2> > &p, EPrePostDestruction destroy_when = POST_DESTROY,
    bool force_unique = true);
  
  template<class T1, class T2> 
  const T1& get_extra_data(const RCP<T2>& p, const std::string& name);
  
  template<class T1, class T2>
  T1& get_nonconst_extra_data(RCP<T2>& p, const std::string& name);
  
  template<class T1, class T2>
  Ptr<const T1> get_optional_extra_data(const RCP<T2>& p, const std::string& name);
  
  template<class T1, class T2>
  Ptr<T1> get_optional_nonconst_extra_data(RCP<T2>& p, const std::string& name);
\end{verbatim}}
\end{listing}

Given the support for embedded objects described in
Section~\ref{sec:embedded-objecs}, extra data rarely needs to be used.
Embedding and retrieving objects in the templated {}\ttt{RCPNodeImpl}
object is more efficient that using the more general {}\ttt{std::map}
object and {}\ttt{any} wrapper that are used to implement the ``extra
data'' feature and therefore embedded objects should be used whenever
possible instead of extra data.  However, there are a few key
advantages to using extra data over embedded objects that may be worth
the performance overhead or using extra data may be the only way to
address an issue and some examples include:

\begin{itemize}

{}\item\textit{One can associate new extra data after the RCPNode
object is created.}  With embedded objects, one can only select the
data-type for the embedded object at the time when the first
{}\ttt{RCP} object is created.

{}\item\textit{One can retrieve data without having to know the
concrete template types in the {}\ttt{RCPNodeImpl} object.}  With
extra data, one only needs to know the string name and the type of the
extra data that needs to be retrieved.  With embedded objects, the
original type of the underling reference-counted object that is used
to template the {}\ttt{RCPNodeImpl} class also needs to be known (to
see this compare the template arguments for the
{}\ttt{getEmbeddedObj(...)} and {}\ttt{get\_extra\_data(...)}).  If
this type changes (i.e.\ if the creating code changes the subclass
implementation {}\ttt{TOrig} used), then this will break client code
that tries to retrieve the embedded object.  Therefore, client code
that retrieves embedded object data is more fragile than code that
retrieves extra data.

{}\item\textit{One can completely change the deallocation policy at
runtime after the RCPNode object has been created.}  With embedded
objects, the deallocation policy of a reference-counted object cannot
be changed after the initial {}\ttt{RCPNodeImpl} object has been
created; with extra data it can.

\end{itemize}

To demonstrate the power and flexibility of extra data, let's consider
a (perhaps unlikely) scenario where some piece of code incorrectly
associates the wrong deallocation policy to an allocated object shown
in Listing~\ref{listing:createRCPWithBadDealloc}.

\begin{listing}: Example of incorrect deallocator \\
\label{listing:createRCPWithBadDealloc}
{\small\begin{verbatim}
  RCP<A> createRCPWithBadDealloc()
  {
    return rcp(new A[1]); // Will use delete but should use delete []!
  }
\end{verbatim}}
\end{listing}

Hopefully no one would write code like is shown in
Listing~\ref{listing:createRCPWithBadDealloc} (but shockingly I did
once write code similar to this).  However, let's suppose that one has
to use the function {}\ttt{createRCPWithBadDealloc()} to allocate
{}\ttt{A} objects and are stuck with a pre-compiled library and one
cannot access the source code to fix the problem.  On most systems an
error like this will be tolerated and not cause problems but tools
like Valgrind and Purify will complain about code like this to no end
and there may be some platforms where this will actually cause the
program to crash (since this has undefined behavior).

With {}\ttt{RCP} and extra data, one can replace the deallocation
policy on the fly to use the correct policy.  The first step is to
create a class that will call {}\ttt{delete []} on the pointer
correctly as shown in Listing~\ref{listing:DeallocArrayDeleteExtraData}.


\begin{listing}: Deallocator class for extra data deallocation \\
\label{listing:DeallocArrayDeleteExtraData}
{\small\begin{verbatim}
  template<typename T>
  class DeallocArrayDeleteExtraData {
  public:
    static RCP<DeallocArrayDeleteExtraData<T> > create(T* ptr)
      { return rcp(new DeallocArrayDeleteExtraData(ptr)); }
    ~DeallocArrayDeleteExtraData() { delete [] ptr_; }
  private:
    Ptr<T> ptr_;
    DeallocArrayDeleteExtraData(T* ptr) : ptr_(ptr) {}
  };
\end{verbatim}}
\end{listing}


The client code can then fix the deallocation policy as shown in
Listing~\ref{listing:using-DeallocArrayDeleteExtraData}.


{}\begin{listing}: Using {}\ttt{DeallocArrayDeleteExtraData} as extra
data to fix deallocation policy
\label{listing:using-DeallocArrayDeleteExtraData}
{\small\begin{verbatim}
  // Create object with bad deallocator
  RCP<A> a = createRCPWithBadDealloc();

  // Disable default (incorrect) dealloc and set a new deallocation policy as extra data!
  a.release();
  set_extra_data( DeallocArrayDeleteExtraData<A>::create(a.getRawPtr()),
    "dealloc", inOutArg(a));
\end{verbatim}}
\end{listing}


The kind of flexibility shown in the above example is not possible
using embedded objects and is not possible with classes like
{}\ttt{boost:shared\_ptr}.  There are numerous other uses for extra
data to fix nasty memory management problems (which is why the extra
data feature was added in the first place).  However, in well designed
software, there is no need for a feature like this so a developer
should count themselves lucky if they never need to use the extra data
feature.


%
{}\subsection{Roles and responsibilities for persisting associations:
factories and clients}
\label{sec:roles-and-responsibilities}
%

There are two fundamentally different sets of actors that play two
different roles in the use of the reference-counted classes used for
persisting associations: a) factory entities that first create the
reference-counted object {}\ttt{RCP<A>} and defines the deallocation
policy, and b) general clients that accept and use a shared
reference-counted object {}\ttt{A} through an {}\ttt{RCP<A>} object.

Factory entities first create the reference-counted object (or array)
and construct the first {}\ttt{RCP} (or {}\ttt{ArrayRCP}) object
containing it.  The most basic type of factories are non-member
constructor functions described in
Section~\ref{sec:nonmember-constructor-idiom}.  When the first
{}\ttt{RCP} object is created, the factory gets to decide exactly how
object (or array) will be released when the strong reference count
goes to zero.  The default behavior, of course, is to just simply call
{}\ttt{delete} (or {}\ttt{delete []} for arrays) on the contained raw
pointer.  However, the factory can also choose any arbitrary action
imaginable to occur when the reference-count goes to zero.  This is
set up using a template deallocator policy object as described in
Section~\ref{sec:deallocators}.

Alternatively, the responsibilities of general clients that use and
share a reference-counted object are very simple and these
responsibilities are:

\begin{itemize}

{}\item Accept the persisting relationship for a shared
reference-counted object through an {}\ttt{RCP} object (or
{}\ttt{ArrayRCP} for arrays) as described in
Section~\ref{sec:idioms-for-passing-arguments}.

{}\item Share the reference-counted object with other clients by
creating a copy of one's {}\ttt{RCP} (or {}\ttt{ArrayRCP}) object and
giving it to them.

{}\item When one is finished using the object, simply delete or set to
null all of one's {}\ttt{RCP} objects.  If some other client is still
using the object, it will remain alive.  If the client's is the last
(strong) reference, then the deallocator policy object that is
embedded in the underlying {}\ttt{RCPNodeImpl} object is invoked which
knows exactly how to clean up and reclaim the underlying object (or
array of memory).

\end{itemize}

That is all there is to it.  Factories create the underlying object(s)
wrapped in the first {}\ttt{RCP} object and define how the referenced
object(s) will be reclaimed when it is time to do so.  General clients
just accept and maintain their references to shared objects (or
arrays) by accepting and storing {}\ttt{RCP} objects (or
{}\ttt{ArrayRCP} objects) and then setting them to null when they are
finished using the object(s).


%
{}\subsection{Debug-mode runtime checking}
\label{sec:debug-mode-runtime-checking}
%

The primary reason that these Teuchos memory management classes need
to be developed in tandem with each other and know each other's
internal implementations to some extend is to be able to implement
robust and effective debug-mode runtime checking.  The debug-mode
runtime testing that is built into these classes is very strong and
will catch nearly every type of programmer error that is possible, as
long as raw C++ pointers are never externally exposed and if raw C++
references are only used for persisting associations.  The different
categories of debug-mode runtime testing are described in the
following subsections along with what the typical diagnostic error
messages look like that are attached to exceptions when they are
thrown.


%
{}\subsubsection{Detection of null dereferences and range checking}
\label{sec:null-dereferences-range-checking}
%

One of the most basic types of debug-mode runtime checking performed
by the Teuchos memory management classes are for attempts to
dereference a null pointer and range checking of arrays and iterators.

\begin{listing}: Debug-mode null dereference checking (all types) \\
\label{listing:null-deref}
{\small\begin{verbatim}
  RCP<A> a_ptr;        // Default constructs to null
  A &a_ref = *a_ptr;   // Throws!
  a_ptr->someFunc();   // Throws!

  ArrayRCP<int> aa;        // Default constructs to null
  a[0];                    // Throws!
  int &i_ref = *a.begin(); // Throws!

  ...  
\end{verbatim}}
\end{listing}

All of the Teuchos memory management classes throw on null
dereferences.  While most systems will abort the program on null
dereferences there are some platforms (e.g.\ some Intel C++ compilers)
that will not and it will result in memory errors that may not be seen
until later in the program.  Technically, dereferencing a null pointer
has undefined behavior and compilers and runtime systems can do
anything they want with undefined behavior (including corrupting
memory and continuing as is the case with some Intel C++ compilers).

The Teuchos array classes {}\ttt{Array}, {}\ttt{ArrayView},
{}\ttt{ArrayRCP}, and {}\ttt{Tuple} all perform array bounds
checking in debug-mode builds:

\begin{listing}: Debug-mode array-bounds checking (all Teuchos array types) \\
\label{listing:array-bounds-checking}
{\small\begin{verbatim}
  Array<int> a(n);
  a[-1];   // Throws!
  a[n];    // Throws!
\end{verbatim}}
\end{listing}

In a debug-mode build of the code, all the iterators returned by the
{}\ttt{begin()} and {}\ttt{end()} functions of the classes
{}\ttt{Array}, {}\ttt{ArrayView}, {}\ttt{ArrayRCP}, and
{}\ttt{Tuple} are of the type {}\ttt{ArrayRCP} which is a fully
ranged checked iterator.


{}\begin{listing}: Debug-mode iterator range checking (all Teuchos
array types)
\label{listing:iterator-checking}
{\small\begin{verbatim}
  Array<int> a(n);
  *(a.begin()-1);           // Throws!
  *(a.begin() + a.size());  // Throws!
  *a.end();                 // Throws!
\end{verbatim}}
\end{listing}


In addition, comparisons between iterators will thrown if they do not
point into the same underlying contiguous array of memory.


{}\begin{listing}: Debug-mode iterator matching checking (all Teuchos
array types)
\label{listing:iterator-matching-checking}
{\small
\begin{verbatim}
  ArrayRCP<int> a_arcp = arcp<int>(n);
  Array<int> a(n);
  // Simple mistake calling standard STL algorithm
  std::copy( a.begin(), a_arcp.begin(), a_arcp.end() ); // Throws!
\end{verbatim}}
\end{listing}


These types of checks are fairly straightforward but are extremely
useful and work on every platform.  This checking is built into
programs automatically in a debug-mode build of the code.  Contrast
this to checked STL implementations that may or may not exist on a
given platform and if they do exist, the quality of the
implementations can vary widely.  Note that in a non-debug build of
the code, none of these checks are performed which leads to the
fastest code possible.


%
{}\subsubsection{Detection of circular references}
\label{sec:detection-circular-references}
%

One of the more sophisticated types of debug-mode runtime checking
supported by the Teuchos memory management classes is the detection
and reporting of circular {}\ttt{RCP} references that result in memory
leaks.  The issue of circular references and the concept of weak
pointers was outlined in
Section~\ref{sec:circular-references-weak-pointers}.  When debug-mode
node tracing is enabled, the reference-counting machinery keeps track
of all the {}\ttt{RCPNode} objects that are created and destroyed.  If
the program ends and there are one or more {}\ttt{RCPNode} objects
that are still remaining, then a error message is printed to
{}\ttt{std::cerr} that gives all the details of the objects involved
in the circular reference.

For example, consider the simple circular reference created in
Listing~\ref{listing:CircularRCP_A_B} and shown in
Figure~\ref{fig:CircularRCP_A_B}.  If left this way, when debug-mode
node tracing is enabled, the program ends and prints an error message
like the following to {}\ttt{std::cerr}:


{}\begin{listing}: Example error message printed after a program ends
when there are unresolved strong circular references
\label{listing:curcular-ref-error-msg}
{\small\begin{verbatim}
  ***
  *** Warning! The following Teuchos::RCPNode objects were created but have
  *** not been destroyed yet.  A memory checking tool may complain that these
  *** objects are not destroyed correctly.
  ***
  *** There can be many possible reasons that this might occur including:
  ***
  ***   a) The program called abort() or exit() before main() was finished.
  ***      All of the objects that would have been freed through destructors
  ***      are not freed but some compilers (e.g. GCC) will still call the
  ***      destructors on static objects (which is what causes this message
  ***      to be printed).
  ***
  ***   b) The program is using raw new/delete to manage some objects and
  ***      delete was not called correctly and the objects not deleted hold
  ***      other objects through reference-counted pointers.
  ***
  ***   c) This may be an indication that these objects may be involved in
  ***      a circular dependency of reference-counted managed objects.
  ***
  
    0: RCPNode (map_key_void_ptr=0x4a3ff50)
         Information = {T=A, ConcreteT=A, p=0x4a3ff50, has_ownership=1}
         RCPNode address = 0x4a3ffa8
         insertionNumber = 23
    1: RCPNode (map_key_void_ptr=0x4a40548)
         Information = {T=B, ConcreteT=B, p=0x4a40548, has_ownership=1}
         RCPNode address = 0x4a405f0
         insertionNumber = 24
 
  NOTE: To debug issues, open a debugger, and set a break point in the function where the
  the RCPNode object is first created to determine the context where the object first
  gets created.  Each RCPNode object is given a unique insertionNumber to allow setting
  breakpoints in the code.  For example, in GDB one can perform:
  
  1) Open the debugger (GDB) and run the program again to get updated object addresses
   
  2) Set a breakpoint in the RCPNode insertion routine when the desired RCPNode is first
  inserted.  In GDB, to break when the RCPNode with insertionNumber==3 is added, do:
   
    (gdb) b 'Teuchos::RCPNodeTracer::addNewRCPNode( [TAB] [ENTER]
    (gdb) cond 1 insertionNumber==3 [ENTER]
  
  3) Run the program in the debugger.  In GDB, do:
  
    (gdb) run [ENTER]
  
  4) Examine the call stack when the prgoram breaks in the function addNewRCPNode(...)
\end{verbatim}}
\end{listing}
  

This error message is enough information to allow one to open a
debugger, and set a break-point in the function
{}\ttt{RCPNodeTracer::addNewRCPNode(...)} and then examine where these
objects are getting created that result in the circular reference (see
Section~\ref{sec:except-handling-debugging}).

Note that in reality, the circular references will involve many
objects (sometimes more than a dozen as shown in
Figure~\ref{fig:CircularChain}) and therefore this output will contain
many {}\ttt{RCPNode} objects.  A program may also contain large
numbers of smaller sets of circular dependencies.  One example in
Trilinos had a test that generated hundreds of thousands of smaller
circular cycles and leaked memory from hundreds of thousands of
objects.


%
{}\subsubsection{Detection of dangling references}
\label{sec:detection-dangling-references}
%

Another useful and necessary form of debug-mode runtime checking
involves the detection and reporting of access to invalid objects and
arrays made through dangling references.  A dangling reference is a
catch-all term that refers to any pointer or reference that points to
a no-longer valid object or array.  For example, the following code
fragment shows invalid access to a dangling iterator to an array that
has changed shape:

\begin{listing}: Example of a dangling iterator \\
\label{listing:Array-dangling-iterator}
{\small\begin{verbatim}
  Array<int> a(n);
  Array<int>::iterator itr = a.begin();
  a.resize(0);
  *itr = 1; // Invalid access of dangling iterator (throws)!
\end{verbatim}}
\end{listing}

In debug-mode, the above example would result in an exception being
thrown with an error message like shown below:

\begin{listing}: Example of a dangling reference error message \\
\label{listing:dangling-ref-error-msg}
{\small\begin{verbatim}
  Teuchos_RCPNode.hpp:515:
  
  Throw number = 3
  
  Throw test that evaluated to true: true
  
  Error, an attempt has been made to dereference the underlying object
  from a weak smart pointer object where the underling object has already
  been deleted since the strong count has already gone to zero.
  
  Context information:
  
    RCP type:             Teuchos::ArrayRCP<int>
    RCP address:          0x7fbfffec98
    RCPNode type:         Teuchos::RCPNodeTmpl<int,
      Teuchos::EmbeddedObjDealloc<int,
        Teuchos::RCP<__gnu_debug_def::vector<int, std::allocator<int> > >,
        Teuchos::DeallocArrayDelete<int> > >
    RCPNode address:      0xab65a0
    insertionNumber:      5
    RCP ptr address:      0xab4c50
    Concrete ptr address: 0xab4c50
  
  NOTE: To debug issues, open a debugger, and set a break point in the function where the
  the RCPNode object is first created to determine the context where the object first
  gets created. ...
\end{verbatim}}
\end{listing}

The erorr message shown in
Listing~\ref{listing:dangling-ref-error-msg} contains all the
information needed to open a debugger, run the program again to create
new pointer addresses, set up breakpoints and break conditions, and
debug the problem.  Breakpoints can be set when the {}\ttt{RCPNode}
object is first created and inserted and also when the exception is
thown (see Section~\ref{sec:except-handling-debugging}).  The NOTE at
the bottom of the error message in
Listing~\ref{listing:dangling-ref-error-msg} is really the same as
shown in Listing~\ref{listing:curcular-ref-error-msg} and is only cut
off to save space.

A few other examples of dangling references are shown in
Listings~\ref{listing:Array-dangling-ArrayView}--{}\ref{listing:RCP-dangling-Ptr}.

\begin{listing}: Example of a dangling {}\ttt{ArrayView} \\
\label{listing:Array-dangling-ArrayView}
{\small\begin{verbatim}
  ArrayView<int> av;
  {
    Array<int> a(n);
    av = a;
  }
  av[0] = 1; // Invalid access to dangling ArrayView (throws)
\end{verbatim}}
\end{listing}

\begin{listing}: Example of a dangling {}\ttt{Ptr} \\
\label{listing:RCP-dangling-Ptr}
{\small\begin{verbatim}
  Ptr<A> a_ptr;
  {
    RCP<A> a_rcp = createA();
    a_ptr = a_rcp.ptr();
  }
  a_ptr->someFunction(); // Invalid access to dangling Ptr (throws)
\end{verbatim}}
\end{listing}


In general, {}\ttt{Ptr}, {}\ttt{ArrayView} and iterators (returned
from the {}\ttt{begin()} member functions) all can be involved in
dangling references.  Therefore, anytime a {}\ttt{Ptr},
{}\ttt{ArrayView}, or iterator object is created from some other
Teuchos memory management object, one can expect that in a debug build
that dangling references will checked for and if detected will result
in exceptions being thrown with very detailed error messages like
shown in Listing~\ref{listing:dangling-ref-error-msg}.

Note that the ability to detect a dangling {}\ttt{ArrayView} of an
{}\ttt{Array} object as shown in
Listing~\ref{listing:Array-dangling-ArrayView} is due to the fact that
the debug-mode internal implementation of {}\ttt{Array} is designed to
support this.  Compare this to {}\ttt{ArrayView} views of
{}\ttt{std::vector}, as shown in
Listing~\ref{listing:vector-dangling-ArrayView} where dangling
references cannot be detected.


{}\begin{listing}: Dangling {}\ttt{ArrayView} of {}\ttt{std::vector}
(cannot detect dangling references) \\
\label{listing:vector-dangling-ArrayView}
{\small\begin{verbatim}
  ArrayView<int> av;
  {
    std::vector<int> v(n);
    av = v;
  }
  av[0] = 1; // Invalid access to dangling ArrayView (does *not* throw)
\end{verbatim}}
\end{listing}


The code in Listing~\ref{listing:vector-dangling-ArrayView} has
undefined behavior and will most likely segfault if one is lucky.  If
unlucky, the program may actually appear to run correctly on the main
development and testing platforms and it will not be until moved to a
production platform that the ill-effects of this erroneous code will
be seen.  This is one example of why it is so important to use
{}\ttt{Array} instead of raw {}\ttt{std::vector} objects.  Strong
debug-mode runtime checking of {}\ttt{ArrayView} views are not
possible when using {}\ttt{std::vector}.

Another type of more sophisticated debug-mode dangling reference
detection involves non-owning {}\ttt{RCP} objects to existing
reference-counted objects.  Consider code like shown in
Listing~\ref{listing:RCP-nonowning-dangling-ref}.


{}\begin{listing}: Example of a dangling non-owning {}\ttt{RCP} object
detected through node tracing
\label{listing:RCP-nonowning-dangling-ref}
{\small\begin{verbatim}
  RCP<A> a_rcp = createA();
  A &a_ref = *a_rcp;
  RCP<A> a_rcp2 = rcpFromRef(a_ref);  // Same as rcp(a_ref.getRawPtr(), false)
  a_rcp = null;   // The 'A' object gets deleted (a_rcp2 is a dangling pointer)
  a_rcp2->someFunction();  // Invalid reference to deleted 'A' object (throws)
\end{verbatim}}
\end{listing}


In a debug-mode build with node tracing turned on, the dangling
non-owning {}\ttt{RCP} reference {}\ttt{a\_rcp2} in
Listing~\ref{listing:RCP-nonowning-dangling-ref} will be caught by the
system.  This works because the statement {}\ttt{rcpFromRef(a\_ref)}
results in a call to {}\ttt{RCPNodeTracer::getExistingRCPNode(...)} to
look-up the existing {}\ttt{RCPNode} object that points to the same
{}\ttt{A} object.  In this case, the existing {}\ttt{RCPNode} object
is found and it is used to create a weak {}\ttt{RCP} object (see
Section~\ref{sec:circular-references-weak-pointers}) that can then
detect if the original reference-counted object has been deleted.
Again, this more sophisticated type of debug-mode runtime checking
requires that node tracing be enabled\footnote{In order to handle
multiple inheritance and virtual bases classes and still get the
correct base object address, Boost support must also be configured
which is needed to use {}\ttt{boost::is\_polymorphic} to allow the use
of {}\ttt{dynamic\_cast<void*>(...)} to determine the true base
address of a polymorphic object.  Otherwise, without this, the system
will not be able to determine if two abstract interfaces really point
to the same object and therefore the look-up of the {}\ttt{RCPNode}
object may fail to detect when two addresses are pointing to the same
object.}.

Debug-mode runtime detection and reporting of dangling references is
built on the foundation of weak {}\ttt{RCP} and {}\ttt{ArrayRCP}
objects.  Basically, all non-persisting views use a weak {}\ttt{RCP}
or {}\ttt{ArrayRCP} object (see
Section~\ref{sec:circular-references-weak-pointers}) internally to
allow the parent object to be changed or be deleted and to detect this
if a client tries to access the now invalid object through the
dangling reference.


%
{}\subsubsection{Detection of multiple owning {}\ttt{RCP} objects}
\label{sec:detection-dual-owning-rcps}
%


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.65]{RCPEx2}
%}
\end{center}
\caption{
\label{fig:RCPEx2}
Example of duplicate owning {}\ttt{RCPNodeImpl} objects}
\end{figure}
\esinglespace}


There are other types of invalid usage that can be detected and caught
in debug-mode with node tracing enabled.  Consider, for example, what
happens when one or more of the commandments in
Appendix~\ref{apdx:commandments} are broken and more than one owning
{}\ttt{RCPNode} object is created pointing to the same underlying
{}\ttt{ConcreteT} object as shown in Figure~\ref{fig:RCPEx2} generated
by the sloppy code shown in
Listing~\ref{listing:duplicate_owning_rcp}.


{}\begin{listing}: Invalid creation of dual owning {}\ttt{RCPNodeImpl}
objects (shown in Figure~\ref{fig:RCPEx2})
\label{listing:duplicate_owning_rcp}
{\small\begin{verbatim}
  C *c_raw_ptr = new C;
  RCP<C> c_ptr(c_raw_ptr);
  RCP<A> a_ptr1 = c_ptr;
  ...
  A *a_raw_ptr = c_raw_ptr;
  RCP<A> a_ptr2(a_raw_ptr);
\end{verbatim}}
\end{listing}


The problem is that the two {}\ttt{RCPNodeImpl} objects generated by
Listing~\ref{listing:duplicate_owning_rcp} (shown in
Figure~\ref{fig:RCPEx2}) do not know about each other and the first
one who has its strong reference count go to zero will result in the
underlying {}\ttt{C} object being deleted.  In this case, the other
remaining {}\ttt{RCPNodeImpl} object, and all of the resulting
{}\ttt{RCP} objects pointing to it will be left with a non-null
pointer to a now deleted {}\ttt{C} object.  If the client tries to
access the underlying object through one of these now invalid
references, it will yield undefined behavior and will likely result in
a segfault (if one is lucky).  Also, a second call to {}\ttt{delete}
will also occur even if invalid access is not performed.

Not to fear, in a debug-mode build with node tracing enabled, the
{}\ttt{RCPNodeTracing} object automatically detects the creation of
the second owning {}\ttt{RCPNodeImpl<A>} object and will thrown an
exception with an error message that looks something like
Listing~\ref{listing:error_msg_dual_owning_rcp_nodes}.


{}\begin{listing}: Example of an error message from a the attempt to
create dual owning {}\ttt{RCPNodeImpl} objects
\label{listing:error_msg_dual_owning_rcp_nodes}
{\small\begin{verbatim}
  Trilinos/packages/teuchos/src/Teuchos_RCPNode.cpp:240:
  
  Throw number = 1
  
  Throw test that evaluated to true: rcp_node_already_exists && rcp_node->has_ownership()
  
  RCPNodeTracer::addNewRCPNode(rcp_node): Error, the client is trying to create a new
  RCPNode object to an existing managed object in another RCPNode:
  
    New RCPNode {address=0x9cb3e0, base_obj_map_key_void_ptr=0x9cac40,
      base_obj_type_name=A, map_key_void_ptr=0x9cac40, has_ownership=1, insertionNumber=6}
  
    Existing RCPNode {address=0x9cb2b0, base_obj_map_key_void_ptr=0x9cac40,
     base_obj_type_name=C, map_key_void_ptr=0x9cac40, has_ownership=1, insertionNumber=5}
  
    Number current nodes = 6
  
  This may indicate that the user might be trying to create a weak RCP to an existing
  object but forgot make it non-ownning.  Perhaps they meant to use rcpFromRef(...)
  or an equivalent function?

  NOTE: To debug issues, open a debugger, and set a break point in the function where the
  the RCPNode object is first created to determine the context where the object first
  gets created. ...
\end{verbatim}}
\end{listing}


A debugger can be opened, a break-point can be set in the function {}\ttt{Teuchos\-::TestForException\_break(...)}, and the program can be run again and break at the time the exception is thrown to see the context under which the second illegal {}\ttt{RCPNode} is created (see Section~\ref{sec:except-handling-debugging}).  A breakpoint can also be set in the function {}\ttt{Teuchos\-::RCPNodeTracer\-::addNewRCPNode(...)} to see when the other {}\ttt{RCPNode} object was created (see Section~\ref{sec:except-handling-debugging}).

If one is willing to pay for a little extra overhead of
{}\ttt{RCPNode} tracing (see
Section~\ref{sec:reference-counting-overhead} for some timing results
of the overhead), then node tracing will detect the erroneous creation
of multiple owning {}\ttt{RCPNode} objects and respond in a graceful
way.  Note that creating multiple {}\underline{non-owning}
{}\ttt{RCPNode} objects is okay and is allowed both when node tracing
is enabled and when it is not enabled (however, see
Commandment~\ref{cmnd:owning-rcp-first} in
Appendix~\ref{apdx:commandments} for restrictions on the creation of
owning and non-owning {}\ttt{RCP} objects).


%
{}\subsubsection{Performance of debug-mode checking versus memory
checking tools}
%

One of the common criticisms of debug-mode runtime checking is that it
incurs an unacceptably large runtime overhead.  However, this overhead
is only incurred for debug-mode builds and does not affect non-debug
optimized builds.  To speed up debug-mode runtime checking, one can
compile with optimized compiler options (e.g.\ {}\ttt{-O3}) which
significantly speeds up the code.  Also, one has to consider the
relative cost of built-in debug-mode runtime checking versus running a
memory checking tool like Valgrind or Purify.

To investigate the cost of debug-mode runtime checking, the Trilinos
package
Tpetra\footnote{{}\ttt{http://trilinos.sandia.gov/packages/tpetra/}}
is used since it relies the Teuchos memory management classes at a
very low level and therefore would be expected to show the largest
runtime overhead for debug-mode checking.
Table~\ref{tbl:overhead-of-runtime-checking} shows the runtime of the
Tpetra serial test suite (12 test programs) for several different
build and runtime configurations.  In all of these builds, optimized
compiler options (-O3) were used.  All of these timing tests were
performed on an a 3.2GHz AMD machine with 8 cores running Linux
2.6.9-78.0.1.ELsmp using GCC 3.4.6.  Valgrind tests were run using
version 3.2.1.  All of the test executables were run in serial on the
unloaded Linux machine.

\begin{table}
%
\begin{center}
%
{\small\begin{tabular}{|l|r|r|r|}
\hline
Configuration
& Runtime (sec)
& Multiplier
& Valgrind Mult \\
\hline
\hline
1) Optimized build (base-line)
& 0.16
& 1.0
& - \\
\hline
2) Debug-mode runtime checking
& 0.49
& 3.1
& - \\
\hline
3) Debug-mode runtime checking + node tracing
& 1.08
& 6.8
& - \\
\hline
4) Valgrind optimized build
& 56.21
& 351.3
& 351.3 \\
\hline
5) Valgrind debug-mode runtime checking
& 214.01
& 1337.6
& 431.5 \\
\hline
6) Valgrind debug-mode runtime checking + node tracing
& 378.54
& 2365.9
& 347.9 \\
\hline
\end{tabular}}
%
\end{center}
%
\caption{\label{tbl:overhead-of-runtime-checking}
Overhead of runtime checking for serial Tpetra test suite.}
%
\end{table}

The results in Table~\ref{tbl:overhead-of-runtime-checking} give the
total runtimes as well as the relative runtimes for debug-mode
checking and Valgrind.  The second column `Runtime' gives the raw CPU
time in seconds (as reported by CTest) for all 12 test executables in
the Tpetra test suite.  The third column `Multiplier' gives the ratio
of the runtime relative to the base-line optimized build case.  The
fourth column `Valgrind Multi' gives the fractional increase in the
runtime of the test suite run with Valgrind relative to running the
same executables without Valgrind.

The results in Table~\ref{tbl:overhead-of-runtime-checking} show that
while the cost incurred by debug-mode runtime checking can be
significant (a factor of 3.1 for basic debug-mode runtime checking) it
is still quite reasonable.  When node tracing is enabled, the cost
more than doubles to a factor of 6.8 times the basic optimized build.
While the cost of full debug-mode runtime checking with node tracing
is a factor of 6.8 over the basic optimized build, the cost of running
with Valgrind is a factor of over 300!  The increased cost of running
Valgrind is a factor of 431.5 for the basic debug-mode executables.  A
factor of 300 can make running a tool like Valgrind prohibitive for
even moderate sized problems while a factor of 6.8 may be quite
reasonable.  For example, a test problem that takes 20 minutes to run
in a standard optimized build may take 2 hours 15 minutes to run with
full debug-mode runtime checking with node tracing enabled but that
same program may take 100 hours (i.e.\ more than 4 days) to run with
Valgrind!  Also, as has been mentioned several times before, in some
respects the level of runtime checking provided by Teuchos in a
debug-mode build is more effective that what one gets with just
Valgrind\footnote{However, Valgrind does perform a number of other
types of checks including usage of uninitialized memory that are very
useful and cannot be duplicated by the Teuchos memory management
classes.}.  In order to perform the most detailed runtime checking
possible, one can run with Valgrind with debug-mode runtime checking
with node tracing enabled.  However, the overhead of this maximal
checking is staggering at more than 23,000 times the cost of the basic
optimized build!  With this level of overhead, only very small test
problems can be run.

What these timing results suggest is that the cost of debug-mode
runtime checking for programs using the Teuchos memory management
classes will be less than a factor of 10 more than the basic optimized
build in the worst case while the overhead of running a tool like
Valgrind can be as much as a factor of 400 or more.  This means that
enabling debug-mode runtime checking in regular development and
automated testing is quite reasonable.  Note that the Tpetra package
used in this example is likely an extreme case in the usage of the
Teuchos memory management classes.  Other types of software that don't
use the Teuchos memory management classes for such low-level
computations will see much less of a slow-down.  However, note that
theses tests were only performed on one machine using one compiler so
results on other platforms using different compilers may vary
significantly.


%
{}\subsubsection{Limitations of debug-mode runtime checking}
\label{sec:limitations-debug-mode-checking}
%

Once memory is dynamically allocated and owned by one of the Teuchos
memory management class objects, the debug-mode runtime checking will
catch every imaginable type of programming error as long as a raw C++
pointer or raw C++ reference is not exposed.  If all the idioms and
rules outlined in this paper are followed, then the only issue the
developer will have to address that is not 100\% obvious are circular
references.  However, if programmers never made any mistakes, there
would be no need for debug-mode runtime testing in the first place.
While the level of debug-mode runtime testing implemented in the
Teuchos memory management classes is unmatched, code that converts
from raw pointers (and raw references) to Teuchos memory management
objects and vice versa is vulnerable to programming errors that the
debug-mode runtime checking cannot catch.

The first category of programming errors that cannot be detected
involve some types of conversions of raw pointers (and raw references)
to Teuchos memory management objects.  However, before discussing
situations where the debug-mode runtime checking will not catch
errors, first note that if an object is dynamically allocated and is
immediately given over to a strong owning {}\ttt{RCP} object (or an
{}\ttt{ArrayRCP} object in the case of arrays) then many different
types of bad conversions from raw pointers (and raw references) to
memory management types will be caught.  That is because when an
object's address is associated with a strong owning RCP, it gets added
to the debug-mode {}\ttt{RCPNode} tracing system discussed in
Section~\ref{sec:basic-reference-counting-machinery}.  Given this
tracking, future conversions from a raw pointer or raw reference to a
Teuchos memory management class object that result in multiple owning
{}\ttt{RCP}s or dangling references from {}\ttt{Ptr}s and non-owning
{}\ttt{RCP}s will all be detected and cleanly reported (see
Sections~\ref{sec:detection-dangling-references}
and~\ref{sec:detection-dual-owning-rcps}).  One way to guarantee this
is to require that a classes' objects be dynamically allocated through
its non-member constructors
(Section~\ref{sec:nonmember-constructor-idiom}) which returned the new
objects wrapped in strong owning {}\ttt{RCP}s.  In this way, the
object is immediately tracked under the debug-mode node tracing
system.

However, not every class can or should employ the non-member
constructor idiom to force the creation of strong owning {}\ttt{RCP}
objects.  In particular, value-type classes
(Section~\ref{sec:value-and-reference-types}) such as
{}\ttt{std::vector} and {}\ttt{Teuchos::Array} must be allowed to be
generally constructed on the stack or globally but one still needs to
be able to dynamically allocate them in many different situations.
The downside to allowing value-type class objects to be dynamically
allocated and managed with {}\ttt{RCP} is that it allows client code
to try to create an owning {}\ttt{RCP} to a stack (or otherwise
non-dynamically) allocated object which the debug-mode runtime
checking will not be able to detect as shown, for example, in
Listing~\ref{listing:bad-delete-error}.


{}\begin{listing}: Example where debug-mode checking cannot detect an
erroneous delete issue
\label{listing:bad-delete-error}
{\small\begin{verbatim}
  {
     std::vector<int> vec(n);
     const RCP<std::vector<int> > vec_rcp(&vec); // Gives ownership to delete!
     ...
     // When vec_rcp is destroyed it will call delete on the address &vec
     // resulting in undefined behavior (e.g.\ segfault)!
  }
\end{verbatim}}
\end{listing}


In this case, the owing {}\ttt{RCP<std::vector<int> >} object will try
to call {}\ttt{delete} on the address {}\ttt{\&vec} at the end of the
block which will result in undefined behavior (e.g.\ segfault).  The
lack of debug-mode checking shown in
Listing~\ref{listing:bad-delete-error} is unfortunate but it is very
hard to detect if an address is for a dynamically allocated object
where it is okay to call {}\ttt{delete}\footnote{Perhaps in the future
a portable library function can be written and used that will be able
to detect the difference between a stack address and a heap address so
an exception can be thrown right when the bad owning {}\ttt{RCP} is
first created.  }.  Note that the code in this example violates
Commandment~\ref{cmnd:rcp-new} in Appendix~\ref{apdx:commandments}
that states that owning {}\ttt{RCP} (and {}\ttt{ArrayRCP}) objects
should only be created by passing in the address directly returned
from {}\ttt{new} (or {}\ttt{new[]} for {}\ttt{ArrayRCP}) unless a
customized deallocation policy object is attached which defines a more
specialized dellocatioin policy.  The good news though is that memory
checking tools like Valgrind and Purify usually do a good job of
detecting and reporting erroneous calls to {}\ttt{delete} (i.e.\
{}\ttt{free(...)}) that try to free stack-owned memory.  But again if
the idioms outlined in Section~\ref{sec:idioms} and the commandments
defined in Appendix~\ref{apdx:commandments} are followed, this problem
should never occur.

% ToDo: Look into overloading global new and delete in a debug-mode
% build in order to log every new and delete and be able to determine if
% an address is on the stack or the heap.  This could be very hard to
% pull off.

The other category of programming errors that the debug-mode runtime
checking cannot detect and report involves exposing and then misusing
raw C++ pointers and references.  As soon as client code exposes a raw
C++ pointer and starts copying it around, all bets are off.  However,
even if client code never exposes a C++ pointer, one can still get
into trouble.  One unfortunate case involves the use of raw C++
references.  If raw C++ references are only used as formal arguments
to C++ functions, one will almost never have a problem.  However,
incorrectly returning an {}\ttt{RCP} object by reference instead of by
value, as is described in Section~\ref{sec:idioms-returning-objects},
can result in invalid C++ references.  Also, if one uses references
like in Listing~\ref{listing:raw-ref-dangling-ref}, then one can of
course have dangling raw C++ references that the Teuchos debug-mode
runtime checking can never catch.

{}\begin{listing}: Example of where holding on to a raw C++ references
disables debug-mode runtime checking
\label{listing:raw-ref-dangling-ref}
{\small\begin{verbatim}
  RCP<A> a_ptr = newA();
  A &a = *a_ptr;
  ...
  a->someFunc();
  // This above object may not be valid anymore and may result in
  // undefined behavior (a segfault)!
\end{verbatim}}
\end{listing}

The code in Listing~\ref{listing:raw-ref-dangling-ref} violates the
use of raw C++ references only for non-persisting associations.  The
statement {}\ttt{A \&a = *a\_ptr} results in the creation of a
persisting relationship in that it extends past the statement where it
was created.

In summary, as soon as an object reference is exposed through a raw
C++ pointer or a raw C++ reference, in general the Teuchos debug-mode
runtime checking can no longer detect errors.  Therefore, never expose
a raw C++ pointer (except for the situations described in
Section~\ref{sec:role-of-raw-pointers}) and only expose and use raw
C++ references for strictly non-persisting associations.  Also, great
care must be taken in first constructing Teuchos memory management
class objects such they have the correct memory management properties.


%
{}\subsubsection{Exception handling and debugging}
\label{sec:except-handling-debugging}
%

The debug-mode runtime checking performed by the Teuchos memory management classes throw exceptions when violations are detected.  As has been shown throughout this document, these exceptions have associated messages that contain detailed information about the nature and context of the problem.

All exceptions thrown by the Teuchos memory management classes (and the rest of Trilinos for that matter) all use a system of macros in the file {}\ttt{Teuchos\_TestForException.hpp}.  All of these macros call the function {}\ttt{Teuchos\-::TestForException\_break(...)} just before an exception is thrown.  Therefore, if the error is repeatable (and most errors are), then one can open a debugger (e.g.\ GDB) and set a break-point in that function, run the program, and then examine the state of the program just as the exception is being thorwn.  Several exceptions can be thrown before the exception that one needs to debug. To make it easier to break on the exception that one cares about, every exception message has a {}\ttt{Thrown number} associated with it embedded in the error message of the exception object.  One can set a conditional break-point in {}\ttt{TestForException\_break(...)} to only stop when {}\ttt{throwNumber} has the right value.  For example, if one needs to stop on {}\ttt{Throw number = 10}, then in GDB one can set (assuming this is the first breakpoint created, otherwise the breakpoint number will be greater than \texttt{1}):

{\small\begin{verbatim}
  (gdb) b 'Teuchos::TestForException_break( [TAB] [ENTER]
  (gdb) cond 1 throwNumber==10
  (gdb) run
\end{verbatim}}

When the program stops at this break-point, one can then examine the
call stack to troubleshoot the problem.

Many exception messages contain other types of information that would
have one set breakpoints in other functions.  For example, a dangling
reference exception (as shown in
Section~\ref{sec:detection-dangling-references}) would contain
addresses of objects that one would use to set conditional
breakpoints.  To examine the context under which an {}\ttt{RCPNode} is
first created, one would set a break-point in the function
{}\ttt{Teuchos::RCPNodeTracer::addNewRCPNode(...)} and set a condition
to only break when {}\ttt{insertionNumber} is the number printed in
the exception message.  For example, for the exception message shown
in Listing~\ref{listing:dangling-ref-error-msg}, one would set the
break-point in GDB as:

{\small
\begin{verbatim}
  (gdb) b 'Teuchos::RCPNodeTracer::addNewRCPNode( [TAB] [ENTER]
  (gdb) cond 1 insertionNumber==5
  (gdb) run
\end{verbatim}}

When the debugger breaks, one would then be able to examine the call
stack to see the context under which this {}\ttt{RCPNode} object is
first created.

NOTE: Setting breakpoints based on {}\ttt{insertionNumber} is
generally better than trying to set breakpoints based on the object
addresses because the same address can get reused multiple times as
objects are created and destroyed.  Only the {}\ttt{insertionNumber}
uniquely identifies a particular {}\ttt{RCPNode} object.  In builds
where node tracing is not enabled, {}\ttt{insertionNumber} will be
equal to -1 and will not aid in debugging.

NOTE: Before entering a conditional break-point involving an address,
one must first run the program again in the debugger which will
typically produce an exception message with different object addresses
because the debugger moves things around in memory.  One will need to
use these new pointer addresses when setting conditional breakpoints.

The Teuchos reference-counting classes are all fully exception safe in
that they provide either the basic guarantee (retain some valid object
state and no leaked memory when an exception is thrown), the strong
guarantee (retain original state when an exception is thrown), or the
no-throw guarantee (see {}\cite[Item 71]{C++CodingStandards05}).
However, if exceptions are thrown from destructors when objects are
being destroyed, then the reference-counting classes are only fully
exception safe in a debug-mode build.  This does not really break
exception safety since destructors should not be throwing exceptions
in most valid C++ programs (see {}\cite[Item
51]{C++CodingStandards05}).  The Teuchos memory management classes
provide the foundation for allowing the wide-spread and consistent use
of C++ exception handling in all client code in such a way as memory
will not be leaked when exceptions are thrown.  However, achieving a
truly exception safe program means more than just not leaking memory;
it means that all code provides at least one of the fundamental
exception guarantees (again, see {}\cite[Item
71]{C++CodingStandards05}).

Note that throwing exceptions differs from what many other class
libraries do which is typically to call {}\ttt{assert(...)} when a
runtime failure is discovered.  For example, the checked STL for g++
will call assert when a usage violation is discovered.  There are pros
and cons for throwing exceptions versus halting the program but if
code can be made exception safe, then one can argue that throwing
exceptions is better because it allows the program to recover in case
of a catastrophic failure of a submodule while calling
{}\ttt{assert(...)} does not.  Also, writing unit tests for code that
throws exceptions is much easier and more efficient than trying to
write unit tests for code that halts the program.  This issue of
testability is a huge advantage of exception handling over calling
{}\ttt{assert(...)} or {}\ttt{exit(...)} when an error occurs.


%
{}\subsection{Optimized performance}
\label{sec:optimized-performance}
%

While debug-mode runtime checking is of great importance, of equal
importance is speed in a optimized non-debug build.  It is critical in
high performance code that the wise use of the Teuchos memory
management classes lead to optimized performance that is nearly
identical to the performance of raw pointers.  Otherwise, if there is
always a performance gap with using the Teuchos memory management
classes, then there will always be an excuse to go back to using raw
pointers will all of the disastrous consequences discussed in
Section~\ref{sec:intro} and
Section~\ref{sec:problems-with-raw-pointers}.

In this section, the optimized performance of the Teuchos memory
management classes is analyzed.  In an optimized build, all of the
runtime checking is disabled but there is still some non-trivial
overhead associated with the reference-counting machinery.  If used at
too fine a granularity, reference-counting overhead can become a
significant space/time performance problem on real-world problems.

The optimized performance of several different types of operations are
examined in the next few sections.  All of these performance timing
tests were run on three different compilers shown in
Table~\ref{tbl:PerfTestPlatforms} that represent two mainstream
platforms.  The GCC 4.1.2 and Intel ICC 10.1 results where run on the
same Linux machine and therefore one can directly compare the
optimizing capability of these two compilers on this platform.  Note
that the processor used for the Microsoft Vista platform is also Intel
and has the same clock speed as for the Linux platform.  Therefore,
one can make fairly direct comparisons of runtimes between the three
different compilers.  Timings on other compilers may give different
results, especially for compilers that have a bad history at
optimizing C++ code (e.g.\ PGI, Sun, AIX etc.).  All of these
performance timing tests are driven by a performance testing framework
in Teuchos and there are nightly performance tests that strictly
enforce relative performance timing targets.

\begin{table}
%\fbox{\begin{minipage}{\textwidth}
\begin{description}
%
{}\item[GCC 4.1.2:] GNU GCC 4.1.2 (compiler options {}\ttt{-O3
-DBOOST\_SP\_DISABLE\_THREADS}) running under Linux 2.6.18-128.1.6.el5
on 2 Quad Intel Xeon CPUs at 2.93GHz and 4MB L1 Cache and 16 GB RAM.
%
{}\item[ICC 10.1:] Intel ICC C++ 10.1 (compiler options {}\ttt{-O3
-DBOOST\_SP\_DISABLE\_THREADS}) running under Linux 2.6.18-128.1.6.el5
on 2 Quad Intel Xeon CPUs at 2.93GHz and 4MB L1 Cache and 16 GB RAM.
%
{}\item[MSVC++ 2008:] Microsoft Visual C++ 2008 (compiler options
{}\ttt{/D\_SECURE\_SCL=0 /DBOOST\_SP\_DISABLE\_THREADS /Ox})
running under Windows Vista Enterprise on an Intel Core 2 Duo CPU
T9800 at 2.93GHz and 2.00 MB RAM.
%
\end{description}
%\end{minipage}}
\caption{\label{tbl:PerfTestPlatforms}
Performance testing platforms.}
\end{table}

This section is broken up into subsections as follows.  First, the
optimized performance of the reference-counting machinery is looked at
in Section~\ref{sec:reference-counting-overhead}.  Reference-counting
overhead will never go to zero with respect to raw pointers but it is
constant-time overhead and therefore its impact can be minimized by
not applying it at too low a level.  The optimized performance of the
Teuchos array classes is given in Section~\ref{sec:array-overhead}.
The timing results show that the basic bracket operator (i.e.\
{}\ttt{a[i]}) and iterator (i.e.\ {}\ttt{a.begin()}) access methods
all yield raw pointer performance.  Finally, in
Section~\ref{sec:perf-tuning-strategies}, performance tuning
strategies are discussed primarily addressing the issue of performance
optimizations related to semi-persisting associations.


%
{}\subsubsection{Reference counting overhead}
\label{sec:reference-counting-overhead}
%

While the reference-counting machinery used by the {}\ttt{RCP} and
{}\ttt{ArrayRCP} classes significantly improves software
development productivity and quality in many respects, it also has a
certain amount of space and time overhead that needs to be considered
in design decisions.  Here, the cost of the various operations
associated with the {}\ttt{RCP} class are compared to raw pointers
and to the {}\ttt{boost::shared\_ptr} class.  Timings are performed
for creating and destroying the {}\ttt{RCPNode} object and
reference-counted object, for manipulating the reference count, and
for accessing the underlying reference-counted object.  These are the
core operations of the {}\ttt{RCP} class that are most likely to
affect performance.

All of the operations being timed are very low-level and therefore it
is difficult to get meaningful unbiased timing results.  To get
accurate timings, one must perform the operation in loop and average
the times.  With naive code, some compilers (e.g.\ Microsoft Visual
C++) will just optimize away the entire loop.  Therefore, the
operation must be performed in the context of a loop over an array
where the result of the loop gets used in some way to accumulate a
final result.  Examples of these types of timing loops will be given
below.  Because of the loop and iterator overhead and this extra
(minimal) computation, the timings listed for each operation are
higher that what they would be otherwise.  Therefore, the overhead
reported is lower that what it really is but by how much one cannot be
sure.  Also, when performing loops, issues of loop initialization and
cache issues come into play.  In order to avoid these issues, a single
loop size from all the results of 1024 was selected to display in the
figures and tables in this section.  The raw timing results for other
loops sizes are given in Appendix~\ref{apdx:raw-rcp-perf-data}.

Note that the atomic thread-safe reference-counting machinary in
{}\ttt{boost::shared\_ptr} was turned off in order to get better
timing comparisons.  Preliminary timing studies showed that the
assembler-optimized atomic lock-free reference-counting machinary on
Linux/GCC imparted about a 4x overhead.  To avoid this performance
overhead, the assember code for atomic reference-count manipulation
was disabled by compiling with {}\ttt{-DBOOST\_SP\_DISABLE\_THREADS}.
Issues of thead safety are briefly discussed in
Section~\ref{sec:comparison_with_other_libs}.

The first type of overhead to consider is the memory overhead of the
reference-counting machinery shown in
Figure~\ref{fig:TeuchosRCPDesign}.  Table~\ref{tbl:RCP-SP-sizes} shows
the sizes of some important objects associated with {}\ttt{RCP} and
{}\ttt{boost::shared\_ptr} (on a 64 bit platform where pointers are 8
bytes).  The sizes are shown for allocating
{}\ttt{std::vector<double>} objects but the memory used by the
reference counting machinery only depends on pointers so the memory
usage overhead is the same no mater what type of object is used.  From
looking at Table~\ref{tbl:RCP-SP-sizes}, one can see that the static
size of {}\ttt{std::vector<double>} is 24 bytes for this compiler.
Consider allocating an {}\ttt{std::vector<double>} object with only
one element.  This would dynamically allocate one {}\ttt{double}
object in an array giving a total of 32 bytes.  Now consider the
reference-counting machinery overhead.  For every allocated
{}\ttt{std::vector<double>} object, there is a reference-counting node
object of type {}\ttt{RCPNodeImpl<std::vector<double>, ... >} which is
48 bytes.  In addition there is also an {}\ttt{RCP<std::vector<double>
>} object of size 24 bytes.  That gives a total of 24+48=72 bytes of
reference-counting overhead to manage an object that only consumes 32
bytes.  That is memory overhead of 225\%!  However, when the
{}\ttt{std::vector<double>} is allocated to hold 100 elements, the
memory consumed by the {}\ttt{std::vector<double>} object is
24+8*(100) = 824 bytes.  Now the 72 bytes of reference-counting
overhead is only 8.7\%.  By the time one gets to 1000 elements, the
overhead drops to 0.8\%.  The point is that the reference-counting
machinery imparts a storage overhead that is non-trivial for small
objects.  Therefore, {}\ttt{RCP} should not be used to manage large
numbers small objects.  Likewise, {}\ttt{ArrayRCP} should not be used
to manage large numbers of small arrays for the same reason.

Table~\ref{tbl:RCP-SP-sizes} also shows the sizes of comparable
objects associated with the {}\ttt{boost::shared\_ptr} class.  The
boost {}\ttt{sp\_counted\_impl\_p} node object only consumes 32 bytes
on this machine as apposed to the 48 bytes for the {}\ttt{RCPNodeImpl}
object.  The increased overhead of the {}\ttt{RCPNodeImpl} object is
due to the pointer for the extra data map, an extra ownership Boolean,
and storage of the deallocator object.  Also, the
{}\ttt{boost::shared\_ptr} object itself only consumes 16 bytes while
the equivalent {}\ttt{RCP} object uses 24 bytes.  This increase in
storage is due to having to store a {}\ttt{strength} enum to
dynamically handle {}\ttt{STRONG} and {}\ttt{WEAK} references.  This
is the storage cost of increase flexibility of the {}\ttt{RCP} class
over the {}\ttt{boost::shared\_ptr} class.

\begin{table}
\begin{center}
\begin{tabular}{|l|r|}
\hline
Type
& {}\ttt{sizeof(Type)} \\
\hline
{}\ttt{bool}
& 1 \\
\hline
{}\ttt{double*}
& 8 \\
\hline
{}\ttt{double}
& 8 \\
\hline
{}\ttt{std::vector<double>}
& 24 \\
\hline
{}\ttt{boost::shared\_ptr<std::vector<double> >}
& 16 \\
\hline
{}\ttt{boost::detail::sp\_counted\_impl\_p<std::vector<double> >}
& 32 \\
\hline
{}\ttt{RCP<std::vector<double> >}
& 24 \\
\hline
{}\ttt{RCPNodeImpl<std::vector<double>, ... >}
& 48 \\
\hline
\end{tabular}
\end{center}
\caption{\label{tbl:RCP-SP-sizes}
Sizes of RCP and boost::shared\_ptr objects for 64 bit GCC 4.1.2.}
\end{table}


Now consider the runtime overhead associated with dynamic allocation
and deallocation.  Figure~\ref{fig:RCPAllocTimings} shows the timings
for dynamically allocating and deleting {}\ttt{std::vector<double>}
objects for different numbers of vector elements on the three
compilers shown in Table~\ref{tbl:PerfTestPlatforms}.
Figure~\ref{fig:RCPAllocTimings}.a shows the timings for allocating
{}\ttt{std::vector<double>} objects with only one element.  This shows
that there is some runtime overhead needed to dynamically allocate new
node objects for {}\ttt{RCP}.  The extra overhead is due to an extra
call to {}\ttt{new} in order to allocate the node object.  Note that
the extra overhead for {}\ttt{RCP} is quite small with respect to
{}\ttt{boost::shared\_ptr} for all three compilers (because both
classes do very similar things).  However, this is constant time
overhead so as larger {}\ttt{std::vector<double>} objects are
allocated (with associated initialization of the vector elements in an
inner loop) the relative overhead goes to zero, as shown in
Figure~\ref{fig:RCPAllocTimings}.b.  Therefore, the runtime overhead
of the reference-counting machinery for allocating and deallocating
large objects is very small.


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=1.00]{RCPAllocTimings}
%}
\end{center}
\caption{
\label{fig:RCPAllocTimings}
Timings for allocating and deallocating objects using RCP}
\end{figure}
\esinglespace}


Now consider timings for dereferencing using {}\ttt{RCP::operator*()},
member access through the arrow operator {}\ttt{RCP::operator->()},
and assignment through {}\ttt{RCP::operator=(...)} (which changes the
reference counts) shown in Figure~\ref{fig:RCPTimings}.  These
timings are the average CPU time (in seconds) per inner loop iteration
(see Listing~\ref{listing:RCP-assignment-timing} for an example).
These timing results show that dereferencing and member access for
{}\ttt{RCP} yield raw pointer performance on all the compilers because
these member functions are trivially inlined to expose the raw
pointer.

The assignment operator, however, imposes significant overhead because
of the need to increment and deincrement the reference counts.  The
timing code fragment that exercises {}\ttt{RCP::operator=(...)} is
shown in Listing~\ref{listing:RCP-assignment-timing}.  (Note that
{}\ttt{std::vector} is used instead of {}\ttt{Array} in
Listing~\ref{listing:RCP-assignment-timing} in order to avoid timing
overhead that might result from a bad implementation of
{}\ttt{Array::operator[](...)} that would affect the timing results.)


\begin{listing}: Performance timing loops for {}\ttt{RCP::operator=(...)} \\
\label{listing:RCP-assignment-timing}
{\small\begin{verbatim}
  {
    RCP<char> p(new char('n'));
    std::vector<RCP<char> > p_vec(arraySize);
    TEUCHOS_START_PERF_OUTPUT_TIMER_INNERLOOP(outputter, numActualLoops, arraySize)
    {
      for (int i=0; i < arraySize; ++i) {
        p_vec[i] = p;
        // NOTE: This assignment operation tests the copy constructor and
        // the swap function.  This calls both bind() and unbind()
        // underneath.
      }
    }
  }
  TEUCHOS_END_PERF_OUTPUT_TIMER(outputter, rcpTime);
\end{verbatim}}
\end{listing}


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=1.00]{RCPTimings}
%}
\end{center}
\caption{
\label{fig:RCPTimings}
Timings of basic RCP operations on for three compilers}
\end{figure}
\esinglespace}


Timing results for the code in
Listing~\ref{listing:RCP-assignment-timing} for
{}\ttt{numActualLoops=338498} and {}\ttt{arraySize=1024} are shown in
Figure~\ref{fig:RCPTimings} along with similar timings for raw
pointers and {}\ttt{boost::shared\_ptr}.  The full timing results for
other sizes are show in in Appendix~\ref{apdx:raw-rcp-perf-data}.

Several interesting points to note about these timing results are
described below.

First, the timing results for the simple raw-pointer loops shown in
Figure~\ref{fig:RCPTimings} suggest that these two machines have
nearly identical processor speeds.  Therefore, the CPU times on the
Y-axis scale for each of these compiler/machine bar charts is made the
same to allow for absolute comparisons.  This allows for direct
comparisons of the optimizing capabilities of these three compilers
with respect to dealing with general C++ code (and not just C-like raw
pointer loops).  This suggests that GCC 4.1.2 is better than the rest
and that MSVC++ 2008 is quite bad at optimizing general {}\ttt{RCP}
C++ code.

Second, note that the cost of manipulating the reference count in
{}\ttt{RCP::operator=(...)} is an order of magnitude higher than
the dereference and arrow operators which have raw-pointer
performance.  The real overhead of manipulating the reference counts
may not actually be this high due to the simple nature of the raw
pointer code run in a loop getting better optimization.  The
reference-count manipulation code involves if statements that may
disable certain loop optimizations.

Third, note that {}\ttt{RCP::operator=(...)} is about 30\% slower on
GCC 4.1.2 than for {}\ttt{boost::shared\_ptr} due to the extra
overhead of dynamically handling strong and weak reference counts.
The overhead of {}\ttt{RCP} over {}\ttt{boost::shared\_ptr} goes up to
50\% on on ICC 10.1 and then falls off a cliff going up to 300\% for
MSVC++ 2008.  Clearly the MSVC++ compiler is not inlining the
{}\ttt{RCP} functions as well in this case.  However, there may be
compiler options that would cause the MSVC++ compiler to be more
aggressive in inlining but none could be found after a moderate level
of experimentation.

Fourth, note that for GCC 4.1.2, the cost of manipulating the
reference count (at {}\ttt{5.59-09 sec}) is two orders of magnitude
less than the cost to allocate and deallocate an
{}\ttt{std::vector<double>} object with only one element (at
{}\ttt{1.39-07 sec}) and is three orders of magnitude less for 16384
elements (at {}\ttt{5.84-06 sec}) as shown in
Appendix~\ref{apdx:raw-rcp-perf-data}.  Therefore, just the memory
allocation overhead can dominate these other costs in some cases.
Also, if a large object is being used with expensive operations, then
the reference-counting overhead will be insignificant compared to
using the object.  Again, this argues that classes like {}\ttt{RCP}
should only be used to manage larger objects that have more expensive
operations associated with them.  The same argument can be made that
{}\ttt{ArrayRCP} should only be used for managing larger arrays of
data where the cost of loops over the data overwhelm the
reference-counting costs.

Lastly, note that the {}\ttt{RCP::operator=(...)} implementation both
deincrements and increments the reference count while the copy
constructor only has to increment the reference count.  Therefore, we
might expect that the copy constructor would be about twice as fast as
the assignment operator.  The performance of the copy constructor is
not measured in a loop because it is hard write a loop that tests it
without other overhead.  However, the fastest approach is to avoid the
copy of the {}\ttt{RCP} objects at all by passing in constant
references to the {}\ttt{RCP} objects as formal function arguments
which is advocated in Section~\ref{sec:idioms-for-passing-arguments}.


%
{}\subsubsection{Array access and iterator overhead}
\label{sec:array-overhead}
%

Another important type of performance (perhaps more important than the
performance of {}\ttt{RCP} for handling single objects) is the
performance of the Teuchos array classes.  In an optimized non-debug
build these classes must yield the same performance as using raw
pointers or the performance of the application will definitely be
affected.

Performance timing experiments for the bracket operator
{}\ttt{operator[](size\_type)} and iterators (returned from the
{}\ttt{begin()} and {}\ttt{end()} functions) were performed using
simple timing loops.  Unlike the performance tests for {}\ttt{RCP}
described in the previous section, timing array operations naturally
lends themselves to performance timings.  The performance timing code
fragments for the {}\ttt{Array} class are shown in
Listing~\ref{listing:Array-bracket-timing}
and~\ref{listing:Array-iterator-timing}.  The timing loop code for raw
pointers and the {}\ttt{ArrayRCP} and {}\ttt{ArrayView} classes are
nearly identical.


\begin{listing}: Performance timing loops for
{}\ttt{Array::operator[](size\_type)} \\
\label{listing:Array-bracket-timing}
{\small\begin{verbatim}
  Teuchos::Array<double> a(arraySize); 
  TEUCHOS_START_PERF_OUTPUT_TIMER_INNERLOOP(outputter, numActualLoops, arraySize) 
  { 
    for (Ordinal i=0; i < arraySize; ++i) 
      a[i] = 0.0; 
  }
  TEUCHOS_END_PERF_OUTPUT_TIMER(outputter, arrayTime); 
\end{verbatim}}
\end{listing}


\begin{listing}: Performance timing loops for {}\ttt{Array} iterators \\
\label{listing:Array-iterator-timing}
{\small\begin{verbatim}
  Teuchos::Array<double> a(arraySize); 
  TEUCHOS_START_PERF_OUTPUT_TIMER_INNERLOOP(outputter, numActualLoops, arraySize) 
  { 
    Teuchos::Array<double>::iterator a_itr = a.begin(), a_end = a.end(); 
    for ( ; a_itr < a_end; ++a_itr) 
      *a_itr = 0.0; 
  }
  TEUCHOS_END_PERF_OUTPUT_TIMER(outputter, arrayTime); 
\end{verbatim}}
\end{listing}


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=1.00]{ArrayTimings}
%}
\end{center}
\caption{
\label{fig:ArrayTimings}
Timings for basic Array, ArrayRCP, and ArrayView operations}
\end{figure}
\esinglespace}


Figure~\ref{fig:ArrayTimings} shows the CPU timings for
{}\ttt{operator[](size\_type)} and iterators for the performance tests
with sizes {}\ttt{numActualLoops=230574} and {}\ttt{arraySize=1600}.
These timing results are fairly interesting and there are a few
important details to note.

First, the performance of the raw pointer iterator loops on all three
platforms is almost identical.  The CPU time per inner loop iteration
for the raw iterator form of the loop for all three compilers on the
two different Linux and Windows machines is about {}\ttt{3.5e-10}
seconds.  This suggests that the CPUs on these two machines are nearly
identical for low level operations.  This therefore suggests that only
the compilers that result in different performance for the other
operations.  Because these processors appear to be giving the same raw
performance, the Y-axis scales on all the timing bar charts are made
the same in Figure~\ref{fig:ArrayTimings} to allow for direct
comparison between each of the platforms.

Second, the ICC 4.1.2 compiler does not optimize the GNU
{}\ttt{std::vector::iterator} type\footnote{The data-type for the
optimized iterator for {}\ttt{std::vector::iterator} on GNU is not
a raw pointer.  Instead it is a library-defined data type with all
inline functions that should in theory be optimized as well as the raw
pointer but not always.} as well as it optimizes raw pointer iterator
syntax.  The GNU GCC 4.1.2 compiler itself does not even quite fully
optimize its own {}\ttt{std::vector::iterator} type!

Third, the ICC 4.12 compiler is not optimizing the array indexing form
of the inner loops shown in Listing~\ref{listing:Array-bracket-timing}
as well as the other two compilers even for the use of raw pointers.
The performance is even worse for the abstract data types
{}\ttt{std::vector}, {}\ttt{Array}, {}\ttt{ArrayRCP}, and
{}\ttt{ArrayView}.

Forth, for some reason the MSVC++ 2008 compiler is not optimizing the
loop using {}\ttt{ArrayRCP::operator[](size\_type)} as well as for the
other array types.  Several different compiler options and variations
on the {}\ttt{ArrayRCP} and performance timing code where experimented
with without any impact (except to make every operation slower).
However, the performance timing loop using iterator for
{}\ttt{ArrayRCP} yield raw-pointer performance (not surprising given
that {}\ttt{ArrayRCP::iterator} is just a raw pointer in a non-debug
build).

The take-away points from these timing results are that all compilers
do not fully optimize the array indexing form of the loops and only
raw pointers used as iterators will yield the optimal performance.
The Teuchos array classes perform at least as well as
{}\ttt{std::vector} and actually out-perform {}\ttt{std::vector} in
some cases.  This is only because the Teuchos array classes use raw
C++ pointers for iterators in an optimized non-debug build while the
GNU implementation {}\ttt{std::vector} uses a library-defined class.


%
{}\subsubsection{Performance tuning strategies, semi-persisting associations}
\label{sec:perf-tuning-strategies}
%

The timing results shown in the prior two sections lead to a few
different conclusions related to performance issues in the use of the
Teuchos memory management types:

\begin{itemize}

{}\item The reference-counting machinery of the {}\ttt{RCP} class
imparts at least 72 bytes of overhead for every reference-counted
object (the overhead for {}\ttt{ArrayRCP} is slightly higher) and
therefore {}\ttt{RCP} should not be used to manage massive numbers of
small objects, just from a memory usage standpoint.  Likewise,
{}\ttt{ArrayRCP} should not be used to manage large collections of
small arrays since the memory overhead could be significant.

{}\item The extra runtime overhead of reference-counting machinery
does not significantly increase dynamic memory allocation and
deallocation runtime costs for moderately large objects.

{}\item The runtime reference-counting overhead of {}\ttt{RCP} with
respect to {}\ttt{boost::shared\_ptr} can vary from as little as 30\%
on a good optimizing compiler (e.g.\ GCC 4.1.2) to as much as 300\% or
more on a poor optimizing compiler (e.g.\ MSVC++ 2008).  Therefore, if
portable performance of is critical, make sure and use the
reference-counting types at as high a level of granularity as one can
such that it does not damage the quality of the software (i.e.\
safety, flexibility, usability, maintainability).

{}\item The most portable way to achieve high performance in array
operations is to use iterators on {}\ttt{ArrayRCP} and
{}\ttt{ArrayView} objects.  The timing results on ICC 10.1 show that
some compilers will not even given optimize performance for
{}\ttt{std::vector::iterator}!  Also, all compilers do not
automatically fully optimize the array bracket form of an array-based
loop so an iterator loop is the only foolproof way to get the best
optimized performance across platforms.

\end{itemize}

The performance tests described above show that the memory and runtime
overhead of the reference-counting machinery can be high when used
with small cheap objects.  Therefore, if the reference-counted types
{}\ttt{RCP} and {}\ttt{ArrayRCP} are used at too low a level of
granularity, the overall performance of the program may suffer and may
use significantly more memory than it would with raw pointers.  In
such low-level code, strictly adhering to the idioms described in
Sections~\ref{sec:idioms-for-passing-arguments}
and~\ref{sec:idioms-returning-objects} with respect to persisting
relationships can significantly degrade performance.  Therefore, in
low-level performance-critical code, the strict idioms related to
persisting associations need to be relaxed or the design must be
changed to raise the level of granularity where the reference-counted
types are used.

However, just because one cannot use {}\ttt{RCP} and {}\ttt{ArrayRCP}
in every situration and still achieve high performance does not mean
that the code should hard-code the use ofraw pointers.  Instead,
{}\ttt{Ptr} can be used instead of {}\ttt{RCP} and {}\ttt{ArrayView}
can be used instead of {}\ttt{ArrayRCP} when the full semantics of
persisting relationships are not needed and instead only
semi-persisting relationships are needed (see
Section~\ref{sec:nonpersisting-persisting-associations}).  By using
the types {}\ttt{Ptr} and {}\ttt{ArrayView} instead of raw pointers
for all semi-persisting associations one still gets all of the strong
debug-mode runtime checking that is described in
Section~\ref{sec:debug-mode-runtime-checking} (e.g.\ dangling
reference checking, null checking, range checking, etc.) yet these
types remove all overhead over raw pointers in a non-debug optimized
build.

As an example, consider the design of a sparse matrix class that
stores its data as compressed sparse rows and allows access to the
sparse rows.  The client of the sparse matrix class would obtain
handles to the sparse row data, make modifications to it, and then
release the handles.  Performing all of these operations in a single
statement (as is strictly required for a non-persisting relationship
as defined in Section~\ref{sec:nonpersisting-persisting-associations})
is impractical.  Therefore, the handles for the internal sparse row
data represent a persisting relationship and the strict interpretation
of the idioms defined in
Sections~\ref{sec:idioms-for-passing-arguments}
and~\ref{sec:idioms-returning-objects} would require the use of
{}\ttt{ArrayRCP} yielding the sparse matrix class interface shown in
Listing~\ref{listing:SparseMatrix-ArrayRCP}.


\begin{listing}: Sparse matrix class interface adhering to strict
interpretation of idioms for persisting relationships  \\
\label{listing:SparseMatrix-ArrayRCP}
{\small\begin{verbatim}
  class SparseMatrix {
  public:
    ...
    int getNumRows() const;
    void getSparseRow( int rowId, const Ptr<ArrayRCP<double> > &values,
      const Ptr<ArrayRCP<const int> > &colIds);
    ...
  };
\end{verbatim}}
\end{listing}


The {}\ttt{SparseMatrix} class shown in
Listing~\ref{listing:SparseMatrix-ArrayRCP} would be used as shown in
Listing~\ref{listing:zeroOutSparseMatrix-ArrayRCP}.


\begin{listing}: Client code using {}\ttt{ArrayRCP} form of the
 {}\ttt{SparseMatrix} class  \\
\label{listing:zeroOutSparseMatrix-ArrayRCP}
{\small\begin{verbatim}
  void zeroOutSparseMatrix(const Ptr<SparseMatrix> &M)
  {
    const int numRows = M->getNumRows();
    for (int row_i = 0; row_i < numRows; ++row_i) {
      ArrayRCP<double> values;
      M->getSparseRow(row_i, outArg(values), null);
      typedef ArrayRCP<double>::iterator itr_t;
      for (itr_t itr = values.begin(); itr != values.end(); ++itr)
        *itr = 0.0;
    }
  }
\end{verbatim}}
\end{listing}


While the interface and the user code shown in
Listing~\ref{listing:zeroOutSparseMatrix-ArrayRCP} strictly satisfies
that safe and bullet-proof idioms on persisting associations described
in Section~\ref{sec:idioms-for-passing-arguments}, the reference
counting overhead (in memory size and speed) of this code can be quite
high if the rows are very sparse.  Looking at code such as shown in
Listing~\ref{listing:zeroOutSparseMatrix-ArrayRCP} and similar use
cases, it never seems reasonable that a client would grab
{}\ttt{ArrayRCP} objects to internal rows and expect to have the row
data persist even if the matrix changed structure or was deleted.
Instead, one just needs to set up the infrastructure for
semi-persisting associations to be able to detect those types of
invalid usage in a debug-mode build but yield high performance in an
optimized build.  Therefore, it seems reasonable to replace
{}\ttt{ArrayRCP} in {}\ttt{SparseMatrix::getSparseRow(...)} in
Listing~\ref{listing:SparseMatrix-ArrayRCP} with {}\ttt{ArrayView}
yielding the new {}\ttt{SparseMatrix} interface shown in
Listing~\ref{listing:SparseMatrix-ArrayView}.


\begin{listing}: Sparse matrix class interface using a semi-persisting
association for row views for the sake of performance \\
\label{listing:SparseMatrix-ArrayView}
{\small\begin{verbatim}
  class SparseMatrix {
  public:
    ...
    int getNumRows() const;
    void getSparseRow( int rowId, const Ptr<ArrayView<double> > &values,
      const Ptr<ArrayView<const int> > &colIds);
    ...
  };
\end{verbatim}}
\end{listing}


The updated client code zeroing out the rows of the matrix would then
look like Listing~\ref{listing:zeroOutSparseMatrix-ArrayView}.


\begin{listing}: Client code using {}\ttt{ArrayView} form of the
{}\ttt{SparseMatrix} class with semi-persisting row views  \\
\label{listing:zeroOutSparseMatrix-ArrayView}
{\small\begin{verbatim}
  void zeroOutSparseMatrix(const Ptr<SparseMatrix> &M)
  {
    const int numRows = M->getNumRows();
    for (int row_i = 0; row_i < numRows; ++row_i) {
      ArrayView<double> values;
      M->getSparseRow(row_i, outArg(values), null);
      typedef ArrayView<double>::iterator itr_t;
      for (itr_t itr = values.begin(); itr != values.end(); ++itr)
        *itr = 0.0;
    }
  }
\end{verbatim}}
\end{listing}


Now the client code in
Listing~\ref{listing:zeroOutSparseMatrix-ArrayView} will have no
reference-counting overhead in a non-debug optimized build but in a
debug-mode build, all invalid usage will be detected.  For example,
consider invalid code such as shown
Listing~\ref{listing:SparseMatrix-dangling-ref} where the client code
tries to hold on to sparse row data after the matrix is deleted.


\begin{listing}: Example of invalid usage of {}\ttt{SparseMatrix} leading
to a dangling reference exception in a debug-mode build  \\
\label{listing:SparseMatrix-dangling-ref}
{\small\begin{verbatim}

  // Create and initialize the matrix
  RCP<SparseMatrix> M = createSparseMatrix(...); // Non-member constructor
  ...

  // Grab a sparse row to the matrix
  ArrayView<double> values_row_0;
  ArrayView<const int> colIds_row_0;
  M->getSpaseRow(0, outArg(values_row_0), outArg(colIds_row_0));

  // Delete the matrix (leaving dangling values_row_0 and colIds_row_0)
  M = null;

  // Try to access the row
  ArrayView<double>::iterator
    itr = values.begin(),     // Throws exception in debug-mode build!
    itr_end = values.end();
  for ( ; itr != itr_end; ++itr)
    *itr = 0.0; 
\end{verbatim}}
\end{listing}


As shown in Listing~\ref{listing:SparseMatrix-dangling-ref}, using
{}\ttt{ArrayView} allows programming errors to be detected in a
debug-mode build.  If raw pointers would have been used, this dangling
reference may not be detected right away.  On some platforms for some
problem sizes, the program using raw pointers may seem to run just
fine and Valgrind may not complain (especially if sophisticated memory
management is used inside the {}\ttt{SparseMatrix} class).  The error
may not present itself until months or years later where it may do
untold harm.

Note that there may be some extreme cases where the overhead of an
extra size data member in {}\ttt{ArrayView} is too high.  In these
cases, one can instead use an iterator type such as
{}\ttt{Array::iterator} or {}\ttt{ArrayRCP::iterator} (depending on
type of the underlying container class).  In a debug-mode build, the
iterator objects will be fully checked {}\ttt{ArrayRCP} objects while
in a non-debug optimized build, the iterators will be raw pointers (or
{}\ttt{std::vector::iterator} in the case of {}\ttt{Array::iterator}).
This yields raw pointer performance in a non-debug optimized build
with no space or time overhead (because all the objects actually are
raw pointers in this case).

The point of this section is to acknowledge that there will be
situations in low-level code where the strict adherence to using
reference-counted types {}\ttt{RCP} and {}\ttt{ArrayRCP} for
persisting associations may not yield acceptable performance and
therefore one must instead provide for semi-persisting views.
However, as demonstrated above, the solution to the performance
problem is not to fall back to using raw pointers but instead to fall
back on the non-reference-counted types {}\ttt{Ptr} and
{}\ttt{ArrayView} (or {}\ttt{Array[RCP]::iterator}).  By using the
types {}\ttt{Ptr} and {}\ttt{ArrayView} (or
{}\ttt{Array[RCP]::iterator}), one maintains all the desirable
debug-mode runtime checking without any of the reference-counting
overhead in a non-debug optimized build.  We can have our cake and eat
it too!


%
{}\subsection{Related idioms and design patterns}
%

There are a number of important idioms related to the usage of the
Teuchos memory management classes and most specifically the
{}\ttt{RCP} class.  The power and flexibility of the
reference-counting machinery built in to the {}\ttt{RCP} class
opens the door the a whole host of interesting idioms, a few of which
are described in the following subsections.


%
{}\subsubsection{The inverted object ownership idiom}
\label{sec:inverting-obj-ownership}
%

A rare situation that can occur is when one has an object that
maintains an {}\ttt{RCP} to another object but one wants to expose the
second object and have it remember the first object; in other words,
one wants to invert the object ownership.  To demonstrate, consider
the two classes in Listing~\ref{listing:B_owns_A_decl}.

\begin{listing}: Two classes where one maintains an RCP to the other \\
\label{listing:B_owns_A_decl}
{\small\begin{verbatim}
  class A { ... };

  RCP<A> createA(...);

  class B {
  public:
    static RCP<B> create(const RCP<A> &a) {return rcp(new B(a)); }
    RCP<A> getA() { return a_; }
    void unsetA() { a_ = null; }
    ...
  private:
    RCP<A> a_;
    B(const RCP<A> &a) a_(a) {}
  };

  RCP<B> createB(const RCP<A> &a) {return B::create(a);}
\end{verbatim}}
\end{listing}

The class {}\ttt{A} in Listing~\ref{listing:B_owns_A_decl} may involve
some complex initialization or it may only be an abstract interface
with multiple subclasses.  In either case, it may make sense to
provide a factory function (or a set of such functions) that creates
and initializes a {}\ttt{B} object for different complex
initializations of {}\ttt{A} objects such as the example shown in
Listing~\ref{listing:createBFactory}.

\begin{listing}: A factory function that creates a {}\ttt{B} object
wrapping a complex {}\ttt{A} object \\
\label{listing:createBFactory}
{\small\begin{verbatim}
  RCP<B> createBFactory(...)
  {
     // Complex initialization of A
     RCP<A> a;
     ...
     // Wrapped B
     return createB(a);
  }
\end{verbatim}}
\end{listing}

Up to now, this is pretty standard code.  The client would typically
hold an {}\ttt{RCP<B>} object and would manage the lifetime of the
{}\ttt{A} object implicitly wrapped in the {}\ttt{B} object.

However, now consider a rare use case where a client may only want to
deal directly with the {}\ttt{A} object but still maintain the
{}\ttt{B} object for later use.  There are a few approaches that
one could try to implement this inversion of RCP ownership but there
is a way to enable this that is 100\% bullet-proof without having to
change the existing {}\ttt{A} or {}\ttt{B} classes or any other
code at all.  The way to do this is to use the
{}\ttt{rcpWithInvertedObjOwnership(...)} function (defined in
Listing~\ref{listing:rcpWithInvertedObjOwnership}) as shown in
Listing~\ref{listing:A_owns_B_owns_A}.

\begin{listing}: A factory function that returns an {}\ttt{A} object
embedded with a {}\ttt{B} object (inverting the ownership relationship) \\
\label{listing:A_owns_B_owns_A}
{\small\begin{verbatim}
  RCP<A> createAFactory(...)
  {
    RCP<B> b = createBFactory(...);
    return rcpWithInvertedObjOwnership(b->getA(), b);
  }
\end{verbatim}}
\end{listing}


\begin{listing}: Standard helper function implementing the ``inverted
object ownership'' idiom \\
\label{listing:rcpWithInvertedObjOwnership}
{\small\begin{verbatim}
  template<class T, class ParentT>
  RCP<T> rcpWithInvertedObjOwnership(const RCP<T> &child, const RCP<ParentT> &parent)
  {
    typedef std::pair<RCP<T>, RCP<ParentT> > Pair_t;
    return rcpWithEmbeddedObj(child.getRawPtr(), Pair_t(child, parent), false);
  }
\end{verbatim}}
\end{listing}


% ToDo: Show UML object diagram that shows the two RCPNode objects.


Without going into a lot of detail, what the code in
Listings~\ref{listing:A_owns_B_owns_A}
and~\ref{listing:rcpWithInvertedObjOwnership} accomplishes is that it
defines a new {}\ttt{RCP<A>} object with a new {}\ttt{RCPNode} object
that uses the other existing {}\ttt{RCP<A>} and {}\ttt{RCP<B>} objects
to define ownership and ensure that the underlying {}\ttt{A} and
{}\ttt{B} objects do not go away until the last {}\ttt{RCP<A>} object
copied from the object returned by the function
{}\ttt{createAFactory(...)} has gone away.  The reason that
{}\ttt{false} is passed into the {}\ttt{rcpWithEmbeddedObj(...)} call
is because it is the embedded objects {}\ttt{RCP<A>} and
{}\ttt{RCP<B>} that define the deallocation and not the embedded
deallocator (which calls {}\ttt{delete}).  The reason that both
{}\ttt{RCP<A>} and {}\ttt{RCP<B>} are passed as an embedded object
(stored in an {}\ttt{std::pair} object) is that one needs to make sure
the {}\ttt{A} object does not get deleted in case some client calls
the {}\ttt{B::unsetA()} function.

Given this data-structure, another piece of code can then extract the
underlying {}\ttt{RCP<B>} object is shown in
Listing~\ref{listing:Extract_B_from_A} which uses the standard Teuchos
function {}\ttt{getInvertedObjOwnershipParent(...)} defined in
Listing~\ref{listing:getInvertedObjOwnershipParent}.

\begin{listing}: A function that extracts the B object from the A object \\
\label{listing:Extract_B_from_A}
{\small\begin{verbatim}
  RCP<B> extractBFromA(const RCP<A> &a)
  {
    return getInvertedObjOwnershipParent<B>(a);
  }
\end{verbatim}}
\end{listing}


\begin{listing}: Standard helper grabbing the inverted parent \\
\label{listing:getInvertedObjOwnershipParent}
{\small\begin{verbatim}
  template<class ParentT, class T>
  RCP<ParentT> getInvertedObjOwnershipParent(const RCP<T> &invertedChild)
  {
    typedef std::pair<RCP<T>, RCP<ParentT> > Pair_t;
    Pair_t pair = getEmbeddedObj<T, Pair_t>(invertedChild);
    return pair.second;
  }
\end{verbatim}}
\end{listing}


That is all there is to it.  This is not the sort of thing that one
wants to expose to general clients but it can be very handy to have
this type of flexibility when implementing the guts of library code.
The above example shows the flexibility of these memory management
classes and what some of the possibilities are if one understands the
underlying reference-counting machinery a little.


%
{}\subsubsection{The separate construction and just-in-time
initialization idioms}
\label{sec:separate-construct-init}
%

The ``separate construction and initialization'' and ``just-in-time
initialization'' idioms described here are not specific to the use of
the Teuchos memory management classes but they do provide the basic
foundation for the next idiom described, the ``object self-reference''
idiom.  To set up the context for the discussion, consider a typical
class design shown in Listing~\ref{listing:sci:SomeClass-before}.


\begin{listing}: Example of a typical C++ class that uses constructors for all
initialization  \\
\label{listing:sci:SomeClass-before}
{\small\begin{verbatim}
  class SomeClass : public SomeBaseClass {
    int member1_;
    double member2_;
    RCP<A> a_;
    RCP<B> b_;
    RCP<C> c_;
    void finalInitialization() { ...} // Can't call virtual functions on SomeBaseClass
  public:
    SomeClass(): member1_(1), member2_(5.0) {}
    SomeClass(const RCP<A> &a) : member1_(1), member2_(5.0), a_(a)
      { finalInitialization(); }
    SomeClass(const RCP<B> &b) : member1_(1), member2_(5.0), b_(b)
      { finalInitialization(); }
    SomeClass(const RCP<A> &a, const RCP<B> &b, const int someValue)
      : member1_(1), member2_(5.0), a_(a), b_(b)
      { c_ = createC(rcp(this, false), a, b, someValue);
        finalInitialization(); }
    RCP<A> get_A() { return a_; }
    RCP<B> get_B() { return b_; }
    RCP<C> get_C() { return c_; }
    void doSomeOperation(...) {...}
  };

\end{verbatim}}
\end{listing}


So what is wrong with the design of {}\ttt{SomeClass} in
Listing~\ref{listing:sci:SomeClass-before}?  First, there is the
duplication of default values for {}\ttt{member1\_}, {}\ttt{member2\_}
in all of the constructors.  This makes it labor intensive and
error-prone to change the values later.  Yes, one could create static
constants of some type to be reused in all the constructor
initialization lists but one still has to list all of these arguments
in every constructor\footnote{The new C++0x standard will address the
problem of duplicate constructor initialization lists by allowing
constructors to call each other but we will not see such a feature in
wide spread use until many years after the C++0x standard is
finalized.}.

The second problem with the class {}\ttt{SomeClass} that it cannot
call any virtual functions in the base class {}\ttt{SomeBaseClass} to
help initialize its state in the constructors {}\cite[Item
49]{C++CodingStandards05}.

The third problem with the design of {}\ttt{SomeClass} shown in
Listing~\ref{listing:sci:SomeClass-before} is that the {}\ttt{C}
object that is created in the third constructor that takes {}\ttt{A}
and {}\ttt{B} objects is not properly setting up a persisting
relationship between the {}\ttt{C} object and the {}\ttt{SomeClass}
object.  When this {}\ttt{C} object is exposed through the
{}\ttt{get\_C()} member function, this creates a dangerous situation
where the {}\ttt{SomeClass} object may be deleted leaving a client
with a dangling {}\ttt{RCP<C>} object with no way for the
reference-counting machinery described in
Section~\ref{sec:reference-counting-machinary} do detect the the
problem.  This issue will be discussed more in the context of the
``object self-reference'' idiom in Section~\ref{sec:self-references}.

Lastly, the class {}\ttt{SomeClass} is inflexible in that it requires
the client creating the {}\ttt{SomeClass} object to know the concrete
types of {}\ttt{A} and or {}\ttt{B} (which could be abstract
interfaces in this example) right when the {}\ttt{SomeClass} object is
first created.  This creates a three-way coupling between a) the
client, with b) defining the time when the {}\ttt{SomeClass} object is
first created, and c) needing fully constructed {}\ttt{A} and
{}\ttt{B} objects right when {}\ttt{SomeClass} is first created.  In
complex programs, it is very hard and very constraining to have to
fully initialize a web interconnected objects before constructing
downstream objects.

Without further ado, the use of the ``separate construction and
initialization'' and ``just-in-time initialization'' idioms applied to
{}\ttt{SomeClass} shown in Listing~\ref{listing:sci:SomeClass-before}
gives the new refactored class in
Listing~\ref{listing:sci:SomeClass-refactored}.


\begin{listing}: Example of the use of the ``separate construction and
initialization'' and ``just-in-time initialization'' idioms  \\
\label{listing:sci:SomeClass-refactored}
{\small\begin{verbatim}
  class SomeClass : public SomeBaseClase {
  public:
    SomeClass(): isIntialized_(false), member1_(1), member2_(5.0) {}
    void set_A(const RCP<A> &a) { a_ = a; isIntialized_=false; }
    void set_B(const RCP<B> &b) { b_ = b; isIntialized_=false; }
    RCP<A> get_A() { return a_; }
    RCP<B> get_B() { return b_; }
    RCP<C> get_C() { justInTimeInitialize(); return c_; }
    void uninitialize() { a_ = null, b_ = null; c_ = null; isIntialized_=false; }
    void doSomeOperation(...)
      {
        justInTimeInitialize();
        ...
       }
  private:
    bool isIntialized_;
    int member1_;
    double member2_;
    RCP<A> a_;
    RCP<B> b_;
    RCP<C> c_;
    void justInTimeInitialize()
      {
        if (isIntialized_) return;
        // Can now call virtual functions on SomeBaseClass (someBaseFunc())!
        if (nonnull(a_) && nonnull(b_))
          c_ = createC(rcp(this, false), a, b, this->getSomeValue());
        ...
        isIntialized_ = true;
      }
  };

  // Non-member constructors
  RCP<SomeClass> someClass()
    { return rcp(new someClass()); }
  RCP<SomeClass> someClass(const RCP<A> &a)
    { RCP<someClass> sc(new someClass()); sc->set_A(a); return sc; }
  RCP<SomeClass> someClass(const RCP<B> &b)
    { RCP<someClass> sc(new someClass()); sc->set_B(b); return sc; }
  RCP<SomeClass> someClass(const RCP<A> &a, const RCP<B> &b)
    { RCP<someClass> sc(new someClass()); sc->set_A(a); sc->set_B(b);  return sc; }
\end{verbatim}}
\end{listing}


SIDE NOTE: Before describing the specific advantages of the refactored
class in Listing~\ref{listing:sci:SomeClass-refactored}, first note
that the issue of the creation of the {}\ttt{C} object and dangling
references of {}\ttt{c\_} returned from {}\ttt{get\_C()} have not been
addressed in this design.  That issue will be addressed with the
``object self-reference'' idiom described in
Section~\ref{sec:self-references}.

Some of the specific advantages of the usage of the ``separate
construction and initialization'' idiom as applied to the design of
{}\ttt{SomeClass} shown in
Listing~\ref{listing:sci:SomeClass-refactored} are described below.

a) The default values for {}\ttt{member1\_} and {}\ttt{member2\_} are
defined in only one constructor initialization list.  This massively
simplifies the maintenance of large complex classes with lots of data
members and more than one constructor.

b) The private initialization function {}\ttt{justInTimeInitialize()}
can now call a virtual function on the base class
{}\ttt{SomeBaseClass::getSomeValue()} to get the value of
{}\ttt{someValue} instead of requiring the client to pass it into the
constructor.

c) The objects {}\ttt{a} and {}\ttt{b} can be constructed and injected
into the {}\ttt{SomeClass} object in different parts of the code by
different clients.  This breaks a fundamental dependency which couples
these objects and the clients together and can massively simplify the
structure of complex programs.

d) The ``separate construction and initialization'' idiom naturally
leads to the ``just-in-time initialization'' idiom where the
{}\ttt{justInTimeInitialize()} function is not called until the
functions {}\ttt{doSomeOperation(...)} or {}\ttt{get\_C()} are called
by a client.  This allows the objects {}\ttt{a} and/or {}\ttt{b} to be
passed into the functions {}\ttt{set\_A(...)}  and {}\ttt{set\_B(...)} 
in a partially initialized state.  These objects do not need to be
fully initialized until the {}\ttt{doSomeOperation(...)} or
{}\ttt{get\_C()} functions are called.  This can massively simplify
and robustify the design of complex programs by separating code that
creates the links between objects from the code that fully initializes
the objects.  This avoids the constraints of needing to use a factory
object to create fully initialized ``aggregate'' objects described in
{}\cite{DomainDrivenDesign}.

e) An object of type {}\ttt{SomeClass} is not any harder for a client
to create because the non-member constructor functions allow the
object to be constructed in a single function call (see
Section~\ref{sec:nonmember-constructor-idiom}) for all the use cases
given in the original class constructor design.

The only real disadvantage of the ``separate construction and
initialization'' idiom is some small decrease in performance in using
assignment instead of member initialization lists {}\cite[Item
4]{EffectiveC++ThirdEdition}.  However, this type of low-level
performance is almost never an issue in higher-level classes like
{}\ttt{SomeClass} shown in
Listing~\ref{listing:sci:SomeClass-refactored}.  Most classes in a
complex program are higher-level classes where low-level performance
considerations like this are not an issue so the the ``separate
construction and initialization'' idiom is applicable in more cases
than not.

The main disadvantage of the ``just-in-time initialization'' idiom is
the need to have a call the function {}\ttt{justInTimeInitialize()} in
every operation that requires the object to be fully initialized.
This is minor programming inconvenience and a minor performance
overhead.  The more significant disadvantage is that more unit testing
is needed to test the behavior of the user functions for when the
object is not ready to be fully initialized.  However, good class
design makes this fairly easy.


%
{}\subsubsection{The object self-reference idiom}
\label{sec:self-references}
%

There are occasions where an object needs to provide an {}\ttt{RCP} to
itself with the full protection of the debug-mode checking with
node-tracing enabled.  However, for an object to hold a strong
{}\ttt{RCP} to itself would set up a circular reference and the object
would never be deleted.  The issue of self references was mentioned in
the previous section in the context of the ``separate construction and
initialization'' idiom.

The most straightforward example of where the ``object
self-reference'' idiom is needed is when a factory object creates a
product that must in turn store a strong owning {}\ttt{RCP} to the
factory that created it.  This is the exact use case that exists in
the Thyra package for {}\ttt{VectorBase} and {}\ttt{VectorSpaceBase}
objects {}\cite{ThyraOperatorVectorSAND}.  In this case,
{}\ttt{VectorSpaceBase} acts as the factory and {}\ttt{VectorBase}
acts as the product.  Also, every {}\ttt{VectorBase} object has a
function {}\ttt{space()} that returns an {}\ttt{RCP} to the
{}\ttt{VectorSpaceBase} object that created it to be used to create
other {}\ttt{VectorBase} objects.

A simplified version of the implementation of the
{}\ttt{VectorSpaceBase} standard subclass
{}\ttt{DefaultSpmdVectorSpace} using the ``object self-reference''
idiom is shown in Listing~\ref{listing:osr:DefaultSpmdVectorSpace}.


\begin{listing}: Example of the ``object self-reference'' idiom where a
factory must give a strong owning {}\ttt{RCP} self reference to its products.  \\
\label{listing:osr:DefaultSpmdVectorSpace}
{\small\begin{verbatim}
  class DefaultSpmdVectorSpace : public VectorSpaceBase {
    RCP<DefaultSpmdVectorSpace> weakSelfPtr_;
    Ordinal localDim_;
    DefaultSpmdVectorSpace() : localDim_(0) {}
  public:
    static RCP<DefaultSpmdVectorSpace> create()
      {
        RCP<DefaultSpmdVectorSpace> vs(new DefaultSpmdVectorSpace);
        vs.weakSelfPtr_ = vs.create_weak();
        return vs;
      }
    void initialize(const Ordinal localDim)
      {  localDim_ = localDim; }
    RCP<VectorBase> createMember()
      { return defaultSpmdVector(weakSelfPtr_.create_strong()); }
  };

  // Nonmeber constructor
  RCP<DefaultSpmdVectorSpace> defaultSpmdVectorSpace(const Ordinal localDim)
  {
    RCP<DefaultSpmdVectorSpace> vs = DefaultSpmdVectorSpace::create();
    vs->initialize(localDim);
    return vs;
  }
\end{verbatim}}
\end{listing}


The way the ``object self-reference'' idiom works is that a static
function {}\ttt{create()} allocates a default-initialized
{}\ttt{DefaultSpmdVectorSpace} object and stores it in a strong owning
{}\ttt{RCP} object.  It then creates a weak {}\ttt{RCP} object that it
sets as the self reference on the newly created
{}\ttt{DefaultSpmdVectorSpace} object.  The default constructor is
made private so the only way for a client to create an
{}\ttt{DefaultSpmdVectorSpace} object is to use use the static
{}\ttt{create()} function (or call it indirectly through the
non-member constructor function {}\ttt{defaultSpmdVectorSpace()}).
Because this self reference is a weak tracing {}\ttt{RCP}, it can
detect dangling references or can be used to create a strong
{}\ttt{RCP} when needed while at the same time not creating a circular
reference that would result in a memory leak.

The member function {}\ttt{createMember()} shown in
Listing~\ref{listing:osr:DefaultSpmdVectorSpace} creates a strong
owning {}\ttt{RCP} to itself which is given to the newly created
{}\ttt{DefaultSpmdVector} object in the statement
{}\ttt{defaultSpmdVector(weakSelfPtr\_.create\_strong())}.  This
allows the resulting product {}\ttt{DefaultSpmdVector} object to
outlive the client's {}\ttt{RCP} references to the
{}\ttt{DefaultSpmdVectorSpace} factory object.  A simple example of
this is shown in
Listing~\ref{listing:osr:DefaultSpmdVectorSpace-use-delete}.


{}\begin{listing}: Example of client code that creates a factory, uses
it to create a product and lets the factory go away where the factory
is remembered in the product
\label{listing:osr:DefaultSpmdVectorSpace-use-delete}
{\small\begin{verbatim}
  RCP<VectorBase> createMyVector(const Ordinal localDim)
  {
     RCP<DefaultSpmdVectorSpace> vs = defaultSpmdVectorSpace(localDim);
     return vs->createMember();
     // NOTE: The DefaultSpmVectorSpace object is embedded in the returned
     // DefaultSpmdVector object and will not be deleted
  }
\end{verbatim}}
\end{listing}


Code like shown in
Listing~\ref{listing:osr:DefaultSpmdVectorSpace-use-delete} may seem
contrived but there have been several use cases for Thyra over the
years that required code just like this to work or it would have
resulted in a much more complex design of the client's code to work
around this issue.

There are also other less obvious examples where the ``object
self-reference'' idiom is useful.  For one such case, consider
Listing~\ref{listing:osr:SomeClass-before} which shows a simplified
version of the class shown in
Listing~\ref{listing:sci:SomeClass-before} that has to pass a self
reference to an object it creates and holds internally.


{}\begin{listing}: Example of an class with {}\ttt{RCP}-to-self
problems (similar to the class in
Section~\ref{sec:separate-construct-init})
\label{listing:osr:SomeClass-before}
{\small\begin{verbatim}
  class SomeClass : public SomeBaseClass {
    RCP<C> c_;
    void finalInitialization() { ...}
  public:
    SomeClass() {}
      { c_ = createC(rcp(this, false)); finalInitialization(); }
    RCP<C> get_C() { return c_; }
    ...
  };
\end{verbatim}}
\end{listing}


The problem with the code in
Listing~\ref{listing:osr:SomeClass-before} is that it gives up an
{}\ttt{RCP<C>} object to its internal {}\ttt{C} object that is
constructed internally but a proper node tracing relationship has not
been established between the {}\ttt{C} object and the
{}\ttt{SomeClass} object.  (Even if {}\ttt{SomeClass} does not
intentionally give up its {}\ttt{RCP<C>} object, it is still very easy
to do it by accident so this scenario still applies.)  To see the
problem with this, consider the client code in
Listing~\ref{listing:osr:bad-use-SomeClass}.


{}\begin{listing}: Client code that results in undefined behavior
(e.g.\ segfault) \\
\label{listing:osr:bad-use-SomeClass}
{\small\begin{verbatim}
  RCP<SomeClass> sc(new SomeClass);
  RCP<C> c = sc->get_C();
  sc = null; // The SomeClass object is destroyed which invalidates 'c'!
  c->someFunc(); // Undefined behavior of call to deleted SomeClass!
\end{verbatim}}
\end{listing}


The problem with the code in
Listing~\ref{listing:osr:bad-use-SomeClass} is that when the
{}\ttt{SomeClass} object {}\ttt{sc} is destroyed, there is no way for
the reference-counting machinery in to catch the dangling reference.
This code yields undefined behavior and will segfault if one is lucky
but like any memory usage error, if one is unlucky the code will
appear to work correctly but will be a ticking time-bomb that will go
off eventually.  The reason for this behavior is that the statement
{}\ttt{c\_ = createC(rcp(this, false))} in the constructor
{}\ttt{SomeClass()} creates a non-owing {}\ttt{RCPNode} object
{}\underline{before} the owning {}\ttt{RCPNode} object is created by
the client code {}\ttt{RCP<SomeClass> sc(new SomeClass)}.  This
violates Commandment~\ref{cmnd:owning-rcp-first} in
Appendix~\ref{apdx:commandments}.  The node-tracing reference-counting
machinery would have to be more complex and much more expensive to
catch dangling reference errors where the strong owning
{}\ttt{RCPNode} object was not the first {}\ttt{RCPNode} object
created.

The solution to this problem is to use a variation of the ``object
self-reference'' idiom.  The updated design that accomplishes this is
shown in Listing~\ref{listing:osr:SomeClass-refactored}.


\begin{listing}:  Example of the ``object self-reference'' idiom for
detecting dangling references to internally held objects  \\
\label{listing:osr:SomeClass-refactored}
{\small\begin{verbatim}
  class SomeClass : public SomeBaseClass {
    RCP<SomeClass> weakSelfPtr_;
    RCP<C> c_;
    SomeClass() {}
    void justInTimeInitialize() { c_ = createC(weakSelfPtr_); }
  public:
    static RCP<SomeClass> create()
      {
        RCP<SomeClass> sc(new SomeClass);
        sc.weakSelfPtr_ = sc.create_weak();
        return sc;
      }
    RCP<C> get_C() { justInTimeInitialize(); return c_; }
    ...
  };

  // Nonmeber constructor
  RCP<SomeClass> someClass() { return SomeClass::create(); }
\end{verbatim}}
\end{listing}

The advantage of the design in
Listing~\ref{listing:osr:SomeClass-refactored} is that now client code
like shown in Listing~\ref{listing:osr:dangling-ref-SomeClass} below
will result in a dangling reference exception in a node-tracing
debug-mode build.


\begin{listing}: Client code that results a clean dangling-reference exception  \\
\label{listing:osr:dangling-ref-SomeClass}
{\small\begin{verbatim}
  RCP<SomeClass> sc = someClass();
  RCP<C> c = sc->get_C();
  sc = null; // The SomeClass object is destroyed which invalidates 'c'!
  c->someFunc(); // Now the dangling reference is detected and throws!
\end{verbatim}}
\end{listing}


Note that the implementation of {}\ttt{SomeClass} in
Listing~\ref{listing:osr:SomeClass-refactored} means that the nature
of the relationship between the {}\ttt{C} object returned from
{}\ttt{SomeClass::get\_C()}, the parent {}\ttt{SomeClass} object, and
the client code represents a semi-persisting association as defined in
Section~\ref{sec:nonpersisting-persisting-associations}.  In this
case, the usage of the {}\ttt{C} object is only valid while the parent
{}\ttt{SomeClass} object still exists.  However, if the client
mistakenly tries to use a dangling {}\ttt{C} object after its parent
{}\ttt{SomeClass} object is destroyed, then a clean runtime
dangling-reference exception is thrown as described in
Section~\ref{sec:detection-dangling-references}.

Alternatively, if one wants the {}\ttt{SomeClass::get\_C()} function
to create a true persisting association where the {}\ttt{C} object can
outlive all of the client references to the parent {}\ttt{SomeClass}
object, then the implementation of {}\ttt{SomeClass::get\_C()} can be
modified to what is shown in
Listing~\ref{listing:osr:SomeClass-get_C-persisting}.


\begin{listing}:  Implementation of the ``object self-reference'' idiom
using a true persisting association  \\
\label{listing:osr:SomeClass-get_C-persisting}
{\small\begin{verbatim}
  RCP<C> SomeClass::get_C()
  {
    justInTimeInitialize();
    return rcpInvertedObjOwnership(c, weakSelfPtr_.create_strong());
  }
\end{verbatim}}
\end{listing}


Creating a strong {}\ttt{RCP} is required in this case as well as the
inversion of the object ownership (which is an instance of the
``inverted object ownership'' idiom which is described in
Section~\ref{sec:inverting-obj-ownership}).

Given the implementation in
Listing~\ref{listing:osr:SomeClass-get_C-persisting}, client code like
shown in Listing~\ref{listing:osr:dangling-ref-SomeClass} will allow
the {}\ttt{C} object to be used after the client's
{}\ttt{RCP<SomeClass>} object is made {}\ttt{null} without thrown a
dangling reference exception.  Choosing between a semi-persisting or a
persisting association is a design decision for the creator of
{}\ttt{SomeClass}.


%
{}\subsubsection{The generalized view design pattern}
\label{sec:generalized-view-design-pattern}
%

One of the most useful and powerful idioms / design-patterns related
to the use of the Teuchos memory management classes is the
``generalized view'' design pattern\footnote{Here the term `design
pattern' and not `idiom' is used to describe the ``generalized view''
design pattern.  The reason that the more general term `design
pattern' is being used is that the majority of the pattern is really
language independent and the behaviors are more general then what one
will find in a typical language-specific idiom.  It is only the
{}\ttt{RCP} details that would classify this as a C++ idiom.  However,
this is an important example of the use of {}\ttt{RCP} so it is worthy
to be discussed in this document.}.  In this context, a ``view'' is
some object that is created off of a parent object and provides some
type of access to some part of the parent.  Views can be const or
non-const and can be persisting or semi-persisting (see
Section~\ref{sec:nonpersisting-persisting-associations} for the
definition of persisting and semi-persisting associations).  Views can
also be direct views or ``generalized views'' (i.e.\ potentially
detached non-direct views).

A direct view is one which directly points into the the internal data
structures of the parent so that a change of the view instantaneously
changes the parent and changes to the parent instantaneously changes
the view(s).  An example of a direct view is an iterator into an
container such as is returned from {}\ttt{std::vector::begin()} or
{}\ttt{std::list::begin()}.  Other examples of direct views include
{}\ttt{ArrayView} views of {}\ttt{Array} and {}\ttt{ArrayRCP} objects.
Direct views can be non-const or const as is demonstrated with
iterators and {}\ttt{ArrayView}s.  Direct views are a pleasure to work
with but they also fundamentally constrain the implementation of the
parent objects that they are providing the views into.  In the case of
contiguous array containers like {}\ttt{std::vector} and
{}\ttt{ArrayRCP}, constraining the implementation to store a pointer
to a contiguous array of data internally is not a problem, that is an
important and proper design constraint for these classes.  However,
for more general classes, the rigid constraints imposed by direct
views are unacceptable and break the abstraction in many cases.  For
example, if an abstract matrix object provides direct views of the
rows of a matrix then the matrix must necessarily be stored in a
row-major data-structure, precluding other possibilities.  Once a
direct row-based view is supported by such a matrix class, it becomes
impossible to change the internal representation of the matrix to
anything other than a row-oriented implementation and still maintain
high performance and a reasonable implementation.


%
{}\subsubsection*{Basic overview of the ``generalized view'' design
pattern}
%

Because direct views can overly constrain the implementation freedom
of the parent, in order to allow for the fullest freedom to pick the
internal implementations of the parent and the view separately, we
must instead consider using potentially detached non-direct views
defined here as ``generalized views''.  A ``generalized view'' is a
view of a parent object that is not guaranteed to be a direct view
such that changes to the view may not be instantaneously propagated to
the parent and vice versa.  One example of a case where a
``generalized view'' is needed is when creating a view of
non-contiguous columns of a dense matrix where, for the sake of
efficiency, one must create a temporary contiguous copy as a new dense
matrix.  This type of generalized view is used in the implementation
of Thyra MultiVector non-contiguous column views
{}\cite{ThyraOperatorVectorSAND} which is depicted in
Figure~\ref{fig:MultiVectorView}. In the Thyra MultiVector
implementation, when the client requests a view of a set of
non-contiguous columns, the implementation will create a temporary
contiguous copy which results in improved performance of many types of
operations\footnote{Using contiguous columns of a Fortran-style
column-major dense matrix is required in order to take advantage of
high performance Basic Linear Algebra Subroutines (BLAS)
software~\cite{ref:demmel_1997}.}.  The Thyra example of
non-contiguous column views is a good example because it is a simple
case to describe yet has all the features needed to demonstrate the
workings of the generalized view design pattern.


{\bsinglespace
\begin{figure}
\begin{center}
%\fbox{
\includegraphics*[angle=270,scale=0.50]{MultiVectorView}
%}
\end{center}
\caption{
\label{fig:MultiVectorView}
Depiction of contiguous and non-contiguous multi-vector column views.}
\end{figure}
\esinglespace}


Before describing the Thyra MultiVector example in more detail, first,
a generic description of the ``generalized view'' design pattern is
presented.  The most general description of the ``generalized view''
design pattern is shown in
Figure~\ref{fig:GeneralizedViewClassDiagram} (UML class diagram) and
Figure~\ref{fig:GeneralizedViewStateDiagram} (UML state diagram).
Figure~\ref{fig:GeneralizedViewClassDiagram} shows two generic
classes; a {}\ttt{Parent} and a {}\ttt{View}.  In this case, only one
type of the view is shown but in reality there can be several
different types of views into a single parent object (as there are in
the Thyra MultiVector case).  A view is created using either the
{}\ttt{createNonconstView(...)} or the {}\ttt{createView(...)} 
functions.  In either case, the returned view is wrapped in an
{}\ttt{RCP} object.  There are two purposes for wrapping the view in
an {}\ttt{RCP} object.  First, a new {}\ttt{View} object may need to
be dynamically allocated to satisfy the view request (and therefore
needs {}\ttt{RCP} to take care to control the lifetime of the
dynamically allocated view object).  Second, the action needed to
re-sync the parent up with the view can be set as an embedded object
on the returned {}\ttt{RCP} (see Section~\ref{sec:embedded-objecs}).
In fact, the {}\ttt{Parent} object is not guaranteed to be updated
after changes to a non-const view are made until the view is
destroyed/released.  To demonstrate, consider the client code in
Listing~\ref{listing:generalized-view-ex1}.


{\bsinglespace
\begin{figure}[p]
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=0.65]{GeneralizedViewClassDiagram}
%}
\end{center}
\caption{
\label{fig:GeneralizedViewClassDiagram}
Parent and child classes for ``generalized view'' design pattern.}
\end{figure}
\esinglespace}


{\bsinglespace
\begin{figure}[p]
\begin{center}
%\fbox{
\includegraphics*[angle=0,scale=0.65]{GeneralizedViewStateDiagram}
%}
\end{center}
\caption{
\label{fig:GeneralizedViewStateDiagram}
State behavior for parent object in ``generalized view'' design
pattern.}
\end{figure}
\esinglespace}


{}\begin{listing}: Example use of a generalized view
\label{listing:generalized-view-ex1}
{\small\begin{verbatim}
  void changeParent(const Ptr<Parent> &parent)
  {
    // Create a non-const view
    const RCP<View> view = parent->createNonconstView(...);

    // Change the parent through the view
    view->makeChange(...);
    view->makeChange(...);
    ...

    // Destroy the view which resycs the view with the parent
    view = null;

    // Now the parent has been updated for changes through the view!

  }
\end{verbatim}}
\end{listing}


The code in Listing~\ref{listing:generalized-view-ex1} demonstrates
that the parent is only guaranteed to be updated after the non-const
generalized view has been destroyed.  The state of the parent is
undefined while a non-const view is active.  One of three
possibilities exist for the state of the parent while a non-const view
is active.  First, if the view just happens to be a direct view, then
changes to the view are instantaneously reflected in the parent.
Second, if the view is a completely separate chunk of data, changes to
the view do not affect the state of the parent at all until the view
is destroyed and the data in the view is copied into the parent's
internal data structures in the appropriate way.  The third option is
somewhere in between the first two; part of the view's data may
directly point back into the parent's internal data structures and the
rest of the view's data may be separate from the parent.  In this
case, the state of the parent object may actually violate its internal
invariants and the parent object would not even be usable while the
non-const view is active.

In order to allow complete freedom in how a generalized view is
implemented and to allow the implementation to change at will, a
relatively strict usage protocol must be defined as shown in the
parent's state diagram in
Figure~\ref{fig:GeneralizedViewStateDiagram}.  With respect to
generalized views, the {}\ttt{Parent} has one of three states; `no
views', `has const views(s)', and `has non-const view'.  The default
state of the parent is `no views'.  In this state, either a const or a
non-const view can be created and all types of query and modifying
functioins can then be called.  When a const view is created, the
parent enters the state `has const view(s)'.  In this state, the
parent object is still allowed to be queried and other const-views can
be created.  However, while there are active const views, a non-const
view cannot be created.  The reason that non-const views cannot be
allowed while const views are active is that creating a non-const view
and then changing it while const views are active would put the const
views into an undefined state.  If the const and non-const views
happened to be implemented as direct views, then changes to the
non-const view would not only change the parent but it would also
change the direct const views.  However, if the views are implemented
as detached copies of data, then changes to the non-const view would
not be expected to be propagated to the existing const
views\footnote{Actually, one could implement an
OBSERVER~\cite{AgileSoftwareDevelopment} type of implementation where
changes to the views would automatically be written back and forth to
keep the parent and the views in sync but this would lead to complex
and fragile implementations and could significantly degrade
performance if frequent small changes to data resulted in lots of
syncs.  Therefore, to allow for a simple implementation and the
highest performance, the generalized view design pattern discourages
this type of more complex less efficient OBSERVER-type of
implementation.}.  Since this type of ambiguity would destroy the
abstraction, the generalized view design pattern simply states that
creating non-const views on the parent while const views are active is
just not allowed.  Likewise, any operations on the parent that might
change the state in a way that would affect the views must also be
disallowed.  In summary, when const views are active, the non-const
interface of the parent must be locked down.  When the last const view
is destroyed, the parent goes back to the `no views' state.

When a non-const view is created the parent goes into the `has
non-const view' state.  In this state, no other non-const or const
views can be created and the entire const and non-const interface of
the parent must be locked down.  In essence, when a non-const view is
active, the parent object has to be completely left along.  The reason
for this should be obvious.  When a non-const view is represented as a
separate copy of data, then the state of the parent is undefined until
the non-const view is destroyed and the data is written back.  In this
case, a query of the parent would not show the changes made in the
active non-const view.  Again, this type of ambiguity would destroy
the abstraction and therefore the parent object must be totally locked
down while a non-const view is active.  Likewise, only one non-const
view can be allowed at any one time due to similar arguments.  When
the non-const view is destroyed, any changes in the data are written
back to the parent's internal data structures and the parent goes back
to the state `no views'.

In order to allow for the highest performance, the simplest
implementations of the parent and the view classes in all cases, and
to help catch errors in client code, therefore by default the
generalized view design pattern states that views should be
semi-persisting; that is, the views are only valid while the client's
{}\ttt{RCP} to the parent is still active and the view is not expected
to live on past the lifetime of the parent.  Therefore, any access to
generalized views that remain after the last strong
{}\ttt{RCP<Parent>} object is released should result in dangling
reference exceptions in a debug-mode build as shown in
Listing~\ref{listing:generalized-view-dangling}.


\begin{listing}:  Example of a dangling reference generalized view  \\
\label{listing:generalized-view-dangling}
{\small\begin{verbatim}
  // Create and initialize parent
  RCP<Parent> parent = createParent(...);
  ...

  // Create a view
  RCP<View> view = parent->createNonconstView(...);

  // Destroy the parent (invalidating the existing view)
  parent = null;

  // Try to access the now dangling view
  view->makeChange(...); // Throws dangling reference exception!
\end{verbatim}}
\end{listing}


Even if a generalized view can be made persisting (which it is in the
MultiVector example given later), the implementation should still
prefer to implement non-const views as semi-persisting views.  The
main purpose of a non-const view is to change the parent object so if
the parent is released before the non-const view is written to and
written back, then that is most likely a programming error in the
client's code.  For example, the code in
Listing~\ref{listing:generalized-view-dangling} is most likely an
error in program logic because if the parent has been deleted then
there is no use in modifying the view.  By implementing generalized
views and semi-persisting views the objects help to better catch these
types of errors in client code.

However, if it makes sense in the particular setting, an
implementation of the generalized view design pattern can choose to
implement the views as full persisting views that will persist even
after all the external parent references are removed (thereby avoiding
dangling-reference exceptions).  Note that if the parent class
implements the ``object self-reference'' idiom described in
Section~\ref{sec:self-references} then a strong {}\ttt{RCP} to the
parent object can always be attached to the {}\ttt{RCP} of the view,
thereby providing for persisting generalized views no mater what
internal data structures are used.

Another aspect of the generalized view design pattern is that it is
important to distinguish between non-const views and const views.  In
the case of const views, if a separate copy of the data must be
created to support the const view, the data does not have to be
written back to the parent when the const view is destroyed.  This
makes const views fundamentally more efficient than non-const views
(which must write back their data when they are destroyed).  Because
const views are potentially more efficient, the unadorned name
{}\ttt{createView(...)} is given to create const views while the
longer name {}\ttt{createNonconstView(...)} is used to create
non-const views.  The idea is that a developer is more likely to call
the shorter {}\ttt{createView(...)} function creating a more efficient
and safe const view.  If a const view is all the client code requires,
then all is good.  However, if the client code really needs to change
the parent object through the view, then the code will not compile and
the developer will need to change the client code to create a
non-const view through {}\ttt{createNonconstView(...)}.

Because the parent object gets locked down (or is in an undefined
state when debug usage checking is not enabled) when generalized views
are active, it is important that client code only create views at the
last possible moment and then release them at the earliest possible
moment.  The best way to do this, when possible, is to create and
release the view in the same statement where the view will be used as
demonstrated in Listing~\ref{listing:generalized-view-min-lifetime}.


\begin{listing}:  Example of minimizing the lifetime of a generalized
view  \\
\label{listing:generalized-view-min-lifetime}
{\small\begin{verbatim}
  void changeParentThroughView(const Ptr<Parent> &parent)
  {
    changeTheView(*parent-createNonconstView());
    queryTheView(*parent->createView());
    ...
  }
\end{verbatim}}
\end{listing}


The client code in Listing~\ref{listing:generalized-view-min-lifetime}
works just fine because the temporary {}\ttt{RCP<[const] View>}
objects managed by the compiler are guaranteed to exist until the full
statement they are created in ends.  This is one case where using an
{}\ttt{RCP} to manage the memory is very convenient.

The last issue to discuss related to the generalized view design
pattern is that, depending on the nature of the parent and the view
classes, it may be reasonable to have the parent object partitioned
into different logical pieces and then apply the behaviors shown in
Figure~\ref{fig:GeneralizedViewStateDiagram} to each of these logical
pieces separately.  For example, one can treat each row or each column
in a matrix object as a separate logical piece such that one can allow
separate views of each of the rows or columns independent of each
other.  This is the case with the Thyra MultiVector example (mentioned
earlier and to be described in more detail below).  However, any bulk
query operations on the parent object (like taking an induced matrix
norm) must be locked out while non-const views are active.  Likewise,
any bulk modifying operation (like assigning all the matrix entries to
zero) must be locked out when any views are active.


%
{}\subsubsection*{Example implementation of generalized views for
MultiVector non-contiguous column views}
%

Now that a basic overview of the generalized view design pattern has
been given, the Thyra MultiVector non-contiguous column view example
mentioned earlier and depicted in Figure~\ref{fig:MultiVectorView} is
described in more detail.  This is a good example to highlight the
features of the generalized view design pattern and the usage of the
{}\ttt{RCP} class to manage detached view semantics.  A simplified
class declaration for the Thyra MultiVector subclass showing the
relevant class members is given in
Listing~\ref{listing:DefaultSpmdMultiVector-decl}.


\begin{listing}:  Class declaration for Thyra MultiVector implementation
of multi-vector views as ``generalized views''  \\
\label{listing:DefaultSpmdMultiVector-decl}
{\small\begin{verbatim}
  template<class Scalar>
  class DefaultSpmdMultiVector : virtual public SpmdMultiVectorBase<Scalar> {
  public:
  
    ...
  
    DefaultSpmdMultiVector(
      const RCP<const SpmdVectorSpaceBase<Scalar> > &spmdRangeSpace,
      const RCP<const ScalarProdVectorSpaceBase<Scalar> > &domainSpace,
      const ArrayRCP<Scalar> &localValues,
      const Ordinal leadingDim = -1
      );
  
    ...
  
  protected:
  
    ...
  
    RCP<const MultiVectorBase<Scalar> >
    nonContigSubViewImpl(const ArrayView<const int> &cols) const;
  
    RCP<MultiVectorBase<Scalar> >
    nonconstNonContigSubViewImpl(const ArrayView<const int> &cols);
  
    ...
    
  private:
  
    RCP<const SpmdVectorSpaceBase<Scalar> > spmdRangeSpace_;
    RCP<const ScalarProdVectorSpaceBase<Scalar> > domainSpace_;
    ArrayRCP<Scalar> localValues_;
    Ordinal leadingDim_;
  
    ArrayRCP<Scalar> createContiguousCopy(const ArrayView<const int> &cols) const;
    
  };
  
  // Non-member constructor
  template<class Scalar>
  RCP<DefaultSpmdMultiVector<Scalar> >
  defaultSpmdMultiVector(
    const RCP<const SpmdVectorSpaceBase<Scalar> > &spmdRangeSpace,
    const RCP<const ScalarProdVectorSpaceBase<Scalar> > &domainSpace,
    const ArrayRCP<Scalar> &localValues,
    const Ordinal leadingDim = -1
    )
  {
    return Teuchos::rcp(
       new DefaultSpmdMultiVector<Scalar>(
        spmdRangeSpace, domainSpace, localValues, leadingDim ) );
  }
\end{verbatim}}
\end{listing}


The internal private data-structure for a multi-vector is very simple
as shown in Listing~\ref{listing:DefaultSpmdMultiVector-decl}.  A
standard column-major Fortran-style dense matrix format is used where
all of the data in the local processes is stored in a single
contiguous {}\ttt{ArrayRCP<Scalar>} object.  The number of rows in the
local process is given by {}\ttt{spmdRangeSpace\_->localSubDim()} and
{}\ttt{leadingDim\_} is the stride between columns.

The generalized views returned by the functions
{}\ttt{nonContigSubViewImpl(...)} and
{}\ttt{nonconstNonContigSubViewImpl(...)} are of the type
{}\ttt{MultiVectorBase} which is the upper-most base class for
{}\ttt{DefaultSpmdMultiVector}.  (The concrete types of the views are
actually {}\ttt{DefaultSpmdMultiVector}.) Therefore, this is an
instance where the class types of the parent and view are actually the
same (an interesting example of CLOSURE OF OPERATIONS principle
{}\cite[Chapter 10]{DomainDrivenDesign})!

The implementations of the functions {}\ttt{nonContigSubViewImpl(...)} 
and {}\ttt{nonconstNonContigSubViewImpl(...)} are given in
Listing~\ref{listing:DefaultSpmdMultiVector-subivew-impl}.


{}\begin{listing}: Implementation of {}\ttt{DefaultSpmdMultiVector}
functions {}\ttt{nonContigSubViewImpl(...)} and
{}\ttt{nonconstNonContigSubViewImpl(...)} \\
\label{listing:DefaultSpmdMultiVector-subivew-impl}
{\small\begin{verbatim}
  template<class Scalar>
  RCP<const MultiVectorBase<Scalar> >
  DefaultSpmdMultiVector<Scalar>::nonContigSubViewImpl(
    const ArrayView<const int> &cols ) const
  {
    THYRA_DEBUG_ASSERT_MV_COLS("nonContigSubViewImpl(cols)", cols);
    const int numCols = cols.size();
    const ArrayRCP<Scalar> localValuesView = createContiguousCopy(cols);
    return defaultSpmdMultiVector<Scalar>(
      spmdRangeSpace_,
      createSmallScalarProdVectorSpaceBase<Scalar>(*spmdRangeSpace_, numCols),
      localValuesView );
  }
  

  template<class Scalar>
  RCP<MultiVectorBase<Scalar> >
  DefaultSpmdMultiVector<Scalar>::nonconstNonContigSubViewImpl(
    const ArrayView<const int> &cols )
  {
    THYRA_DEBUG_ASSERT_MV_COLS("nonContigSubViewImpl(cols)", cols);
    const int numCols = cols.size();
    const ArrayRCP<Scalar> localValuesView = createContiguousCopy(cols);
    const Ordinal localSubDim = spmdRangeSpace_->localSubDim();
    RCP<CopyBackSpmdMultiVectorEntries<Scalar> > copyBackView =
      copyBackSpmdMultiVectorEntries<Scalar>(cols, localValuesView.getConst(),
        localSubDim, localValues_.create_weak(), leadingDim_);
    return Teuchos::rcpWithEmbeddedObjPreDestroy(
      new DefaultSpmdMultiVector<Scalar>(
        spmdRangeSpace_,
        createSmallScalarProdVectorSpaceBase<Scalar>(*spmdRangeSpace_, numCols),
        localValuesView),
      copyBackView );
  }
\end{verbatim}}
\end{listing}


The implementation of the sub-view functions in
Listing~\ref{listing:DefaultSpmdMultiVector-subivew-impl} is fairly
simple.  First, the private helper function
{}\ttt{createContiguousCopy(...)}  creates an {}\ttt{ArrayRCP<Scalar>}
object for a contiguous copy of the non-contiguous columns being
requested.  This contiguous copy of data is then given over to create
a new {}\ttt{DefaultSpmdMultiVector} object which represents the view.
The implementation of the function {}\ttt{createContiguousCopy(...)} 
is simple enough and is given in
Listing~\ref{listing:DefaultSpmdMultiVector-createContiguousCopy}.


{}\begin{listing}: Implementation of {}\ttt{DefaultSpmdMultiVector}
function {}\ttt{createContiguousCopy(...)}
\label{listing:DefaultSpmdMultiVector-createContiguousCopy}
{\small\begin{verbatim}
  template<class Scalar>
  ArrayRCP<Scalar>
  DefaultSpmdMultiVector<Scalar>::createContiguousCopy(
    const ArrayView<const int> &cols ) const
  {
    typedef typename ArrayRCP<Scalar>::const_iterator const_itr_t;
    typedef typename ArrayRCP<Scalar>::iterator itr_t;
    const int numCols = cols.size();
    const Ordinal localSubDim = spmdRangeSpace_->localSubDim();
    ArrayRCP<Scalar> localValuesView = Teuchos::arcp<Scalar>(numCols*localSubDim);
    // Copy to contiguous storage column by column
    const const_itr_t lv = localValues_.begin();
    const itr_t lvv = localValuesView.begin();
    for (int k = 0; k < numCols; ++k) {
      const int col_k = cols[k];
      const const_itr_t lv_k = lv + leadingDim_*col_k;
      const itr_t lvv_k = lvv + localSubDim*k;
      std::copy(lv_k, lv_k+localSubDim, lvv_k);
    }
    return localValuesView;
  }
\end{verbatim}}
\end{listing}


Note how iterators are used to perform the raw data copy in
Listing~\ref{listing:DefaultSpmdMultiVector-createContiguousCopy}.
This results in very well checked code in a debug-mode build (see
Section~\ref{sec:debug-mode-runtime-checking}) but very high
performance code in a non-debug optimized build (see
Section~\ref{sec:optimized-performance}).

Note that the key difference between the implementation of the
functions {}\ttt{nonContigSubViewImpl(...)} and
{}\ttt{nonconstNonContigSubViewImpl(...)} in
Listing~\ref{listing:DefaultSpmdMultiVector-subivew-impl} is that
{}\ttt{nonconstNonContigSubViewImpl(...)} creates an {}\ttt{RCP} to an
object of type {}\ttt{CopyBackSpmdMultiVectorEntries} and attaches it
to the created {}\ttt{RCP<DefaultSpmdMultiVector<Scalar> > } object as
an embedded object (see Section~\ref{sec:embedded-objecs}).  The
destructor for {}\ttt{CopyBackSpmdMultiVectorEntries} performs the
copy-back of the non-const view after the last {}\ttt{RCP} to the view
is destroyed.  The implementation of the class
{}\ttt{CopyBackSpmdMultiVectorEntries} is given in
Listing~\ref{listing:CopyBackSpmdMultiVectorEntries}.


{}\begin{listing}: Implementation of the class
{}\ttt{CopyBackSpmdMultiVectorEntries}
\label{listing:CopyBackSpmdMultiVectorEntries}
{\small\begin{verbatim}
  template<class Scalar>
  class CopyBackSpmdMultiVectorEntries {
  public:
    CopyBackSpmdMultiVectorEntries(
      const ArrayView<const int> &cols,
      const ArrayRCP<const Scalar> &localValuesView, const Ordinal localSubDim,
      const ArrayRCP<Scalar> &localValues, const Ordinal leadingDim
      )
      : cols_(cols), localValuesView_(localValuesView), localSubDim_(localSubDim),
        localValues_(localValues), leadingDim_(leadingDim)
      {}
    ~CopyBackSpmdMultiVectorEntries()
      {
        typedef typename ArrayRCP<const Scalar>::const_iterator const_itr_t;
        typedef typename ArrayRCP<Scalar>::iterator itr_t;
        // Copy from contiguous storage column by column
        if (localValues_.strong_count()) {
          const int numCols = cols_.size();
          const const_itr_t lvv = localValuesView_.begin();
          const itr_t lv = localValues_.begin();
          for (int k = 0; k < numCols; ++k) {
            const int col_k = cols_[k];
            const const_itr_t lvv_k = lvv + localSubDim_*k;
            const itr_t lv_k = lv + leadingDim_*col_k;
            std::copy( lvv_k, lvv_k + localSubDim_, lv_k );
          }
        }
      }
  private:
    Array<int> cols_;
    ArrayRCP<const Scalar> localValuesView_;
    Ordinal localSubDim_;
    ArrayRCP<Scalar> localValues_;
    Ordinal leadingDim_;
  };


  // Non-member constructor  
  template<class Scalar>
  RCP<CopyBackSpmdMultiVectorEntries<Scalar> >
  copyBackSpmdMultiVectorEntries(
    const ArrayView<const int> &cols,
    const ArrayRCP<const Scalar> &localValuesView, const Ordinal localSubDim,
    const ArrayRCP<Scalar> &localValues, const Ordinal leadingDim
    )
  {
    return Teuchos::rcp(
      new CopyBackSpmdMultiVectorEntries<Scalar>(
        cols, localValuesView, localSubDim, localValues, leadingDim));
  }
\end{verbatim}}
\end{listing}


The implementation of {}\ttt{CopyBackSpmdMultiVectorEntries} in
Listing~\ref{listing:CopyBackSpmdMultiVectorEntries} is
straightforward.  When the destructor is called, it copies the data in
the non-const view back to the native storage of the parent
{}\ttt{DefaultSpmdMultiVector} object.

The only twist in the implementation of
{}\ttt{nonconstNonContigSubViewImpl(...)} and
{}\ttt{CopyBackSpmdMultiVectorEntries} is that a weak {}\ttt{ArrayRCP}
is used for the parent's {}\ttt{localValues\_} data in the
{}\ttt{CopyBackSpmdMultiVectorEntries} object.  It is created in the
function {}\ttt{nonconstNonContigSubViewImpl(...)} with
{}\ttt{localValues\_.create\_weak()}.  If the parent goes away before
the view, then the weak pointer {}\ttt{localValues\_} in the
destructor for {}\ttt{CopyBackSpmdMultiVectorEntries} will have a
strong count of 0, thereby resulting in the skipping of the copy-back
of data.  This this a performance optimization since there is no point
in copying back the data if the parent object is gone.  This design
allows both const and non-const multi-vector views to be persisting
(past the lifetime of the parent) and still have the highest
performance.

% ToDo: Write a Teuchos utility class to implement the guts of the
% debug-mode runtime checking needed to enforce the semantics of the
% generalized view design pattern.  Use this utility class in a mock Teuchos
% object and in the Thyra::DefaultSpmdMultiVector class.

There are several things that are interesting about this example.
First, by using the embedded object feature of {}\ttt{RCP}, the code
is able to implement the copy-back-to-parent functionality without
having to write a new {}\ttt{MultiVector} subclass just for the view.
The {}\ttt{DefaultSpmdMultiVector} objects that are returned as views
have no idea they are being used as views into other
{}\ttt{DefaultSpmdMultiVector} objects.  Without the embedded object
feature described in Section~\ref{sec:embedded-objecs}, a different
{}\ttt{MultiVector} subclass would have to be created with a
destructor that would copy back the data.  Second, the constraints
imposed by the generalized view design pattern shown in
Figure~\ref{fig:GeneralizedViewStateDiagram} ensure that no problems
will arise due to the fact that the views are stored in detached
copies of the data.  If changes to the parent
{}\ttt{DefaultSpmdMultiVector} were allowed while a non-const
{}\ttt{DefaultSpmdMultiVector} view was active, then all of the
changes in the parent would be overwritten when the
{}\ttt{DefaultSpmdMultiVector} view was destroyed.  Third, this
example demonstrates why const views are fundamentally more efficient
than non-const views.  In the case of a const view, the temporary
contiguous copy of data is just released and does not need to be
copied back to the parent.  This saves the work imposed by the
destructor on the {}\ttt{CopyBackSpmdMultiVectorEntries} object.


%
{}\subsubsection*{Summary of the generalized view design pattern}
%

In summary, the main properties and features of the generalized view
design pattern are:

\begin{itemize}

{}\item Generalized views allow for complete abstraction,
encapsulation, and the highest performance in all cases.  This is
simply not possible to achieve with direct views.

{}\item Non-const generalized views are only guaranteed to update the
state of the parent after the view object has been released.

{}\item A single parent object can provide more than one type of
generalized view and views can be applied separately to different
logically distinct parts of the parent object (e.g.\ views to the rows
or columns of an abstract matrix object can be created and handled
separately).

{}\item It is important to differentiate between non-const views and
const views.  While detached non-const views must be copied back to
parent when the view is released, const views do not (therefore
improving the performance of const views).

{}\item It is critical that {}\ttt{RCP} objects be used to wrap the
created view objects in order to allow the views to be dynamically
allocated and to allow for specialized copy-back behavior when
non-const views are destroyed.

{}\item The flexibility and performance gains allowed by the
generalized view design pattern come at the expense of more restricted
usage patterns of the parent and view objects.

  \begin{itemize}

  {}\item Only one non-const view can be active for any logically
  district part of the parent object at any one time and the parent
  object (or at least any functionality that relates to the viewed
  part) must be locked down while a non-const view is active.

  {}\item Multiple const views can be active for any logically
  district part of the parent object at any one time but the non-const
  interface of the parent object (at least any non-const functionality
  that relates to that viewed part) must be locked down while any
  const views are active.

  \end{itemize}

\end{itemize}


%
{}\subsection{Comparison with other class libraries and the standard
C++ library}
\label{sec:comparison_with_other_libs}
%

Comparisons between the Teuchos memory management classes and other
classes in Boost and the standard C++ library have been made
throughout this document.  Here, these comparisons are summarized and
extended.  Comparisons with Boost classes are for version 1.40.

The Teuchos class {}\ttt{RCP} is almost identical in most respects to
the {}\ttt{boost::shared\_ptr} class and therefore also the
{}\ttt{std::tr1::shared\_ptr} in C++03 and {}\ttt{std::shared\_ptr}
class in C++0x.  The first version of the class {}\ttt{RCP} was
developed back in 1998 under the name
{}\ttt{MemMngPack::ref\_count\_ptr} as part of the development of the
rSQP++ package {}\cite{rSQP++} (now called MOOCHO {}\cite{MOOCHO}).
At that time, there was no general purpose high-quality
reference-counted smart pointer class available and many compilers at
the time (e.g.\ MSVC++ 6.0) could not even support template member
functions needed for implicit smart-pointer conversions.  After 1998,
the first {}\ttt{boost::shared\_ptr} class appeared (which did not
allow a customized deallocation policy and was therefore not very
flexible).  Over the years, the two classes independently evolved in
very similar ways.  The current version of {}\ttt{boost::shared\_ptr}
is a high-quality flexible reference-counted smart pointer class.
Because it now supports custom template deallocator policy objects
(which are called ``deleters'' in {}\ttt{boost::shared\_ptr}) it
allows for great flexibility in how it is used.

The key advantages of the {}\ttt{RCP} class over the current
{}\ttt{boost::shared\_ptr} class are greater functionality, greater
flexibility, and better debug-mode runtime checking. The few of the
specific key advantages of the {}\ttt{RCP} class that cannot be
replicated with the {}\ttt{boost::shared\_ptr} class without changing
its design include:

\begin{itemize}

{}\item The {}\ttt{RCP} class has built-in support for debug-mode
runtime tracing of reference-counting nodes
(Section~\ref{sec:basic-reference-counting-machinery}) which is used
to implement a whole host runtime checking including the detection and
reporting of a) circular references
(Section~\ref{sec:detection-circular-references}) and b) multiple
owning reference-counted objects
(Section~\ref{sec:detection-dual-owning-rcps}).

{}\item The {}\ttt{RCP} class allows the association and retrieval of
extra data attached to an already-created reference-counting node
object (Section~\ref{sec:extra-data}).

{}\item The {}\ttt{RCP} class allows a client to call
{}\ttt{release()} to remove deletion ownership from an already-created
{}\ttt{RCP} object (the rare need for this is described in
Section~\ref{sec:extra-data}).

{}\item The {}\ttt{RCP} class has built-in support for both strong and
weak reference-counted pointer handles right in the same class (see
Section~\ref{sec:circular-references-weak-pointers}).  The
{}\ttt{boost::shared\_ptr} class uses a separate
{}\ttt{boost::weak\_ptr} class to represent weak references which is
less flexible.  The {}\ttt{RCP} approach allows the debug-mode runtime
detection and reporting of dangling non-owning references while
{}\ttt{boost::shared\_ptr} class cannot when using a null deleter
(Section~\ref{sec:detection-dangling-references}).

\end{itemize}

The key advantages of the current {}\ttt{boost::shared\_ptr} class
over the current {}\ttt{RCP} class are that it has lower storage and
runtime overhead (Section~\ref{sec:reference-counting-overhead}).

Because both the Teuchos {}\ttt{RCP} and {}\ttt{boost::shared\_ptr}
classes support customized deallocation policy objects, one can embed
an {}\ttt{RCP} object in a {}\ttt{boost::shared\_ptr} object and vice
versa.  This is already supported in Teuchos using the overloaded
non-member template helper functions {}\ttt{Teuchos::rcp(const
boost::shared\_ptr<T> \&p)} and {}\ttt{Teuchos::shared\_pointer(const
RCP<T> \&rcp)} (see Table~\ref{tbl:ConversionsTableSingleObjs}).  This
allows the developer to mix and match {}\ttt{RCP} and
{}\ttt{boost::shared\_ptr} objects in the same code and still have
correct memory management.  However, since {}\ttt{RCP} has better
debug-mode runtime checking and is more flexible it should be
preferred to {}\ttt{boost::shared\_ptr} in most high-level code.
Alternatively, because {}\ttt{boost::shared\_ptr} has slightly lower
overhead and is present {}\ttt{std::tr1} it also has valid uses.
Additionally, of course, one may need to convert back and forth
between {}\ttt{RCP} and {}\ttt{boost::shared\_ptr} objects to glue
together different pieces of separately developed code that use
different smart pointer classes.  The class {}\ttt{boost::scoped\_ptr}
is identical to {}\ttt{std::auto\_ptr} but does not allow copying or
assignment and is therefore safer to use in more limited scopes.

Another smart pointer class for single objects is
{}\ttt{std::auto\_ptr}.  This class does not support sharing and has
only the minimal functionality needed to support the Resource
Allocation Is Initialization (RAII) idiom {}\cite[Item
13]{C++CodingStandards05}.  Given that reference-counting overhead is
low compared to raw allocations and deallocations (see
Section~\ref{sec:reference-counting-overhead}) there is little reason
to ever use {}\ttt{std::auto\_ptr} instead of {}\ttt{RCP} (or
{}\ttt{boost::shared\_ptr} for that matter) except for perhaps the
handling of RAII for small objects.

The Teuchos class {}\ttt{Array} is of course equivalent to
{}\ttt{std::vector} by design and uses an {}\ttt{std::vector}
internally.  The main advantages of using {}\ttt{Array} instead of
directly using {}\ttt{std::vector} are a) {}\ttt{Array} has better
debug-mode runtime checking and produces better error messages, b)
conversion to the other Teuchos array types {}\ttt{ArrayView} and
{}\ttt{ArrayRCP} includes full runtime debug-mode detection and
reporting of dangling references (which is not possible with with
{}\ttt{std::vector}), and c) is more consistent with the usage of the
other Teuchos array types.  A major difference between {}\ttt{Array}
and {}\ttt{std::vector} is that {}\ttt{Array} uses an unsigned integer
for its {}\ttt{size\_type} (see Appendix~\ref{sec:unsigned_size_type}
for the justification).

The Teuchos class {}\ttt{ArrayRCP} really has no equivalent class in
Boost or the C++0x standard libraries.  There is a Boost class called
{}\ttt{boost::shared\_array} which uses the {}\ttt{boost::shared\_ptr}
reference-counting machinery and has an overloaded
{}\ttt{operator[](size\_type)} function but his class does not support
iterators (which are critical for safety and performance) and does not
support persisting sub-views (see Section~\ref{sec:array-views}).

The Teuchos compile-time sized array class {}\ttt{Tuple} is more or
less equivalent to the class {}\ttt{boost::array}.  Both contain an
iterator interface and other STL compliant functions.  The key
advantage of {}\ttt{Tuple} is that conversions to the other Teuchos
array types {}\ttt{ArrayView} and {}\ttt{ArrayRCP} support full
runtime debug-mode detection and reporting of dangling references.

Finally, the Teuchos classes {}\ttt{Ptr} and {}\ttt{ArrayView} have no
equivalent in Boost or C++0x.  As described throughout this paper,
these classes are key to creating C++ code that is maximally self
documenting (by distinguishing between persisting and non-persisting
associations), maximally safe in terms of debug-mode runtime checking,
and while at the same time allowing for the highest performance in
non-debug optimized builds.  One cannot plug the remaining holes in
safety and performance without the {}\ttt{Ptr} and {}\ttt{ArrayView}
classes.

What makes the Teuchos memory management classes unique across all
other class libraries is that they form a complete coordinated system
of types to encapsulate all raw C++ pointers in high-level code while
at the same time providing 100\% secure debug-mode checking.  This is
only possible because these classes are developed as a system of types
and the level of debug-mode runtime checking that exists is only
possible because these types have access to each others private
implementation (in some appropriate way).  In general, one cannot mix
and match Boost, standard C++, and Teuchos classes together at the top
level and get safe C++ programs with the full extent of debug-mode
runtime checking that the integrated set of Teuchos classes provide.
Many examples of this have been given through this document.  One
example is that if one creates an {}\ttt{ArrayView} object from a
{}\ttt{std::vector} object it cannot detect a dangling reference (see
Section~\ref{sec:detection-dangling-references}).  However, there are
some specialized cases where Boost and standard C++ types can be used
safely with the Teuchos memory management classes and some of these
cases have already been discussed above (e.g.\ {}\ttt{RCP} and
{}\ttt{boost::shared\_ptr} objects can be embedded in each other and
deep copies of array objects are always safe).


%
{}\subsection{Advice on refactoring existing software}
%

The easiest way to incorporate the full use of the Teuchos memory
management classes is to develop new code and use them from the very
beginning.  In this mode of development, the debug-mode runtime
checking makes development fast and productive with one never seeing a
segfault or other memory usage error that comes from undefined
behavior.  However, the more typical situation is that a large
existing code-base must continue to be developed, current code must be
modified, and new code must integrated with existing code.  For
existing code bases, the code will need to be refactored to use the
Teuchos memory management classes, replacing the use of raw pointers
and raw calls to {}\ttt{new} and {}\ttt{delete} along the way.

While code refactored to use the Teuchos memory management classes
will be of higher quality and more productive to work with during
further development, there will necessarily be a transition period
where the code will be refactored to replace current uses of raw C++
pointers and less-than-safe (or inflexible) memory management
approaches.  It is not recommended that all work on new capabilities
stop and the existing code base be refactored all at once to switch
over to the complete use of the Teuchos memory management classes.
Instead, the code should be refactored to use the Teuchos memory
management classes in small iterative cycles as needed.  The highest
priority code to refactor are the heavily used major module and class
interfaces.  It is these major interfaces where mistakes and memory
usage problems are most likely to be made.  However, rather than break
backward compatibility it is wise to provide the safe versions of the
interface functions but leave the existing unsafe raw-pointer versions
when possible and have them call the new safe versions (by converting
between raw pointers to the memory management types as needed).  This
avoids duplication which simplifies further maintenance and also
provides for smooth upgrades of client code to incrementally switch
over from raw pointers to the Teuchos memory management classes.  The
help facilitate the transition of client code, the deprecated raw
pointer interface functions and other code can be marked as deprecated
on some compilers which generates warning messages while compiling
(e.g.\ GCC's {}\ttt{ \_\_attribute\_\_((\_\_deprecated\_\_))}).

While the most critical code to refactor to use the Teuchos memory
management types are major module and class interfaces, the next most
important software to refactor is any software that needs to be
changed or extended.  Other code is lower priority to refactor,
especially existing well-encapsulated code that uses raw C++ pointers
internally that does not need to be changed to add new features any
time soon.  It is not until such code needs to be changed that it
should be refactored to use the safer memory management types (which
will make adding new features much easier and safer).

While the final state of code refactored to use the Teuchos memory
management types is excellent (as described throughout this document),
great care must be exercised in refactoring the software.  In general,
before any piece of software is refactored to use the Teuchos memory
management types, it should first be covered with high-quality unit
tests (see {}\cite{WorkingEffectivelyWithLegacyCode05} for a great
treatment on how to add unit tests to existing code bases to
facilitate adding new features).  The general process that should be
followed to refactor existing software to use the Teuchos memory
management types includes the following major steps (consistent with
the advice in {}\cite{WorkingEffectivelyWithLegacyCode05}):

\begin{enumerate}

{}\item Break dependencies to allow unit tests to be written

{}\item Add unit tests to cover behavior of the code to be refactored

{}\item Refactor the targeted code incrementally to use the Teuchos
memory management classes (all the while running the unit tests
constantly including using Valgrind and/or Purify to ensure defects
are not being created) by:

  \begin{enumerate}

  {}\item Replacing raw pointers internally with Teuchos memory
  management types until all raw pointers are gone

  {}\item Writing new versions of the interface functions in terms of
  the safer Teuchos memory management types

  {}\item Keeping the existing raw-pointer interface functions which
  are called by the unit tests but have them call the new functions
  that take the safer memory management types

  {}\item Marking the raw-pointer versions of the functions as
  deprecated as so to facilitate refactoring of client code (e.g.\
  using GCC's {}\ttt{ \_\_attribute\_\_((\_\_deprecated\_\_))})

  \end{enumerate}

{}\item After a unit of code is totally refactored to use the new
Teuchos memory management types, the unit test code should be
refactored to call the safe interface functions that don't pass raw
pointers, thereby removing all raw C++ pointers from the unit test
code itself.

{}\item Selectively refactor client code that can conveniently call
the new safe interface functions of the refactored code.  (Caution,
only do this if there are at least some decent system-level regression
tests in place.)  As more and more code is refactored to use the safe
Teuchos memory management types, the easier and safer this type of
refactoring will become.

{}\item Write new unit tests (using test-driven development) and add
the desired new features in the selected code safely and easily

\end{enumerate}

While the incremental refactoring process described above may be slow
and may only refactor small parts of the code in each batch, over
time, more and more of the code base will be refactored to remove raw
C++ pointers and the code will become more and more safe, easier to
work with, and be better self documenting.  Whatever happens, one
should never attempt to refactor a large volume of code in one batch
to use the Teuchos memory management types, even if there are good
unit tests in place.  Refactorings should {}\textit{never} be
attempted in large batches, no matter what
{}\cite{WorkingEffectivelyWithLegacyCode05}.

The above process was followed with great success to refactor the
Trilinos package Thyra~\cite{ThyraOperatorVectorSAND} over a period of
more than a year.  This process can be followed for a code base very
safely and productively if the above incremental unit-testing
refactoring process is followed.


%
{}\section{Miscellaneous topics}
\label{sec:misc-topics}
%

When thinking about memory management in C++ it is helpful to take a
step back and consider a few different higher-level issues.  In the
following section, the issue of essential and accidental complexity is
discussed and what role the Teuchos memory management classes play in
addressing accidental complexity and helping to make implicit concepts
explicit.  Then, the philosophy of memory management is discussed and
some analogies are used to help put things in perspective and provide
a solid foundation for the approach used in the Teuchos memory
management classes as compared to approaches that start with safer
language but arrive at a similar balance between safety, speed, and
flexibility.


%
{}\subsection{Essential and accidental complexity, making implicit
concepts explicit}
\label{sec:essentail-accidental-complexity}
%

While the idioms described in this document (largely outlined in
Section~\ref{sec:idioms}) may appear complex at first sight, one has
to consider that it is not really the idioms that are complex but the
essential attributes of object relationships that are complex.
Frederick Brooks refers to this as {}\textit{essential complexity} as
opposed to {}\textit{accidental complexity}
{}\cite{MythicalManMonth95}.  {}\textit{Accidental complexity} in
programming refers to complexity resulting from complicating details
of the programming language or environment which are not directly
related to solving the problem at hand.  Accidental complexity has
largely been removed as higher level languages have been developed
{}\cite[Chapter 16]{MythicalManMonth95}.  However, raw pointers in C
and C++ and manual resource management (when that is not the main
focus of the program) are definitely a lingering category of
accidental complexity\footnote{
{}\ttt{http://discuss.joelonsoftware.com/default.asp?joel.3.278613.51}}.
Alternatively, {}\textit{essential complexity} exists because of the
nature of the problem at hand that no programming language will ever
be able to fully remove.  (However, one can use object-oriented and
other design approaches to abstract and partition the essential
complexity such that we can write and maintain complex large-scale
programs.)

What the Teuchos Memory Management classes do is that they remove much
of the accidental complexity of using raw pointers and manual resource
management and instead they more directly address the essential
complexity of writing programs in making important concepts of object
relationships explicit that are instead implicit in most languages
(including raw C++).  Dealing with the nature of relationships between
objects is essential complexity and for every relationship between two
classes (for example in a UML class diagram
{}\cite{UMLDistilledThirdEdition04}) one must answer the essential
questions:

\begin{itemize}

{}\item\textit{What is the multiplicity of the relationship?}  (i.e.\
is there just one object or is there more than one object at the other
end of the association?).  In UML class diagrams, a singular
multiplicity relationship is represented using a {}\ttt{1} and
multiplicity greater than one is represented using {}\ttt{1..*} (see
Figure~\ref{fig:TeuchosRCPDesign} for examples).

{}\item\textit{Is the object optional or required?}  In a UML class
diagram, an optional object is represented using {}\ttt{0..1} while a
required object is represented as {}\ttt{1} (see
Figure~\ref{fig:TeuchosRCPDesign} for examples).

{}\item\textit{Is the object changeable or non-changeable?}  In UML
class diagrams, a non-changeable object is given the attribute
{}\ttt{\{readOnly\}}.  In UML, by default, all objects at the end of
an association are assumed changeable.

{}\item\textit{Is the association persisting or non-persisting?}  In a
UML class diagram, non-persisting associations are referred to as
``dependency associations'' and are represented with a dotted line
(and can also be given the keyword {}\ttt{$\ll$parameter$\gg$}).
Persisting associations are referred to as ``relationships'' and are
represented as solid lines (see Figure~\ref{fig:TeuchosRCPDesign} for
examples).

\end{itemize}

Note that while UML is an expressive language that allows one to
explicitly represent the above essential information, most programming
languages cannot (at least not the raw language).  Consider that in
Java and Python that it is impossible to distinguish between
persisting and non-persisting associations because every user-defined
object is always managed through an indirect reference handed by the
garbage-collected language.  This causes big problems when it comes
time to try to understand a complex program written in these
languages.  For example, consider the agony that Micheal Feathers goes
through in many refactorings described in
{}\cite{WorkingEffectivelyWithLegacyCode05} in trying to determine the
nature of objects as to whether they are actually embedded in each
other (i.e.\ persisting) or are just passed to each other (i.e.\
non-persisting).  Python has no user-definable concept of
{}\ttt{const} but the Python language itself understands the need for
{}\ttt{const} by having built-in immutable data-types like strings and
tuples.

One of the goals of the idioms defined in this paper is to change the
above essential complexities from implicit concepts to explicit
concepts directly stated in code (see ``Making Implicit Concepts
Explicit'' in {}\cite[Chapter 9]{DomainDrivenDesign}).  The essential
attributes of object relationships (i.e.\ multiplicity, persistent
vs.\ non-persistent, changeable vs.\ non-changeable) are present in
every program no mater what high-level programming language is used
{}\cite{MythicalManMonth95, CodeComplete2nd04,
WorkingEffectivelyWithLegacyCode05}.  The issue is that most
executable languages (not withstanding executable XML {}\cite[Chapter
1]{UMLDistilledThirdEdition04}) lack the expressiveness to make these
concepts explicit.  The Teuchos memory management classes and the
associated idioms described in this paper provide a means to make many
of these essential concepts explicit in C++ in a way that is not
possible in any other widely used programming language.

While the Teuchos memory management classes go a long way in removing
some of the accidental complexity of programing in C++ due to manual
memory management, some of the types of remaining accidental
complexity (among many others not mentioned) include:

\begin{itemize}

{}\item\textit{Value semantics versus reference semantics}: The
distinction between value semantics versus reference semantics is a
C++ concept that does not directly relate to solving a problem or
representing a model in code and is therefore accidental complexity.
In Java and Python, all user-defined types use reference semantics but
in C++ programmers can take advantage of value-types which gives more
efficient code and more control in C++ than what is possible in these
other languages.  However, this extra control could be classified as
accidental complexity (which we tolerate for the sake of added control
and improved performance).

{}\item\textit{Pointer syntax for memory management types {}\ttt{Ptr},
and {}\ttt{RCP}}: In order to access the underlying object through the
smart pointer types {}\ttt{Ptr} and {}\ttt{RCP}, one has to use
pointer syntax using {}\ttt{func(*a)} and {}\ttt{a->someMember()}.
The C++ language makes it impossible to define abstract data types
that allow direct access to the underlying object (i.e. using
{}\ttt{func(a)} and {}\ttt{a.someMember()}) like raw C++ references
allow.  Pointer syntax is not essential to the nature of problem
solving (as proven by all the languages that don't have pointers
including Java and Python) and therefore pointer syntax must be
categorized as accidental complexity.  Note, however, that the types
{}\ttt{ArrayView} and {}\ttt{ArrayRCP} were not listed in this
category because one can use these array classes using just the
{}\ttt{operator[](size\_type)} function and one does not need to use
pointer syntax.  In fact, {}\ttt{ArrayView} does not even support any
pointer-like functions and the pointer-like functions on
{}\ttt{ArrayRCP} are only really there to allow it to be used as a
general-purpose checked iterator in a debug-mode build.  While pointer
syntax is not an essential concept they do actually come in handy to
define iterators into containers and present a much more compact
iterator interface that what one will find in other languages.  In
other words, pointers syntax can be considered to be a nice
enhancement when considering iterators.  In most other contexts,
however, we must consider pointer syntax to contribute to accidental
complexity.

\end{itemize}


%
{}\subsection{Philosophy of memory management: Safety, speed,
flexibility and 100\% guarantees}
\label{sec:phylosophy-of-mem-mng}
%

When looking at different strategies for memory management in C++ and
in other languages, it helps to think a little on the philosophical
level which can actually help put the issues involved in perspective.

When looking at the different memory management approaches implemented
in various programming languages, the core issues come down to
trade-offs in safety and correctness versus speed and flexibility.
For example, a language like C sacrifices safety and correctness for
speed and flexibility.  Because C is so ``close'' to the hardware, one
can implement very specialized memory management approaches tailored
to very specific types of domains.  However, the price one pays for
this raw speed and flexibility in C is the fact that there is very
little compiler-supported checking that would otherwise be needed to
assert correct memory usage.

Now take Python on the other extreme.  If one writes code only in
Python, one will almost never experience and memory leak or segfault
of any kind due to code that one directly writes.  Here is a language
which is nearly 100\% safe (assuming the language implementation is
100\% correct) but offers less flexibility in how memory is managed
and results in very slow native code as compared to C in many cases
(e.g.\ for computationally intensive loops).

So how important is a 100\% guarantee that memory will always be used
correctly like is provided in a language like Python?  How important
is a 100\% guarantee in any area?  Well, if one can get a 100\%
guarantee without having to pay a significant price for it then one
would be a fool not to accept it.  For example, if one has a choice
between two vendors selling the same product for the same price but
one vendor will give a 100\% money-back guarantee, with all things
being equal, it would probably be foolish not to go with the vendor
with the 100\% guarantee.

However, in most areas, greater safety (not to mention a 100\%
guarantee) comes with greater costs.  Instead of demanding a 100\%
guarantee, we typically accept some level of extra risk as long as we
have taken basic precautions to protect ourselves.  To demonstrate
this, let's consider another analogy which I like to refer to as the
{}\textit{Transportation Analogy}.  When considering modes of
transportation, we accept that we are not 100\% safe when driving our
cars on the road but we do it anyway.  The reason that we get into our
cars every day is that we take reasonable precautions like purchasing
a car with a good safely design, wearing seat-belts, obeying the
traffic laws, driving a reasonable speed, and practicing defensive
driving.  What is going to be argued here is that the approach to
memory management that is being advocated in this paper is the
equivalent of driving a car, wearing one's seat belt, and taking other
reasonable safety precautions but does not provide a 100\% guarantee.

Now let's talk about the safety versus speed/efficiently extremes in
the Transportation Analogy and in the area of memory management.  At
one extreme, writing all high-level code in C++ (or C) using raw
pointers for everything is like riding a high-performance motorcycle
on a crowded interstate going 150 mph, without wearing a helmet or any
other safety gear, while doing a wheelie.  At this extreme, one wrong
move means certain death.

At the other extreme, writing all code in a language like Python is
like driving around in a reinforced tank that does a maximum of 10 mph
where one sits inside wearing a car racing helmet with the Hans
device, full racing safety gear, and having a massive air bag system
to encase one's entire body in foam three feet thick in case of a
collision.  On this side of extreme safely, we could hit a Mac truck
head on and be just fine.  The only way to really kill one's self
would be to drive off a shear cliff.

If we all required a near 100\% safely guarantee, we would all be
driving around in reinforced tanks like the one described above but we
don't.  We don't because we are not willing to pay the price of the
near 100\% guarantee provided by the tank.  We can't afford it
financially and it would take forever to get back and forth to
work. Instead, we are content with our less than 100\% safe cars
because they are affordable and fast and yet do not pose unreasonable
risks.

Now, we can incrementally go from either extreme to a more balanced
state in both the Transportation Analogy and with memory management in
C++ and Python.

From the extreme of safety with less speed and flexibility represented
by the reinforced tank (and Python) one can incrementally move toward
the middle ground of the car.  One can start by removing the racing
helmet and Hans device, followed by decreasing the weight and
increasing the speed of the tank, and so on.  Continuing on this trend
of sacrificing safety in favor of greater speed and agility leads us
to our typical car.  Likewise, moving from an extreme of safety to a
more reasonable balance between safety and speed/flexibility in Python
involves taking pieces of computationally intensive Python code,
rewriting them in C/C++, and then calling them from Python.  This is
an approach that many Python enthusiasts are advocating
{}\cite{PythonForSCPerforamnce08} but make no mistake that in going
down this road that one is sacrificing safety in Python in the name of
speed and flexibility.  One is giving up Python's near 100\% guarantee
when one does this and will therefore have to deal with difficult and
dangerous memory errors cropping up in the code.

From the extreme of speed and flexibility with little regard for
safety represented by the motorcycle (and C/C++ raw pointers) one can
also incrementally move toward the car.  One can start by putting on a
helmet, followed by slowing down some, and so on.  Continuing on this
trend of adding safety will eventually see one morphing the motorcycle
into the typical car.  Likewise, moving from an extreme of less safety
toward a more reasonable balance between speed/flexibility and safety
in C++ involves adding more and more utility classes to hide more and
more uses of raw C++ pointers in high-level C++ code.  This is the
trend that the C++ community has been following for more than the last
decade.  We see it first in the introduction of {}\ttt{std::auto\_ptr}
and {}\ttt{std::vector}.  This was then followed by the development of
{}\ttt{boost::shared\_ptr} (and therefore {}\ttt{std::shared\_ptr} in
C++0x).  What is being suggested in this paper is the logical
conclusion of this journey which is the development of a complete set
of utility classes in order to remove all raw C++ pointers from
high-level C++ code; i.e.\ complete the transition from the motorcycle
(C/C++ raw pointers) to the car (Teuchos C++ memory management
classes).

With the approach being advocated in this paper, using the Teuchos
memory management classes in debug-mode is like driving around in the
tank where one is protected from almost any danger.  However, using
the Teuchos memory management classes in non-debug optimized builds is
like driving around with the fast high-performance motorcycle.  Try
turning a tank into a motorcycle and then back again that easily!


%
{}\section{Conclusions}
\label{sec:conclusions}
%

Using the Teuchos reference-counted memory management classes allows
one to remove unnecessary constraints in the use of objects by
removing arbitrary lifetime ordering constraints which are a type of
unnecessary coupling {}\cite{CodeComplete2nd04}.  The code one writes
with these classes will be more likely to be correct on first writing,
will be less likely to contain silent (but deadly) memory usage
errors, and will be much more robust to later refactoring and
maintenance.

The level of debug-mode runtime checking provided by the Teuchos
memory management classes is stronger in many respects than what is
provided by memory checking tools like Valgrind and Purify while being
much less expensive.  However, tools like Valgrind and Purify perform
a number of types of checks (like usage of uninitialized memory) that
makes these tools very valuable and therefore complement the Teuchos
memory management debug-mode runtime checking.

The Teuchos memory management classes and idioms largely address the
technical issues in resolving the fragile built-in C++ memory
management model (with the exception of circular references which has
no easy solution but can be managed as discussed).  All that remains
is to teach these classes and idioms and expand their usage in C++
codes.  The long-term viability of C++ as a usable and productive
language depends on it.  Otherwise, if C++ is no safer than C, then is
the greater complexity of C++ worth what one gets as extra features?
Given that C is smaller and easier to learn than C++ and since most
programmers don't know object-orientation (or templates or X, Y, and Z
features of C++) all that well anyway, then what really are most
programmers getting extra out of C++ that would outweigh the extra
complexity of C++ over C?  C++ zealots will argue this point but the
reality is that C++ popularity has peaked and is becoming less popular
while the popularity of C has remained fairly stable over the last
decade\footnote{See the Tiobe index of programming language popularity
at {}\ttt{http://www.tiobe.com}.}.  Idioms like are advocated in this
paper can help to avert this trend but it will require wide community
buy-in and a change in the way C++ is taught in order to have the
greatest impact.

To make these programs more secure, compiler vendors or static
analysis tools (e.g.\
klocwork\footnote{\ttt{http://www.klocwork.com}}) could implement a
preprocessor-like language similar to
OpenMP\footnote{{}\ttt{http://openmp.org}} that would allow the
programmer to declare (in comments) that certain blocks of code should
be ``pointer-free'' or allow smaller blocks to be ``pointers
allowed''.  This would significantly improve the robustness of code
that uses the memory management classes described here.



% ---------------------------------------------------------------------- %
% References
%

\clearpage
% If hyperref is included, then \phantomsection is already defined.
% If not, we need to define it.
\providecommand*{\phantomsection}{}
\phantomsection
\addcontentsline{toc}{section}{References}
\bibliographystyle{plain}
\bibliography{references}

% ---------------------------------------------------------------------- %
% Appendices should be stand-alone for SAND reports. If there is only
% one appendix, put \setcounter{secnumdepth}{0} after \appendix
%
\appendix


\input{apdx_TeuchosMemMngSummary.tex}


%
{}\section{Commandments for the use of the Teuchos memory management
classes}
\label{apdx:commandments}
%

Here are stated commandments (i.e.\ very strongly recommended
guidelines) that if followed, along with the idioms defined in
Section~\ref{sec:idioms}, then client code will be nearly 100\% safe
through debug-mode runtime checking and will almost never result in
undefined behavior (e.g.\ segfaults) or a memory leak (except for
circular references as described in
Section~\ref{sec:detection-circular-references}).  While there will be
situations where it is justified to violate almost any of these
commandments, they should be valid in 99\% of a well written code
base.

\begin{commandment}
Thou shall not expose raw pointers in any high-level C++ code.
\end{commandment}

{}\textit{Exception:} Only expose raw pointers when interfacing with
non-compliant code or momentarily in order to construct a Teuchos
memory management class object.  However, these cases should be
encapsulated as low-level code.

\begin{commandment}
Thou shall only use raw C++ references for non-persisting associations
(see Sections~\ref{sec:nonpersisting-persisting-associations}
and~\ref{sec:raw-C++-references}).
\end{commandment}

\begin{commandment}
Thou shall use {}\ttt{RCP} for handling single objects for all
persisting associations (see
Section~\ref{sec:nonpersisting-persisting-associations}).
\end{commandment}

\begin{commandment}\label{cmnd:rcp-new}
Thou shall put a pointer for an object allocated with operator
{}\texttt{new} into a strong owning {}\texttt{RCP} whenever possible
by directly calling {}\ttt{new} right in the constructor for the
{}\ttt{RCP} object itself or construct from {}\ttt{rcp(...)}.
\end{commandment}

\begin{commandment}\label{cmnd:owning-rcp-first}
When wrapping an object inside of an {}\ttt{RCP}, thou shall create a
strong owning {}\ttt{RCP} object first before any non-owning
{}\ttt{RCP} objects (see Sections~\ref{sec:detection-dual-owning-rcps}
and~\ref{sec:self-references}).
\end{commandment}

{}\textit{Justification:} In order for the reference-counting
machinery to detect dangling non-owning references in a debug-mode
build, the first {}\ttt{RCP} object created must have ownership to
delete.  The system cannot detect dangling references from non-owning
{}\ttt{RCPNode} objects created before an owning {}\ttt{RCPNode}
object is created.

\begin{commandment}\label{cmnd:ptr-semi-persisting}
Thou shall use {}\ttt{Ptr} for handling single objects for all
semi-persisting associations (see
Section~\ref{sec:nonpersisting-persisting-associations}).
\end{commandment}

{}\textit{Justification:} When performance constraints do not allow
for the reference-counting overhead of {}\ttt{RCP}, then {}\ttt{Ptr}
can be used instead to form a semi-persisting association (which
should be accompanied with the appropriate documentation about the
performance optimization).  One should never have to retreat back to
using a raw pointer in these cases.  At least with {}\ttt{Ptr},
invalid usage will be checked for in a debug build so one does not
loose any debug-mode runtime checking when using {}\ttt{Ptr} instead
of {}\ttt{RCP} if one really does not need reference-counting
machinery.

\begin{commandment}
Thou shall use {}\ttt{ArrayRCP} for handling all contiguous arrays of
objects for all persisting associations where the array does not need
to be incrementally resized while sharing the array (see
Sections~\ref{sec:nonpersisting-persisting-associations}
and~\ref{sec:general-array-idioms}).
\end{commandment}

\begin{commandment}\label{cmnd:arrayview-semi-persisting}
Thou shall use {}\ttt{ArrayView} for handling contiguous arrays of
objects for all semi-persisting associations (see
Sections~\ref{sec:nonpersisting-persisting-associations}
and~\ref{sec:perf-tuning-strategies}).
\end{commandment}

{}\textit{Justification:} When performance constraints do not allow
for the reference-counting overhead of {}\ttt{ArrayRCP}, then
{}\ttt{ArrayView} can be used instead to form a semi-persisting
association (which should be accompanied with the appropriate
documentation about the performance optimization).  One should never
have to retreat back to using a raw pointer in these cases.  At least
with {}\ttt{ArrayView}, invalid usage will be checked for in a debug
build so one does not loose any debug-mode runtime checking when using
{}\ttt{ArrayView} instead of {}\ttt{ArrayRCP} if one really does not
need reference-counting machinery.

\begin{commandment}
Thou shall not call raw {}\ttt{new} or {}\ttt{delete} in any
high-level C++ code to dynamically allocate and destroy single
objects.  Instead, create memory using a user-defined non-member
constructor function (see Section~\ref{sec:nonmember-constructor-idiom}).
\end{commandment}

{}\textit{Exception}: Calling raw {}\ttt{new} in okay when an
appropriate non-member constructor is missing.  In general, value-type
classes (e.g.\ {}\ttt{std::vector}) will not have non-member
constructor functions that return {}\ttt{RCP}-wrapped objects.

\begin{commandment}
Thou shall not call raw operator {}\ttt{new []} or {}\ttt{delete []}
in any high-level C++ code to dynamically allocate and destroy
contiguous arrays of data.  Instead, use functions such as
{}\ttt{Teuchos::Array<T>(n)} and {}\ttt{Teuchos::arcp<T>(n)} to
dynamically allocate arrays.
\end{commandment}

\begin{commandment}
Thou shall not directly create and use compile-time fixed sized arrays
with {}\ttt{T[N]}.  Instead, create compile-time fixed-sized arrays
using {}\ttt{Teuchos::Tuple<T,N>} and convert to
{}\ttt{Teuchos::ArrayView<T>} for more general usage.
\end{commandment}

\begin{commandment}
Thou shall use {}\ttt{Teuchos::Array} as a general purpose contiguous
container instead of {}\ttt{std::vector} in order maximize debug-mode
runtime checking (see Sections~\ref{sec:Array}
and~\ref{sec:detection-dangling-references}).
\end{commandment}

\begin{commandment}
Thou shall only convert or cast between different memory management
objects (of the same or different types) using the provided implicit
and explicit conversion functions (see Section~\ref{sec:conversions}).
Thou shall never expose a raw C++ pointer to perform a conversion.
\end{commandment}

{}\textit{Exception}: Some very advanced and rare use cases might have
one exposing a raw C++ pointer (see
Section~\ref{sec:inverting-obj-ownership} for the only example
described in this paper).

\begin{commandment}
Thou shall only pass in the types {}\ttt{Ptr},
{}\ttt{RCP}, {}\ttt{ArrayView}, and
{}\ttt{ArrayRCP} by constant reference (e.g.\
{}\ttt{const RCP<T> \&a}) and never by non-const reference (e.g.\
never do {}\ttt{RCP<T> \&a}).
\end{commandment}

{}\textit{Exception}: The only time one should ever pass in a
non-const reference to one of these types (e.g.\ {}\ttt{RCP<T>
\&a}) is when the function will modify what data the object points to.
However, if this is the case, it is typically better and more clear to
pass in the object through a {}\ttt{Ptr} object (e.g.\
{}\ttt{const Ptr<RCP<T> > \&a}) using the {}\ttt{outArg(...)} function
(see Section~\ref{sec:vars-passing-single-objs}).

\begin{commandment}
Thou shall only reutrn objects of type {}\ttt{Ptr}, {}\ttt{RCP},
{}\ttt{ArrayView}, and {}\ttt{ArrayRCP} from a function by value and
not a constant reference (see
Section~\ref{sec:idioms-returning-objects}).
\end{commandment}

{}\textit{Exception}: Returning one of these types by non-const
reference makes sense when using the local static variable
initialization trick described in {}\cite[Item
4]{EffectiveC++ThirdEdition}.  However, returning one of these types
by const reference would almost never be justified.


%
{}\section{Argument for using a signed integer for
{}\ttt{size\_type} in the Teuchos array classes}
\label{sec:unsigned_size_type}
%

The Teuchos array memory management classes {}\ttt{Array},
{}\ttt{ArrayRCP}, and {}\ttt{ArrayView} all use a signed integer for
{}\ttt{size\_type} ({}\ttt{ptrdiff\_t} by default).  This breaks from
the C++ standard library convention of the standard containers like
{}\ttt{std::vector} that all use an unsigned integer for
{}\ttt{size\_type} (which is {}\ttt{size\_t} in most implementations).
The primary disadvantage for using an unsigned integral type is that
subtractions that would normally produce a negative number instead
roll over into a huge positive number, making it more difficult to
debug problems.  For example, consider the simple program shown in
Listing~\ref{listing:unsigned-int-problem}:


{}\begin{listing}: Example program showing the problem with unsigned
integral types
\label{listing:unsigned-int-problem}
{\small\begin{verbatim}
  #include <iostream>
  #include <string>
  
  typedef unsigned long int size_type ;
  
  void print_val(const std::string &valName, const size_type val)
  { std::cout << valName << " = " << val << "\n";}
  
  int main()
  {
    const size_type a = 5, b = 7;
    const size_type c = b - a;
    const size_type d = a - b;
    print_val("a", a);
    print_val("b", b);
    print_val("b - a", c);
    print_val("a - b", d);
    return 0;
  }
\end{verbatim}}
\end{listing}


When the above program is compiled with GCC 3.4.6 on a 64 bit Linux
machine and run it produces the output:


{\small\begin{verbatim}
  a = 5
  b = 7
  b - a = 2
  a - b = 18446744073709551614
\end{verbatim}}


In the above program, the subtraction of {}\ttt{a - b} is a
programming error but that error results in the number
{}\ttt{18446744073709551614} when using an unsigned type.  Getting a
number like {}\ttt{18446744073709551614} in program output or in the
debugger does not exactly give a great hint as to what the problem
might be.  Was uninitialized memory used to produce this result?  Is
there some other memory usage problem that would cause the program to
produce a ridiculous result such as this?  It is problems like this
that greatly contribute to the accidental complexity that is inherent
in C/C++ programing (see Section~\ref{sec:essentail-accidental-complexity}).

However, when {}\ttt{unsigned long int} is replaced with {}\ttt{long
int} in Listing~\ref{listing:unsigned-int-problem} and the code is
rebuilt and run one gets:


{\small\begin{verbatim}
  a = 5
  b = 7
  b - a = 2
  a - b = -2
\end{verbatim}}


Now, getting output like {}\ttt{-2} when a positive number is expected
is much easier to debug.  The chance of getting {}\ttt{-2} as the
result of a memory usage error is very unlikely.  This would
immediately be flagged as a subtraction error in the program and
quickly tracked down and fixed.  Therefore, from a program correctness
and debugging perspective, signed integral types are far superior to
unsigned types.

So if programs with unsigned integers are harder to debug when things
go wrong, then what are the advantages of using an unsigned type?
Well, some might argue that using an unsigned type for integral
objects that that can only be non-negative in valid programs helps to
make the code self documenting.  This is partially true but one can
achieve the same result by using a typedef to make the usage
expectation clear (e.g.\ {}\ttt{size\_type}).

So what then is left as the real advantage for using an unsigned
integral type?  The only real advantage of an unsigned integral type
(e.g.\ {}\ttt{unsigned int}) over a signed integral type (e.g.\
{}\ttt{int}) is that unsigned integral type objects can represent
twice the positive range as the equivalent signed integral type
objects.  For smaller integral types like {}\ttt{char} and and
{}\ttt{short int}, having twice the range can be quite useful.
However, on 32 bit and 64 bit modern computers, using an
{}\ttt{unsigned [long] int} instead of a {}\ttt{[long] int} as the
size for a container is quite worthless.  On a 64 bit Linux machine
with GCC 3.4.6, the sizes of several integral types pertinent to this
discussion are shown in Listing~\ref{listing:integral-type-sizes}.


{}\begin{listing}: Sizes and ranges of some common integral types of
GCC on a 64 bit Linux machine
\label{listing:integral-type-sizes}
{\small\begin{verbatim}
  sizeof(int) = 4
  std::numeric_limits<int>::min()= -2147483648
  std::numeric_limits<int>::max()= 2147483647
  std::log10(std::numeric_limits<int>::max())= 9.33193
  
  sizeof(unsigned int) = 4
  std::numeric_limits<unsigned int>::min()= 0
  std::numeric_limits<unsigned int>::max()= 4294967295
  std::log10(std::numeric_limits<unsigned int>::max())= 9.63296
  
  sizeof(long int) = 8
  std::numeric_limits<long int>::min()= -9223372036854775808
  std::numeric_limits<long int>::max()= 9223372036854775807
  std::log10(std::numeric_limits<long int>::max())= 18.9649
  
  sizeof(unsigned long int) = 8
  std::numeric_limits<unsigned long int>::min()= 0
  std::numeric_limits<unsigned long int>::max()= 18446744073709551615
  std::log10(std::numeric_limits<unsigned long int>::max())= 19.2659
  
  sizeof(size_t) = 8
  std::numeric_limits<size_t>::min()= 0
  std::numeric_limits<size_t>::max()= 18446744073709551615
  std::log10(std::numeric_limits<size_t>::max())= 19.2659
  
  sizeof(ptrdiff_t) = 8
  std::numeric_limits<ptrdiff_t>::min()= -9223372036854775808
  std::numeric_limits<ptrdiff_t>::max()= 9223372036854775807
  std::log10(std::numeric_limits<ptrdiff_t>::max())= 18.9649
\end{verbatim}}
\end{listing}


On a 32 bit machine, {}\ttt{size\_t} is a 4 bit {}\ttt{unsigned int}
and {}\ttt{ptrdiff\_t} is a 4 bit {}\ttt{int}.  The standard C library
typedef {}\ttt{size\_t} is guaranteed to be the largest possible
object size returned from {}\ttt{sizeof(...)} and is also used for
functions like {}\ttt{malloc(...)}.  The standard C library typedef
{}\ttt{ptrdiff\_t} is supposed to be guaranteed to hold the difference
between the subtraction of any two pointers in the largest allocatable
array.  Right here lies the first problem with this approach as shown
in the simple program in
Listing~\ref{listing:size_t-ptrdiff_t-incompatibility}.


{}\begin{listing}: Simple program showing the fundamental
incompatibility of {}\ttt{size\_t} and {}\ttt{ptrdiff\_t}.
\label{listing:size_t-ptrdiff_t-incompatibility}
{\small\begin{verbatim}
  #include <iostream> 
  #include <string> 
  #include <limits> 
   
  template<typename T> 
  void print_val(const std::string &valName, const T val) 
  { std::cout << valName << " = " << val << "\n";} 
   
  int main() 
  { 
    const size_t maxSize = std::numeric_limits<size_t>::max(); 
    const size_t size = static_cast<size_t>(0.75 * maxSize); 
    char *a = new char[size]; 
    ptrdiff_t a_diff = (a+size) - a; 
    print_val("maxSize", maxSize); 
    print_val("size", size); 
    print_val("a+size - a", a_diff); 
    delete a;
    return 0; 
  }
\end{verbatim}}
\end{listing}


The program in Listing~\ref{listing:size_t-ptrdiff_t-incompatibility}
allocates a {}\ttt{char} array 75\% the size of the maximum allowed by
{}\ttt{size\_t}.  In this program, {}\ttt{size} is 50\% larger than
the largest value that can be represented by the signed type
{}\ttt{ptrdiff\_t} (which is the type as {}\ttt{int} in this case).
When this program is compiled with GCC 3.4.6 in 32 bit mode (i.e.\
with {}\ttt{-m32}) and run it produces the following output:

{\small\begin{verbatim}
  maxSize = 4294967295
  size = 3221225471
  a+size - a = -1073741825
\end{verbatim}}

The value of {}\ttt{ptr2 - ptr1 = -1073741825} where {}\ttt{ptr1 = a}
and {}\ttt{ptr2 = a+size} is totally wrong.  What this output suggests
is that {}\ttt{ptr2 = a+size} is {}\ttt{1073741825} elements
{}\underline{in front of} {}\ttt{ptr1 = a} which is completely wrong
when in actuality {}\ttt{ptr2 = a+size} is {}\ttt{size = 3221225471}
elements {}\underline{after} {}\ttt{ptr1 = a}.  What this 32 bit
output confirms is that it false to claim that {}\ttt{ptrdiff\_t} can
store the difference between any two pointers in a single array of
data.  Perhaps that was true on the machines when C was first
developed the early 1970's but it is not true today where machines
with 4+ GB of memory are common.

Now consider practical usage of types like {}\ttt{std::vector} on
modern machines.  First, consider what it would mean to allocate the
largest {}\ttt{std::vector} of even {}\ttt{char}s.  A {}\ttt{char} is
1 byte so on a 32 bit machine, an {}\ttt{std::vector<char>} of max
size would have {}\ttt{4294967295} bytes = 4.3 GB of memory.  That
would exhaust all of the memory of a 4 GB machine and more.  Being
limited to only half the range of {}\ttt{size\_t} (which is the
positive range representable by {}\ttt{ptrdiff\_t}) would give an
{}\ttt{std::vector<char>} that takes up 2.3 GB of memory.  No real 32
bit program is ever going to allocate a single {}\ttt{std::vector} of
{}\ttt{char}s that takes up more than half of the addressable memory
of the entire machine!  It is hard to imagine what useful task such a
program would perform.

When one moves up to an {}\ttt{std::vector<int>} for a 32 bit (4 byte)
{}\ttt{int} the maximum size of array that one can create is
{}\ttt{4294967295 * 4 / 1e+9} = 17.2 GB.  Being limited to the
{}\ttt{unsigned int} type {}\ttt{ptrdiff\_t} would limit one to an
{}\ttt{std::vector<int>} of size 8.6 GB which is already twice the
addressable memory of a 32 bit system.

Therefore, even on a 32 bit machine, limiting the maximum size of
{}\ttt{std::vector} objects to have only
{}\ttt{std::numeric\_limits<ptrdiff\_t)>::max()} = $2.3\times{}10^9$
elements is really not any kind of limit at all.  For any reasonable
program on any reasonable 32 bit machine one cannot even store that
much memory.

On a 64 bit machine this of course becomes silly.  By limiting the
maximum number of elements in an {}\ttt{std::vector<char>} (not to
mention arrays with larger data types) to be
{}\ttt{std::numeric\_limits<ptrdiff\_t)>::max()} on 64 bit machine
would mean that one would take up {}\ttt{18446744073709551615 / 2} =
{}\ttt{9.2e+9} GB of memory to allocate a single array!  We will
likely never in human history ever see a machine with $2\times{}10^9$
GB of memory in a single address space.

In summary, limiting the maximum number of elements in an
{}\ttt{std::vector} (and therefore Teuchos {}\ttt{Array}) to be half
of {}\ttt{size\_t} using the {}\ttt{long signed int} type
{}\ttt{ptrdiff\_t} for {}\ttt{size\_type} is not any kind of limit at
all in any realistic 32 bit program and especially not a 64 bit
program.

Therefore, the Teuchos array memory management classes all use by
default {}\ttt{ptrdiff\_t} as {}\ttt{size\_type} because of the
inherent debugging and other advantages of using a signed integral
type instead of an unsigned type and with no real advantages at all
for using {}\ttt{size\_t} over {}\ttt{ptrdiff\_t}.


%
{}\section{Raw performance data}
\label{apdx:raw-perf-data}
%

%
{}\subsection{Raw RCP performance data}
\label{apdx:raw-rcp-perf-data}
%

\begin{listing}: Raw {}\ttt{RCP} timing data on GCC 4.1.2  \\
\label{listing:RCP-GCC-Timings}
{\scriptsize\begin{verbatim}
0. RCP_createDestroyOverhead_UnitTest ... 
 
 Messuring the overhead of creating and destorying objects of different sizes
 using raw C++ pointers, shared_ptr, and using RCP.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.001 = 5e+06
 
   obj size   num loops  raw             shared_ptr      RCP             shared_ptr/raw  RCP/raw       
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
           1    3465735    7.407462e-08    1.215497e-07    1.398462e-07    1.640909e+00    1.887910e+00
           4    2011797    7.450006e-08    1.239370e-07    1.413890e-07    1.663582e+00    1.897838e+00
          16     885379    8.031363e-08    1.284388e-07    1.467530e-07    1.599215e+00    1.827249e+00
          64     326124    1.130889e-07    1.589150e-07    1.792815e-07    1.405222e+00    1.585315e+00
         256     108380    2.369718e-07    2.786677e-07    2.359753e-07    1.175953e+00    9.957949e-01
        1024      33849    5.029395e-07    5.578008e-07    5.812875e-07    1.109081e+00    1.155780e+00
        4096      10153    1.552546e-06    1.608293e-06    1.630947e-06    1.035907e+00    1.050498e+00
       16384       2961    5.759541e-06    5.821344e-06    5.840932e-06    1.010731e+00    1.014132e+00
       65536        846    2.503073e-05    2.513239e-05    2.515721e-05    1.004061e+00    1.005053e+00

1. RCP_dereferenceOverhead_UnitTest ... 
 
 Messuring the overhead of dereferencing RCP, shared_ptr and a raw pointer.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64    3261240    7.765547e-10    1.037752e-09    6.958626e-10    8.960896e-01    6.705479e-01
         256    1083803    7.295887e-10    8.572714e-10    7.611003e-10    1.043191e+00    8.878173e-01
        1024     338498    7.117812e-10    8.238572e-10    7.125746e-10    1.001115e+00    8.649249e-01
        4096     101538    7.187575e-10    1.155846e-09    1.192136e-09    1.658607e+00    1.031397e+00
       16384      29614    8.350258e-10    1.155404e-09    1.190919e-09    1.426207e+00    1.030739e+00
       65536       8461    8.362559e-10    1.155293e-09    1.199785e-09    1.434711e+00    1.038512e+00

2. RCP_memberAccessOverhead_UnitTest ... 
 
 Messuring the overhead of dereferencing RCP, shared_ptr and a raw pointer.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64    3261240    7.794917e-10    1.037733e-09    6.954218e-10    8.921479e-01    6.701355e-01
         256    1083803    7.295743e-10    8.639896e-10    7.611075e-10    1.043221e+00    8.809221e-01
        1024     338498    7.115158e-10    8.325987e-10    7.242242e-10    1.017861e+00    8.698358e-01
        4096     101538    7.252928e-10    1.156058e-09    1.192244e-09    1.643811e+00    1.031302e+00
       16384      29614    8.369755e-10    1.154404e-09    1.190985e-09    1.422963e+00    1.031688e+00
       65536       8461    8.364092e-10    1.154440e-09    1.199527e-09    1.434139e+00    1.039056e+00

3. RCP_referenceCountManipulationOverhead_UnitTest ... 
 
 Messuring the overhead of incrementing and deincrementing the reference count
 comparing RCP to raw pointer and boost::shared_ptr.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64      65224    1.554978e-09    4.145809e-09    6.009579e-09    3.864736e+00    1.449555e+00
         256      21676    7.138151e-10    4.221439e-09    5.832524e-09    8.170916e+00    1.381644e+00
        1024       6769    6.919181e-10    4.224365e-09    5.589158e-09    8.077773e+00    1.323076e+00
        4096       2030    6.863599e-10    4.226880e-09    6.094856e-09    8.879972e+00    1.441928e+00
       16384        592    6.854083e-10    4.224623e-09    6.234040e-09    9.095367e+00    1.475644e+00
       65536        169    6.848397e-10    4.228219e-09    6.216828e-09    9.077785e+00    1.470318e+00
\end{verbatim}}
\end{listing}

\pagebreak

\begin{listing}: Raw {}\ttt{RCP} timing data on Intel ICC 10.1  \\
\label{listing:RCP-ICC-Timings}
{\scriptsize\begin{verbatim}
0. RCP_createDestroyOverhead_UnitTest ... 
 
 Messuring the overhead of creating and destorying objects of different sizes
 using raw C++ pointers, shared_ptr, and using RCP.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.001 = 5e+06
 
   obj size   num loops  raw             shared_ptr      RCP             shared_ptr/raw  RCP/raw       
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
           1    3465735    1.157942e-07    1.941906e-07    2.041379e-07    1.677032e+00    1.762938e+00
           4    2011797    1.194609e-07    1.984465e-07    2.031149e-07    1.661184e+00    1.700263e+00
          16     885379    1.200751e-07    2.013262e-07    2.105720e-07    1.676669e+00    1.753668e+00
          64     326124    1.390085e-07    2.170309e-07    2.277876e-07    1.561279e+00    1.638660e+00
         256     108380    3.299409e-07    4.036446e-07    4.223381e-07    1.223384e+00    1.280041e+00
        1024      33849    6.118349e-07    7.350291e-07    7.567432e-07    1.201352e+00    1.236842e+00
        4096      10153    1.724909e-06    1.833645e-06    1.851472e-06    1.063039e+00    1.073374e+00
       16384       2961    6.138467e-06    6.252955e-06    6.269504e-06    1.018651e+00    1.021347e+00
       65536        846    2.482151e-05    2.497754e-05    2.505437e-05    1.006286e+00    1.009381e+00

1. RCP_dereferenceOverhead_UnitTest ... 
 
 Messuring the overhead of dereferencing RCP, shared_ptr and a raw pointer.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64    3261240    6.909757e-10    3.551453e-09    1.027399e-09    1.486881e+00    2.892897e-01
         256    1083803    7.113406e-10    3.384829e-09    7.973226e-10    1.120873e+00    2.355577e-01
        1024     338498    6.914017e-10    2.841675e-09    7.658747e-10    1.107713e+00    2.695152e-01
        4096     101538    6.864300e-10    3.701316e-09    9.940787e-10    1.448187e+00    2.685744e-01
       16384      29614    7.319499e-10    3.367334e-09    9.934011e-10    1.357198e+00    2.950112e-01
       65536       8461    7.317167e-10    2.931704e-09    9.912099e-10    1.354636e+00    3.381003e-01

2. RCP_memberAccessOverhead_UnitTest ... 
 
 Messuring the overhead of dereferencing RCP, shared_ptr and a raw pointer.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64    3261240    6.899839e-10    6.952541e-10    8.252660e-10    1.196066e+00    1.186999e+00
         256    1083803    7.112650e-10    7.159684e-10    7.949727e-10    1.117688e+00    1.110346e+00
        1024     338498    6.911940e-10    6.924634e-10    7.741691e-10    1.120046e+00    1.117993e+00
        4096     101538    6.863435e-10    7.000054e-10    9.928501e-10    1.446579e+00    1.418346e+00
       16384      29614    7.326919e-10    8.507246e-10    9.953219e-10    1.358445e+00    1.169970e+00
       65536       8461    7.315725e-10    8.489935e-10    9.923713e-10    1.356491e+00    1.168880e+00

3. RCP_referenceCountManipulationOverhead_UnitTest ... 
 
 Messuring the overhead of incrementing and deincrementing the reference count
 comparing RCP to raw pointer and boost::shared_ptr.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64      65224    1.032260e-09    5.619576e-09    8.805472e-09    8.530285e+00    1.566928e+00
         256      21676    7.246278e-10    5.881181e-09    8.692109e-09    1.199527e+01    1.477953e+00
        1024       6769    7.678041e-10    6.050677e-09    8.797574e-09    1.145810e+01    1.453982e+00
        4096       2030    7.621277e-10    5.988180e-09    8.991230e-09    1.179754e+01    1.501496e+00
       16384        592    8.004678e-10    6.102691e-09    8.966497e-09    1.120157e+01    1.469269e+00
       65536        169    7.999578e-10    6.108933e-09    8.973161e-09    1.121704e+01    1.468859e+00
\end{verbatim}}
\end{listing}

\pagebreak

{}\begin{listing}: Raw {}\ttt{RCP} timing data on MSVC++ 2009
\label{listing:RCP-MSVC-Timings}
{\scriptsize\begin{verbatim}
0. RCP_createDestroyOverhead_UnitTest ... 
 
 Messuring the overhead of creating and destorying objects of different sizes
 using raw C++ pointers, shared_ptr, and using RCP.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+003/0.001 = 5e+006
 
   obj size   num loops  raw             shared_ptr      RCP             shared_ptr/raw  RCP/raw       
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
           1    3465735   2.628591e-007   3.641363e-007   4.117453e-007   1.385291e+000   1.566411e+000
           4    2011797   2.390897e-007   3.718069e-007   4.130635e-007   1.555094e+000   1.727651e+000
          16     885379   2.484812e-007   3.885342e-007   4.303242e-007   1.563636e+000   1.731818e+000
          64     326124   2.882339e-007   4.262182e-007   4.660804e-007   1.478723e+000   1.617021e+000
         256     108380   4.336593e-007   5.628345e-007   5.997416e-007   1.297872e+000   1.382979e+000
        1024      33849   9.749180e-007   1.093090e-006   1.122633e-006   1.121212e+000   1.151515e+000
        4096      10153   3.250271e-006   3.250271e-006   3.348764e-006   1.000000e+000   1.030303e+000
       16384       2961   1.182033e-005   1.350895e-005   1.215805e-005   1.142857e+000   1.028571e+000
       65536        846   4.609929e-005   4.609929e-005   4.609929e-005   1.000000e+000   1.000000e+000

1. RCP_dereferenceOverhead_UnitTest ... 
 
 Messuring the overhead of dereferencing RCP, shared_ptr and a raw pointer.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64    3261240   1.034882e-009   1.034882e-009   6.995039e-010   6.759259e-001   6.759259e-001
         256    1083803   1.052428e-009   1.052428e-009   7.136329e-010   6.780822e-001   6.780822e-001
        1024     338498   1.035711e-009   1.038596e-009   6.952820e-010   6.713092e-001   6.694444e-001
        4096     101538   1.021881e-009   1.043521e-009   1.012263e-009   9.905882e-001   9.700461e-001
       16384      29614   1.088221e-009   1.141807e-009   1.020207e-009   9.375000e-001   8.935018e-001
       65536       8461   1.082056e-009   1.141569e-009   1.011722e-009   9.350000e-001   8.862559e-001

2. RCP_memberAccessOverhead_UnitTest ... 
 
 Messuring the overhead of dereferencing RCP, shared_ptr and a raw pointer.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64    3261240   1.039674e-009   1.044465e-009   1.015718e-009   9.769585e-001   9.724771e-001
         256    1083803   1.045220e-009   1.048824e-009   7.136329e-010   6.827586e-001   6.804124e-001
        1024     338498   1.032826e-009   1.038596e-009   6.923970e-010   6.703911e-001   6.666667e-001
        4096     101538   1.029094e-009   1.053139e-009   1.009859e-009   9.813084e-001   9.589041e-001
       16384      29614   1.077915e-009   1.135624e-009   1.007841e-009   9.349904e-001   8.874773e-001
       65536       8461   1.080252e-009   1.137962e-009   1.018936e-009   9.432387e-001   8.954041e-001

3. RCP_referenceCountManipulationOverhead_UnitTest ... 
 
 Messuring the overhead of incrementing and deincrementing the reference count
 comparing RCP to raw pointer and boost::shared_ptr.
 
   array dim  num loops  raw             shared_ptr      RCP             RCP/raw         RCP/shared_ptr
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
          64      65224   7.186772e-010   5.270299e-009   1.413398e-008   1.966667e+001   2.681818e+000
         256      21676   3.604217e-010   4.144849e-009   1.261476e-008   3.500000e+001   3.043478e+000
        1024       6769   1.442698e-010   4.183825e-009   1.269575e-008   8.800000e+001   3.034483e+000
        4096       2030   2.405326e-010   4.089055e-009   1.274823e-008   5.300000e+001   3.117647e+000
       16384        592   3.092998e-010   4.227097e-009   1.278439e-008   4.133333e+001   3.024390e+000
       65536        169   2.708661e-010   4.153280e-009   1.291128e-008   4.766667e+001   3.108696e+000
\end{verbatim}}
\end{listing}

\pagebreak

%
{}\subsection{Raw Array performance data}
\label{apdx:raw-array-perf-data}
%

\begin{listing}: Raw Array timing data on GCC 4.1.2  \\
\label{listing:Array-GCC-Timings}
% From ./results/UnitTimings/GCC4/results2/Teuchos_Array_PeformanceTest.out
{\scriptsize\begin{verbatim}
0. Array_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the Array braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         vector          Array           vector/raw      Array/raw     
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
         100    2307560    4.244007e-10    4.244137e-10    4.244440e-10    1.000031e+00    1.000102e+00
         400     749245    3.631856e-10    3.629053e-10    3.629787e-10    9.992283e-01    9.994304e-01
        1600     230574    3.475457e-10    3.475999e-10    3.476270e-10    1.000156e+00    1.000234e+00
        6400      68470    5.450882e-10    5.452091e-10    5.367154e-10    1.000222e+00    9.846397e-01

1. Array_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the Array iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         vector          Array           vector/raw      Array/raw     
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
         100    2307560    4.620638e-10    4.725251e-10    4.757363e-10    1.022640e+00    1.029590e+00
         400     749245    3.722247e-10    3.979673e-10    3.989416e-10    1.069159e+00    1.071776e+00
        1600     230574    3.498009e-10    3.796775e-10    3.797046e-10    1.085410e+00    1.085488e+00
        6400      68470    5.465578e-10    5.450813e-10    5.454967e-10    9.972986e-01    9.980585e-01

2. ArrayRCP_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560    4.620552e-10    4.449722e-10    9.630283e-01
         400     749245    3.722748e-10    3.680972e-10    9.887783e-01
        1600     230574    3.498687e-10    3.486869e-10    9.966221e-01
        6400      68470    5.456381e-10    6.259333e-10    1.147158e+00

3. ArrayRCP_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560    4.414750e-10    4.451065e-10    1.008226e+00
         400     749245    3.670995e-10    3.679571e-10    1.002336e+00
        1600     230574    3.485405e-10    3.488902e-10    1.001003e+00
        6400      68470    5.448531e-10    5.452068e-10    1.000649e+00

4. ArrayRCP_selfIteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP as a self iterataor relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560    4.587616e-10    8.386087e-10    1.827984e+00
         400     749245    3.713705e-10    7.234583e-10    1.948077e+00
        1600     230574    3.497250e-10    6.945384e-10    1.985956e+00
        6400      68470    5.297461e-10    6.887003e-10    1.300057e+00

5. ArrayView_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayView braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayView       ArrayView/raw 
   ---------  ---------  --------------  --------------  --------------
         100    2307560    4.621072e-10    4.244570e-10    9.185250e-01
         400     749245    3.722814e-10    3.627618e-10    9.744291e-01
        1600     230574    3.499283e-10    3.474156e-10    9.928192e-01
        6400      68470    5.455994e-10    5.369824e-10    9.842065e-01

6. ArrayView_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayView iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayView       ArrayView/raw 
   ---------  ---------  --------------  --------------  --------------
         100    2307560    4.588396e-10    4.552254e-10    9.921232e-01
         400     749245    3.716074e-10    3.705230e-10    9.970818e-01
        1600     230574    3.495732e-10    3.493184e-10    9.992711e-01
        6400      68470    5.299196e-10    5.453255e-10    1.029072e+00
\end{verbatim}}
\end{listing}

\pagebreak

\begin{listing}: Raw Array timing data on ICC 10.1  \\
\label{listing:Array-ICC-Timings}
% From ./results/UnitTimings/ICC/results2/Teuchos_Array_PerformanceTest.out
{\scriptsize\begin{verbatim}
0. Array_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the Array braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         vector          Array           vector/raw      Array/raw     
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
         100    2307560    9.041672e-10    1.092201e-09    1.092210e-09    1.207964e+00    1.207973e+00
         400     749245    8.995689e-10    1.207742e-09    1.121359e-09    1.342579e+00    1.246551e+00
        1600     230574    8.816611e-10    1.154434e-09    1.172907e-09    1.309385e+00    1.330338e+00
        6400      68470    9.466212e-10    1.240822e-09    1.252366e-09    1.310790e+00    1.322986e+00

1. Array_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the Array iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         vector          Array           vector/raw      Array/raw     
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
         100    2307560    6.093189e-10    6.334830e-10    5.921796e-10    1.039657e+00    9.718714e-01
         400     749245    6.862308e-10    6.941621e-10    6.795441e-10    1.011558e+00    9.902559e-01
        1600     230574    6.543805e-10    6.653910e-10    6.629027e-10    1.016826e+00    1.013023e+00
        6400      68470    7.261278e-10    7.312829e-10    7.259452e-10    1.007099e+00    9.997486e-01

2. ArrayRCP_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560    7.565177e-10    1.091967e-09    1.443413e+00
         400     749245    7.061542e-10    1.116170e-09    1.580633e+00
        1600     230574    6.943432e-10    1.171088e-09    1.686613e+00
        6400      68470    6.937756e-10    1.305848e-09    1.882234e+00

3. ArrayRCP_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560    3.658930e-10    3.765406e-10    1.029100e+00
         400     749245    3.789682e-10    3.671329e-10    9.687698e-01
        1600     230574    3.575045e-10    3.575994e-10    1.000265e+00
        6400      68470    5.485934e-10    5.484793e-10    9.997920e-01

4. ArrayRCP_selfIteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP as a self iterataor relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560    3.729480e-10    1.878863e-09    5.037869e+00
         400     749245    3.919746e-10    1.754433e-09    4.475884e+00
        1600     230574    3.606841e-10    1.922398e-09    5.329866e+00
        6400      68470    5.474158e-10    2.262937e-09    4.133853e+00

5. ArrayView_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayView braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayView       ArrayView/raw 
   ---------  ---------  --------------  --------------  --------------
         100    2307560    7.635771e-10    1.092032e-09    1.430153e+00
         400     749245    7.155570e-10    1.121049e-09    1.566680e+00
        1600     230574    7.017405e-10    1.160129e-09    1.653217e+00
        6400      68470    7.770807e-10    1.261093e-09    1.622860e+00

6. ArrayView_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayView iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+03/0.0001 = 5e+07
 
   array dim  num loops  raw ptr         ArrayView       ArrayView/raw 
   ---------  ---------  --------------  --------------  --------------
         100    2307560    3.629461e-10    3.765493e-10    1.037480e+00
         400     749245    3.772431e-10    3.936763e-10    1.043561e+00
        1600     230574    3.589737e-10    3.622779e-10    1.009205e+00
        6400      68470    5.477992e-10    5.479590e-10    1.000292e+00
\end{verbatim}}
\end{listing}

\pagebreak

\begin{listing}: Raw Array timing data on MSVC++ 2008  \\
\label{listing:Array-MSVC-Timings}
% From ./results/UnitTimings/MSVC/results1/Teuchos_Array_PerformanceTest.out
{\scriptsize\begin{verbatim}
0. Array_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the Array braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+003/0.0001 = 5e+007
 
   array dim  num loops  raw ptr         vector          Array           vector/raw      Array/raw     
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
         100    2307560   7.757111e-010   6.110350e-010   5.243634e-010   7.877095e-001   6.759777e-001
         400     749245   3.803829e-010   3.837196e-010   4.037398e-010   1.008772e+000   1.061404e+000
        1600     230574   3.523814e-010   3.605133e-010   3.550921e-010   1.023077e+000   1.007692e+000
        6400      68470   5.203009e-010   5.157368e-010   5.225829e-010   9.912281e-001   1.004386e+000

1. Array_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the Array iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+003/0.0001 = 5e+007
 
   array dim  num loops  raw ptr         vector          Array           vector/raw      Array/raw     
   ---------  ---------  --------------  --------------  --------------  --------------  --------------
         100    2307560   5.416977e-010   5.373641e-010   5.546985e-010   9.920000e-001   1.024000e+000
         400     749245   3.903930e-010   3.837196e-010   3.903930e-010   9.829060e-001   1.000000e+000
        1600     230574   3.550921e-010   3.794877e-010   3.659346e-010   1.068702e+000   1.030534e+000
        6400      68470   5.294289e-010   5.203009e-010   5.225829e-010   9.827586e-001   9.870690e-001

2. ArrayRCP_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+003/0.0001 = 5e+007
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560   5.330306e-010   8.753835e-010   1.642276e+000
         400     749245   4.938305e-010   8.642033e-010   1.750000e+000
        1600     230574   3.605133e-010   8.375836e-010   2.323308e+000
        6400      68470   5.317110e-010   8.169636e-010   1.536481e+000

3. ArrayRCP_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+003/0.0001 = 5e+007
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560   5.460313e-010   5.460313e-010   1.000000e+000
         400     749245   4.170865e-010   4.037398e-010   9.680000e-001
        1600     230574   3.578027e-010   3.578027e-010   1.000000e+000
        6400      68470   5.203009e-010   5.339930e-010   1.026316e+000

4. ArrayRCP_selfIteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayRCP as a self iterataor relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+003/0.0001 = 5e+007
 
   array dim  num loops  raw ptr         ArrayRCP        ArrayRCP/raw  
   ---------  ---------  --------------  --------------  --------------
         100    2307560   5.460313e-010   2.452807e-009   4.492063e+000
         400     749245   4.904938e-010   2.375725e-009   4.843537e+000
        1600     230574   3.578027e-010   2.355534e-009   6.583333e+000
        6400      68470   5.362750e-010   2.471429e-009   4.608511e+000

5. ArrayView_braketOperatorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayView braket operator relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+003/0.0001 = 5e+007
 
   array dim  num loops  raw ptr         ArrayView       ArrayView/raw 
   ---------  ---------  --------------  --------------  --------------
         100    2307560   5.330306e-010   5.286970e-010   9.918699e-001
         400     749245   3.803829e-010   4.004031e-010   1.052632e+000
        1600     230574   3.550921e-010   3.605133e-010   1.015267e+000
        6400      68470   5.111728e-010   5.180188e-010   1.013393e+000

6. ArrayView_iteratorOverhead_UnitTest ... 
 
 Measuring the overhead of the ArrayView iterators relative to raw pointers.
 
 Number of loops = relCpuSpeed/relTestCost = 5e+003/0.0001 = 5e+007
 
   array dim  num loops  raw ptr         ArrayView       ArrayView/raw 
   ---------  ---------  --------------  --------------  --------------
         100    2307560   5.373641e-010   5.460313e-010   1.016129e+000
         400     749245   3.970664e-010   3.970664e-010   1.000000e+000
        1600     230574   3.550921e-010   3.523814e-010   9.923664e-001
        6400      68470   5.294289e-010   5.408391e-010   1.021552e+000
\end{verbatim}}
\end{listing}

\begin{SANDdistribution}[NM]

  % Housekeeping copies necessary for every unclassified report:
  % \SANDdistCRADA	% If this report is about CRADA work
  % \SANDdistPatent	% If this report has a Patent Caution or Patent Interest
  % \SANDdistLDRD	% If this report is about LDRD work

  % Some external Addresses
  \SANDdistExternal{1}{An Address\\ 99 $99^{th}$ street NW\\City, State}
  \SANDdistExternal{3}{Some Address\\ and street\\City, State}
  \SANDdistExternal{12}{Another Address\\ On a street\\City, State\\U.S.A.}
  \bigskip


  % The following MUST BE between the external and internal distributions!
  % \SANDdistClassified % If this report is classified


  % Internal Addresses
  \SANDdistInternal{1}{1319}{Rolf Riesen}{1423}
  \SANDdistInternal{1}{1110}{Another One}{01400}

  % Example of a mail channel use (instead of a mail stop)
  \SANDdistInternalM{1}{M9999}{Someone}{01234}

\end{SANDdistribution}

\end{document}
